% This file was created with JabRef 2.10.
% Encoding: UTF8


@Misc{totesrandomkeybyalex126,
  Title                    = {{ITR: COLLABORATIVE RESEARCH- (ECS+ASE)- (dmc/int) Live Wires: Always On Adaptive and Editable Simulations With Live Feed}},

  Author                   = {(pi, Maria Hybinette and (co-pi, Eileen T. Kraemer and Co-pi, Tucker Balch (collaborative},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We will develop new algorithms that enable live, collaborative, dynamic and scalable simulations. We envision large-scale, complex simulation systems connected to real-world live feed data that can be used by lay persons via the Internet, and viewed and edited simultaneously by collaborating scientists. Real-time live-feed data streams will be provided by world-wide-web sources and other Internet sources. In addition we will apply machine learning techniques to improve predictive performance of the simulations Thus we propose innovative approaches to the integration of data-driven applications for use in prediction, risk-assessment and decision making (the dmc technical focus area). Our work is focused on both the economic prosperity and vibrant civil society (ECS) and the advances in science and engineering national priority areas (ASE). We will demonstrate the generality of our research by applying it to two quite different applications that we will implement: simulation of economic markets and simulation of automobile traffic in the Atlanta, Georgia area. In both applications the world wide web provides real time data on the progress of the corresponding real systems. In particular, for automobile traffic, we will use real-time data from Georgia’s Department of Transportation (GDOT) traffic website, as well as data from IQStat, Inc as input to our simulator. For the purpose of providing real-time marketing research on car radio use, IQStat has equipped hundreds of cars in the Atlanta area with GPS receivers, radio monitors, and data transmitters to relay},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper seems mostly like a recipe for a future research program. approved under uncertainty. They will use ML, 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.420.9920}
}

@Misc{2003,
  Title                    = {{Online Mining of Changes from Data Streams:}},

  Author                   = {And, Research Problems and Dong, Guozhu and Han, Jiawei and Lakshmanan, Laks V. S. and Pei, Jian and Wang, Haixun and Yu, Philip S.},
  Year                     = {2003},

  __markedentry            = {[Alexander:]},
  Abstract                 = {As data streams are gaining prominence in a growing number of emerging applications, advanced analysis and mining of data streams is becoming increasingly important. While there are some recent studies on mining data streams, we would like to ask the following essential question: What are the distinct features of mining data streams compared to mining other kinds of data? In this paper, we take the following position: online mining of the changes in data streams is one of the core issues. We propose some interesting research problems and highlight the inherent challenges. Moreover, we sketch some preliminary results.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Paper investigates what might be interesting research problems regarding data streams, sketches preliminary results. Nothing new, apparantly no ML. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.670}
}

@Misc{A,
  Title                    = {{Context-Aware Adaptive Data Stream Mining}},

  Author                   = {A, Pari Delir Haghighi and A, Arkady Zaslavsky and A, Shonali Krishnaswamy and Medhat, Mohamed and B, Gaber and C, Seng Loke},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In resource-constrained devices, adaptation of data stream processing to variations of data rates and availability of resources is crucial for consistency and continuity of running applications. However, to enhance and maximize the benefits of adaptation, there is a need to go beyond mere computational and device capabilities to encompass the full spectrum of contextawareness. This paper presents a general approach for context-aware adaptive mining of data streams that aims to dynamically and autonomously adjust data stream mining parameters according to changes in context and situations. We perform intelligent and real-time analysis of data streams generated from sensors that is under-pinned using context-aware adaptation. A prototype of the proposed architecture is implemented and evaluated in the paper through a realworld scenario in the area of healthcare monitoring.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Propses that it is important to have data stream processing sensitive to data rates and resource availability. Presents data mining that adjusts its parameters according to changes in context and situation. Evaluated a prototype in healthcare. Approved. 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.205.2825}
}

@Misc{Aarthi,
  Title                    = {{AN EXPLORATION OF GRAPH BASED APPROACHES IN DATA STREAM MINING}},

  Author                   = {Aarthi, D. and Sneghapriya, R. and Pavithra, P. and Poornima, N.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Progressive advancements in the data stream mining have paved way for many algorithms to solve the problem of concept drift, a serious problem due to the wavering nature of the real time concepts. Concepts tend to change with time therefore concept drift is unavoidable in data stream mining but efficient algorithms can be designed to detect the concept drift and solve the problem. This paper presents a comparison based frame work of five algorithms that are designed to elucidate the drift. The five algorithms presented are OLIN (online information network), VFDT (very fast decision tree), CVFDT (concept adapting very fast decision tree), UFFT (ultra fast forest trees), and CBDT (concept based decision tree). All the above said frame works are based on sliding window algorithm and decision trees. Each time when the concept changes both the old and new set of concepts or data streams are compared to check their rigidity, the more rigid one continues to exist and the other is eradiated. To determine this disparity, decision trees are used as models. Construction of the trees and ability to grow the tree is the distinguishing factor of all the algorithms. The aim of the paper is to effectively discuss the algorithms and suggest the best out of the list, comparing their efficiencies and performances depending on the construction of the tree, its size and various other factors.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper presents a comparison based frame work of five algorithms that are designed to elucidate the drift Appears to be just an evaluation paper of 4 mining algorithms, graph based. No novel contribution Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.414.579}
}

@Misc{Abakumov,
  Title                    = {{JSQ: Distributed querying of JSON stream data}},

  Author                   = {Abakumov, C Konstantin},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Nowadays, the necessity for online processing of data is becoming more evident. The most convenient way to perform analytical online processing is declaring continuous queries using special query languages. The goal of this work is to propose the system for distributed continuous query processing on clusters of commodity computers. We studied existing solutions and requirements for such systems and proposed JSQ system desing.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {The goal of this work is to propose the system for distributed continuous query processing on clusters of commodity computers. Data processing in clusters, no ML. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.394.3932}
}

@Misc{Abbass2004,
  Title                    = {{Online Adaptation in Learning Classifier Systems: Stream Data Mining}},

  Author                   = {Abbass, Hussein A. and Bacardit, Jaume and Butz, Martin V. and Llor\`{a}, Xavier},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In data mining, concept drift refers to the phenomenon that the underlying model (or concept) is changing over time. The aim of this paper is twofold. First, we propose a fundamental characterization and quantification of different types of concept drift. The proposed theory enables a rigorous investigation of learning system performance on streamed data. In particular, we investigate the impact of different amounts and types of concept drift on evolutionary classification systems focusing on the learning classifier system approach. We compare performance of one Pittsburgh-type system, GAssist, which learns in batch mode using windowing techniques, with a Michigan-type system, XCS, which is a natural online learner. The results show that both systems are able to handle the various concept drifts well. Behavioral differences are discussed revealing task dependencies, representation dependencies as well as dynamics dependencies. Discussions and conclusions outline the path towards more detailed measures for problem dynamics in the data mining realm.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a fundamental characterization and quantification of different types of concept drift. Investigate the impact of different amounts and types of concept drift on evolutionary classification systems focusing on the learning classifier system approach. Analyses the problem of concept drift and tests and evaluates some algorithms according to their classifications. This concept drift classification seems to be a novel contribution. Approved 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.9243}
}

@InProceedings{Abdulsalam2007,
  Title                    = {{Streaming Random Forests}},
  Author                   = {Abdulsalam, Hanady and Skillicorn, David B. and Martin, Patrick},
  Booktitle                = {11th International Database Engineering and Applications Symposium (IDEAS 2007)},
  Year                     = {2007},
  Month                    = sep,
  Note                     = {cited By (since 1996)9},
  Pages                    = {225--232},
  Publisher                = {IEEE},

  Abstract                 = {Many recent applications deal with data streams, conceptually endless sequences of data records, often arriving at high flow rates. Standard data-mining techniques typically assume that records can be accessed multiple times and so do not naturally extend to streaming data. Algorithms for mining streams must be able to extract all necessary information from records with only one, or perhaps a few, passes over the data. We present the streaming random forests algorithm, an online and incremental stream classification algorithm that extends Breiman's random forests algorithm. The streaming random forests algorithm grows multiple decision trees, and classifies unlabeled records based on the plurality of tree votes. We evaluate the classification accuracy of the streaming random forests algorithm on several datasets, and show that its accuracy is comparable to the standard random forest algorithm.},
  Affiliation              = {School of Computing, Queen's University, Kingston, ON K7L 3N6, Canada},
  Art_number               = {4318108},
  Author_keywords          = {Classification; Data mining; Data-stream classification; Decision trees; Random forests},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/IDEAS.2007.4318108},
  ISBN                     = {0-7695-2947-X},
  ISSN                     = {1098-8068},
  Journal                  = {Proceedings of the International Database Engineering and Applications Symposium, IDEAS},
  Keywords                 = {Approximation algorithms,Classification,Classification tree analysis,Clustering algorithms,Data flow computing,Data mining,Data-stream classification,Decision trees,Loans and mortgages,Predictive models,Random Forests.,Robustness,Testing,classification,data mining,data streams,decision trees,multiple decision trees,random forest streaming,stream classification},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Tested random forest algorithm on streaming data. Reports classification results to be comparable to normal standard forest classification. Very short, nothing about test data or informative about the results. Approved 1,2,3,4,6},
  Shorttitle               = {Database Engineering and Applications Symposium, 2},
  Source                   = {Scopus},
  Timestamp                = {2014.10.23},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4318108}
}

@Article{Aboalsamh2009,
  Title                    = {A novel incremental approach for stream data mining},
  Author                   = {Aboalsamh, H.A.},
  Journal                  = {AEJ - Alexandria Engineering Journal},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Number                   = {4},
  Pages                    = {419-426},
  Volume                   = {48},

  Abstract                 = {With the recent advances in data collection systems, different continuously generated data have been collected in a wide range of applications. According to that, stream data analysis is considered as a crucial component of strategic control over a broad variety of disciplines in business, science and engineering. Many examples could be considered as applications for stream data mining in areas such as stock markets, sensor networks, network traffics, and explicit time series. Stream data mining has recently received much interest from researches working in the field of data mining. Mining data streams is defined as extracting knowledge structures from continuous streams of information. Online analysis on data streams is needed where data values change frequently. With the increase of computational operations for mining data streams, finding efficient techniques is considered a challenging task. Unfortunately most of the existing data mining algorithms have been designed for stored data, and could not be considered on data streams. For on-line mining tasks, new techniques in areas such as classification, clustering, frequent itemsets mining, pattern matching, etc., should be presented. Also, suitable architectures should be proposed for handling new mining methods. In this paper, we propose a novel stream data mining technique based on the association mining approach, along with a suitable structure for generating continuous or transient rules. The proposed technique collects knowledge through dynamic windows, where computations are done in an incremental fashion. A hierarchical structure is designed for storing transient patterns. The experimental results show that the performance of the Incremental Approach for Stream Data Mining (IASDM) technique against the Closed Frequent Itemsets (CFI) -Stream technique, which is considered as one of the latest and accredited techniques in the area of stream data mining, is improving the process of stream data mining by almost 60%. Ã‚Â© Faculty of Engineering Alexandria University, Egypt.},
  Affiliation              = {Computer Sciences, King Saud Unversity, Saudi Arabia},
  Author_keywords          = {Association rule mining; Dynamic data mining; Frequent closed itemsets; Incremental data mining; Stream data mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we propose a novel stream data mining technique based on the association mining approach, along with a suitable structure for generating continuous or transient rules. The method collects knowledge through dynamic windows, where computations are done in an incremental fashion. Experimental results show better performance than accredited technque. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954296044&partnerID=40&md5=1345f3eec23ace3fbfc233f556ddc74c}
}

@Misc{Agarwal,
  Title                    = {{Kernel-based online machine learning and support vector reduction}},

  Author                   = {Agarwal, Sumeet and Saradhi, V. Vijaya},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Discarded, duplicate of Agarwal2008.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.218.2494}
}

@Article{Agarwal2008,
  Title                    = {Kernel-based online machine learning and support vector reduction },
  Author                   = {Sumeet Agarwal and V. Vijaya Saradhi and Harish Karnick},
  Journal                  = {Neurocomputing },
  Year                     = {2008},
  Note                     = {Progress in Modeling, Theory, and Application of Computational Intelligenc 15th European Symposium on Artificial Neural Networks 2007 15th European Symposium on Artificial Neural Networks 2007 },
  Number                   = {7Ã¢â‚¬â€œ9},
  Pages                    = {1230 - 1237},
  Volume                   = {71},

  Abstract                 = {We apply kernel-based machine learning methods to online learning situations, and look at the related requirement of reducing the complexity of the learnt classifier. Online methods are particularly useful in situations which involve streaming data, such as medical or financial applications. We show that the concept of span of support vectors can be used to build a classifier that performs reasonably well while satisfying given space and time constraints, thus making it potentially suitable for such online situations. The span-based heuristic is observed to be effective under stringent memory limits (that is when the number of support vectors a machine can hold is very small).},
  Doi                      = {http://dx.doi.org/10.1016/j.neucom.2007.11.023},
  ISSN                     = {0925-2312},
  Keywords                 = {Support vector machines},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They apply kernel-based machine learning methods to online learning situations, and look at the related requirement of reducing the complexity of the learnt classifier. The span-based heuristic is observed to be effective under stringent memory limits Approved, but limited innovation. Little details about experimentation and outcome 1,2,3,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0925231208000581}
}

@Article{Agarwal2008a,
  Title                    = {Kernel-based online machine learning and support vector reduction},
  Author                   = {Agarwal, S.a and Vijaya Saradhi, V.b and Karnick, H.b },
  Journal                  = {Neurocomputing},
  Year                     = {2008},
  Note                     = {cited By (since 1996)18},
  Number                   = {7-9},
  Pages                    = {1230-1237},
  Volume                   = {71},

  Abstract                 = {We apply kernel-based machine learning methods to online learning situations, and look at the related requirement of reducing the complexity of the learnt classifier. Online methods are particularly useful in situations which involve streaming data, such as medical or financial applications. We show that the concept of span of support vectors can be used to build a classifier that performs reasonably well while satisfying given space and time constraints, thus making it potentially suitable for such online situations. The span-based heuristic is observed to be effective under stringent memory limits (that is when the number of support vectors a machine can hold is very small). Ã‚Â© 2008 Elsevier B.V. All rights reserved.},
  Affiliation              = {Systems Biology Doctoral Training Centre, University of Oxford, United Kingdom; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur, Kanpur, India},
  Author_keywords          = {Budget algorithm; Classifier complexity reduction; Online SVMs; Span of support vectors; Support vector machines},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, duplicate of Agarwal2008.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-40649103591&partnerID=40&md5=0bcb7fea85303fb3d7a3ed70007355d5}
}

@Conference{Agarwal2007,
  Title                    = {Kernel-based online machine learning and support vector reduction},
  Author                   = {Agarwal, S.a and Vijaya Saradhi, V.b and Karnick, H.b },
  Year                     = {2007},
  Note                     = {cited By (since 1996)1},
  Pages                    = {343-348},

  Abstract                 = {We apply kernel-based machine learning methods to online learning situations, and look at the related requirement of reducing the complexity of the learnt classifier. Online methods are particularly useful in situations which involve streaming data, such as medical or financial applications. We show that the concept of span of support vectors can be used to build a classifier that performs reasonably well while satisfying given space and time constraints, thus making it potentially suitable for such online situations.},
  Affiliation              = {IBM India Research Lab, New Delhi, India; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur, Kanpur, India},
  Document_type            = {Conference Paper},
  Journal                  = {ESANN 2007 Proceedings - 15th European Symposium on Artificial Neural Networks},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, duplicate of Agarwal2008.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-55949108596&partnerID=40&md5=d53fce1028b854b325ae36debe19979c}
}

@Article{Aggarwal2012,
  Title                    = {A segment-based framework for modeling and mining data streams},
  Author                   = {Aggarwal, C.C.},
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2012},
  Note                     = {cited By (since 1996)5},
  Number                   = {1},
  Pages                    = {1-29},
  Volume                   = {30},

  Abstract                 = {Data Streams have become ubiquitous in recent years because of advances in hardware technology which have enabled automated recording of large amounts of data. The primary constraint in the effective mining of streams is the large volume of data which must be processed in real time. In many cases, it is desirable to store a summary of the data stream segments in order to perform data mining tasks. Since density estimation provides a comprehensive overview of the probabilistic data distribution of a stream segment, it is a natural choice for this purpose. A direct use of density distributions can however turn out to be an inefficient storage and processing mechanism in practice. In this paper, we introduce the concept of cluster histograms, which provides an efficient way to estimate and summarize the most important data distribution profiles over different stream segments. These profiles can be constructed in a supervised or unsupervised way depending upon the nature of the underlying application. The profiles can also be used for change detection, anomaly detection, segmental nearest neighbor search, or supervised stream segment classification. Furthermore, these techniques can also be used for modeling other kinds of data such as text and categorical data. The flexibility of the tasks which can be performed from the cluster histogram framework follows from its generality in storing the historical density profile of the data stream. As a result, this method provides a holistic framework for density-based mining of data streams. We discuss and test the application of the cluster histogram framework to a variety of interesting data mining applications. Ã‚Â© 2010 Springer-Verlag London Limited.},
  Affiliation              = {IBM T. J. Watson Research Center, 19 Skyline Drive, Hawthorne, NY 10532, United States},
  Author_keywords          = {Clustering; Stream mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Introduce the concept of cluster histograms, which provides an efficient way to estimate and summarize the most important data distribution profiles over different stream segments. Can be constructed in a supervised or unsupervised way depending upon the nature of the underlying application. As a result, this method provides a holistic framework for density based mining of data streams. Tested on different applications. Approved 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855559607&partnerID=40&md5=93fe4002dfeba6347dd9af59e3cddeae}
}

@Conference{Aggarwal2009,
  Title                    = {On segment-based stream modeling and its applications},
  Author                   = {Aggarwal, C.C.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {717-728},
  Volume                   = {2},

  Abstract                 = {The primary constraint in the effective mining of data streams is the large volume of data which must be processed in real time. In many cases, it is desirable to store a summary of the data stream segments in order to perform data mining tasks. Since density estimation provides a comprehensive overview of the probabilistic data distribution of a stream segment, it is a natural choice for this purpose. A direct use of density distributions can however turn out to be an inefficient storage and processing mechanism in practice. In this paper, we introduce the concept of cluster histograms, which provides an efficient way to estimate and summarize the most important data distribution profiles over different stream segments. These profiles can be constructed in a supervised or unsupervised way depending upon the nature of the underlying application. The profiles can also be used for change detection, anomaly detection, segmental nearest neighbor search, or supervised stream segment classification. The flexibility of the tasks which can be performed from the cluster histogram framework follows from its generality in storing the historical density profile of the data stream. As a result, this method provides a holistic framework for density based mining of data streams. We discuss and test the application of the cluster histogram framework to a variety of interesting data mining applications such as speaker recognition and intrusion detection.},
  Affiliation              = {IBM T. J. Watson Research Center, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Society for Industrial and Applied Mathematics - 9th SIAM International Conference on Data Mining 2009, Proceedings in Applied Mathematics},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, older version of Aggarwal2012.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-72749091067&partnerID=40&md5=ffdc9a42f745154a5216097cf47857e6}
}

@Article{Aggarwal2014a,
  Title                    = {{Evolutionary Network Analysis}},
  Author                   = {Aggarwal, Charu and Subbian, Karthik},
  Journal                  = {ACM Computing Surveys},
  Year                     = {2014},

  Month                    = jul,
  Number                   = {1},
  Pages                    = {1--36},
  Volume                   = {47},

  Abstract                 = {Discarded, duplicate of Aggarwal2014.},
  Doi                      = {10.1145/2601412},
  ISSN                     = {03600300},
  Keywords                 = {Network analysis,dynamic graphs,temporal graphs},
  Owner                    = {alex},
  Publisher                = {ACM},
  Qualityassured           = {qualityAssured},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2620784.2601412}
}

@Article{Aggarwal2014,
  Title                    = {Evolutionary network analysis: A survey},
  Author                   = {Aggarwal, C.a and Subbian, K.b c },
  Journal                  = {ACM Computing Surveys},
  Year                     = {2014},
  Note                     = {cited By (since 1996)1},
  Number                   = {1},
  Volume                   = {47},

  Abstract                 = {Evolutionary network analysis has found an increasing interest in the literature because of the importance of different kinds of dynamic social networks, email networks, biological networks, and social streams. When a network evolves, the results of data mining algorithms such as community detection need to be correspondingly updated. Furthermore, the specific kinds of changes to the structure of the network, such as the impact on community structure or the impact on network structural parameters, such as node degrees, also needs to be analyzed. Some dynamic networks have a much faster rate of edge arrival and are referred to as network streams or graph streams. The analysis of such networks is especially challenging, because it needs to be performed with an online approach, under the one-pass constraint of data streams. The incorporation of content can add further complexity to the evolution analysis process. This survey provides an overview of the vast literature on graph evolution analysis and the numerous applications that arise in different contexts. Ã‚Â© 2014 ACM.},
  Affiliation              = {IBM T. J. Watson Research Center, 1101 Kitchawan Rd, Yorktown Heights, NY, 10598, United States; University of Minnesota, United States; Computer Science Department, 200 Union St SE, Minneapolis, MN, 55455, United States},
  Art_number               = {a10},
  Author_keywords          = {Dynamic graphs; Network analysis; Temporal graphs},
  Document_type            = {Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, just a survey of literature on graph evolution analysis and applications that arise.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905869515&partnerID=40&md5=35f9f658fb510ca05139b7ffc7f7e7a5}
}

@Misc{Aggarwal,
  Title                    = {{A SURVEY OF CHANGE DIAGNOSIS ALGORITHMS IN EVOLVING DATA STREAMS}},

  Author                   = {Aggarwal, Cham C.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {An important problem in the field of data stream analysis is change detection and monitoring. In many cases, the data stream can show changes over time which can be used for understanding the nature of several applications. We discuss the concept of velocity density estimation, a technique used to understand, visualize and determine trends in the evolution of fast data streams. We show how to use velocity density estimation in order to create both temporal velocity proJiles and spatial velocity profiles at periodic instants in time. These profiles are then used in order to predict three kinds of data evolution. Methods are proposed to visualize the changing data trends in a single online scan of the data stream, and a computational requirement which is linear in the number of data points. In addition, batch processing techniques are proposed in order to identify combinations of dimensions which show the greatest amount of global evolution. We also discuss the problem of change detection in the context of graph data, and illustrate that it may often be useful to determine communities of evolution in graph environments. The presence of evolution in data streams may also change the underlying data to the extent that the underlying data mining models may need to be modified to account for the change in data distribution. We discuss a number of methods for micro-clustering which are used to study the effect of evolution on problems such as clustering and classification.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Discuss several methods, but with a focus on change detection. They propose methods for visualizing changing data trends and batch processing techniques to show combinations of dimensions which have the greatest change. Clearly using ML, not sure if novel. Appear to have a tight focus and some new contributions despite being called "survey". Approved 6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.352.1852}
}

@Misc{Aggarwalb,
  Title                    = {{On Segment-Based Stream Modeling and its Applications âˆ—}},

  Author                   = {Aggarwal, Charu C.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The primary constraint in the effective mining of data streams is the large volume of data which must be processed in real time. In many cases, it is desirable to store a summary of the data stream segments in order to perform data mining tasks. Since density estimation provides a comprehensive overview of the probabilistic data distribution of a stream segment, it is a natural choice for this purpose. A direct use of density distributions can however turn out to be an inefficient storage and processing mechanism in practice. In this paper, we introduce the concept of cluster histograms, which provides an efficient way to estimate and summarize the most important data distribution profiles over different stream segments. These profiles can be constructed in a supervised or unsupervised way depending upon the nature of the underlying application. The profiles can also be used for change detection, anomaly detection, segmental nearest neighbor search, or supervised stream segment classification. The flexibility of the tasks which can be performed from the cluster histogram framework follows from its generality in storing the historical density profile of the data stream. As a result, this method provides a holistic framework for density based mining of data streams. We discuss and test the application of the cluster histogram framework to a variety of interesting data mining applications such as speaker recognition and intrusion detection.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Duplicate of Aggarwal2012},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.217.1847}
}

@Misc{Aggarwala,
  Title                    = {{Under consideration for publication in Knowledge and Information Systems On Clustering Massive Text and Categorical Data Streams}},

  Author                   = {Aggarwal, Charu C. and Yu, Philip S.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In this paper, we will study the data stream clustering problem in the context of text and categorical data domains. While the clustering problem has been studied recently for numeric data streams, the problems of text and categorical data present different challenges because of the large and un-ordered nature of the corresponding attributes. Therefore, we will propose algorithms for text and categorical data stream clustering. We will propose a condensation based approach for stream clustering which summarizes the stream into a number of fine grained cluster droplets. These summarized droplets can be used in conjunction with a variety of user queries to construct the clusters for different input parameters. Thus, this provides an online analytical processing approach to stream clustering. We also study the problem of detecting noisy and outlier records in real time. We will test the approach for a number of real and synthetic data sets, and show the effectiveness of the method over the baseline OSKM algorithm for stream clustering.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They consider data stream clustering problem in the context of text and categorical data domains. Propose algorithms for text and categorical data clustering. Test it on datasets and show it is more effective than baseline OSKM algorithm for stream clustering. Approved. 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.305.3288}
}

@Article{Aggarwalc,
  Title                    = {{Online analysis of community evolution in data streams}},
  Author                   = {Aggarwal, Charu C. and Yu, Philip S.},
  Journal                  = {SDM, 2005. LARS BACKSTROM, DAN HUTTENLOCHER, JON KLEINBERG, AND XIANGYANG},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Information diffusion in social networks provide great opportunities for political and social change as well as societal education. Therefore understanding information diffusion in social networks is a critical research goal. This greater understanding can be achieved through data analysis, development of reliable models that can predict outcomes of social processes, and ultimately the creation of applications that can shape the outcome of these processes. In this tutorial, we aim to provide an overview of such recent research based on a wide variety of techniques such as optimization algorithms, data mining, data streams covering a large number of problems such as influence spread maximization, misinformation limitation and study of trends in online social networks.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {Overview paper. Covers a wide variety of techniques such as optimization algorithms, data mining, data streams covering a large number of problems Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.215.2391}
}

@InProceedings{Aggarwal2008,
  Title                    = {{LOCUST: An Online Analytical Processing Framework for High Dimensional Classification of Data Streams}},
  Author                   = {Aggarwal, Charu C. and Yu, Philip S.},
  Booktitle                = {2008 IEEE 24th International Conference on Data Engineering},
  Year                     = {2008},
  Month                    = apr,
  Pages                    = {426--435},
  Publisher                = {IEEE},

  Abstract                 = {In recent years, data streams have become ubiquitous because of advances in hardware and software technology. The ability to adapt conventional mining problems to data streams is a great challenge in a data stream environment. Many data streams are inherently high dimensional, which creates a special challenge for data mining algorithms. In this paper, we consider the problem of classification of high dimensional data streams. For the high dimensional case, even traditional classifiers do not work very well on fixed data sets. We discuss a number of insights for the intractability of the high dimensional case. We use these insights to propose a new classification method (LOCUST) which avoids many of these weaknesses. The key is to develop a subspace-based instance centered classification approach which can be implemented efficiently for a fast data stream. We propose a methodology to effectively process the data stream in an organized way, so that the intermediate data structures can be used to sample locally discriminative subspaces for the classification process. We show that LOCUST is able to work effectively in the high dimensional case, and is also flexible in terms of increased robustness with greater resource availability.},
  Doi                      = {10.1109/ICDE.2008.4497451},
  ISBN                     = {978-1-4244-1836-7},
  Keywords                 = {Automatic testing,Availability,Classification algorithms,Classification tree analysis,Computational modeling,Data mining,Decision trees,Hardware,Knowledge based systems,LOCUST,Robustness,conventional mining problem,data mining,data mining algorithm,data stream environment,intermediate data structure,online analytical processing framework,pattern classification,subspace-based instance centered classification ap},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we consider the problem of classification of high dimensional data streams. For the high dimensional case, even traditional classifiers do not work very well on fixed data sets. The key is to develop a subspace-based instance centered classification approach which can be implemented efficiently for a fast data stream. Proposes a methodology to process the stream in an effective way. Shown to be effective. Approved 1,2,6},
  Shorttitle               = {Data Engineering, 2008. ICDE 2008. IEEE 24th Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4497451}
}

@Misc{Aggarwal2008a,
  Title                    = {{LOCUST: An Online Analytical Processing Framework for High Dimensional Classification of Data Steams}},

  Author                   = {Aggarwal, Charu C. and Yu, Philip S.},
  Year                     = {2008},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, duplicate of Aggarwal2008.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.297.6086}
}

@Article{Aghabozorgi2014,
  Title                    = {An approachable analytical study on big educational data mining},
  Author                   = {Aghabozorgi, S.a and Mahroeian, H.b and Dutt, A.a and Wah, T.Y.a and Herawan, T.a c },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 5},
  Pages                    = {721-737},
  Volume                   = {8583 LNCS},

  Abstract                 = {The persistent growth of data in education continues. More institutes now store terabytes and even petabytes of educational data. Data complexity in education is increasing as people store both structured data in relational format and unstructured data such as Word or PDF files, images, videos and geo-spatial data. Indeed learning developers, universities, and other educational sectors confirm that tremendous amount of data captured is in unstructured or semi-structured format. Educators, students, instructors, tutors, research developers and people who deal with educational data are also challenged by the velocity of different data types, organizations as well as institutes that process streaming data such as click streams from web sites, need to update data in real time to serve the right advert or present the right offers to their customers. This analytical study is oriented to the challenges and analysis with big educational data involved with uncovering or extracting knowledge from large data sets by using different educational data mining approaches and techniques. Ã‚Â© 2014 Springer International Publishing.},
  Affiliation              = {Department of Information System, University of Malaya, 50603 Pantai Valley, Kuala Lumpur, Malaysia; University of Otago, New Zealand; AMCS Research Center, Yogyakarta, Indonesia},
  Author_keywords          = {Analytical Study; Big Data; Data Mining; Educational Data; Educational Data Mining},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This analytical study is oriented to the challenges and analysis with big educational data involved with uncovering or extracting knowledge from large data sets by using different educational data mining approaches and techniques. Interesting because it relates to the large amount of structured and unstructured data gathered at educational institutions. Approved 6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84904891731&partnerID=40&md5=d24c98310435ff762a3a2adbbe573160}
}

@Article{Agrawal2009,
  Title                    = {The reality of real-time business intelligence},
  Author                   = {Agrawal, D.},
  Journal                  = {Lecture Notes in Business Information Processing},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {75-88},
  Volume                   = {27 LNBIP},

  Abstract                 = {Real-time Business Intelligence has emerged as a new technology solution to provide timely data-driven analysis of enterprise wide data and information. Such type of data analysis is needed for both tactical as well as strategic decision making tasks within an enterprise. Unfortunately, there is no clarity about the critical technology components that distinguish a real-time business intelligence system from traditional data warehousing and business intelligence solutions. In this paper, we take an evolutionary approach to obtain a better understanding of the role of real-time business intelligence in the context of enterprise-wide information infrastructures. We then propose a reference architecture for building a real-time business intelligence system. By using this reference architecture we identify the key research and development challenges in the areas of data-stream analysis, complex event processing, and real-time data integration that must be overcome for making real-time business intelligence a reality. Ã‚Â© 2009 Springer Berlin Heidelberg.},
  Affiliation              = {University of California, Santa Barbara, CA 93106, United States},
  Author_keywords          = {Data-cube; Data-streams; Data-warehousing; Databases},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Propose a reference architecture for building a real-time business intelligence system. Usage of machine learning unclear. Approved 1},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70349549848&partnerID=40&md5=6ca52e1268e5de1481685215b8c9dafd}
}

@Conference{Agrawal2011,
  Title                    = {Information diffusion in social networks: Observing and affecting what society cares about},
  Author                   = {Agrawal, D. and Budak, C. and El Abbadi, A.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Pages                    = {2609},

  Abstract                 = {Information diffusion in social networks provide great opportunities for political and social change as well as societal education. Therefore understanding information diffusion in social networks is a critical research goal. This greater understanding can be achieved through data analysis, development of reliable models that can predict outcomes of social processes, and ultimately the creation of applications that can shape the outcome of these processes. In this tutorial, we aim to provide an overview of such recent research based on a wide variety of techniques such as optimization algorithms, data mining, data streams covering a large number of problems such as influence spread maximization, misinformation limitation and study of trends in online social networks. Ã‚Â© 2011 Authors.},
  Affiliation              = {Department of Computer Science, UCSB, Santa Barbara, CA 93106-5110, United States},
  Author_keywords          = {information cascades; misinformation; social networks; trends},
  Document_type            = {Conference Paper},
  Journal                  = {International Conference on Information and Knowledge Management, Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Just an overview of methods paper.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-83055161410&partnerID=40&md5=3b8e757d5fca8d1d2362285291c1901f}
}

@InProceedings{Agrawal2011a,
  Title                    = {{Information diffusion in social networks}},
  Author                   = {Agrawal, Divyakant and Budak, Ceren and {El Abbadi}, Amr},
  Booktitle                = {Proceedings of the 20th ACM international conference on Information and knowledge management - CIKM '11},
  Year                     = {2011},

  Address                  = {New York, New York, USA},
  Month                    = oct,
  Pages                    = {2609},
  Publisher                = {ACM Press},

  Abstract                 = {Information diffusion in social networks provide great opportunities for political and social change as well as societal education. Therefore understanding information diffusion in social networks is a critical research goal. This greater understanding can be achieved through data analysis, development of reliable models that can predict outcomes of social processes, and ultimately the creation of applications that can shape the outcome of these processes. In this tutorial, we aim to provide an overview of such recent research based on a wide variety of techniques such as optimization algorithms, data mining, data streams covering a large number of problems such as influence spread maximization, misinformation limitation and study of trends in online social networks.},
  Doi                      = {10.1145/2063576.2064036},
  ISBN                     = {9781450307178},
  Keywords                 = {information cascades,misinformation,social networks,trends},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Just an overview of methods paper. Duplicate of Agrawal2011a.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2063576.2064036}
}

@InProceedings{Agrawal2006,
  Title                    = {{Supporting self-adaptation in streaming data mining applications}},
  Author                   = {Agrawal, G.},
  Booktitle                = {Proceedings 20th IEEE International Parallel \& Distributed Processing Symposium},
  Year                     = {2006},
  Pages                    = {10 pp.},
  Publisher                = {IEEE},

  Abstract                 = {There are many application classes where the users are flexible with respect to the output quality. At the same time, there are other constraints, such as the need for real-time or interactive response, which are more crucial. This paper presents and evaluates a runtime algorithm for supporting adaptive execution for such applications. The particular domain we target is distributed data mining on streaming data. This work has been done in the context of a middleware system called GATES (grid-based adaptive execution on streams) that we have been developing. The self-adaptation algorithm we present and evaluate in this paper has the following characteristics. First, it carefully evaluates the long-term load at each processing stage. It considers different possibilities for the load at a processing stage and its next stages, and decides if the value of an adaptation parameter needs to be modified, and if so, in which direction. To find the ideal new value of an adaptation parameter, it performs a binary search on the specified range of the parameter. To evaluate the self-adaptation algorithm in our middleware, we have implemented two streaming data mining applications. The main observations from our experiments are as follows. First, our algorithm is able to quickly converge to stable values of the adaptation parameter, for different data arrival rates, and independent of the specified initial value. Second, in a dynamic environment, the algorithm is able to adapt the processing rapidly. Finally, in both static and dynamic environments, the algorithm clearly outperforms the algorithm described in our earlier work and an obvious alternative, which is based on linear-updates.},
  Doi                      = {10.1109/IPDPS.2006.1639312},
  ISBN                     = {1-4244-0054-6},
  Keywords                 = {Application software,Computer science,Data mining,Data visualization,Heuristic algorithms,Middleware,Program processors,Real time systems,Runtime,Streaming media,data mining,distributed data mining,grid computing,grid-based adaptive execution,middleware,middleware system,self-adaptation,self-adjusting systems,streaming data mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Proposes a middleware system that evaluates a runtime algorithm for supporting adaptive execution on distributed data mining. Reports good results on two data stream mining applications witch quick convergence to stable values. Difficult to understand what they had actually done. On the fence about this one. Uncertain about ML usage, so included. Approved 3,4},
  Shorttitle               = {Parallel and Distributed Processing Symposium, 200},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1639312}
}

@Article{Ahmadi2012,
  Title                    = {Semi-supervised ensemble learning of data streams in the presence of concept drift},
  Author                   = {Ahmadi, Z. and Beigy, H.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2012},
  Note                     = {cited By (since 1996)1},
  Number                   = {PART 2},
  Pages                    = {526-537},
  Volume                   = {7209 LNAI},

  Abstract                 = {Increasing access to very large and non-stationary datasets in many real problems has made the classical data mining algorithms impractical and made it necessary to design new online classification algorithms. Online learning of data streams has some important features, such as sequential access to the data, limitation on time and space complexity and the occurrence of concept drift. The infinite nature of data streams makes it hard to label all observed instances. It seems that using the semi-supervised approaches have much more compatibility with the problem. So in this paper we present a new semi-supervised ensemble learning algorithm for data streams. This algorithm uses the majority vote of learners for the labeling of unlabeled instances. The empirical study demonstrates that the proposed algorithm is comparable with the state-of-the-art semi-supervised online algorithms. Ã‚Â© 2012 Springer-Verlag.},
  Affiliation              = {Department of Computer Engineering, Sharif University of Technology, Tehran, Iran},
  Author_keywords          = {Concept Drift; Ensemble Learning; Semi- Supervised Learning; Stream Mining},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Propose that semi-supervised is more compatible than supervised for streams.New semi-supervised ensemble learning algorithm. Majority vote to ask for labeling. Empirical study shows that it is comparable to state of the art online algorthms Approved 1,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84858817533&partnerID=40&md5=07c9dba46f3f2ba5efb6c5f99fb22a33}
}

@Article{Ahmed2011a,
  Title                    = {A framework for mining interesting high utility patterns with a strong frequency affinity},
  Author                   = {Ahmed, C.F.a and Tanbeer, S.K.a and Jeong, B.-S.a and Choi, H.-J.b },
  Journal                  = {Information Sciences},
  Year                     = {2011},
  Note                     = {cited By (since 1996)6},
  Number                   = {21},
  Pages                    = {4878-4894},
  Volume                   = {181},

  Abstract                 = {High utility pattern (HUP) mining is one of the most important research issues in data mining. Although HUP mining extracts important knowledge from databases, it requires long calculations and multiple database scans. Therefore, HUP mining is often unsuitable for real-time data processing schemes such as data streams. Furthermore, many HUPs may be unimportant due to the poor correlations among the items inside of them. Hence,the fast discovery of fewer but more important HUPs would be very useful in many practical domains. In this paper, we propose a novel framework to introduce a very useful measure, called frequency affinity, among the items in a HUP and the concept of interesting HUP with a strong frequency affinity for the fast discovery of more applicable knowledge. Moreover, we propose a new tree structure, utility tree based on frequency affinity (UTFA), and a novel algorithm, high utility interesting pattern mining (HUIPM), for single-pass mining of HUIPs from a database. Our approach mines fewer but more valuable HUPs, significantly reduces the overall runtime of existing HUP mining algorithms and is applicable to real-time data processing. Extensive performance analyses show that the proposed HUIPM algorithm is very efficient and scalable for interesting HUP mining with a strong frequency affinity. Ã‚Â© 2011 Elsevier Inc. All rights reserved.},
  Affiliation              = {Department of Computer Engineering, Kyung Hee University, 1 Seochun-dong, Kihung-gu, Youngin-si, Kyunggi-do 446-701, South Korea; Department of Computer Science, Korea Advanced Institute of Science and Technology (KAIST), 335 Gwahak-ro, Yuseong-gu, Daejeon 305-701, South Korea},
  Author_keywords          = {Data mining; Frequency affinity; High utility pattern mining; Interesting patterns; Knowledge discovery},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we propose a novel framework to introduce a very useful measure, called frequency affinity, among the items in a high utility pattern. HPU mining. novel algorithm, Extensive performance analyses show that the proposed HUIPM algorithm is very efficient and scalable for interesting HUP mining with a strong frequency affinity. Approved. 1,2,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80051549279&partnerID=40&md5=0105d07ce3df9aefcf8f05e76a41a168}
}

@Article{Ahmed2008,
  Title                    = {Efficient single-pass mining of weighted interesting patterns},
  Author                   = {Ahmed, C.F. and Tanbeer, S.K. and Jeong, B.-S. and Lee, Y.-K.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Pages                    = {404-415},
  Volume                   = {5360 LNAI},

  Abstract                 = {Mining weighted interesting patterns (WIP) [5] is an important research issue in data mining and knowledge discovery with broad applications. WIP can detect correlated patterns with a strong weight and/or support affinity. However, it still requires two database scans which are not applicable for efficient processing of the real-time data like data streams. In this paper, we propose a novel tree structure, called SPWIP-tree (Single-pass Weighted Interesting Pattern tree), that captures database information using a single-pass of database and provides efficient mining performance using a pattern growth mining approach. Extensive experimental results show that our approach outperforms the existing WIP algorithm. Moreover, it is very efficient and scalable for weighted interesting pattern mining with a single database scan. Ã‚Â© 2008 Springer Berlin Heidelberg.},
  Affiliation              = {Department of Computer Engineering, Kyung Hee University, 1 Seochun-dong, Kihung-gu, Youngin-si, Kyunggi-do 446-701, South Korea},
  Author_keywords          = {Correlated patterns; Data mining; Data stream; Knowledge discovery; Weighted interesting pattern mining},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining weighted interesting patterns (WIP). Finds interesting patterns from a database in a single pass. Efficient and scalable. Experimental results outperform existing algorithm for WIP. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-58349116920&partnerID=40&md5=0188690b42397fed00c9d67ebc450748}
}

@Conference{Ahn2013,
  Title                    = {What can we learn from Facebook activity? Using social learning analytics to observe new media literacy skills},
  Author                   = {Ahn, J.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {135-144},

  Abstract                 = {Social media platforms such as Facebook are now a ubiquitous part of everyday life for many people. New media scholars posit that the participatory culture encouraged by social media gives rise to new forms of literacy skills that are vital to learning. However, there have been few attempts to use analytics to understand the new media literacy skills that may be embedded in an individual's participation in social media. In this paper, I collect raw activity data that was shared by an exploratory sample of Facebook users. I then utilize factor analysis and regression models to show how (a) Facebook members' online activity coalesce into distinct categories of social media behavior and (b) how these participatory behaviors correlate with and predict measures of new media literacy skills. The study demonstrates the use of analytics to understand the literacies embedded in people's social media activity. The implications speak to the potential of social learning analytics to identify and predict new media literacy skills from data streams in social media platforms. Ã‚Â© 2013 ACM.},
  Affiliation              = {University of Maryland, College Park, College of Information Studies, 2117J Hornbake Building, College Park, MD, United States},
  Author_keywords          = {learning analytics; literacy; new media literacy; social learning analytics; social media},
  Document_type            = {Conference Paper},
  Journal                  = {ACM International Conference Proceeding Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84876474504&partnerID=40&md5=a4a5d43cd090b1a8bc44f2b39b1af94b}
}

@InProceedings{Ahn2013a,
  Title                    = {{What can we learn from Facebook activity?}},
  Author                   = {Ahn, June},
  Booktitle                = {Proceedings of the Third International Conference on Learning Analytics and Knowledge - LAK '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = apr,
  Pages                    = {135},
  Publisher                = {ACM Press},

  Abstract                 = {Social media platforms such as Facebook are now a ubiquitous part of everyday life for many people. New media scholars posit that the participatory culture encouraged by social media gives rise to new forms of literacy skills that are vital to learning. However, there have been few attempts to use analytics to understand the new media literacy skills that may be embedded in an individual's participation in social media. In this paper, I collect raw activity data that was shared by an exploratory sample of Facebook users. I then utilize factor analysis and regression models to show how (a) Facebook members' online activity coalesce into distinct categories of social media behavior and (b) how these participatory behaviors correlate with and predict measures of new media literacy skills. The study demonstrates the use of analytics to understand the literacies embedded in people's social media activity. The implications speak to the potential of social learning analytics to identify and predict new media literacy skills from data streams in social media platforms. Ã‚Â© 2013 ACM.},
  Doi                      = {10.1145/2460296.2460323},
  ISBN                     = {9781450317856},
  Keywords                 = {learning analytics,literacy,new media literacy,social learning analytics,social media},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Used statistical methods ML to analyze static data, but not data streams. He says it could have implications for RT analytics, but that's not enough},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2460296.2460323}
}

@Conference{Akhouri2013,
  Title                    = {Data management for M2M communication using telecom mediation systems},
  Author                   = {Akhouri, S. and Girdhar, K.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {161-166},

  Abstract                 = {Mediation systems are an integral part of a telecom carrier's Business Support System / Operational Support System (BSS / OSS) landscape. They are responsible for collecting, transforming and consolidating massive volumes of data from a diverse set of Network Elements (NE) across a range of protocols. Traditionally, mediation systems support revenue management functions such as charging and billing. Unlike standard data warehousing applications that are based on Extract-Transform-Lead (ETL) paradigm, mediation systems are focused on rapid processing of events in real-time or near real-time. This paper proposes the use of mediation system as a data management platform for Machine-to-Machine (M2M) communication. Mediation systems inherently deliver scalable solutions for handling huge volumes of sensor data. They can connect across a diverse set of M2M communication protocols to collect, consolidate, process sensor data and feed it downstream to decision support systems for actionable intelligence. This paper briefly explores the integration of mediation systems with stream mining applications to classify and cluster data-streams.},
  Affiliation              = {Ericsson R and D, Ericsson India Global Services, Gurgaon, India},
  Author_keywords          = {Analytics; Anomaly detection; BSS/OSS; Clustering; M2M; Mediation; Revenue management; Sensor data management; Stream data mining; Telecommunication},
  Document_type            = {Conference Paper},
  Journal                  = {DATA 2013 - Proceedings of the 2nd International Conference on Data Technologies and Applications},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mediation systems are responsible for collecting, transforming and consolidating massive volumes of data from different network elements. Paper proposes to use it for machine to machine communication. Explores integrating mediation systems with stream mining applications for classification and clustering. Approved 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84887196432&partnerID=40&md5=c5a378cd615918cf6b1adcc6778c5aa9}
}

@InProceedings{Almeida2013a,
  Title                    = {{Random rules from data streams}},
  Author                   = {Almeida, Ezilda and Kosina, Petr and Gama, Jo\~{a}o},
  Booktitle                = {Proceedings of the 28th Annual ACM Symposium on Applied Computing - SAC '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {813},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/2480362.2480518},
  ISBN                     = {9781450316569},
  Keywords                 = {classification,data streams,random rules,rule learning},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, duplicate of Almeida2013.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2480362.2480518}
}

@Conference{Almeida2013,
  Title                    = {Random rules from data streams},
  Author                   = {Almeida, E.a and Kosina, P.a b and Gama, J.a c},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {813-814},

  Abstract                 = {Existing works suggest that random inputs and random features produce good results in classification. In this paper we study the problem of generating random rule sets from data streams. One of the most interpretable and flexible models for data stream mining prediction tasks is the Very Fast Decision Rules learner (VFDR). In this work we extend the VFDR algorithm using random rules from data streams. The proposed algorithm generates several sets of rules. Each rule set is associated with a set of Natt attributes. The proposed algorithm maintains all properties required when learning from stationary data streams: online and any-time classification, processing each example once. Copyright 2013 ACM.},
  Affiliation              = {LIAAD - INESC Porto L.A., Portugal; Fac. of Informatics, Masaryk University, Brno, Czech Republic; Fac. of Economics, University of Porto, Portugal},
  Author_keywords          = {Classification; Data streams; Random rules; Rule learning},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM Symposium on Applied Computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {States that previous litterature shows that random features and inputs give good results in classification. Modifies a decision rules learner to use a set of random rules to learn from stationary data streams. One-pass algorithm. Approved 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84877997557&partnerID=40&md5=a0aac37e20082d4f789304c048a6c885}
}

@Article{Alsumait2008,
  Title                    = {{Online LDA: Adaptive Topic Model for Mining Text Streams with Application on Topic Detection and}},
  Author                   = {Alsumait, Loulwah and Barbar\'{a}, Daniel and Domeniconi, Carlotta},
  Journal                  = {TRACKING, PROCEEDINGS OF IEEE INTERNATIONAL CONFERENCE ON DATA MINING (ICDM08},
  Year                     = {2008},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper presents Online Topic Model (OLDA), a topic model that automatically captures the thematic patterns and identifies emerging topics of text streams and their changes over time. Our approach allows the topic modeling framework, specifically the Latent Dirichlet Allocation (LDA) model, to work in an online fashion such that it incrementally builds an up-to-date model (mixture of topics per document and mixture of words per topic) when a new document (or a set of documents) appears. A solution based on the Empirical Bayes method is proposed. The idea is to incrementally update the current model according to the information inferred from the new stream of data with no need to access previous data. The dynamics of the proposed approach also provide an efficient mean to track the topics over time and detect the emerging topics in real time. Our method is evaluated both qualitatively and quantitatively using benchmark datasets. In our experiments, the OLDA has discovered interesting patterns by just analyzing a fraction of data at a time. Our tests also prove the ability of OLDA to align the topics across the epochs with which the evolution of the topics over time is captured. The OLDA is also comparable to, and sometimes better than, the original LDA in predicting the likelihood of unseen documents},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Online Topic Model (OLDA), a topic model that automatically captures the thematic patterns and identifies emerging topics of text streams and their changes over time. Modified Latent dirichlet allocation (LDA) for online. A solution based on the Empirical Bayes method is proposed. evaluated both qualitatively and quantitatively using benchmark datasets. The OLDA is also comparable to, and sometimes better than, the original LDA in predicting the likelihood of unseen documents Approved 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.409.3975}
}

@Article{Alzghoul2011,
  Title                    = {Increasing availability of industrial systems through data stream mining },
  Author                   = {Ahmad Alzghoul and Magnus LÃƒÂ¶fstrand},
  Journal                  = {Computers \& Industrial Engineering },
  Year                     = {2011},
  Number                   = {2},
  Pages                    = {195 - 205},
  Volume                   = {60},

  Abstract                 = {Improving industrial product reliability, maintainability and thus availability is a challenging task for many industrial companies. In industry, there is a growing need to process data in real time, since the generated data volume exceeds the available storage capacity. This paper consists of a review of data stream mining and data stream management systems aimed at improving product availability. Further, a newly developed and validated grid-based classifier method is presented and compared to one-class support vector machine (OCSVM) and a polygon-based classifier. The results showed that, using 10% of the total data set to train the algorithm, all three methods achieved good (&gt;95% correct) overall classification accuracy. In addition, all three methods can be applied on both offline and online data. The speed of the resultant function from the \{OCSVM\} method was, not surprisingly, higher than the other two methods, but in industrial applications the OCSVMsÃ¢â‚¬â„¢ comparatively long time needed for training is a possible challenge. The main advantage of the grid-based classification method is that it allows for calculation of the probability (%) that a data point belongs to a specific class, and the method can be easily modified to be incremental. The high classification accuracy can be utilized to detect the failures at an early stage, thereby increasing the reliability and thus the availability of the product (since availability is a function of maintainability and reliability). In addition, the consequences of equipment failures in terms of time and cost can be mitigated.},
  Doi                      = {http://dx.doi.org/10.1016/j.cie.2010.10.008},
  ISSN                     = {0360-8352},
  Keywords                 = {Availability},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A newly grid-based classifier method is presented and compared to other methods, intended to approach the problem of processing data in real time. Main advantage of their new method is that it gives probability of classification. Research goal is not crystal clear, but they are clearly approaching a specific challenge. Approved 2,3,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0360835210002743}
}

@Conference{Amatriain2013,
  Title                    = {Big \& personal: Data and models behind Netflix recommendations},
  Author                   = {Amatriain, X.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1-6},

  Abstract                 = {Since the Netfix $1 million Prize, announced in 2006, our company has been known to have personalization at the core of our product. Even at that point in time, the dataset that we released was considered "large", and we stirred innovation in the (Big) Data Mining research field. Our current product offering is now focused around instant video streaming, and our data is now many orders of magnitude larger. Not only do we have many more users in many more countries, but we also receive many more streams of data. Besides the ratings, we now also use information such as what our members play, browse, or search. In this paper, we will discuss the different approaches we follow to deal with these large streams of data in order to extract information for personalizing our service. We will describe some of the machine learning models used, as well as the architectures that allow us to combine complex offine batch processes with real-time data streams.},
  Affiliation              = {Netflix, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Proc. of 2nd Int. Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications, BigMine 2013 - Held in Conj. with SIGKDD 2013 Conf.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank2},
  Relevance                = {relevant},
  Review                   = {Netflix describe what they do to extract information for personalizing their service. Describe the machine learning used and architectures for . Sufficiently novel, because they have unique data streams. Approved 6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84890614611&partnerID=40&md5=a689cd386cfe27da594e95eb71d3485e}
}

@InProceedings{Amatriain2013a,
  Title                    = {{Big \& personal}},
  Author                   = {Amatriain, Xavier},
  Booktitle                = {Proceedings of the 2nd International Workshop on Big Data, Streams and Heterogeneous Source Mining Algorithms, Systems, Programming Models and Applications - BigMine '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {1--6},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/2501221.2501222},
  ISBN                     = {9781450323246},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, duplicate of Amatriain2013.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2501221.2501222}
}

@Misc{An,
  Title                    = {{Chapter 6 MULTI-DIMENSIONAL ANALYSIS OF DATA STREAMS USING STREAM CUBES}},

  Author                   = {An, Jiawei and Cai, Y Dora and Chen, Yixin},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Large volumes of dynamic stream data pose great challenges to its analysis. Besides its dynamic and transient behavior, stream data has another important characteristic: multi-dimensionality. Much of stream data resides at a multidimensional space and at rather low level of abstraction, whereas most analysts are interested in relatively high-level dynamic changes in some combination of dimensions. To discover high-level dynamic and evolving characteristics, one may need to perform multi-level, multi-dimensional on-line analytical processing (OLAP) of stream data. Such necessity calls for the investigation of new architectures that may facilitate on-line analytical processing of multi-dimensional stream data. In this chapter, we introduce an interesting stream-cube architecture that effectively performs on-line partial aggregation of multi-dimensional stream data, captures the essential dynamic and evolving characteristics of data streams, and facilitates fast OLAP on stream data. Three important techniques are proposed forDATA STREAMS: MODELS AND ALGORITHMS},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {To discover high-level dynamic and evolving characteristics, one may need to perform multi-level, multi-dimensional on-line analytical processing (OLAP) of stream data. Introduce a stream scube architecure to perform online partial aggregation of multidim streaming data, capturing essential dynamics and characteristics. It is discussed in context of stream mining. Not clear if this paper implements an example also, but the online partial aggregation, dynamics and characteristics part of the architecture might already use ML. Approved 1,3,4},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.352.3466}
}

@Article{Anagnostopoulos2013,
  Title                    = {Information-theoretic data discarding for dynamic trees on data streams},
  Author                   = {Anagnostopoulos, C.a and Gramacy, R.B.b },
  Journal                  = {Entropy},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {12},
  Pages                    = {5510-5535},
  Volume                   = {15},

  Abstract                 = {Ubiquitous automated data collection at an unprecedented scale is making available streaming, real-time information flows in a wide variety of settings, transforming both science and industry. Learning algorithms deployed in such contexts often rely on single-pass inference, where the data history is never revisited. Learning may also need to be temporally adaptive to remain up-to-date against unforeseen changes in the data generating mechanism. Online Bayesian inference remains challenged by such transient, evolving data streams. Nonparametric modeling techniques can prove particularly ill-suited, as the complexity of the model is allowed to increase with the sample size. In this work, we take steps to overcome these challenges by porting information theoretic heuristics, such as exponential forgetting and active learning, into a fully Bayesian framework. We showcase our methods by augmenting a modern non-parametric modeling framework, dynamic trees, and illustrate its performance on a number of practical examples. The end product is a powerful streaming regression and classification tool, whose performance compares favorably to the state-of-the-art. Ã‚Â© 2013 by the authors; licensee MDPI, Basel, Switzerland.},
  Affiliation              = {Department of Mathematics, Imperial College London, South Kensington Campus, London SW7 2AZ, United Kingdom; Booth School of Business, The University of Chicago, 5807 South Woodlawn Avenue, Chicago, IL 60637, United States},
  Author_keywords          = {Active learning; Dynamic trees; Massive data; Online learning; Regression and classification trees; Streaming data},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Try to mitigate performance and prediction problems of learning from streams by porting information theoretic heuristics, such as exponential forgetting and active learning, into a fully Bayesian framework. Illustrate it performance on practical examples. Performance compares favorably to the state-of-the-art. Approved 1,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84891705253&partnerID=40&md5=64a9f6dc2e91d84000a2eebbae1908fa}
}

@InProceedings{AnakJoseph2014,
  Title                    = {{A fast Incremental Kernel Principal Component Analysis for data streams}},
  Author                   = {{Anak Joseph}, Annie and Ozawa, Seiichi},
  Booktitle                = {2014 International Joint Conference on Neural Networks (IJCNN)},
  Year                     = {2014},
  Month                    = jul,
  Pages                    = {3135--3142},
  Publisher                = {IEEE},

  Abstract                 = {Kernel Principal Component Analysis (KPCA) is widely used feature extraction as it have been proven that KPCA is powerful in many areas in pattern recognition. Considering that the conventional KPCA should decompose a kernel matrix of all training data, this would be an unrealistic assumption for data streams in real-world applications. Therefore, in this paper, we propose an online feature extraction called Chunk Incremental Kernel Principal Component Analysis (CIKPCA) that can handle data streams in an incremental mode. In the proposed method, the training data are assumed to be given in a chunk of multiple data at one time. In CIKPCA, an eigen-feature space is updated by solving the eigenvalue decomposition once whenever a chunk of data is given. However, if a chunk size is large, a kernel matrix to be decomposed is also large, resulting in high computational time. Considering that not all the data are useful for the eigen-feature space learning, the data in a chunk are first selected based on the importance. Several benchmark data sets in the UCI Machine Learning Repository are used to evaluate the performance of the proposed method. The experimental results show that our proposed method can accelerate the learning of the eigen-feature space compared to Takeuchi et al.'s IKPCA without reducing the recognition accuracy.},
  Doi                      = {10.1109/IJCNN.2014.6889940},
  ISBN                     = {978-1-4799-1484-5},
  Keywords                 = {Accuracy,CIKPCA,Eigenvalues and eigenfunctions,Feature extraction,KPCA,Kernel,Matrix decomposition,Principal component analysis,Training data,UCI machine learning repository,chunk incremental kernel principal component analy,data handling,data streams,eigen-feature space learning,fast incremental kernel principal component analys,kernel matrix,learning (artificial intelligence),online feature extraction,pattern recognition,principal component analysis},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Kernel Principal Component Analysis is not good for streams, since it relies on full matrix decomposition. They propose a Chunk Incremental version. Data arrives in chunks of multiple data at one time. In CIKPCA, an eigen-feature space is updated by solving the eigenvalue decomposition once whenever a chunk of data is given. Experiments on UCI datasets, performance is similar to previous method, but with stream compatibility. Approved 1,2,3,4,6},
  Shorttitle               = {Neural Networks (IJCNN), 2014 International Joint },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6889940}
}

@Article{Angelov2011,
  Title                    = {{Fuzzily Connected Multimodel Systems Evolving Autonomously From Data Streams.}},
  Author                   = {Angelov, Plamen},
  Journal                  = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
  Year                     = {2011},

  Month                    = jan,
  Number                   = {4},
  Pages                    = {898--910},
  Volume                   = {41},

  Abstract                 = {A general framework and a holistic concept are proposed in this paper that combine computationally light machine learning from streaming data with the online identification and adaptation of dynamic systems in regard to their structure and parameters. According to this concept, the system is assumed to be decomposable into a set of fuzzily connected simple local models. The main thrust of this paper is in the development of an original approach for the self-design, self-monitoring, self-management, and self-learning of such systems in a dynamic manner from data streams which automatically detect and react to the shift in the data distribution by evolving the system structure. Novelties of this contribution lie in the following: 1) the computationally simple approach ( simpl\_e\_Clustering-simplified evolving Clustering) to data space partitioning by recursive evolving clustering based on the relative position of the new data sample to the mean of the overall data, 2) the learning technique for online structure evolution as a reaction to the shift in the data distribution, 3) the method for online system structure simplification based on utility and inputs/feature selection, and 4) the novel graphical illustration of the spatiotemporal evolution of the data stream. The application domain for this computationally efficient technique ranges from clustering, modeling, prognostics, classification, and time-series prediction to pattern recognition, image segmentation, vector quantization, etc., to more general problems in various application areas, e.g., intelligent sensors, mobile robotics, advanced manufacturing processes, etc.},
  Doi                      = {10.1109/TSMCB.2010.2098866},
  ISSN                     = {1941-0492},
  Keywords                 = {Evolving fuzzy systems,Finite element methods,Inspection,Layout,Lithography,Resists,Systematics,computationally light machine learning,data distribution,data handling,data streaming,dynamic system online identification,fuzzily connected multimodel systems,fuzzily weighted recursive least-squares estimatio,fuzzy rule-based systems,fuzzy set theory,image segmentation,learning (artificial intelligence),least squares approximations,online system structure,pattern classification,pattern clustering,pattern recognition,self-design,self-learning,self-monitoring,time-series prediction,vector quantization},
  Owner                    = {Alexander},
  Pmid                     = {21245012},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Framework to combine computationally light machine learning from streaming data with the online identification and adaptation of dynamic systems in regard to their structure and parameters. Self learning and arranging systems that detect and react to changes in a stream by changing their own structure. Approved 1, 6},
  Shorttitle               = {Systems, Man, and Cybernetics, Part B: Cybernetics},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/21245012}
}

@Article{Angelov2011a,
  Title                    = {Fuzzily connected multimodel systems evolving autonomously from data streams},
  Author                   = {Angelov, P.},
  Journal                  = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
  Year                     = {2011},
  Note                     = {cited By (since 1996)23},
  Number                   = {4},
  Pages                    = {898-910},
  Volume                   = {41},

  Abstract                 = {A general framework and a holistic concept are proposed in this paper that combine computationally light machine learning from streaming data with the online identification and adaptation of dynamic systems in regard to their structure and parameters. According to this concept, the system is assumed to be decomposable into a set of fuzzily connected simple local models. The main thrust of this paper is in the development of an original approach for the self-design, self-monitoring, self-management, and self-learning of such systems in a dynamic manner from data streams which automatically detect and react to the shift in the data distribution by evolving the system structure. Novelties of this contribution lie in the following: 1) the computationally simple approach (simpl-e-Clustering-simplified evolving Clustering) to data space partitioning by recursive evolving clustering based on the relative position of the new data sample to the mean of the overall data, 2) the learning technique for online structure evolution as a reaction to the shift in the data distribution, 3) the method for online system structure simplification based on utility and inputs/feature selection, and 4) the novel graphical illustration of the spatiotemporal evolution of the data stream. The application domain for this computationally efficient technique ranges from clustering, modeling, prognostics, classification, and time-series prediction to pattern recognition, image segmentation, vector quantization, etc., to more general problems in various application areas, e.g., intelligent sensors, mobile robotics, advanced manufacturing processes, etc. Ã‚Â© 2011 IEEE.},
  Affiliation              = {InfoLab21, School of Computing and Communications, Lancaster University, Lancaster, LA1 4WA, United Kingdom},
  Art_number               = {5688483},
  Author_keywords          = {Evolving fuzzy systems; fuzzily weighted recursive least-squares estimation; fuzzy rule-based systems},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, duplicate of Angelov2011},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79960697024&partnerID=40&md5=5af1b4d0db51a31f27b39eca6c4d867d}
}

@Book{Angelov2010,
  Title                    = {Evolving Intelligent Systems: Methodology and Applications},
  Author                   = {Angelov, P.a and Filev, D.P.b and Kasabov, N.c },
  Year                     = {2010},
  Note                     = {cited By (since 1996)76},

  Abstract                 = {From theory to techniques, the first all-in-one resource for EIS There is a clear demand in advanced process industries, defense, and Internet and communication (VoIP) applications for intelligent yet adaptive/evolving systems. Evolving Intelligent Systems is the first self- contained volume that covers this newly established concept in its entirety, from a systematic methodology to case studies to industrial applications. Featuring chapters written by leading world experts, it addresses the progress, trends, and major achievements in this emerging research field, with a strong emphasis on the balance between novel theoretical results and solutions and practical real-life applications. Explains the following fundamental approaches for developing evolving intelligent systems (EIS): the Hierarchical Prioritized Structure the Participatory Learning Paradigm the Evolving Takagi-Sugeno fuzzy systems (eTS+) the evolving clustering algorithm that stems from the well-known Gustafson-Kessel offline clustering algorithm Emphasizes the importance and increased interest in online processing of data streams Outlines the general strategy of using the fuzzy dynamic clustering as a foundation for evolvable information granulation Presents a methodology for developing robust and interpretable evolving fuzzy rule-based systems Introduces an integrated approach to incremental (real-time) feature extraction and classification Proposes a study on the stability of evolving neuro-fuzzy recurrent networks Details methodologies for evolving clustering and classification Reveals different applications of EIS to address real problems in areas of: evolving inferential sensors in chemical and petrochemical industry learning and recognition in robotics Features downloadable software resources Evolving Intelligent Systems is the one-stop reference guide for both theoretical and practical issues for computer scientists, engineers, researchers, applied mathematicians, machine learning and data mining experts, graduate students, and professionals. Ã‚Â© 2010 Institute of Electrical and Electronics Engineers.},
  Affiliation              = {Lancaster University, United Kingdom; Ford Research and Advanced Engineering, United States; Knowledge Engineering, Discovery Research Institute (KEDRI), Auckland, New Zealand},
  Document_type            = {Book},
  Journal                  = {Evolving Intelligent Systems: Methodology and Applications},
  Owner                    = {Alexander},
  Page_count               = {444},
  Qualityassured           = {qualityAssured},
  Review                   = {This is a full book on evolving intelligent systems. Too wide scope. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84891585323&partnerID=40&md5=fa878f1954a3fb0b6eb1a8cf3394296f}
}

@InProceedings{Anuradha2014,
  Title                    = {{Suggested techniques for clustering and mining of data streams}},
  Author                   = {Anuradha, G. and Roy, Bidisha},
  Booktitle                = {2014 International Conference on Circuits, Systems, Communication and Information Technology Applications (CSCITA)},
  Year                     = {2014},
  Month                    = apr,
  Pages                    = {265--270},
  Publisher                = {IEEE},

  Abstract                 = {The buzz word in research is Big Data. Big Data gets characterized by 5 V's: Volume, Velocity, Variety, Veracity and Value of data. Volume in order of penta bytes, velocity which refers to click stream data in various domains, variety comprising of heterogeneous data, veracity indicating the cleanliness of data and value emphasizing on the return on investment for companies who invest in Big Data technologies. This Big Data is better modeled not as persistent tables but in the form of transient data streams which need different clustering and mining techniques to be effectively processed and managed. In this paper some suggestions on online learning through clustering and mining of stream data are presented.},
  Doi                      = {10.1109/CSCITA.2014.6839270},
  ISBN                     = {978-1-4799-2494-3},
  Keywords                 = {Algorithm design and analysis,Big Data,Big Data technology,Big data,Classification algorithms,Clustering,Clustering algorithms,Data Streams,Data mining,Heuristic algorithms,Mining,Prediction algorithms,buzz word,data mining,data stream clustering technique,data stream mining technique,data value,data variety,data velocity,data veracity,data volume,heterogeneous data,online learning,pattern clustering,return on investment,transient data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {No specific problem or algorithms studied, just some suggestions on online learning through clustering and mining of stream data. Discarded.},
  Shorttitle               = {Circuits, Systems, Communication and Information T},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6839270}
}

@Conference{Anuradha2014a,
  Title                    = {Suggested techniques for clustering and mining of data streams},
  Author                   = {Anuradha, G. and Roy, B.},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {265-270},

  Abstract                 = {The buzz word in research is Big Data. Big Data gets characterized by 5 V's: Volume, Velocity, Variety, Veracity and Value of data. Volume in order of penta bytes, velocity which refers to click stream data in various domains, variety comprising of heterogeneous data, veracity indicating the cleanliness of data and value emphasizing on the return on investment for companies who invest in Big Data technologies. This Big Data is better modeled not as persistent tables but in the form of transient data streams which need different clustering and mining techniques to be effectively processed and managed. In this paper some suggestions on online learning through clustering and mining of stream data are presented. Ã‚Â© 2014 IEEE.},
  Affiliation              = {Dept. of Computer Engineering, St. Francis Institute of Technology, Borivili, Mumbai, India},
  Art_number               = {6839270},
  Author_keywords          = {Big Data; Clustering; Data Streams; Mining},
  Document_type            = {Conference Paper},
  Journal                  = {2014 International Conference on Circuits, Systems, Communication and Information Technology Applications, CSCITA 2014},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Anuradha2014. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84904214282&partnerID=40&md5=66558269f5b95fe8526cb8ab239ae3f0}
}

@Article{Ao2009,
  Title                    = {Online mining closed frequent itemsets over a stream sliding window},
  Author                   = {Ao, F.-J.a and Du, J.b and Yan, Y.-J.b and Huang, K.-D.a },
  Journal                  = {Xi Tong Gong Cheng Yu Dian Zi Ji Shu/Systems Engineering and Electronics},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Number                   = {5},
  Pages                    = {1235-1240},
  Volume                   = {31},

  Abstract                 = {Online mining closed frequent itemsets in sliding window is one of the most important issues for mining data streams. A novel algorithm, FPCFI-DS, is proposed, which can efficiently mine closed frequent itemsets over a stream sliding window with limited memory space, and maintain exact closed frequent itemsets in current window at any time. For data in the first window, the algorithm FPCFI-DS mines closed frequent itemsets using single-pass procedure, denoted as FPCFI. The resulting closed frequent itemsets are stored in a global closed frequent itemsets tree (GCT). When the window slides forward, the FPCFI-DS quickly updates closed frequent itemsets in current window using the updating-mining method. The experimental results show that FPCFI-DS is superior to that of state-of-the-art algorithm Moment in terms of time and space efficiency.},
  Affiliation              = {Coll. of Mechanical Engineering and Automation, National Univ. of Defense Technology, Changsha 410073, China; School of Computer Science, National Univ. of Defense Technology, Changsha 410073, China},
  Author_keywords          = {Closed frequent itemset; Data stream; Online mining; Sliding window},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Online mining closed frequent itemsets. A new algorithm FPCFI-DS canefficiently mine closed frequent itemsets over a stream sliding window with limited memory space, and maintain exact closed frequent itemsets in current window at any time. The experimental results show that FPCFI-DS is superior to that of state-of-the-art algorithm Moment in terms of time and space efficiency. Approved. 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-67649236244&partnerID=40&md5=2f03ebd750a744a34571d5aff2f19a5d}
}

@Article{Ao2009a,
  Title                    = {Online mining maximal frequent itemsets in sliding window over data streams},
  Author                   = {Ao, F.-J.a and Yan, Y.-J.b and Liu, B.-H.a and Huang, K.-D.a },
  Journal                  = {Xitong Fangzhen Xuebao / Journal of System Simulation},
  Year                     = {2009},
  Note                     = {cited By (since 1996)2},
  Number                   = {4},
  Pages                    = {1134-1139},
  Volume                   = {21},

  Abstract                 = {For the number of maximal frequent itemsets (MFIs) is less than that of frequent itemsets, the efficiency of algorithm for mining MFIs is higher. A novel single-pass lexicographical-order FP-Tree based algorithm, FPMFI-DS was proposed. FPMFI-DS uses a kind of mixed item ordering policy and imports a new pruning technique, subset equivalence pruning technique. These two techniques effectively decrease the size of searching space. Based on FPMFI-DS, another algorithm, FPMFI-DS+ was proposed, which could mine MFIs in sliding window over data streams in an online updating fashion. FPMFI-DS+ can maintain MFIs in current sliding window over data streams at any time. The experiments show that FPMFI-DS is comparable with multi-pass algorithm FPMax* regarding with the efficiency, and has good scalability, and FPMFI-DS+ has high updating-mining speed.},
  Affiliation              = {College of Mechanical Engineering and Automation, National University of Defense Technology, Changsha 410073, China; College of Computer Science, National University of Defense Technology, Changsha 410073, China},
  Author_keywords          = {Data streams; Lexicographical-order FP-Tree; Maximal frequent itemsets; Online mining; Sliding window},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {New algorithm for online mining maximal frquent itemsets using sliding window, which is sometimes for efficient than closed(?) Two variants, FPMFI-DS and FPMFI-DS+. The experiments show that FPMFI-DS is comparable with multi-pass algorithm FPMax* regarding with the efficiency, and has good scalability, and FPMFI-DS+ has high updating-mining speed. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-62249117113&partnerID=40&md5=fe8a182b1f1eb48c52fa62043382e8e0}
}

@InProceedings{Ari2012,
  Title                    = {{Data stream analytics and mining in the cloud}},
  Author                   = {Ari, Ismail and Olmezogullari, Erdi and Celebi, Omer Faruk},
  Booktitle                = {4th IEEE International Conference on Cloud Computing Technology and Science Proceedings},
  Year                     = {2012},
  Month                    = dec,
  Pages                    = {857--862},
  Publisher                = {IEEE},

  Abstract                 = {Due to prevalent use of sensors and network monitoring tools, big volumes of data or Ã¢â‚¬Å“big dataÃ¢â‚¬ï¿½ today traverse the enterprise data processing pipelines in a streaming fashion. While some companies prefer to deploy their data processing infrastructures and services as private clouds, others completely outsource these services to public clouds. In either case, attempting to store the data first for subsequent analysis creates additional resource costs and unwanted delays in obtaining actionable information. As a result, enterprises increasingly employ data or event stream processing systems and further want to extend them with complex online analytic and mining capabilities. In this paper, we present implementation details for doing both correlation analysis and association rule mining (ARM) over streams. Specifically, we implement Pearson-Product Moment Correlation for analytics and Apriori \& FPGrowth algorithms for stream mining inside a popular event stream processing engine called Esper. As a unique contribution, we conduct experiments and present performance results of these new tools with different tumbling and sliding time-windows over two different stream types: one for moving bus trajectories and another for web logs from a music site. We find that while tumbling windows may be more preferable for performance in certain applications, sliding windows can provide additional benefits with rule mining. We hope that our findings can shed light on the design of other cloud analytics systems.},
  Doi                      = {10.1109/CloudCom.2012.6427563},
  ISBN                     = {978-1-4673-4510-1},
  Keywords                 = {ARM,Apriori,Apriori \& FPGrowth algorithms,Association Rule Mining,Association rules,Cloud computing,Complex Event Processing,Correlation,Data streams,Engines,Esper,FP-growth,Itemsets,Pearson-product moment correlation,Real-time systems,Stream mining,Web logs,actionable information,association rule mining,big data,cloud analytics systems,cloud computing,computerised monitoring,correlation analysis,correlation theory,data mining,data stream analytics,data stream mining,enterprise resource planning,event stream processing systems,moving bus trajectories,network monitoring tools,pipeline enterprise data processing,pipeline processing,popular event stream processing engine,public clouds,resource costs,rule mining,sensors,service-oriented architecture,services as private clouds,sliding time-windows,tumbling time-windows},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we present implementation details for doing both correlation analysis and association rule mining (ARM) over streams. Pearson-Product Moment Correlation for analytics and Apriori & FPGrowth algorithms for stream mining. Uses processing engine Esper. Conduct experiments and present performance results of these new tools with different tumbling and sliding time-windows over two different stream types, moving bus trajectories and web logs from music site. 1,3,4,6},
  Shorttitle               = {Cloud Computing Technology and Science (CloudCom),},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6427563}
}

@InProceedings{Asai2002,
  Title                    = {{Online algorithms for mining semi-structured data stream}},
  Author                   = {Asai, T. and Arimura, H. and Abe, K. and Kawasoe, S. and Arikawa, S.},
  Booktitle                = {2002 IEEE International Conference on Data Mining, 2002. Proceedings.},
  Year                     = {2002},
  Pages                    = {27--34},
  Publisher                = {IEEE Comput. Soc},

  Abstract                 = {In this paper, we study an online data mining problem from streams of semi-structured data such as XML data. Modeling semi-structured data and patterns as labeled ordered trees, we present an online algorithm StreamT that receives fragments of an unseen possibly infinite semi-structured data in the document order through a data stream, and can return the current set of frequent patterns immediately on request at any time. A crucial part of our algorithm is the incremental maintenance of the occurrences of possibly frequent patterns using a tree sweeping technique. We give modifications of the algorithm to other online mining model. We present theoretical and empirical analyses to evaluate the performance of the algorithm.},
  Doi                      = {10.1109/ICDM.2002.1183882},
  ISBN                     = {0-7695-1754-4},
  Keywords                 = {Algorithm design and analysis,Data communication,Data mining,Informatics,Monitoring,Pattern analysis,Performance analysis,StreamT,Technology management,Web pages,XML,XML data,data mining,data structures,frequent pattern discovery,hypermedia markup languages,incremental maintenance,online algorithm,online data mining,pattern recognition,semi-structured data,tree sweeping technique},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Study online mining from semi-structured data such as XML. Models semi-structured data and patterns as labelled ordered trees. Online algorithm StreamT receives possibly infinite streams and can return current set of frequent patterns at a given time. A crucial part of our algorithm is the incremental maintenance of the occurrences of possibly frequent patterns using a tree sweeping technique 1,3,4,6},
  Shorttitle               = {Data Mining, 2002. ICDM 2003. Proceedings. 2002 IE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1183882}
}

@Conference{Asai2002a,
  Title                    = {Online algorithms for mining semi-structured data stream},
  Author                   = {Asai, T.a and Arimura, H.b and Abe, K.a and Kawasoe, S.a and Arikawa, S.a},
  Year                     = {2002},
  Note                     = {cited By (since 1996)24},
  Pages                    = {27-34},

  Abstract                 = {In this paper, we study an online data mining problem from streams of semi-structured data such as XML data. Modeling semi-structured data and patterns as labeled ordered trees, we present an online algorithm StreamT that receives fragments of an unseen possibly infinite semi-structured data in the document order through a data stream, and can return the current set of frequent patterns immediately on request at any time. A crucial part of our algorithm is the incremental maintenance of the occurrences of possibly frequent patterns using a tree sweeping technique. We give modifications of the algorithm to other online mining model. We present theoretical and empirical analyses to evaluate the performance of the algorithm. Ã‚Â© 2002 IEEE.},
  Affiliation              = {Department of Informatics, Kyushu University, Fukuoka 812-8581, Japan; PRESTO, JST, Japan},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Asai2002. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-4444224481&partnerID=40&md5=81aba50d1c5501a8523b7224a1094030}
}

@Article{Asai2002b,
  Title                    = {{Online Algorithms for Mining Semi-structured Data Stream}},
  Author                   = {Asai, Tatsuya and Arimura, Hiroki and Abe, Kenji and Kawasoe, Shinji and Arikawa, Setsuo},
  Journal                  = {IN PROC. 2002 INT. CONF. ON DATA MINING (ICDMâ€™02},
  Year                     = {2002},
  Volume                   = {27},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In this paper, we study an online data mining problem from streams of semi-structured data such as XML data. Modeling semi-structured data and patterns as labeled ordered trees, we present an online algorithm StreamT that receives fragments of an unseen possibly infinite semi-structured data in the document order through a data stream, and can return the current set of frequent patterns immediately on request at any time. A crucial part of our algorithm is the incremental maintenance of the occurrences of possibly frequent patterns using a tree sweeping technique. We give modifications of the algorithm to other online mining model. We present theoretical and empirical analyses to evaluate the performance of the algorithm.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Asai2002. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.7164}
}

@Article{Asai2007,
  Title                    = {Efficient algorithms for finding frequent substructures from semi-structured data streams},
  Author                   = {Asai, T.a b and Abe, K.a c and Kawasoe, S.a d and Arimura, H.a e and Arikawa, S.a},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {29-45},
  Volume                   = {3609 LNAI},

  Abstract                 = {In this paper, we study an online data mining problem from streams of semi-structured data such as XML data. Modeling semi-structured data and patterns as labeled ordered trees, we present an online algorithm StreamT that receives fragments of an unseen possibly infinite semi-structured data in the document order through a data stream, and can return the current set of frequent patterns immediately on request at any time. We give modifications of the algorithm to other online mining models. Furthermore we implement our algorithms in different online models and candidate management strategies, then show empirical analyses to evaluate the algorithms. Ã‚Â© Springer-Verlag Berlin Heidelberg 2007.},
  Affiliation              = {Kyushu University, 6-10-1 Hakozaki, Higashi-ku, Fukuoka 812-8581, Japan; Fujitsu Laboratories Ltd., Japan; Sharp Corp., Japan; NTT Comware Corp., Japan; Hokkaido University, Japan},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Asai2002. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-36348939190&partnerID=40&md5=1c0bba89900ac8e88dc9533e55535332}
}

@InProceedings{Ashani2009,
  Title                    = {{Architectural Considerations for Video Content Analysis in Urban Surveillance}},
  Author                   = {Ashani, Zvika},
  Booktitle                = {2009 Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance},
  Year                     = {2009},
  Month                    = sep,
  Pages                    = {289--289},
  Publisher                = {IEEE},

  Abstract                 = {Successfully deploying video content analysis (VCA) solutions for urban surveillance poses significant challenges for manufacturers and system integrators. Urban surveillance is typically characterized by a very large number of cameras (thousands and more) distributed over a large area and installed in both outdoor and indoor views. From the user perspective the primary rule of the surveillance system is to provide quick, reliable and high quality access to live and recorded video streams from all cameras. VCA is considered an important but secondary functionality that is required in order to provide features such as real time alerts for predefined rules, forensic search capabilities, statistical analysis of crowd and traffic flow and more. Ideally the user would like to have some form of VCA functionality for every camera deployed. In an urban environment the VCA system is required to handle a variety of detection tasks dealing with people, vehicles and objects and their behaviors and interactions with each other. Given unlimited computational resources this task is still a very challenging one and is expected to require significant research from the industry and academia in the foreseeable future. In a real life deployment where cost is a major factor the availability of sufficient computing resources for VCA becomes a limiting factor which may severely limit the usability of such a technology in a large scale installation. By nature of being a complementary system component, a VCA system deployment is expected to provide good detection performance (high POD and low FAR) while maintaining the following critical conditions: (a) acceptable cost relative to the other components and ( b) minimal impact on the performance of other system features. Additional considerations for such a deployment are: (c) complexity of setting up and configuring the analytics (d) ease of management and maintenance (e) upgrade path. This presentation will analyze the strengths and weaknes- ses of known VCA deployment architectures namely "server based" and "edge based" in the context of a large scale deployment scenario and will demonstrate an alternative architecture developed and patented by Agent Vi. This proven architecture known as image processing over IP networks (IPoIP) enables providing the end user with a system that scores very highly on all points (a)-(e) mentioned above. The cost/performance advantage of IPoIP is achieved through distribution of the VCA task between the edge device (IP camera or video encoder) and a server. The edge device is tasked with performing the initial analysis of the video stream and extracting information which is relevant in the context of video scene analysis. This information sent to the server as a continuous data stream where it is further analyzed and turned into metadata describing the objects in each and every camera view. The generated metadata is recorded for later offline search functionality and also analyzed in real time to detect deviation from any user defined rule and if this is detected an appropriate event is generated and distributed to any listening client. Using this architecture it is possible to support full VCA functionality for all cameras in a large surveillance installation with a minimal cost overhead while maintaining very high and feature rich performance.},
  Doi                      = {10.1109/AVSS.2009.112},
  ISBN                     = {978-1-4244-4755-8},
  Keywords                 = {Cameras,Costs,Event detection,IP networks,Image analysis,Information analysis,Large-scale systems,Manufacturing,Network servers,Streaming media,Surveillance,edge based deployment,image processing over IP networks,server based deployment,urban surveillance,video content analysis,video scene analysis,video surveillance},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This presentation will analyze the strengths and weaknes- ses of known VCA deployment architectures namely "server based" and "edge based" in the context of a large scale deployment scenario and will demonstrate an alternative architecture developed and patented by Agent Vi. Stream analysis, but only an overview of existing architecture. Discarded.},
  Shorttitle               = {Advanced Video and Signal Based Surveillance, 2009},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5279786}
}

@Article{Attar2012,
  Title                    = {An instance-window based classification algorithm for handling gradual concept drifts},
  Author                   = {Attar, V.a and Chaudhary, P.a and Rahagude, S.a and Chaudhari, G.a and Sinha, P.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2012},
  Note                     = {cited By (since 1996)1},
  Pages                    = {156-172},
  Volume                   = {7103 LNAI},

  Abstract                 = {Mining concept drifting data stream is a challenging area for data mining research. In real world, data streams are not stable but change with time. Such changes termed as drifts in concept of the data stream are categorized into gradual and abrupt, based on the amount of drifting time, i.e. the time steps taken to replace the old concept completely by the new one. In traditional online learning systems, this categorization has not been exploited in developing different approaches for handling different types of drifts in the data stream. Such handling of concept drifts according to their type can help improve the performance of the classification system and hence, the issue can be explored further. Among the most popular and effective approaches to handle concept drifts is ensemble learning, where a set of models built over different time periods is maintained and the predictions of models are combined, usually according to their expertise level regarding the current concept. If early instances of new concept are stored and used for ensemble learning once the drift is detected, this may help increase the overall accuracy after the drift. Moreover, if an ensemble learns with zero diversity for instances of a new concept during the drifting period, the ensemble may learn the new concept faster, thus boosting recovery. The paper presents the above mentioned approach for effective handling of gradual concept drifts in the data streams.},
  Affiliation              = {College of Engineering, Pune (CoEP), Shivajinagar, Pune 411 005, India; Centre for Development of Advanced Computing (C-DAC), Pune 411007, India},
  Author_keywords          = {Boosting; Diversity; Ensemble; Gradual concept drift; Instance Window; Online Learning},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A variant of ensemble learning from streams with concept drift that keeps early instances of new concept are stored and use them for ensemble learning once the drift is detected. This may help increase the overall accuracy after the drift. Unsure if novel, but clearly using machine learning and adaptation of algorithm. Approved. 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84255166802&partnerID=40&md5=dffd5139c2518bbba4b5c5032dfde760}
}

@Misc{Authors,
  Title                    = {{Research Challenges for Data Mining in Science and Engineering âˆ—}},

  Author                   = {unknown Authors},

  __markedentry            = {[Alexander:]},
  Abstract                 = {With the rapid development of computer and information technology in the last several decades, an enormous amount of data in science and engineering has been and will continuously be generated in massive scale, either being stored in gigantic storage devices or flowing into and out of the system in the form of data streams. Moreover, such data has been made widely available, e.g., via the Internet. Such tremendous amount of data, in the order of tera- to petabytes, has fundamentally changed science and engineering, transforming many disciplines from data-poor to increasingly data-rich, and calling for new, data-intensive methods to conduct research in science and engineering. In this paper, we discuss the research challenges in science and engineering, from the data mining perspective, with a focus on the following issues: (1) information network analysis, (2) discovery, usage, and understanding of patterns and knowledge, (3) stream data mining, (4) mining moving object data, RFID data, and data from sensor networks, (5) spatiotemporal and multimedia data mining, (6) mining text, Web, and other unstructured data, (7) data cube-oriented multidimensional online analytical mining, (8) visual data mining, and (9) data mining by integration of sophisticated scientific and engineering domain knowledge.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {An discussion of research challenges in science and engineering, from the data mining perspective, with a focus on 10 issues. Potentially interesting for discussion. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.134.1976}
}

@Misc{Authorsa,
  Title                    = {{Mobile Data Mining for Intelligent Healthcare Support}},

  Author                   = {unknown Authors},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The growth in numbers and capacity of mobile devices such as mobile phones coupled with widespread availability of inexpensive range of biosensors presents an unprecedented opportunity for mobile healthcare applications. In this paper we propose a novel approach for Situation-Aware Adaptive Processing (SAAP) of data streams for smart and real-time analysis of data. The implementation and evaluation of the framework for a health monitoring application is described},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper we propose a novel approach for Situation-Aware Adaptive Processing (SAAP) of data streams for smart and real-time analysis of data, in the context of mobile and bio sensors. The implementation and evaluation of the framework for a health monitoring application is described Approved 1, 6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.205.3569}
}

@Misc{Authorsb,
  Title                    = {{Objective CS281 Final Project Requirements}},

  Author                   = {unknown Authors},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The objective of this final project is to explore new research in machine learning. The ideal outcome would be a paper that could be submitted to one of the top machine learning conferences, such as NIPS, ICML or AISTATS. A strong paper along these lines is one that develops a new or improved algorithm (runs faster, scales better, makes better predictions) that learns to generalize from experience, broadly defined. Such a paper would demonstrate theoretical and/or empirical improvements over the state of the art. One type of paper along these lines would introduce a new probabilistic model that captures important characteristics of data that had previously been unexplored. Another type of paper might propose a new algorithm for performing inference and learning in existing models. A third type of paper might consider models and learning algorithms in important settings of constrained resources, such as with limited memory, real-time performance requirements, or streaming data. Of course, such papers require innovative ideas about machine learning that may be difficult to come by in a single semester. It is helpful, therefore, to initially focus on a specific problem domain that you find important and exciting. Consider what the fundamental task is that needs to be solved and think about how it might map onto, e.g., regression or clustering. Catalogue the types of data that are available and consider how these might be exploited. What are the features that will help your algorithm make decisions or predictions? Don’t be afraid to make assumptions that help establish an abstraction. Prefer abstractions and assumptions that may generalize beyond the immediate task at hand. The next step is critical: define quantitative metrics for success on held-out test data. Classification},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Not a paper, just a project problem statement. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.410.7676}
}

@Misc{Authorsc,
  Title                    = {{Objective CS281 Final Project Requirements}},

  Author                   = {unknown Authors},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The objective of this final project is to explore new research in machine learning. The ideal outcome would be a paper that could be submitted to one of the top machine learning conferences, such as NIPS, ICML or AISTATS. A strong paper along these lines is one that develops a new or improved algorithm (runs faster, scales better, makes better predictions) that learns to generalize from experience, broadly defined. Such a paper would demonstrate theoretical and/or empirical improvements over the state of the art. One type of paper along these lines would introduce a new probabilistic model that captures important characteristics of data that had previously been unexplored. Another type of paper might propose a new algorithm for performing inference and learning in existing models. A third type of paper might consider models and learning algorithms in important settings of constrained resources, such as with limited memory, real-time performance requirements, or streaming data. Of course, such papers require innovative ideas about machine learning that may be difficult to come by in a single semester. It is helpful, therefore, to initially focus on a specific problem domain that you find important and exciting. Consider what the fundamental task is that needs to be solved and think about how it might map onto, e.g., regression or clustering. Catalogue the types of data that are available and consider how these might be exploited. What are the features that will help your algorithm make decisions or predictions? Don’t be afraid to make assumptions that help establish an abstraction. Prefer abstractions and assumptions that may generalize beyond the immediate task at hand. The next step is critical: define quantitative metrics for success on held-out test data.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Duplicate of Authorsb and not a paper.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.361.8591}
}

@Misc{Authorsd,
  Title                    = {{B.Suresh Babu,}},

  Author                   = {unknown Authors},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Data mining is the process of finding patterns or correlations from a different data set and changing it into the useful information. Clustering is dividing the data into groups that are similar in behavior among the data sets in a group and distinct across the groups. Data Stream mining is very important and challenging problem, because in business transactions we need to make better managerial choices and extract the essence of this streaming data where the data streams are temporally ordered, fast changing, large and continuous concurrent flow of data. Our objective in this paper is to propose a model using data mining, with the help key performance indicators (variables) found for each customer, clustering will be done using K-means clustering technique on real time basis with streaming data.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In business transactions we need to make better managerial choices and extract the essence of this streaming data where the data streams are temporally ordered, fast changing, large and continuous concurrent flow of data. Our objective in this paper is to propose a model using data mining, with the help key performance indicators (variables) found for each customer, clustering will be done using K-means clustering technique on real time basis with streaming data. Approved. 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.401.9040}
}

@Misc{Authorse,
  Title                    = {{â€˜Defined â€™ Strategic A Practical Implementation of Data Mining Techniques for the Collection and Analysis of Very}},

  Author                   = {unknown Authors},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to document being removed},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.127.1317}
}

@Misc{Authorsf,
  Title                    = {{Stream Data Mining and Comparative Study of Classification Algorithms}},

  Author                   = {unknown Authors},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Stream Data Mining is a new emerging topic in the field of research. Today, there are number of application that generate Massive amount of stream data. Examples of such kind of systems are Sensor networks, Real time surveillance systems, telecommunication systems. Hence there is requirement of intelligent processing of such type of data that would help in proper analysis and use of this data in other task even. Mining stream data is concerned with extracting knowledge structures represented in models and patterns in non stopping streams of information [1]. Such massive data are handled with software such as MOA (Massive Online Analysis) or other open sources like Data Miner. In this paper we present some theoretical aspects of stream data mining and certain experimental results obtained on that basis with the use of MOA.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {In this paper we present some theoretical aspects of stream data mining and certain experimental results obtained on that basis with the use of MOA (massive online analysis software). Comparative study of classification algorithms in stream data mining. No novel contribution. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.415.4675}
}

@Misc{Authorsg,
  Title                    = {{Mining Frequent Patterns from Data streams using Dynamic DP-tree Shaik.Hafija, M.Tech(CS), JNTU Kakinada. J.V.R. Murthy,}},

  Author                   = {unknown Authors},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A DataStream is a real time continuous, ordered sequence of items. It is impossible to control the order in which items arrive, nor it is feasible to locally store a stream in reality. By short it is a rapid flow of continuous ordered data. By these specific characteristics static models and static two pass algorithms are not suitable to data streams. Data stream mining have following three challenges one every item is examined only once. Second the storage space should control even there is a large amount of data, third the mining results have to be produced as early as possible. In this paper we propose a novel method to mine the frequent items over data streams by dividing data as no of windows and mine frequent item sets over window using a very compact data structure DP-Tree and placing the every DP-Tree safely in disk space so that we can retrieve the tree structure for pruning as and when we require. More over we propose methods to dynamically construct and update the DP-Tree},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Propose a novel method to mine the frequent items over data streams by dividing data as no of windows and mine frequent item sets over window using a very compact data structure DP-Tree and placing the every DP-Tree safely in disk space so that we can retrieve the tree structure for pruning as and when we require. Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.258.9795}
}

@Misc{Authorsh,
  Title                    = {{Mining Frequent Itemsets in Time-Varying Data Streams}},

  Author                   = {Yingying Tao and M. Tamer Özsu},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A transactional data stream is an unbounded sequence of transactions continuously generated, usually at a high rate. Mining frequent itemsets in such a data stream is beneficial to many realworld applications but is also a challenging task since data streams are unbounded and have high arrival rates. Moreover, the distribution of data streams can change over time, which makes the task of maintaining frequent itemsets even harder. In this paper, we propose a false-negative oriented algorithm, called TWIM, that can find most of the frequent itemsets, detect distribution changes, and update the mining results accordingly. TWIM uses two tumbling windows, one for maintenance and one for change prediction. We maintain a frequent itemset list and a candidate list for a data stream. Every time the two windows tumble, we check members in both lists. New frequent itemsets will be added and itemsets no longer frequent will be removed. Experimental results show that our algorithm performs as good as other false-negative algorithms on data streams without distribution change, and has the ability to detect changes over time-varying data streams in real-time with a high accuracy rate},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Frequent itemsets from streams. Propose a false-negative oriented algorithm, called TWIM, that can find most of the frequent itemsets, detect distribution changes, and update the mining results accordingly. Experimental results show that our algorithm performs as good as other false-negative algorithms on data streams without distribution change. 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.386.6696}
}

@Misc{Authorsi,
  Title                    = {{What Can We Learn from Facebook Activity? Using Social Learning Analytics to Observe New Media Literacy Skills}},

  Author                   = {unknown Authors},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Social media platforms such as Facebook are now a ubiquitous part of everyday life for many people. New media scholars posit that the participatory culture encouraged by social media gives rise to new forms of literacy skills that are vital to learning. However, there have been few attempts to use analytics to understand the new media literacy skills that may be embedded in an individual’s participation in social media. In this paper, I collect raw activity data that was shared by an exploratory sample of Facebook users. I then utilize factor analysis and regression models to show how (a) Facebook members ’ online activity coalesce into distinct categories of social media behavior and (b) how these participatory behaviors correlate with and predict measures of new media literacy skills. The study demonstrates the use of analytics to understand the literacies embedded in people’s social media activity. The implications speak to the potential of social learning analytics to identify and predict new media literacy skills from data streams in social media platforms.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of some other paper. Also, not applied to data streams. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.294.3651}
}

@Misc{Authors2009,
  Title                    = {{Complex Patterns in Streams (COMPASS) Open Competition Project NWO}},

  Author                   = {unknown Authors},
  Year                     = {2009},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In recent years there has been a growing interest in the study and analysis of flows of so-called data streams. Typical examples of such streams include Internet traffic data and continuous sensor readings. Traditional data mining approaches are not suitable for mining such streams, because they assume static data stored in a database, whereas streams are continuous, high speed, and unbounded. Therefore, streams must be analyzed as they are produced and high quality, online results need to be guaranteed. Until now, most pattern mining techniques focus either on non-streaming data, or only consider very simple patterns, such as identifying the hot items from one stream, or constantly maintaining the frequencies in a window sliding over the stream. The challenging task we set forward in this project is to extend the existing state-of-the-art techniques into two, orthogonal directions: on the one hand, the mining of more complex patterns in streams, such as sequential patterns and evolving graph patterns and on the other hand, more natural stream support measures taking into account the temporal nature of most data streams. The developed techniques will be tested on real-life data, such as social network data and the World-Wide Web. Next to those datasets, in the project we will have access to the data streams generated by a sensor network mounted on a large bridge in The Netherlands.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Until now, most pattern mining techniques focus either on non-streaming data, or only consider very simple patterns, such as identifying the hot items from one stream, or constantly maintaining the frequencies in a window sliding over the stream. They attempt to extend existing state-of-the-art techniques into two, orthogonal directions: on the one hand, the mining of more complex patterns in streams, such as sequential patterns and evolving graph patterns and on the other hand, more natural stream support measures taking into account the temporal nature of most data streams. The developed techniques will be tested on real-life data, such as social network data and the World-Wide Web. project we will have access to the data streams generated by a sensor network mounted on a large bridge in The Netherlands. NOT a scientific paper, just a problem statement. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.182.8604}
}

@Conference{Aƒa€“lmezoA‡A§ullari2013,
  Title                    = {Data stream mining to address big data problems [BÃƒÂ¼yÃƒÂ¼k veri problemlerine ÃƒÂ§ÃƒÂ¶zÃƒÂ¼m olarak veri akiÃ…Å¸ madenciliÃ‡Â§i]},
  Author                   = {Ãƒâ€“lmezoÃ‡Â§ullari, E.a and Ari, I.a and Ãƒâ€¡elebi, Ãƒâ€“.F.b and ErgÃƒÂ¼t, S.b },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Today, the IT world is trying to cope with "big data" problems (data volume, velocity, variety, veracity) on the path to obtaining useful information. In this paper, we present implementation details and performance results of realizing "online" Association Rule Mining (ARM) over big data streams for the first time in the literature. Specifically, we added Apriori and FP-Growth algorithms for stream mining inside an event processing engine, called Esper. Using the system, these two algorithms were compared over LastFM social music site data and by using tumbling windows. The better-performing FPGrowth was selected and used in creation of a real-time rulebased recommendation engine. Our most important findings show that online association rule mining can generate (1) more rules, (2) much faster and more efficiently, and (3) much sooner than offline rule mining. In addition, we have found many interesting and realistic musical preference rules such as "George HarrisonÃ¢â€¡â€™Beatles". We hope that our findings can shed light on the design and implementation of other big data analytics systems in the future. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Bilgisayar MÃƒÂ¼hendisliÃ‡Â§i BÃƒÂ¶lÃƒÂ¼mÃƒÂ¼, Ãƒâ€“ZyeÃ‡Â§in ÃƒÅ“niversitesi, Istanbul, Turkey; Avea Labs, Istanbul, Turkey},
  Art_number               = {6531483},
  Author_keywords          = {Apriori; Association rule mining; Complex event processing; Data stream mining; FP-growth},
  Document_type            = {Conference Paper},
  Journal                  = {2013 21st Signal Processing and Communications Applications Conference, SIU 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We present implementation details and performance results of realizing "online" Association Rule Mining (ARM) over big data streams for the first time in the literature. Using the system, these two algorithms were compared over LastFM social music site data and by using tumbling windows. We have found many interesting and realistic musical preference rules such as "George Harrison -> Beatles". Findings show that online association rule mining can generate (1) more rules, (2) much faster and more efficiently, and (3) much sooner than offline rule mining Approved 1,2,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880882823&partnerID=40&md5=86b2303a0baeea83d112330561652539}
}

@InProceedings{Boese2010,
  Title                    = {{Beyond online aggregation}},
  Author                   = {B\"{o}se, Joos-Hendrik and Andrzejak, Artur and H\"{o}gqvist, Mikael},
  Booktitle                = {Proceedings of the 2010 Workshop on Massive Data Analytics on the Cloud - MDAC '10},
  Year                     = {2010},

  Address                  = {New York, New York, USA},
  Month                    = apr,
  Pages                    = {1--6},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/1779599.1779602},
  ISBN                     = {9781605589916},
  Keywords                 = {Map-Reduce,machine learning,stream mining},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Boese. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1779599.1779602}
}

@Misc{Boese,
  Title                    = {{Beyond Online Aggregation: Parallel and Incremental Data Mining with Online Map-Reduce (DRAFT)}},

  Author                   = {B\"{o}se, Joos-hendrik and Sci, Intl Comp and Andrzejak, Artur and H\"{o}gqvist, Mikael},

  __markedentry            = {[Alexander:]},
  Abstract                 = {There are only few data mining algorithms that work in a massively parallel and yet online (i.e. incremental) fashion. A combination of both features is essential for mining of large data streams and adds scalability to the concept of Online Aggregation introduced by J. M. Hellerstein et al. in 1997. We show how an online version of the Map-Reduce programming model can be used to implement such algorithms, and propose a solution for the “hardest ” class of these algorithms- those requiring multiple Map-Reduce phases. An experimental evaluation confirms that the proposed methods can substantially accelerate interactive analysis of large data sets and facilitate scalable stream mining.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Show how an online version of the Map-Reduce programming model can be used to implement massively paralell yet online data mining algorithms. Propose a solution for the "hardest" class of these algorithms - those requiring multiple Map-Reduce phases. An experimental evaluation confirms that the proposed methods can substantially accelerate interactive analysis of large data sets and facilitate scalable stream mining. Approved 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.4279}
}

@Article{Babcock2003,
  Title                    = {{Chain: Operator Scheduling for Memory Minimization in Data Stream Systems}},
  Author                   = {Babcock, Brian and Babu, Shivnath and Datar, Mayur},
  Journal                  = {IN SIGMOD},
  Year                     = {2003},
  Pages                    = {253 -- 264},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In many applications involving continuous data streams, data arrival is bursty and data rate fluctuates over time. Systems that seek to give rapid or real-time query responses in such an environment must be prepared to deal gracefully with bursts in data arrival without compromising system performance. We discuss one strategy for processing bursty streams — adaptive, load-aware scheduling of query operators to minimize resource consumption during times of peak load. We show that the choice of an operator scheduling strategy can have significant impact on the run-time system memory usage. We then present Chain scheduling, an operator scheduling strategy for data stream systems that is near-optimal in minimizing run-time memory usage for any collection of singlestream queries involving selections, projections, and foreign-key joins with stored relations. Chain scheduling also performs well for queries with sliding-window joins over multiple streams, and multiple queries of the above types. A thorough experimental evaluation is provided where we demonstrate the potential benefits of Chain scheduling, compare it with competing scheduling strategies, and validate our analytical conclusions.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Scheduling for memory minimization in bursty data streams. Not ML. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.130.1544}
}

@Conference{Banerjee2013a,
  Title                    = {Efficient learning from explanation of prediction errors in streaming data},
  Author                   = {Banerjee, B. and Dutta, J.K.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {14-20},

  Abstract                 = {Streaming data from different kinds of sensors contributes to Big Data in a significant way. Recognizing the norms and abnormalities in such spatiotemporal data is a challenging problem. We present a general-purpose biologically-plausible computational model, called SELP, for learning the norms or invariances as features in an unsupervised and online manner from explanations of saliencies or surprises in the data. Given streaming data, this model runs a relentless cycle of Surprise Ã¢â€ â€™ Explain Ã¢â€ â€™ Learn Ã¢â€ â€™ Predict involving the real external world and its internal model, and hence the name. The key characteristic of the model is its efficiency, crucial for streaming Big Data applications, which stems from two functionalities exploited at each sampling instant - it operates on the change in the state of data between consecutive sampling instants as opposed to the entire state of data, and it learns only from surprise or prediction error to update its internal state as opposed to learning from the entire input. The former allows the model to concentrate its computational resources on spatial regions of the data changing most frequently and ignore others, while the latter allows it to concentrate on those instants of time when its prediction is erroneous and ignore others. The model is implemented in a neural network architecture. We show the performance of the network in learning and retaining sequences of handwritten numerals. When exposed to natural videos acquired by a camera mounted on a cat's head, the neurons learn receptive fields resembling simple cells in the primary visual cortex. The model leads to an agent-dependent framework for mining streaming data where the agent interprets and learns from the data in order to update its internal model. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Institute for Intelligent Systems, Dept. of Electrical and Computer Engineering, University of Memphis, Memphis, TN 38152, United States},
  Art_number               = {6691728},
  Author_keywords          = {explain; generative model; learn; predict; predictive coding; salience; surprise},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2013 IEEE International Conference on Big Data, Big Data 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {general-purpose biologically-plausible computational model, called SELP, for learning the norms or invariances as features in an unsupervised and online manner from explanations of saliencies or surprises in the data. Given streaming data, this model runs a relentless cycle of Surprise → Explain → Learn → Predict. Uses neural network. Approved 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893333650&partnerID=40&md5=a9dc64e6f7b92928029794f84e6e4d72}
}

@InProceedings{Banerjee2013,
  Title                    = {{Efficient learning from explanation of prediction errors in streaming data}},
  Author                   = {Banerjee, Bonny and Dutta, Jayanta K.},
  Booktitle                = {2013 IEEE International Conference on Big Data},
  Year                     = {2013},
  Month                    = oct,
  Pages                    = {14--20},
  Publisher                = {IEEE},

  Abstract                 = {Streaming data from different kinds of sensors contributes to Big Data in a significant way. Recognizing the norms and abnormalities in such spatiotemporal data is a challenging problem. We present a general-purpose biologically-plausible computational model, called SELP, for learning the norms or invariances as features in an unsupervised and online manner from explanations of saliencies or surprises in the data. Given streaming data, this model runs a relentless cycle of Surprise Ã¢â€ â€™ Explain Ã¢â€ â€™ Learn Ã¢â€ â€™ Predict involving the real external world and its internal model, and hence the name. The key characteristic of the model is its efficiency, crucial for streaming Big Data applications, which stems from two functionalities exploited at each sampling instant - it operates on the change in the state of data between consecutive sampling instants as opposed to the entire state of data, and it learns only from surprise or prediction error to update its internal state as opposed to learning from the entire input. The former allows the model to concentrate its computational resources on spatial regions of the data changing most frequently and ignore others, while the latter allows it to concentrate on those instants of time when its prediction is erroneous and ignore others. The model is implemented in a neural network architecture. We show the performance of the network in learning and retaining sequences of handwritten numerals. When exposed to natural videos acquired by a camera mounted on a cat's head, the neurons learn receptive fields resembling simple cells in the primary visual cortex. The model leads to an agent-dependent framework for mining streaming data where the agent interprets and learns from the data in order to update its internal model.},
  Doi                      = {10.1109/BigData.2013.6691728},
  ISBN                     = {978-1-4799-1293-3},
  Keywords                 = {Biological system modeling,Computational modeling,Data models,Feedforward neural networks,Neurons,Predictive coding,Predictive models,SELP,agent-dependent framework,biology computing,data mining,explain,general-purpose biologically-plausible computation,generative model,handwritten numerals,internal state,learn,learning,mining streaming data,natural videos,neural net architecture,neural network architecture,online manner,predict,prediction errors,predictive coding,primary visual cortex,receptive fields,salience,spatial regions,spatiotemporal data,surprise,surprise error,unsupervised learning,unsupervised manner},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Banerjee2013a. Discarded.},
  Shorttitle               = {Big Data, 2013 IEEE International Conference on},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6691728}
}

@Misc{Barlet-Ros2007,
  Title                    = {{Load Shedding in Network Monitoring Applications}},

  Author                   = {Barlet-Ros, Pere and Iannaccone, Gianluca and Sanju\`{a}s-Cuxart, Josep and Amores-L\'{o}pez, Diego and Sol\'{e}-Pareta, Josep},
  Year                     = {2007},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Monitoring and mining real-time network data streams is crucial for managing and operating data networks. The information that network operators desire to extract from the network traffic is of different size, granularity and accuracy depending on the measurement task (e.g., relevant data for capacity planning and intrusion detection are very different). To satisfy these different demands, a new class of monitoring systems is emerging to handle multiple arbitrary and continuous traffic queries. Such systems must cope with the effects of overload situations due to the large volumes, high data rates and bursty nature of the network traffic. In this paper, we present the design and evaluation of a system that can shed excess load in the presence of extreme traffic conditions, while maintaining the accuracy of the traffic queries within acceptable levels. The main novelty of our approach is that it is able to operate without explicit knowledge of the traffic queries. Instead, it extracts a set of features from the traffic streams to build an on-line prediction model of the query resource requirements. This way the monitoring system preserves a high degree of flexibility, increasing the range of applications and network scenarios where it can be used. We implemented our scheme in an existing network monitoring system and deployed it in a research ISP network. Our results show that the system predicts the resources required to run each traffic query with errors below 5%, and that it can efficiently handle extreme load situations, preventing uncontrolled packet losses, with minimum impact on the accuracy of the queries’ results.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Network traffic monitoring when data streams are sometimes overwhelming. The main novelty of our approach is that it is able to operate without explicit knowledge of the traffic queries. Instead, it extracts a set of features from the traffic streams to build an on-line prediction model of the query resource requirements. Our results show that the system predicts the resources required to run each traffic query with errors below 5%, and that it can efficiently handle extreme load situations, preventing uncontrolled packet losses, with minimum impact on the accuracy of the queries’ results. Approved 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.126.8734}
}

@Conference{Barouni-Ebarhimi2007a,
  Title                    = {A novel approach for frequent phrase mining in web search engine query streams},
  Author                   = {Barouni-Ebarhimi, M. and Ghorbani, A.A.},
  Year                     = {2007},
  Note                     = {cited By (since 1996)5},
  Pages                    = {125-132},

  Abstract                 = {In this paper, conceptual frequency rate, a new frequency definition suitable for query stream mining, is introduced. An online single-pass algorithm called OFSD (Online Frequent Sequence Discovery) is given, to mine the set of all conceptual frequent sequences in a data stream whose conceptual frequency rates satisfy a minimum user defined frequency rate. Phrase recommender algorithm is then described based on the set of conceptual frequent phrases extracted by the OFSD algorithm. We have also designed a query recommender algorithm, OQD (Online Query Discovery). OQD is used for comparison purposes along side the proposed phrase recommender algorithm. Simulation results show the efficiency of the proposed Phrase recommender algorithm compared to OQD. Ã‚Â© 2007 IEEE.},
  Affiliation              = {Faculty of Computer Science, University of New Brunswick, Fredericton, Canada},
  Art_number               = {4215505},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - CNSR 2007: Fifth Annual Conference on Communication Networks and Services Research},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate or older version of of Barouni-Ebarhimi2008. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34548303958&partnerID=40&md5=477086e63d91f16a04b33842a5aecfe2}
}

@InProceedings{Barouni-Ebarhimi2007,
  Title                    = {{A Novel Approach for Frequent Phrase Mining in Web Search Engine Query Streams}},
  Author                   = {Barouni-Ebarhimi, M. and Ghorbani, Ali A.},
  Booktitle                = {Fifth Annual Conference on Communication Networks and Services Research (CNSR '07)},
  Year                     = {2007},
  Month                    = may,
  Pages                    = {125--132},
  Publisher                = {IEEE},

  Abstract                 = {In this paper, conceptual frequency rate, a new frequency definition suitable for query stream mining, is introduced. An online single-pass algorithm called OFSD (Online Frequent Sequence Discovery) is given, to mine the set of all conceptual frequent sequences in a data stream whose conceptual frequency rates satisfy a minimum user defined frequency rate. Phrase recommender algorithm is then described based on the set of conceptual frequent phrases extracted by the OFSD algorithm. We have also designed a query recommender algorithm, OQD (Online Query Discovery). OQD is used for comparison purposes along side the proposed phrase recommender algorithm. Simulation results show the efficiency of the proposed Phrase recommender algorithm compared to OQD.},
  Doi                      = {10.1109/CNSR.2007.5},
  ISBN                     = {0-7695-2835-X},
  Keywords                 = {Algorithm design and analysis,Communication networks,Computer science,Data mining,Feedback,Frequency,Navigation,OFSD,OQD,Online Frequent Sequence Discovery,Online Query Discovery,Search engines,Web pages,Web search,Web search engine query stream mining,data mining,frequent phrase mining,information filters,online single-pass algorithm,phrase recommender algorithm,query processing,query recommender algorithm,search engines},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate or older version of of Barouni-Ebarhimi2008. Discarded.},
  Shorttitle               = {Communication Networks and Services Research, 2007},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4215505}
}

@Article{Barouni-Ebrahimi2008,
  Title                    = {An interactive search assistant architecture based on intrinsic query stream characteristics},
  Author                   = {Barouni-Ebrahimi, M.a b and Ghorbani, A.A.a },
  Journal                  = {Computational Intelligence},
  Year                     = {2008},
  Note                     = {cited By (since 1996)2},
  Number                   = {2},
  Pages                    = {158-190},
  Volume                   = {24},

  Abstract                 = {Search engine query log mining has evolved over time to more like data stream mining due to the endless and continuous sequence of queries known as query stream. In this paper, we propose an online frequent sequence discovery (OFSD) algorithm to extract frequent phrases from within query streams, based on a new frequency rate metric, which is suitable for query stream mining. OFSD is an online, single pass, and real-time frequent sequence miner appropriate for data streams. The frequent phrases extracted by the OFSD algorithm are used to guide novice Web search engine users to complete their search queries more efficiently. YourEye, our online phrase recommender is then introduced. The advantages of YourEye compared with Google Suggest, a service powered by Google for phrase suggestion, is also described. Various characteristics of two specific Web search engine query logs are analyzed and then the query logs are used to evaluate YourEye. The experimental results confirm the significant benefit of monitoring frequent phrases within the queries instead of the whole queries because none-separable items. The number of the monitored elements substantially decreases, which results in smaller memory consumption as well as better performance. Re-ranking the retrieved pages based on past users clicks for each frequent phrase extracted by OFSD is also introduced. The preliminary results show the advantages of the proposed method compared to the similar work reported in Smyth et al. Ã‚Â© 2008 Blackwell Publishing.},
  Affiliation              = {University of New Brunswick, Fredericton, Canada; Faculty of Computer Science, University of New Brunswick, Fredericton, NB E3B 5A3, Canada},
  Author_keywords          = {Adaptive Web search engine; Page re-rank; Query completion; Query stream mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-44349181400&partnerID=40&md5=b44427cdbebfdac9c83cd8648ede923c}
}

@Conference{BAƒA¶se2010,
  Title                    = {Beyond online aggregation: Parallel and incremental data mining with online Map-Reduce},
  Author                   = {BÃƒÂ¶se, J.-H.a and Andrzejak, A.b and HÃƒÂ¶gqvist, M.b},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {There are only few data mining algorithms that work in a massively parallel and yet online (i.e. incremental) fashion. A combination of both features is essential for mining of large data streams and adds scalability to the concept of Online Aggregation introduced by J. M. Hellerstein et al. in 1997. We show how an online version of the Map-Reduce programming model can be used to implement such algorithms, and propose a solution for the "hardest" class of these algorithms - those requiring multiple Map-Reduce phases. An experimental evaluation confirms that the proposed methods can substantially accelerate interactive analysis of large data sets and facilitate scalable stream mining. Ã‚Â© 2010 ACM.},
  Affiliation              = {Intl. Comp. Sci. Institute, Berkeley, United States; Zuse Institute Berlin (ZIB), Berlin, Germany},
  Art_number               = {1779602},
  Author_keywords          = {machine learning; Map-Reduce; stream mining},
  Document_type            = {Conference Paper},
  Journal                  = {ACM International Conference Proceeding Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Boese. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954518625&partnerID=40&md5=41feeb874c059a3563a8fa544ee3cee5}
}

@Article{Becker2007,
  Title                    = {{Real-time Ranking with Concept Drift Using Expert Advice}},
  Author                   = {Becker, Hila},
  Journal                  = {PROC. OF KDD 2007},
  Year                     = {2007},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In many practical applications, one is interested in generating a ranked list of items using information mined from continuous streams of data. For example, in the context of computer networks, one might want to generate lists of nodes ranked according to their susceptibility to attack. In addition, real-world data streams often exhibit concept drift, making the learning task even more challenging. We present an online learning approach to ranking with concept drift, using weighted majority techniques. By continuously modeling different snapshots of the data and tuning our measure of belief in these models over time, we capture changes in the underlying concept and adapt our predictions accordingly. We measure the performance of our algorithm on real electricity data as well as a synthetic data stream, and demonstrate that our approach to ranking from stream data outperforms previously known batch-learning methods and other online methods that do not account for concept drift.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We present an online learning approach to ranking with concept drift, using weighted majority techniques. By continuously modeling different snapshots of the data and tuning our measure of belief in these models over time, we capture changes in the underlying concept and adapt our predictions accordingly. We measure the performance of our algorithm on real electricity data as well as a synthetic data stream, and demonstrate that our approach to ranking from stream data outperforms previously known batch-learning methods and other online methods that do not account for concept drift. Approved 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.1571}
}

@Misc{Beringer,
  Title                    = {{Fuzzy Clustering of Parallel Data Streams}},

  Author                   = {Beringer, J\"{u}rgen and H\"{u}llermeier, Eyke},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The management and processing of so-called data streams has recently become a topic of active research in several fields of computer science, notably database systems and data mining. A data stream can roughly be thought of as a transient, continuously increasing sequence of time-stamped data. In this paper, we consider the problem of clustering parallel streams of real-valued data, that is to say, continuously evolving time series. More specifically, we are interested in grouping data streams the evolution over time of which is similar in a specific sense. In order to maintain an up-to-date clustering structure, it is necessary to analyze the incoming data in an online manner, tolerating not more than a constant time delay. For this purpose, we develop an efficient online version of the fuzzy C-means clustering algorithm. A fuzzy approach appears to be particularly useful for this type of application, in which the clustering structure is subject to continuous changes.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Clustering parallel streams of real valued data. Interested in grouping data streams the evolution over time of which is similar in a specific sense. We develop an efficient online version of the fuzzy C-means clustering algorithm. Suggest fuzzy is good for clusters that are subject to change. Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.381.2407}
}

@Article{Beringer2005,
  Title                    = {{Online clustering of parallel data streams}},
  Author                   = {Beringer, J\"{u}rgen and H\"{u}llermeier, Eyke},
  Journal                  = {IN PRESS FOR DATA \& KNOWLEDGE ENGINEERING},
  Year                     = {2005},
  Volume                   = {58},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In recent years, the management and processing of so-called data streams has become a topic of active research in several fields of computer science such as, e.g., distributed systems, database systems, and data mining. A data stream can roughly be thought of as a transient, continuously increasing sequence of time-stamped data. In this paper, we consider the problem of clustering parallel streams of real-valued data, that is to say, continuously evolving time series. In other words, we are interested in grouping data streams the evolution over time of which is similar in a specific sense. In order to maintain an up-to-date clustering structure, it is necessary to analyze the incoming data in an online manner, tolerating not more than a constant time delay. For this purpose, we develop an efficient online version of the classical K-means clustering algorithm. Our method’s efficiency is mainly due to a scalable online transformation of the original data which allows for a fast computation of approximate distances between streams.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we consider the problem of clustering parallel streams of real-valued data, that is to say, continuously evolving time series. It is necessary to analyze the incoming data in an online manner, tolerating not more than a constant time delay. For this purpose, we develop an efficient online version of the classical K-means clustering algorithm.Our method’s efficiency is mainly due to a scalable online transformation of the original data which allows for a fast computation of approximate distances between streams Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.2607}
}

@Article{Beringer2007,
  Title                    = {An efficient algorithm for instance-based learning on data streams},
  Author                   = {Beringer, J.a and HÃƒÂ¼llermeier, E.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {34-48},
  Volume                   = {4597 LNCS},

  Abstract                 = {The processing of data streams in general and the mining of such streams in particular have recently attracted considerable attention in various research fields. A key problem in stream mining is to extend existing machine learning and data mining methods so as to meet the increased requirements imposed by the data stream scenario, including the ability to analyze incoming data in an online, incremental manner, to observe tight time and memory constraints, and to appropriately respond to changes of the data characteristics and underlying distributions, amongst others. This paper considers the problem of classification on data streams and develops an instance-based learning algorithm for that purpose. The experimental studies presented in the paper suggest that this algorithm has a number of desirable properties that are not, at least not as a whole, shared by currently existing alternatives. Notably, our method is very flexible and thus able to adapt to an evolving environment quickly, a point of utmost importance in the data stream context. At the same time, the algorithm is relatively robust and thus applicable to streams with different characteristics. Ã‚Â© Springer-Verlag Berlin Heidelberg 2007.},
  Affiliation              = {FakultÃƒÂ¤t fÃƒÂ¼r Informatik, Otto-von-Guericke-UniversitÃƒÂ¤t Magdeburg, Germany; Fachbereich Mathematik und Informatik, Philipps-UniversitÃƒÂ¤t Marburg, Germany},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper considers the problem of classification on data streams and develops an instance-based learning algorithm for that purpose. Experimental studies presented in the paper suggest that this algorithm has a number of desirable properties that are not, at least not as a whole, shared by currently existing alternatives. Approved 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-37249072465&partnerID=40&md5=7114d182190e973bb675f93a1ce0b64a}
}

@Article{Beringer2007a,
  Title                    = {Efficient instance-based learning on data streams},
  Author                   = {Beringer, J.a and HÃƒÂ¼llermeier, E.b },
  Journal                  = {Intelligent Data Analysis},
  Year                     = {2007},
  Note                     = {cited By (since 1996)22},
  Number                   = {6},
  Pages                    = {627-650},
  Volume                   = {11},

  Abstract                 = {The processing of data streams in general and the mining of such streams in particular have recently attracted considerable attention in various research fields. A key problem in stream mining is to extend existing machine learning and data mining methods so as to meet the increased requirements imposed by the data stream scenario, including the ability to analyze incoming data in an online, incremental manner, to observe tight time and memory constraints, and to appropriately respond to changes of the data characteristics and underlying distributions, amongst others. This paper considers the problem of classification on data streams and develops an instance-based learning algorithm for that purpose. The experimental studies presented in the paper suggest that this algorithm has a number of desirable properties that are not, at least not as a whole, shared by currently existing alternatives. Notably, our method is very flexible and thus able to adapt to an evolving environment quickly, a point of utmost importance in the data stream context. At the same time, the algorithm is relatively robust and thus applicable to streams with different characteristics. Ã‚Â© 2007 IOS Press. All rights reserved.},
  Affiliation              = {Department of Computer Science, Magdeburg University, Marburg, Germany; Department of Mathematics and Computer Science, Marburg University, Marburg, Germany},
  Author_keywords          = {Classification; Concept drift; Data streams; Instance-based learning},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, duplicate of Beringer2007.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-51349124012&partnerID=40&md5=45d15a8be5e1034d8a28d37795f56c7b}
}

@Article{Beringer2006,
  Title                    = {Online clustering of parallel data streams },
  Author                   = {JÃƒÂ¼rgen Beringer and Eyke HÃƒÂ¼llermeier},
  Journal                  = {Data \& Knowledge Engineering },
  Year                     = {2006},
  Number                   = {2},
  Pages                    = {180 - 204},
  Volume                   = {58},

  Abstract                 = {In recent years, the management and processing of so-called data streams has become a topic of active research in several fields of computer science such as, e.g., distributed systems, database systems, and data mining. A data stream can roughly be thought of as a transient, continuously increasing sequence of time-stamped data. In this paper, we consider the problem of clustering parallel streams of real-valued data, that is to say, continuously evolving time series. In other words, we are interested in grouping data streams the evolution over time of which is similar in a specific sense. In order to maintain an up-to-date clustering structure, it is necessary to analyze the incoming data in an online manner, tolerating not more than a constant time delay. For this purpose, we develop an efficient online version of the classical K-means clustering algorithm. Our methodÃ¢â‚¬â„¢s efficiency is mainly due to a scalable online transformation of the original data which allows for a fast computation of approximate distances between streams.},
  Doi                      = {http://dx.doi.org/10.1016/j.datak.2005.05.009},
  ISSN                     = {0169-023X},
  Keywords                 = {Data mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, duplicateof Beringer2005.},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0169023X05000819}
}

@InProceedings{Berndt2012,
  Title                    = {{Characterizing latency in periodic P2P hypercube gossiping}},
  Author                   = {Berndt, Philipp and Hovestadt, Matthias and Kao, Odej},
  Booktitle                = {2012 Fourth International Conference on Communication Systems and Networks (COMSNETS 2012)},
  Year                     = {2012},
  Month                    = jan,
  Pages                    = {1--8},
  Publisher                = {IEEE},

  Abstract                 = {The efficient structure of the hypercube allows for an optimal solution to the two-way gossip problem at logarithmic node degree. It thereby enables scalable dissemination of live streaming data in peer-to-peer networks. Applications range from audio conferencing to distributed object tracking or real-time business intelligence. For such real-time applications traversal time is a concern. A considerable portion is due to wait delay or bide time at intermediate nodes. Previous work has analyzed abstract effort for hypercube gossiping schemes and derived worst-case bounds for several timing modes. In this paper we analyze the hop count distribution to complement previously established worst-case times by expectation values for uniformly distributed network delays. We compare these results to results from a simulation with a life-like network delay distribution. Results attest that expected wait latency is indeed highly dependent on the timing of the communication and considerably lower than worst-case traversal time.},
  Doi                      = {10.1109/COMSNETS.2012.6151309},
  ISBN                     = {978-1-4673-0298-2},
  Keywords                 = {Berlin,Delay,Hypercubes,Network topology,P2P hypercube gossiping problem,Peer to peer computing,Real time systems,Synchronization,analysis,audio conferencing,audio streaming,communication,computer network reliability,delays,distributed network delay,distributed object tracking,gossiping,hop count distribution,hypercube,hypercube networks,intermediate node,latency,live streaming data,logarithmic node degree,object tracking,overlay,p2p,peer-to-peer computing,peer-to-peer network,performance modeling,real-time,real-time business intelligence,teleconferencing,topologies,traversal time},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Berndt2012a. Discarded.},
  Shorttitle               = {Communication Systems and Networks (COMSNETS), 201},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6151309}
}

@Conference{Berndt2012a,
  Title                    = {Characterizing latency in periodic P2P hypercube gossiping},
  Author                   = {Berndt, P. and Hovestadt, M. and Kao, O.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The efficient structure of the hypercube allows for an optimal solution to the two-way gossip problem at logarithmic node degree. It thereby enables scalable dissemination of live streaming data in peer-to-peer networks. Applications range from audio conferencing to distributed object tracking or real-time business intelligence. For such real-time applications traversal time is a concern. A considerable portion is due to wait delay or bide time at intermediate nodes. Previous work has analyzed abstract effort for hypercube gossiping schemes and derived worst-case bounds for several timing modes. In this paper we analyze the hop count distribution to complement previously established worst-case times by expectation values for uniformly distributed network delays. We compare these results to results from a simulation with a life-like network delay distribution. Results attest that expected wait latency is indeed highly dependent on the timing of the communication and considerably lower than worst-case traversal time. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Complex and Distributed IT Systems, Technische UniversitÃƒÂ¤t, Berlin, Germany},
  Art_number               = {6151309},
  Author_keywords          = {analysis; communication; gossiping; hypercube; latency; overlay; p2p; performance modeling; real-time; topologies},
  Document_type            = {Conference Paper},
  Journal                  = {2012 4th International Conference on Communication Systems and Networks, COMSNETS 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The've experimented on a mathematical problem, which they state can have applications in RT Business Intelligence, enables scalable dissemination of live streaming data in peer-to-peer network.They compare these results to results from a simulation with a life-like network delay distribution. To much based on previous work, seems more like a network problem. Accepted},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84858039951&partnerID=40&md5=b48c42f284932ab990e6a70ad63a8d97}
}

@InProceedings{Berry2013,
  Title                    = {{Real-Time Analytics for Legacy Data Streams in Health: Monitoring Health Data Quality}},
  Author                   = {Berry, Andrew and Milosevic, Zoran},
  Booktitle                = {2013 17th IEEE International Enterprise Distributed Object Computing Conference},
  Year                     = {2013},
  Month                    = sep,
  Pages                    = {91--100},
  Publisher                = {IEEE},

  Abstract                 = {Healthcare organizations are increasingly using information technology to ensure patient safety, increase effectiveness and improve efficiency of healthcare delivery. While the use of health information technology (HIT) has realized many improvements, it has also introduced new failure modes arising from data quality and IT system usability issues. This paper presents an approach towards addressing these failure modes by applying real-time analytics to existing streams of clinical messages exchanged by HIT systems. We use complex event processing provided by the Event Swarm software framework to monitor data quality in such systems through intercepting messages and applying rules reflecting the syndromic surveillance model proposed in [4]. We believe this is the first work reporting on the real-time application of syndromic surveillance rules to legacy clinical data streams. Our design and implementation demonstrates the feasibility of this approach and highlights benefits obtained through improved operational quality of HIT systems, notably better patient safety, reduced risks in healthcare delivery and potentially reduced costs.},
  Doi                      = {10.1109/EDOC.2013.19},
  ISBN                     = {978-0-7695-5081-7},
  ISSN                     = {1541-7719},
  Keywords                 = {HIT systems,IT system usability,Laboratories,Medical services,Pattern matching,Real-time systems,Safety,Surveillance,data analysis,data quaility,event swarm software framework,failure modes,health analytics,health care,health data quality monitoring,healthcare delivery efficiency,healthcare organizations,information technology,legacy clinical data streams,medical information systems,patient safety,real-time,real-time analytics,syndromic surveillance,syndromic surveillance model},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents an approach towards addressing these failure in healthcare IT systems by applying real-time analytics to existing streams of clinical messages exchanged by health IT systems. We believe this is the first work reporting on the real-time application of syndromic surveillance rules to legacy clinical data streams Approved. 1,6},
  Shorttitle               = {Enterprise Distributed Object Computing Conference},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6658267}
}

@Conference{Berry2013a,
  Title                    = {Real-Time analytics for legacy data streams in health: Monitoring health data quality},
  Author                   = {Berry, A. and Milosevic, Z.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {91-100},

  Abstract                 = {Healthcare organizations are increasingly using information technology to ensure patient safety, increase effectiveness and improve efficiency of healthcare delivery. While the use of health information technology (HIT) has realized many improvements, it has also introduced new failure modes arising from data quality and IT system usability issues. This paper presents an approach towards addressing these failure modes by applying real-Time analytics to existing streams of clinical messages exchanged by HIT systems. We use complex event processing provided by the Event Swarm software framework to monitor data quality in such systems through intercepting messages and applying rules reflecting the syndromic surveillance model proposed in [4]. We believe this is the first work reporting on the real-Time application of syndromic surveillance rules to legacy clinical data streams. Our design and implementation demonstrates the feasibility of this approach and highlights benefits obtained through improved operational quality of HIT systems, notably better patient safety, reduced risks in healthcare delivery and potentially reduced costs. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Deontik Pty Ltd, Brisbane, Australia},
  Art_number               = {6658267},
  Author_keywords          = {analytics; data quality; health; real-Time; syndromic surveillance},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Berry2013. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84892538383&partnerID=40&md5=568b5b00caa9d487f6843f13c040f33f}
}

@Article{Bhargavi2012,
  Title                    = {An efficient intrusion detection system based on pattern matching and state transition analysis},
  Author                   = {Bhargavi, R. and Vaidehi, V. and Sri Ganesh, K.},
  Journal                  = {European Journal of Scientific Research},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {2},
  Pages                    = {224-236},
  Volume                   = {80},

  Abstract                 = {Emerging technologies have metamorphosed the nature of surveillance and monitoring applications, but the sensory data collected using various gadgets is poorly synchronized and the analysis of such data remain changeable. Over the years, the need for security and surveillance systems has changed significantly due to the influence of various events and attacks. Anomaly detection systems based on various soft computing techniques like Genetic algorithms, neural networks and fuzzy logic exist in literature. Recently data mining and state transition analysis are becoming important components in identifying intrusions. From a data mining perspective, sensor network problems are characterized by a large number of variables (sensors), producing a continuous stream of data, in a dynamic environment. There are two approaches to process the data generated from the sensors namely Centralized approach and Distributed approach. This paper proposes semantic based intrusion detection system based on centralized approach in the application layer. In the proposed scheme, state transition analysis, pattern matching and data mining techniques are integrated to maximize the detection accuracy. Patterns and rules are formulated based on the events detected by the sensors in WSN. The sink receives information about the several events happening in the coverage area and correlates the streaming data (events) in spatial domain (several sensors) and time domain. The proposed scheme is validated with a real time experimental set up that consists of sensor nodes. Number of scenarios is tested during the experimental phase. Experimental results show that the proposed hybrid intrusion detection scheme identifies the intrusion accurately. Ã‚Â© EuroJournals Publishing, Inc. 2012.},
  Affiliation              = {Department of Information Technology, Madras Institute of Technology, Anna University, Chennai, India},
  Author_keywords          = {ANTLR; Intrusion Detection System (IDS); Wireless Sensor Network (WSN)},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {There are two approaches to process the data generated from sensors namely Centralized approach and Distributed approach. This paper proposes semantic based intrusion detection system based on centralized approach in the application layer. In the proposed scheme, state transition analysis, pattern matching and data mining techniques are integrated to maximize the detection accuracy. Real time experiments that show accurate prediction. Approved 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864060657&partnerID=40&md5=1fc4329cbe23c60515e2afbb212ed38e}
}

@Article{Bhatnagar2005,
  Title                    = {User subjectivity in change modeling of streaming itemsets},
  Author                   = {Bhatnagar, V. and Kochhar, S.K.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Pages                    = {812-823},
  Volume                   = {3584 LNAI},

  Abstract                 = {Online mining of changes from data streams is an important problem in view of growing number of applications such as network flow analysis, e-business, stock market analysis etc. Monitoring of these changes is a challenging task because of the high speed, high volume, only-one-look characteristics of the data streams. User subjectivity in monitoring and modeling of the changes adds to the complexity of the problem. This paper addresses the problem of i) capturing user subjectivity and ii) change modeling, in applications that monitor frequency behavior of item-sets. We propose a three stage strategy for focusing on item-sets, which are of current interest to the user and introduce metrics that model changes in their frequency (support) behavior. Ã‚Â© Springer-Verlag Berlin Heidelberg 2005.},
  Affiliation              = {Department of Computer Science, University of Delhi, Delhi-110 007, India},
  Author_keywords          = {Change modeling; Data mining; Data streams; Monitoring; User subjectivity},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {User subjectivity in monitoring and modelling of changes. This paper addresses the problem of i) capturing user subjectivity and ii) change modeling, in applications that monitor frequency behavior of item-sets. Introduce metrics that model changes in their frequency (support) behavior. (?) Approved 6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-26944458808&partnerID=40&md5=14211f3049964b3d4f440a15b766b77d}
}

@InProceedings{Bian2013,
  Title                    = {{Online Redundancy Mining in Enterprise WLAN Traffic}},
  Author                   = {Bian, Zhiqi and Zhu, Hongzi and Xue, Guangtao and Li, Minglu},
  Booktitle                = {2013 8th ChinaGrid Annual Conference},
  Year                     = {2013},
  Month                    = aug,
  Pages                    = {57--62},
  Publisher                = {IEEE},

  Abstract                 = {As various types of mobile devices (e.g., smart phones, laptops and tablets) get connected via Wireless Local Area Networks (WLANs), the dramatic demands for wireless bandwidth have posed new challenges for efficient operation and maintenance of enterprise WLANs. Previous studies have found certain degree of redundancy embedded in user data, which stimulates new redundancy elimination schemes implemented on gateways to restrain redundant data being transmitted within one enterprise WLAN. Due to both the computation and storage limitations of gateways, it is very hard to process all user data online and sampling methods are adopted to shrink the size of data streams. Existing methods simply sample the original user data in a random way, leading to low efficiency of finding redundant data. In this paper, we conduct an empirical study on effective sampling strategies using real user trace collected from a university WLAN. We first investigate the extent to which WLAN traffic can be redundant. We then further analyze the distribution characteristics of redundant blocks and find that the position of redundant chunks exhibit strong spatial correlations with previous ones. Our observations thus provide solid foundation for designing new sampling schemes which can capture more redundant data embedded in WLAN data and improve the performance of redundancy elimination schemes.},
  Doi                      = {10.1109/ChinaGrid.2013.14},
  ISBN                     = {978-0-7695-5058-9},
  Keywords                 = {Bandwidth,Correlation,Entropy,LAN interconnection,Logic gates,Mobile handsets,Online redundancy elimination,Redundancy,WLAN data,Wireless LAN,business communication,computer network performance evaluation,computer network reliability,data mining,data sampling,data streams,enterprise WLAN,enterprise WLAN maintenance,enterprise WLAN operation,enterprise WLAN traffic,gateway storage limitations,mobile computing,mobile devices,online redundancy mining,online user data processing,redundancy,redundancy elimination schemes,redundant chunks,sampling methods,sampling schemes,spatial correlation,telecommunication traffic,university WLAN,user data embedded redundancy,user data sampling methods,wireless LAN,wireless bandwidth,wireless local area networks},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Sampling of data from mobile devices. Interesting, but only relates to sampling and no ML involved. Discarded.},
  Shorttitle               = {ChinaGrid Annual Conference (ChinaGrid), 2013 8th},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6623867}
}

@Article{Biem2013,
  Title                    = {{Real-time analysis and management of big time-series data}},
  Author                   = {Biem, A. and Feng, H. and Riabov, A. V. and Turaga, D. S.},
  Journal                  = {IBM Journal of Research and Development},
  Year                     = {2013},

  Month                    = may,
  Number                   = {3},
  Pages                    = {8:1--8:12},
  Volume                   = {57},

  Abstract                 = {The ability to process and analyze large volumes of time-series data is in increasing demand in various domains including health care, finance, energy and utilities, transportation, and cybersecurity. Despite the broad use of time-series data worldwide, the design of a system to easily manage, analyze, and visualize large multidimensional time series, with dimensions on the order of hundreds of thousands, is still a challenging endeavor. This paper describes the Streaming Time-Series Analysis and Management (STAM) system as a solution to this problem. STAM provides the capability to glean actionable information from continuously changing time series with thousands of dimensions, in real time. STAM exploits the IBM InfoSphereÃ‚Â® Streams platform and allows for general-purpose large-scale time-series analytics for applications including anomaly detection, modeling, smoothing, forecasting, and tracking. In addition, the system provides user-friendly tools for managing, deploying, and initiating analytics on large-scale data streams of interest, and provides a web-based graphical visualization interface that allows highlighting of events of interest with interactive menus. In this paper, we describe the system and illustrate its use in a large-scale system-monitoring application.},
  Doi                      = {10.1147/JRD.2013.2243551},
  ISSN                     = {0018-8646},
  Keywords                 = {Algorithm design and analysis,Data handling,Data visualization,Information management,Information processing,Real-time systems,Time series analysis},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {System for analysis and management of large multidimensional time series, dimensions in order of hundreds of thousands, STAM. In this paper, we describe the system and illustrate its use in a large-scale system-monitoring application. Approved 1},
  Shorttitle               = {IBM Journal of Research and Development},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6517301}
}

@Article{Bifet2013,
  Title                    = {Mining big data in real time},
  Author                   = {Bifet, A.},
  Journal                  = {Informatica (Slovenia)},
  Year                     = {2013},
  Note                     = {cited By (since 1996)3},
  Number                   = {1},
  Pages                    = {15-20},
  Volume                   = {37},

  Abstract                 = {Streaming data analysis in real time is becoming the fastest and most efficient way to obtain useful knowledge from what is happening now, allowing organizations to react quickly when problems appear or to detect new trends helping to improve their performance. Evolving data streams are contributing to the growth of data created over the last few years. We are creating the same quantity of data every two days, as we created from the dawn of time up until 2003. Evolving data streams methods are becoming a low-cost, green methodology for real time online prediction and analysis. We discuss the current and future trends of mining evolving data streams, and the challenges that the field will have to overcome during the next years.},
  Affiliation              = {Yahoo Research Barcelona, Avinguda Diagonal 177, Barcelona, 08018, Catalonia, Spain},
  Author_keywords          = {Big data; Data mining; Data streams},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bifet2012 and not a contribution. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84877045865&partnerID=40&md5=56c506d9f6431988a18b3d655b8e17c3}
}

@Misc{Bifet2012,
  Title                    = {{Mining Big Data in Real Time}},

  Author                   = {Bifet, Albert},
  Year                     = {2012},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Streaming data analysis in real time is becoming the fastest and most efficient way to obtain useful knowledge from what is happening now, allowing organizations to react quickly when problems appear or to detect new trends helping to improve their performance. Evolving data streams are contributing to the growth of data created over the last few years. We are creating the same quantity of data every two days, as we created from the dawn of time up until 2003. Evolving data streams methods are becoming a low-cost, green methodology for real time online prediction and analysis. We discuss the current and future trends of mining evolving data streams, and the challenges that the field will have to overcome during the next years.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discuss the current and future trends of mining evolving data streams, and the challenges that the field will have to overcome during the next years. No contribution. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.368.1471}
}

@Misc{Bifetc,
  Title                    = {{Mining Adaptively Frequent Closed Unlabeled Rooted Trees in Data Streams}},

  Author                   = {Bifet, Albert and Gavald\`{a}, Ricard and {De Llenguatges I Sistemes}, Departament},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Closed patterns are powerful representatives of frequent patterns, since they eliminate redundant information. We propose a new approach for mining closed unlabeled rooted trees adaptively from data streams that change over time. Our approach is based on an efficient representation of trees and a low complexity notion of relaxed closed trees, and leads to an on-line strategy and an adaptive sliding window technique for dealing with changes over time. More precisely, we first present a general methodology to identify closed patterns in a data stream, using Galois Lattice Theory. Using this methodology, we then develop three closed tree mining algorithms: an incremental one IncTreeNat, a sliding-window based one, WinTreeNat, and finally one that mines closed trees adaptively from data streams, Ada-TreeNat. To the best of our knowledge this is the first work on mining frequent closed trees in streaming data varying with time. We give a first experimental evaluation of the proposed algorithms.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Closed patterns are powerful representatives of frequent patterns, since they eliminate redundant information. We propose a new approach for mining closed unlabeled rooted trees adaptively from data streams that change over time. Adaptive sliding window technique for dealing with changes over time. To the best of our knowledge this is the first work on mining frequent closed trees in streaming data varying with time. We give a first experimental evaluation of the proposed algorithms Approved 1,3,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.142.1888}
}

@Article{Bifet2011,
  Title                    = {MOA-TweetReader: Real-time analysis in twitter streaming data},
  Author                   = {Bifet, A. and Holmes, G. and Pfahringer, B.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)5},
  Pages                    = {46-60},
  Volume                   = {6926 LNAI},

  Abstract                 = {Twitter is a micro-blogging service built to discover what is happening at any moment in time, anywhere in the world. Twitter messages are short, generated constantly, and well suited for knowledge discovery using data stream mining. We introduce MOA-TweetReader, a system for processing tweets in real time. We show two main applications of the new system for studying Twitter data: detecting changes in term frequencies and performing real-time sentiment analysis. Ã‚Â© 2011 Springer-Verlag.},
  Affiliation              = {University of Waikato, Hamilton, New Zealand},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {MOA-TweetReader, a system for processing tweets in real time. They demonstrate detecting changes in term frequencies and performing real-time sentiment analysis. Approved 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053970597&partnerID=40&md5=2b3f8d63b4b19e5ba6849957a3a05129}
}

@Misc{Bifetb,
  Title                    = {{Mining Frequent Closed Graphs on Evolving Data Streams}},

  Author                   = {Bifet, Albert and Holmes, Geoff and Pfahringer, Bernhard and Gavald\`{a}, Ricard},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Graph mining is a challenging task by itself, and even more so when processing data streams which evolve in real-time. Data stream mining faces hard constraints regarding time and space for processing, and also needs to provide for concept drift detection. In this paper we present a framework for studying graph pattern mining on time-varying streams. Three new methods for mining frequent closed subgraphs are presented. All methods work on coresets of closed subgraphs, compressed representations of graph sets, and maintain these sets in a batch-incremental manner, but use different approaches to address potential concept drift. An evaluation study on datasets comprising up to four million graphs explores the strength and limitations of the proposed methods. To the best of our knowledge this is the first work on mining frequent closed subgraphs in non-stationary data streams.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bifet2011a. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.297.1721}
}

@InProceedings{Bifet2011c,
  Title                    = {{Mining frequent closed graphs on evolving data streams}},
  Author                   = {Bifet, Albert and Holmes, Geoff and Pfahringer, Bernhard and Gavald\`{a}, Ricard},
  Booktitle                = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '11},
  Year                     = {2011},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {591},
  Publisher                = {ACM Press},

  Abstract                 = {Graph mining is a challenging task by itself, and even more so when processing data streams which evolve in real-time. Data stream mining faces hard constraints regarding time and space for processing, and also needs to provide for concept drift detection. In this paper we present a framework for studying graph pattern mining on time-varying streams. Three new methods for mining frequent closed subgraphs are presented. All methods work on coresets of closed subgraphs, compressed representations of graph sets, and maintain these sets in a batch-incremental manner, but use different approaches to address potential concept drift. An evaluation study on datasets comprising up to four million graphs explores the strength and limitations of the proposed methods. To the best of our knowledge this is the first work on mining frequent closed subgraphs in non-stationary data streams.},
  Doi                      = {10.1145/2020408.2020501},
  ISBN                     = {9781450308137},
  Keywords                 = {closed mining,concept drift,data streams,graphs},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bifet2011a. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2020408.2020501}
}

@Misc{Bifeta,
  Title                    = {{2nd Workshop on Applications of Pattern Analysis Detecting Sentiment Change in Twitter Streaming Data}},

  Author                   = {Bifet, Albert and Holmes, Geoff and Pfahringer, Bernhard and Gavald\`{a}, Ricard and Diethe, Tom and Balc\'{a}zar, Jos\'{e} L. and Shawe-taylor, John and T\^{\i}rnÄƒucÄƒ, Cristina},

  __markedentry            = {[Alexander:]},
  Abstract                 = {MOA-TweetReader is a real-time system to read tweets in real time, to detect changes, and to find the terms whose frequency changed. Twitter is a micro-blogging service built to discover what is happening at any moment in time, anywhere in the world. Twitter messages are short, and generated constantly, and well suited for knowledge discovery using data stream mining. MOA-TweetReader is a software extension to the MOA framework. Massive Online Analysis (MOA) is a software environment for implementing algorithms and running experiments for online learning from evolving data streams.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Less informative duplicate of Bifet2011. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.370.8922}
}

@Conference{Bifet2011a,
  Title                    = {Mining frequent closed graphs on evolving data streams},
  Author                   = {Bifet, A.a and Holmes, G.a and Pfahringer, B.a and GavaldÃƒÂ , R.b },
  Year                     = {2011},
  Note                     = {cited By (since 1996)16},
  Pages                    = {591-599},

  Abstract                 = {Graph mining is a challenging task by itself, and even more so when processing data streams which evolve in real-time. Data stream mining faces hard constraints regarding time and space for processing, and also needs to provide for concept drift detection. In this paper we present a framework for studying graph pattern mining on time-varying streams. Three new methods for mining frequent closed subgraphs are presented. All methods work on coresets of closed subgraphs, compressed representations of graph sets, and maintain these sets in a batch-incremental manner, but use different approaches to address potential concept drift. An evaluation study on datasets comprising up to four million graphs explores the strength and limitations of the proposed methods. To the best of our knowledge this is the first work on mining frequent closed subgraphs in non-stationary data streams. Copyright 2011 ACM.},
  Affiliation              = {University of Waikato, Hamilton, New Zealand; LARCA Research Group, UPC-Barcelona Tech, Barcelona, Catalonia, Spain},
  Author_keywords          = {Closed mining; Concept drift; Data streams; Graphs},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A framework for studying graph pattern mining on time-varying streams. Mining frequent closed subgraphs. Batch-incremental. Tested on four million graphs. To the best of our knowledge this is the first work on mining frequent closed subgraphs in non-stationary data streams Approved 1,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052650039&partnerID=40&md5=b90c4203c4d9f58ae6fe7d5ce276bd8c}
}

@InProceedings{Bifet2009a,
  Title                    = {{New ensemble methods for evolving data streams}},
  Author                   = {Bifet, Albert and Holmes, Geoff and Pfahringer, Bernhard and Kirkby, Richard and Gavald\`{a}, Ricard},
  Booktitle                = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '09},
  Year                     = {2009},

  Address                  = {New York, New York, USA},
  Month                    = jun,
  Pages                    = {139},
  Publisher                = {ACM Press},

  Abstract                 = {Advanced analysis of data streams is quickly becoming a key area of data mining research as the number of applications demanding such processing increases. Online mining when such data streams evolve over time, that is when concepts drift or change completely, is becoming one of the core issues. When tackling non-stationary concepts, ensembles of classifiers have several advantages over single classifier methods: they are easy to scale and parallelize, they can adapt to change quickly by pruning under-performing parts of the ensemble, and they therefore usually also generate more accurate concept descriptions. This paper proposes a new experimental data stream framework for studying concept drift, and two new variants of Bagging: ADWIN Bagging and Adaptive-Size Hoefinding Tree (ASHT) Bagging. Using the new experimental framework, an evaluation study on synthetic and real-world datasets comprising up to ten million examples shows that the new ensemble methods perform very well compared to several known methods.},
  Doi                      = {10.1145/1557019.1557041},
  ISBN                     = {9781605584959},
  Keywords                 = {concept drift,data streams,decision trees,ensemble methods},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes a new experimental data stream framework for studying concept drift, and two new variants of Bagging. Using the new experimental framework, an evaluation study on synthetic and real-world datasets shows that the new methods perform very well compared to known methods. Short, but descriptive abstract. Not sure if known methods are SoTA. Would have like to know more about outcome 1,2,3,4,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1557019.1557041}
}

@Conference{Bifet2009,
  Title                    = {New ensemble methods for evolving data streams},
  Author                   = {Bifet, A.a and Holmes, G.b and Pfahringer, B.b and Kirkby, R.b and GavaldÃƒÂ , R.a },
  Year                     = {2009},
  Note                     = {cited By (since 1996)103},
  Pages                    = {139-147},

  Abstract                 = {Advanced analysis of data streams is quickly becoming a key area of data mining research as the number of applications demanding such processing increases. Online mining when such data streams evolve over time, that is when concepts drift or change completely, is becoming one of the core issues. When tackling non-stationary concepts, ensembles of classifiers have several advantages over single classifier methods: they are easy to scale and parallelize, they can adapt to change quickly by pruning under-performing parts of the ensemble, and they therefore usually also generate more accurate concept descriptions. This paper proposes a new experimental data stream framework for studying concept drift, and two new variants of Bagging: ADWIN Bagging and Adaptive-Size Hoefinding Tree (ASHT) Bagging. Using the new experimental framework, an evaluation study on synthetic and real-world datasets comprising up to ten million examples shows that the new ensemble methods perform very well compared to several known methods. Copyright 2009 ACM.},
  Affiliation              = {UPC-Barcelona Tech, Barcelona, Catalonia, Spain; University of Waikato, Hamilton, New Zealand},
  Author_keywords          = {Concept drift; Data streams; Decision tree; Ensemble methods},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bifet2009a. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70350700681&partnerID=40&md5=610db5bdcadd2239f6814a20c41b0a35}
}

@Article{Bifet2011b,
  Title                    = {MOA: A real-time analytics open source framework},
  Author                   = {Bifet, A.a and Holmes, G.a and Pfahringer, B.a and Read, J.a and Kranen, P.b and Kremer, H.b and Jansen, T.b and Seidl, T.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)4},
  Number                   = {PART 3},
  Pages                    = {617-620},
  Volume                   = {6913 LNAI},

  Abstract                 = {Massive Online Analysis (MOA) is a software environment for implementing algorithms and running experiments for online learning from evolving data streams. MOA is designed to deal with the challenging problems of scaling up the implementation of state of the art algorithms to real world dataset sizes and of making algorithms comparable in benchmark streaming settings. It contains a collection of offline and online algorithms for classification, clustering and graph mining as well as tools for evaluation. For researchers the framework yields insights into advantages and disadvantages of different approaches and allows for the creation of benchmark streaming data sets through stored, shared and repeatable settings for the data feeds. Practitioners can use the framework to easily compare algorithms and apply them to real world data sets and settings. MOA supports bi-directional interaction with WEKA, the Waikato Environment for Knowledge Analysis. Besides providing algorithms and measures for evaluation and comparison, MOA is easily extensible with new contributions and allows for the creation of benchmark scenarios. Ã‚Â© 2011 Springer-Verlag.},
  Affiliation              = {Department of Computer Science, University of Waikato, Hamilton, New Zealand; Data Management and Exploration Group, RWTH Aachen University, Germany},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Describes a framework, doesn't appear to be a contribution. Sales pitch, kind of. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052392948&partnerID=40&md5=d78e339e863c7be5b62be033684556ce}
}

@Misc{Bifet,
  Title                    = {{New Ensemble Methods For Evolving Data Streams}},

  Author                   = {Bifet, Albert and Kirkby, Richard and Holmes, Geoff and Gavald\`{a}, Ricard and Pfahringer, Bernhard},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Advanced analysis of data streams is quickly becoming a key area of data mining research as the number of applications demanding such processing increases. Online mining when such data streams evolve over time, that is when concepts drift or change completely, is becoming one of the core issues. When tackling non-stationary concepts, ensembles of classifiers have several advantages over single classifier methods: they are easy to scale and parallelize, they can adapt to change quickly by pruning under-performing parts of the ensemble, and they therefore usually also generate more accurate concept descriptions. This paper proposes a new experimental data stream framework for studying concept drift, and two new variants of Bagging: ADWIN Bagging and Adaptive-Size Hoeffding Tree (ASHT) Bagging. Using the new experimental framework, an evaluation study on synthetic and real-world datasets comprising up to ten million examples shows that the new ensemble methods perform very well compared to several known methods.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bifet2009a. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.151.3596}
}

@Misc{Bigelow,
  Title                    = {{Valmar: High-Bandwidth Real-Time Streaming Data Management}},

  Author                   = {Bigelow, David and Brandt, Scott and Bent, John and Chen, Hb},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In applications ranging from radio telescopes to Internet traffic monitoring, our ability to generate data has outpaced our ability to effectively capture, mine, and manage it. These ultra-high-bandwidth data streams typically contain little useful information and most of the data can be safely discarded. Periodically, however, an event of interest is observed and a large segment of the data must be preserved, including data preceding detection of the event. Doing so requires guaranteed data capture at source rates, line speed filtering to detect events and data points of interest, and TiVo-like ability to save past data once an event has been detected. We present Valmar, a system for guaranteed capture, indexing, and storage of ultra-highbandwidth data streams. Our results show that Valmar performs at nearly full disk bandwidth, up to several orders of magnitude faster than flat file and database systems, works well with both small and large data elements, and allows concurrent read and search access without compromising data capture guarantees.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Valmar, a system for guaranteed capture, indexing, and storage of ultra-highbandwidth data streams. No ML. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.361.3302}
}

@InProceedings{Bigelow2012,
  Title                    = {{Valmar: High-bandwidth real-time streaming data management}},
  Author                   = {Bigelow, David and Brandt, Scott and Bent, John and Chen, H B},
  Booktitle                = {012 IEEE 28th Symposium on Mass Storage Systems and Technologies (MSST)},
  Year                     = {2012},
  Month                    = apr,
  Pages                    = {1--6},
  Publisher                = {IEEE},

  Abstract                 = {In applications ranging from radio telescopes to Internet traffic monitoring, our ability to generate data has outpaced our ability to effectively capture, mine, and manage it. These ultra-high-bandwidth data streams typically contain little useful information and most of the data can be safely discarded. Periodically, however, an event of interest is observed and a large segment of the data must be preserved, including data preceding detection of the event. Doing so requires guaranteed data capture at source rates, line speed filtering to detect events and data points of interest, and TiVo-like ability to save past data once an event has been detected. We present Valmar, a system for guaranteed capture, indexing, and storage of ultra-high-bandwidth data streams. Our results show that Valmar performs at nearly full disk bandwidth, up to several orders of magnitude faster than flat file and database systems, works well with both small and large data elements, and allows concurrent read and search access without compromising data capture guarantees.},
  Doi                      = {10.1109/MSST.2012.6232387},
  ISBN                     = {978-1-4673-1747-4},
  ISSN                     = {2160-195X},
  Keywords                 = {Bandwidth,Disk drives,IP networks,Indexing,Internet,Internet traffic monitoring,Real time systems,TiVo-like ability,Valmar,data preceding detection,line speed filtering,radio telescope,real-time streaming data management,storage management,ultra-high-bandwidth data stream capturing,ultra-high-bandwidth data stream indexing,ultra-high-bandwidth data stream storage},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bigelow and not interesting. Discarded.},
  Shorttitle               = {Mass Storage Systems and Technologies (MSST), 2012},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6232387}
}

@Article{Bilenko2005b,
  Title                    = {{Adaptive product normalization: Using online learning for record linkage in comparison shopping}},
  Author                   = {Bilenko, Mikhail and Basu, Sugato},
  Journal                  = {IN PROCEEDINGS OF ICDM-2005},
  Year                     = {2005},
  Pages                    = {58 -- 65},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The problem of record linkage focuses on determining whether two object descriptions refer to the same underlying entity. Addressing this problem effectively has many practical applications, e.g., elimination of duplicate records in databases and citation matching for scholarly articles. In this paper, we consider a new domain where the record linkage problem is manifested: Internet comparison shopping. We address the resulting linkage setting that requires learning a similarity function between record pairs from streaming data. The learned similarity function is subsequently used in clustering to determine which records are co-referent and should be linked. We present an online machine learning method for addressing this problem, where a composite similarity function based on a linear combination of basis functions is learned incrementally. We illustrate the efficacy of this approach on several real-world datasets from an Internet comparison shopping site, and show that our method is able to effectively learn various distance functions for product data with differing characteristics. We also provide experimental results that show the importance of considering multiple performance measures in record linkage evaluation.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bilenko2005. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.75.4881}
}

@InProceedings{Bilenko2005,
  Title                    = {{Adaptive Product Normalization: Using Online Learning for Record Linkage in Comparison Shopping}},
  Author                   = {Bilenko, M. and Basu, S. and Sahami, M.},
  Booktitle                = {Fifth IEEE International Conference on Data Mining (ICDM'05)},
  Year                     = {2005},
  Pages                    = {58--65},
  Publisher                = {IEEE},

  Abstract                 = {The problem of record linkage focuses on determining whether two object descriptions refer to the same underlying entity. Addressing this problem effectively has many practical applications, e.g., elimination of duplicate records in databases and citation matching for scholarly articles. In this paper, we consider a new domain where the record linkage problem is manifested: Internet comparison shopping. We address the resulting linkage setting that requires learning a similarity function between record pairs from streaming data. The learned similarity function is subsequently used in clustering to determine which records are co-referent and should be linked. We present an online machine learning method for addressing this problem, where a composite similarity function based on a linear combination of basis functions is learned incrementally. We illustrate the efficacy of this approach on several real-world datasets from an Internet comparison shopping site, and show that our method is able to effectively learn various distance functions for product data with differing characteristics. We also provide experimental results that show the importance of considering multiple performance measures in record linkage evaluation.},
  Doi                      = {10.1109/ICDM.2005.18},
  ISBN                     = {0-7695-2278-5},
  ISSN                     = {1550-4786},
  Keywords                 = {Application software,Cleaning,Couplings,Data mining,Databases,Displays,Internet,Internet comparison shopping,Learning systems,Natural language processing,Search engines,adaptive product normalization,home shopping,learning (artificial intelligence),online learning,online machine learning,record linkage,similarity function},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Entite resolution for Internet comparison shopping. An online machine learning method for addressing this problem. We illustrate the efficacy of this approach on several real-world datasets from an Internet comparison shopping site. Approved. 1,3,4,6},
  Shorttitle               = {Data Mining, Fifth IEEE International Conference o},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1565662}
}

@Conference{Bilenko2005a,
  Title                    = {Adaptive product normalization: Using online learning for record linkage in comparison shopping},
  Author                   = {Bilenko, M.a and Basu, S.a and Sahami, M.b},
  Year                     = {2005},
  Note                     = {cited By (since 1996)22},
  Pages                    = {58-65},

  Abstract                 = {The problem of record linkage focuses on determining whether two object descriptions refer to the same underlying entity. Addressing this problem effectively has many practical applications, e.g., elimination of duplicate records in databases and citation matching for scholarly articles. In this paper, we consider a new domain where the record linkage problem is manifested: Internet comparison shopping. We address the resulting linkage setting that requires learning a similarity function between record pairs from streaming data. The learned similarity function is subsequently used in clustering to determine which records are co-referent and should be linked. We present an online machine learning method for addressing this problem, where a composite similarity function based on a linear combination of basis functions is learned incrementally. We illustrate the efficacy of this approach on several real-world datasets from an Internet comparison shopping site, and show that our method is able to effectively learn various distance functions for product data with differing characteristics. We also provide experimental results that show the importance of considering multiple performance measures in record linkage evaluation. Ã‚Â© 2005 IEEE.},
  Affiliation              = {Dept. of Computer Sciences, University of Texas, Austin; Google Inc.},
  Art_number               = {1565662},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bilenko2005. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33746054079&partnerID=40&md5=aacd31c91a30d3d64a4980bc61916105}
}

@InProceedings{BRDWHYYSC2004,
  Title                    = {{Clustering on Demand for Multiple Data Streams}},
  Author                   = {{Bi-Ru Dai} and {Jen-Wei Huang} and {Mi-Yen Yeh} and {Ming-Syan Chen}},
  Booktitle                = {Fourth IEEE International Conference on Data Mining (ICDM'04)},
  Year                     = {2004},
  Pages                    = {367--370},
  Publisher                = {IEEE},

  Abstract                 = {In the data stream environment, the patterns generated by the mining techniques are usually distinct at different time because of the evolution of data. In order to deal with various types of multiple data streams and to support flexible mining requirements, we devise in this paper a clustering on demand framework, abbreviated as COD framework, to dynamically cluster multiple data streams. While providing a general framework of clustering on multiple data streams, the COD framework has two major features, namely one data scan for online statistics collection and compact multiresolution approximations, which are designed to address, respectively, the time and the space constraints in a data stream environment. Furthermore, with the multiresolution approximations of data streams, flexible clustering demands can be supported.},
  Doi                      = {10.1109/ICDM.2004.10060},
  ISBN                     = {0-7695-2142-8},
  Keywords                 = {Aggregates,Association rules,Clustering algorithms,Data mining,Frequency,Investments,Multiresolution analysis,Statistics,clustering-on-demand,compact multiresolution approximations,computational complexity,data evolution,data mining,flexible mining requirements,multiple data streams,online statistics collection,pattern clustering,pattern generation,space constraints,time constraints},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Clustering on demand, to deal with patterns being destinct at different times in evolving streams. One data scan for statistics and compact multires approximations. Approved 1,6},
  Shorttitle               = {Data Mining, 2004. ICDM '04. Fourth IEEE Internati},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1410312}
}

@Article{Bjering2010,
  Title                    = {{A multidimensional temporal abstractive data mining framework}},
  Author                   = {Bjering, Heidi and McGregor, Carolyn},
  Year                     = {2010},

  Month                    = jan,
  Pages                    = {29--38},

  Abstract                 = {This paper presents a framework to support analysis and trend detection in historical data from Neonatal Intensive Care Unit (NICU) patients. The clinical research extensions contribute to fundamental data mining framework research through the integration of temporal abstraction and support of null hypothesis testing within the data mining processes. The application of this new data mining approach is the analysis of level shifts and trends in historical temporal data and to cross correlate data mining findings across multiple data streams for multiple neonatal intensive care patients in an attempt to discover new hypotheses indicative of the onset of some condition. These hypotheses can then be evaluated and defined as rules to be applied in the monitoring of neonates in real-time to enable early detection of possible onset of conditions. This can assist in faster decision making which in turn may avoid conditions developing into serious problems where treatment may be futile.},
  ISBN                     = {978-1-920682-89-7},
  Keywords                 = {clinical research,data mining,temporal abstraction},
  Owner                    = {alex},
  Publisher                = {Australian Computer Society, Inc.},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {framework to support analysis and trend detection in historical data from Neonatal Intensive Care Unit (NICU) patients. Cross correlate data mining findings across multiple data streams for multiple neonatal intensive care patients in an attempt to discover new hypotheses indicative of the onset of some condition. Hypotheses can be tested and used as rules for prediction. Approved 1,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1862303.1862310}
}

@Article{Blount2010,
  Title                    = {{Real-time analysis for intensive care: development and deployment of the artemis analytic system.}},
  Author                   = {Blount, Marion and Ebling, Maria R and Eklund, J Mikael and James, Andrew G and McGregor, Carolyn and Percival, Nathan and Smith, Kathleen P and Sow, Daby},
  Journal                  = {IEEE engineering in medicine and biology magazine : the quarterly magazine of the Engineering in Medicine \& Biology Society},
  Year                     = {2010},

  Month                    = jan,
  Number                   = {2},
  Pages                    = {110--8},
  Volume                   = {29},

  Abstract                 = {The lives of many thousands of children born premature or ill at term around the world have been saved by those who work within neonatal intensive care units (NICUs). Modern-day neonatologists, together with nursing staff and other specialists within this domain, enjoy modern technologies for activities such as financial transactions, online purchasing, music, and video on demand. Yet, when they move into their workspace, in many cases, they are supported by nearly the same technology they used 20 years ago. Medical devices provide visual displays of vital signs through physiological streams such as electrocardiogram (ECG), heart rate, blood oxygen saturation (SpO(2)), and respiratory rate. Electronic health record initiatives around the world provide an environment for the electronic management of medical records, but they fail to support the high-frequency interpretation of streaming physiological data. We have taken a collaborative research approach to address this need to provide a flexible platform for the real-time online analysis of patients' data streams to detect medically significant conditions that precede the onset of medical complications. The platform supports automated or clinician-driven knowledge discovery to discover new relationships between physiological data stream events and latent medical conditions as well as to refine existing analytics. Patients benefit from the system because earlier detection of signs of the medical conditions may lead to earlier intervention that may potentially lead to improved patient outcomes and reduced length of stays. The clinician benefits from a decision support tool that provides insight into multiple streams of data that are too voluminous to assess with traditional methods. The remainder of this article summarizes the strengths of our research collaboration and the resulting environment known as Artemis, which is currently being piloted within the NICU of The Hospital for Sick Children (SickKids) in Toronto, Ontario, Canada. Although the discussion in this article focuses on a NICU, the technologies can be applied to any intensive care environment.},
  Doi                      = {10.1109/MEMB.2010.936454},
  ISSN                     = {1937-4186},
  Keywords                 = {Computer Systems,Decision Support Systems, Clinical,Diagnosis, Computer-Assisted,Diagnosis, Computer-Assisted: instrumentation,Equipment Design,Equipment Failure Analysis,Intensive Care,Medical Records Systems, Computerized,Monitoring, Physiologic,Monitoring, Physiologic: instrumentation},
  Owner                    = {Alexander},
  Pmid                     = {20659848},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bjering2010, and seemingly focused on the collaboration rather than science. Discarded.},
  Shorttitle               = {Engineering in Medicine and Biology Magazine, IEEE},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/20659848}
}

@Conference{Blount2010a,
  Title                    = {On the integration of an artifact system and a real-time healthcare analytics system},
  Author                   = {Blount, M.a and McGregor, C.b and James, A.c and Sow, D.a and Kamaleswaran, R.b and Tuuha, S.b and Percival, J.b and Percival, N.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)2},
  Pages                    = {647-655},

  Abstract                 = {As a result of advances in software technology, particularly stream computing, it is now possible to implement scalable systems capable of real-time analysis of multiple physiological data streams of multiple patients. There is a growing body of evidence showing that early onset indicators of some medical conditions can be observed as subtle changes in the physiological data streams of affected patients. These real-time healthcare analytics systems can detect the early onset indicators and thus may result in earlier detection of the medical condition which may lead to earlier intervention and improved patient outcomes. Blood draws and nasal suctioning can cause changes in the values of some physiological data stream elements. Such events, sometimes referred to as physiological stream artifacts can cause the real-time analytics systems to generate false alarms since the systems assume each data element is indicative the patient's underlying physiological condition. In order to minimize the generation of false alarms, artifact events must be captured and integrated in real time with the analytics result. We present the summary of an artifact study in a tertiary neonatal intensive care unit within a children's hospital where a real-time analytics system is being piloted as part of a clinical research study. We utilize the information gathered relating to the nature of these events and propose a framework to integrate the artifact events with the analytic results in real time Ã‚Â© 2010 ACM.},
  Affiliation              = {IBM T. J. Watson Research Center, 19 Skyline Drive, Hawthorne, NY, United States; University of Ontario, Institute of Technology, 2000 Simcoe St North, Oshawa, ON, Canada; Hospital for Sick Children, University of Toronto, 555 University Ave, Toronto, ON, Canada},
  Author_keywords          = {artifact integration; artifacts; health informatics; neonatal intensive care; real-time analytics system; streaming computing},
  Document_type            = {Conference Paper},
  Journal                  = {IHI'10 - Proceedings of the 1st ACM International Health Informatics Symposium},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Detecting early onset of medical conditions with physiological data streams. Taking blood or nasal suction can cause false alarms in these data streams, "stream artifacts.".We present the summary of an artifact study in a tertiary neonatal intensive care unit within a children's hospital where a real-time analytics system is being piloted as part of a clinical research study. Approved 6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650963516&partnerID=40&md5=db0624f8f2369944d47687aae16b4c67}
}

@InProceedings{Blount2010b,
  Title                    = {{On the integration of an artifact system and a real-time healthcare analytics system}},
  Author                   = {Blount, Marion and McGregor, Carolyn and James, Andrew and Sow, Daby and Kamaleswaran, Rishikesan and Tuuha, Sascha and Percival, Jennifer and Percival, Nathan},
  Booktitle                = {Proceedings of the ACM international conference on Health informatics - IHI '10},
  Year                     = {2010},

  Address                  = {New York, New York, USA},
  Month                    = nov,
  Pages                    = {647},
  Publisher                = {ACM Press},

  Abstract                 = {As a result of advances in software technology, particularly stream computing, it is now possible to implement scalable systems capable of real-time analysis of multiple physiological data streams of multiple patients. There is a growing body of evidence showing that early onset indicators of some medical conditions can be observed as subtle changes in the physiological data streams of affected patients. These real-time healthcare analytics systems can detect the early onset indicators and thus may result in earlier detection of the medical condition which may lead to earlier intervention and improved patient outcomes. Blood draws and nasal suctioning can cause changes in the values of some physiological data stream elements. Such events, sometimes referred to as physiological stream artifacts can cause the real-time analytics systems to generate false alarms since the systems assume each data element is indicative the patient's underlying physiological condition. In order to minimize the generation of false alarms, artifact events must be captured and integrated in real time with the analytics result. We present the summary of an artifact study in a tertiary neonatal intensive care unit within a children's hospital where a real-time analytics system is being piloted as part of a clinical research study. We utilize the information gathered relating to the nature of these events and propose a framework to integrate the artifact events with the analytic results in real time},
  Doi                      = {10.1145/1882992.1883094},
  ISBN                     = {9781450300308},
  Keywords                 = {artifact integration,artifacts,health informatics,neonatal intensive care,real-time analytics system,streaming computing},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Blount2010a. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1882992.1883094}
}

@Article{Bouchachia2014,
  Title                    = {{GT2FC: An Online Growing Interval Type-2 Self-Learning Fuzzy Classifier}},
  Author                   = {Bouchachia, Abdelhamid and Vanaret, Charlie},
  Journal                  = {IEEE Transactions on Fuzzy Systems},
  Year                     = {2014},

  Month                    = aug,
  Number                   = {4},
  Pages                    = {999--1018},
  Volume                   = {22},

  Abstract                 = {In this paper, we propose a Growing Type-2 Fuzzy Classifier (GT2FC) for online rule learning from real-time data streams. While in batch rule learning, the training data are assumed to be drawn from a stationary distribution, in online rule learning, data can dynamically change over time becoming potentially nonstationary. To accommodate dynamic change, GT2FC relies on a new semi-supervised online learning algorithm called Growing Gaussian Mixture Model (2G2M). In particular, 2G2M is used to generate the type-2 fuzzy membership functions to build the type-2 fuzzy rules. GT2FC is designed to accommodate data online and to reconcile labeled and unlabeled data using self-learning. Moreover, GT2FC maintains low complexity of the rule base using online optimization and feature selection mechanisms. GT2FC is tested on data obtained from an ambient intelligence application, where the goal is to exploit sensed data to monitor the living space on behalf of the inhabitants. Because sensors are prone to faults and noise, type-2 fuzzy modeling is very suitable for dealing with such an application. Thus, GT2FC offers the advantage of dealing with uncertainty in addition to self-adaptation in an online manner. For illustration purposes, GT2FC is also validated on synthetic and classic UCI data-sets. The detailed empirical study shows that GT2FC performs very well under various experimental settings.},
  Doi                      = {10.1109/TFUZZ.2013.2279554},
  ISSN                     = {1063-6706},
  Keywords                 = {2G2M algorithm,Adaptation models,Complexity theory,Data models,Fuzzy sets,GT2FC classifier,Gaussian mixture model,Gaussian processes,Growing Gaussian mixture models (2G2M),Uncertainty,ambient intelligence application,batch rule learning,data accommodation,feature selection mechanisms,fuzzy set theory,growing Gaussian mixture model,growing interval type-2 self-learning fuzzy classi,knowledge based systems,learning (artificial intelligence),online learning (OL),online optimization,online rule learning,pattern classification,real-time data streams,semi-supervised learning,semi-supervised online learning algorithm,type-2 fuzzy membership functions,type-2 fuzzy rule systems,type-2 fuzzy rules},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Growing Type-2 Fuzzy Classifier for learning from streams. GT2FC relies on a new semi-supervised online learning algorithm called Growing Gaussian Mixture Model. GT2FC is tested on data obtained from an ambient intelligence application, where the goal is to exploit sensed data to monitor the living space on behalf of the inhabitants. Sensors are prone to faults and noise, so the fuzzy modeling is suitable. GT2FC performs very well under various experimental settings. Approved 1,3,4,6},
  Shorttitle               = {Fuzzy Systems, IEEE Transactions on},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6585801}
}

@Conference{BranisavljeviA„a€¡2010,
  Title                    = {Online time data series pre-processing for the improved performance of anomaly detection methods},
  Author                   = {BranisavljeviÃ„â€¡, N.a and Kapelan, Z.b and ProdanoviÃ„â€¡, D.a },
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Pages                    = {99-103},

  Abstract                 = {The number of automated measuring and reporting systems used in water distribution and sewer systems is dramatically increasing and, as a consequence, so is the volume of acquired data. Since the real time data is likely to contain a certain amount of anomalous values and since the probability of equipment malfunction is high, it is essential to equip the SCADA with automatic procedures that will detect the problems and assist the user in monitoring and data management. A number of anomaly detection techniques and methods exist that can be used with varying success. Some of those techniques in some cases are applicable to the online usage (inspection of the incoming data streams) but usually are more suitable for the offline data processing since they require frequent expert's involvement in parameter adjustment. The aim of this paper is to explore the online and offline data pre-processing techniques that could be used to remove redundant information and reduce the total volume of acquired data whilst preserving all the necessary data series features that could be used for anomaly detections. The paper explores the usefulness of different pre-processing techniques as a tool for improving the anomaly detection methods. The methodology developed is tested on several sets of real-life data, with different anomaly detection procedures including statistical, model-based and data mining approaches. The results obtained demonstrate the effectiveness of the suggested methodology. Ã‚Â© 2010 Taylor & Francis Group, London.},
  Affiliation              = {Faculty of Civil Engineering, University of Belgrad, Serbia; Centre ForWater Systems, University of Exeter, United Kingdom},
  Document_type            = {Conference Paper},
  Journal                  = {Integrating Water Systems - Proceedings of the 10th International on Computing and Control for the Water Industry, CCWI 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The paper explores the usefulness of different online and offline data pre-processing techniques as a tool for improving the anomaly detection methods, in the context of water and sewer systems. Tested on several sets of real data, which demonstrated effectiveness. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84859918707&partnerID=40&md5=c2d6b6ebd7fef9a3e65e5070efbc4b86}
}

@Article{Brink2013,
  Title                    = {Using machine learning for discovery in synoptic survey imaging data},
  Author                   = {Brink, H.a and Richards, J.W.a b and Poznanski, D.c and Bloom, J.S.a and Rice, J.c and Negahban, S.d and Wainwright, M.b d },
  Journal                  = {Monthly Notices of the Royal Astronomical Society},
  Year                     = {2013},
  Note                     = {cited By (since 1996)5},
  Number                   = {2},
  Pages                    = {1047-1060},
  Volume                   = {435},

  Abstract                 = {Modern time-domain surveys continuously monitor large swaths of the sky to look for astronomical variability. Astrophysical discovery in such data sets is complicated by the fact that detections of real transient and variable sources are highly outnumbered by 'bogus' detections caused by imperfect subtractions, atmospheric effects and detector artefacts. In this work, we present a machine-learning (ML) framework for discovery of variability in time-domain imaging surveys. Our ML methods provide probabilistic statements, in near real time, about the degree to which each newly observed source is an astrophysically relevant source of variable brightness.We provide details about each of the analysis steps involved, including compilation of the training and testing sets, construction of descriptive image-based and contextual features, and optimization of the feature subset and model tuning parameters. Using a validation set of nearly 30 000 objects from the Palomar Transient Factory, we demonstrate a missed detection rate of at most 7.7 per cent at our chosen false-positive rate of 1 per cent for an optimized ML classifier of 23 features, selected to avoid feature correlation and overfitting from an initial library of 42 attributes. Importantly, we show that our classification methodology is insensitive to mislabelled training data up to a contamination of nearly 10 per cent, making it easier to compile sufficient training sets for accurate performance in future surveys. This ML framework, if so adopted, should enable the maximization of scientific gain from future synoptic survey and enable fast follow-up decisions on the vast amounts of streaming data produced by such experiments. Ã‚Â© 2013 The Authors Published by Oxford University Press on behalf of the Royal Astronomical Society.},
  Affiliation              = {Department of Astronomy, University of California Berkeley, Berkeley, CA 94720, United States; Department of Statistics, University of California Berkeley, Berkeley, CA 94720, United States; School of Physics and Astronomy, Tel Aviv University, Tel Aviv 6997801, Israel; Department of Electrical Engineering and Computer Sciences, University of California Berkeley, Berkeley, CA 94720, United States},
  Author_keywords          = {Data analysis -methods; General.; Image processing - surveys - supernovae; Methods; Statistical - techniques},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {framework for discovery of variability in time-domain imaging surveys, applied to detection of brightness variability in stars. Tested on real data, with explicit, good result. Importantly, we show that our classification methodology is insensitive to mislabelled training data up to a contamination of nearly 10 per cent,, which makes label compilation easier. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84884740643&partnerID=40&md5=f1fcbd15b8c80e804b2bb7266337b640}
}

@Article{Bronnimann2004,
  Title                    = {{Efficient data-reduction methods for on-line association rule discovery}},
  Author                   = {Bronnimann, Herve and Chen, Bin and Dash, Manoranjan and Haas, Peter and Qiao, Yi and Scheuermann, Peter},
  Journal                  = {CHAPTER 4 OF SELECTED PAPERS FROM THE NSF WORKSHOP ON NEXT-GENERATION DATA MINING (NGDMâ€™02},
  Year                     = {2004},
  Pages                    = {190 -- 208},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Classical data mining algorithms that require one or more computationally intensive passes over the entire database can be prohibitively slow. One effective method for dealing with this ever-worsening scalability problem is to run the algorithms on a small sample of the data. We present and empirically compare two data-reduction algorithms for producing such a sample; these algorithms, called FAST and EA, are tailored to “count ” data applications such as association-rule mining. The algorithms are similar in that both attempt to produce a sample whose “distance ” — appropriately defined — from the complete database is minimal. They differ greatly, however, in the way that they greedily search through the exponential number of possible samples. FAST, originally presented in [8], uses random sampling together with trimming of “outlier” transactions. On the other hand, the EA algorithm, introduced in the current paper, repeatedly and deterministically halves the data to obtain the final sample. Unlike FAST, the EA algorithm provides a guaranteed level of accuracy. Our experiments show that EA is more expensive to run than FAST, but yields more accurate results for a given sample size. Thus, depending on the specific problem under consideration, the user can trade off speed and accuracy by selecting the appropriate method. We conclude by showing how the EA data-reduction approach can potentially be adapted to provide data-reduction schemes for streaming data systems. The proposed schemes favor recent data while still retaining partial information about all of the data seen so far.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Sampling algorihtms only, no ML used. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.94.2658}
}

@Misc{Brzezinski,
  Title                    = {{Reacting to Different Types of Concept Drift: The Accuracy Updated Ensemble Algorithm}},

  Author                   = {Brzezinski, Dariusz and Stefanowski, Jerzy},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Data stream mining has been receiving increasing attention due to its presence in a wide range of applications such as sensor networks, banking, and telecommunication. One of the most important challenges in learning from data streams is reacting to concept drift, i.e., unforeseen changes of the stream’s underlying data distribution. Several classification algorithms that cope with concept drift have been put forward, however, most of them specialize in one type of change. In this paper, we propose a new data stream classifier, called the Accuracy Updated Ensemble (AUE2), which aims at reacting equally well to different types of drift. AUE2 combines accuracy-based weighting mechanisms known from block-based ensembles with the incremental nature of Hoeffding Trees. The proposed algorithm was experimentally compared with 11 state-of-the-art stream methods, including single classifiers, block-based and online ensembles, and hybrid approaches in different drift scenarios. Out of all the compared algorithms, AUE2 provided best average classification accuracy while proving to be less memory consuming than other ensemble approaches. Experimental results show that AUE2 can be considered suitable for scenarios involving many types of drift as well as static environments. Index Terms—concept drift, data stream mining, ensemble classifier, nonstationary environments},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Present Accuracy Updated Ensemble (AUE2), aiming to react equally well to different types of drift. combines accuracy-based weighting mechanisms known from block-based ensembles with the incremental nature of Hoeffding Trees. Experimentally compared with 11 state-of-the-art stream methods, AUE2 provided best average classification accuracy while proving to be less memory consuming than other ensemble approaches. Approved. 1,2,3,4,5,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.394.1077}
}

@Article{Brzezinski2014,
  Title                    = {{Reacting to different types of concept drift: the Accuracy Updated Ensemble algorithm.}},
  Author                   = {Brzezinski, Dariusz and Stefanowski, Jerzy},
  Journal                  = {IEEE transactions on neural networks and learning systems},
  Year                     = {2014},

  Month                    = jan,
  Number                   = {1},
  Pages                    = {81--94},
  Volume                   = {25},

  Abstract                 = {Data stream mining has been receiving increased attention due to its presence in a wide range of applications, such as sensor networks, banking, and telecommunication. One of the most important challenges in learning from data streams is reacting to concept drift, i.e., unforeseen changes of the stream's underlying data distribution. Several classification algorithms that cope with concept drift have been put forward, however, most of them specialize in one type of change. In this paper, we propose a new data stream classifier, called the Accuracy Updated Ensemble (AUE2), which aims at reacting equally well to different types of drift. AUE2 combines accuracy-based weighting mechanisms known from block-based ensembles with the incremental nature of Hoeffding Trees. The proposed algorithm is experimentally compared with 11 state-of-the-art stream methods, including single classifiers, block-based and online ensembles, and hybrid approaches in different drift scenarios. Out of all the compared algorithms, AUE2 provided best average classification accuracy while proving to be less memory consuming than other ensemble approaches. Experimental results show that AUE2 can be considered suitable for scenarios, involving many types of drift as well as static environments.},
  Doi                      = {10.1109/TNNLS.2013.2251352},
  ISSN                     = {2162-2388},
  Keywords                 = {AUE2,Concept drift,Hoeffding trees,accuracy updated ensemble algorithm,accuracy-based weighting mechanisms,block-based ensembles,classification algorithms,concept drift,data mining,data stream classifier,data stream learning,data stream mining,ensemble classifier,learning (artificial intelligence),nonstationary environments,online ensembles,pattern classification,single classifiers,trees (mathematics)},
  Owner                    = {Alexander},
  Pmid                     = {24806646},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Brzezinski. Discarded.},
  Shorttitle               = {Neural Networks and Learning Systems, IEEE Transac},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/24806646}
}

@InProceedings{Budhaditya2009,
  Title                    = {{Effective Anomaly Detection in Sensor Networks Data Streams}},
  Author                   = {Budhaditya, Saha and Pham, Duc-Son and Lazarescu, Mihai and Venkatesh, Svetha},
  Booktitle                = {2009 Ninth IEEE International Conference on Data Mining},
  Year                     = {2009},
  Month                    = dec,
  Pages                    = {722--727},
  Publisher                = {IEEE},

  Abstract                 = {This paper addresses a major challenge in data mining applications where the full information about the underlying processes, such as sensor networks or large online database, cannot be practically obtained due to physical limitations such as low bandwidth or memory, storage, or computing power. Motivated by the recent theory on direct information sampling called compressed sensing (CS), we propose a framework for detecting anomalies from these large-scale data mining applications where the full information is not practically possible to obtain. Exploiting the fact that the intrinsic dimension of the data in these applications are typically small relative to the raw dimension and the fact that compressed sensing is capable of capturing most information with few measurements, our work show that spectral methods that used for volume anomaly detection can be directly applied to the CS data with guarantee on performance. Our theoretical contributions are supported by extensive experimental results on large datasets which show satisfactory performance.},
  Doi                      = {10.1109/ICDM.2009.110},
  ISBN                     = {978-1-4244-5242-2},
  ISSN                     = {1550-4786},
  Keywords                 = {Bandwidth,Compressed sensing,Computer networks,Data mining,Databases,Large-scale systems,Paper technology,Physics computing,Sampling methods,Streaming media,anomaly detection,compressed sensing,data compression,data mining,direct information sampling,residual analysis,security of data,sensor network data stream,spectral methods,stream data processing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Framework for detecting anomalies from these large-scale data mining applications where the full information is not practically possible to obtain. Exploiting the fact that the intrinsic dimension of the data in these applications are typically small relative to the raw dimension. Uses compressed sensing, information sampling method. Theoretical results supported by extensive experimental results on large datasets which show satisfactory performance. Approved 1,3,4,6},
  Shorttitle               = {Data Mining, 2009. ICDM '09. Ninth IEEE Internatio},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5360301}
}

@Article{Budk2014,
  Title                    = {Data stream synchronization for defining meaningful fMRI classification problems },
  Author                   = {Marcin Budka},
  Journal                  = {Applied Soft Computing },
  Year                     = {2014},
  Number                   = {0},
  Pages                    = {212 - 221},
  Volume                   = {24},

  Abstract                 = {Abstract Application of machine learning techniques to the functional Magnetic Resonance Imaging (fMRI) data is recently an active field of research. There is however one area which does not receive due attention in the literature Ã¢â‚¬â€œ preparation of the fMRI data for subsequent modelling. In this study we focus on the issue of synchronization of the stream of fMRI snapshots with the mental states of the subject, which is a form of smart filtering of the input data, performed prior to building a predictive model. We demonstrate, investigate and thoroughly discuss the negative effects of lack of alignment between the two streams and propose an original data-driven approach to efficiently address this problem. Our solution involves casting the issue as a constrained optimization problem in combination with an alternative classification accuracy assessment scheme, applicable to both batch and on-line scenarios and able to capture information distributed across a number of input samples lifting the common simplifying i.i.d. assumption. The proposed method is tested using real fMRI data and experimentally compared to the state-of-the-art ensemble models reported in the literature, outperforming them by a wide margin.},
  Doi                      = {http://dx.doi.org/10.1016/j.asoc.2014.07.011},
  ISSN                     = {1568-4946},
  Keywords                 = {Pattern recognition},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {focus on the issue of synchronization of the stream of fMRI snapshots with the mental states of the subject, which is a form of smart filtering of the input data, performed prior to building a predictive model. Cast the issue as a constrained optimization problem in combination with an alternative classification accuracy assessment scheme, applicable to both batch and on-line scenarios. The proposed method is tested using real fMRI data and experimentally compared to the state-of-the-art ensemble models reported in the literature, outperforming them by a wide margin. 1,2,3,4,5,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S156849461400341X}
}

@InProceedings{Bulut2005,
  Title                    = {{A Unified Framework for Monitoring Data Streams in Real Time}},
  Author                   = {Bulut, A. and Singh, A.K.},
  Booktitle                = {21st International Conference on Data Engineering (ICDE'05)},
  Year                     = {2005},
  Pages                    = {44--55},
  Publisher                = {IEEE},

  Abstract                 = {Online monitoring of data streams poses a challenge in many data-centric applications, such as telecommunications networks, traffic management, trend-related analysis, Web-click streams, intrusion detection, and sensor networks. Mining techniques employed in these applications have to be efficient in terms of space usage and per-item processing time while providing a high quality of answers to (1) aggregate monitoring queries, such as finding surprising levels of a data stream, detecting bursts, and to (2) similarity queries, such as detecting correlations and finding interesting patterns. The most important aspect of these tasks is their need for flexible query lengths, i.e., it is difficult to set the appropriate lengths a priori. For example, bursts of events can occur at variable temporal modalities from hours to days to weeks. Correlated trends can occur at various temporal scales. The system has to discover "interesting" behavior online and monitor over flexible window sizes. In this paper, we propose a multi-resolution indexing scheme, which handles variable length queries efficiently. We demonstrate the effectiveness of our framework over existing techniques through an extensive set of experiments.},
  Doi                      = {10.1109/ICDE.2005.13},
  ISBN                     = {0-7695-2285-8},
  ISSN                     = {1084-4627},
  Keywords                 = {Aggregates,Application software,Computer network management,Computer science,Computerized monitoring,Indexing,Intelligent networks,Intrusion detection,Telecommunication network management,Telecommunication traffic,data mining,data mining techniques,data structures,data-centric applications,database indexing,multi-resolution indexing,online monitoring,query processing,real time data stream monitoring,real-time systems},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Monitoring of thousands of data streams, and aggregate monitoring queries, such as finding surprising levels, i.e., "volatility" of a data stream, and detecting bursts, and to (2) similarity queries, such as detecting correlations and finding similar patterns. We propose a framework for summarizing a set of data streams, and for constructing a composite index structure in order to answer the above types of user queries. . We demonstrate the effective- ness of our method over existing techniques through an extensive set of experiments. In answering aggregate queries, our false alarm rate is up to 400 times lower than current solu tions. In the case of pattern analysis, our tech- nique oﬀers more than two times better accu- racy while minimizing the space required for incremental computation Not clear if using ML, but novel. Approved 1,3,4,5,6},
  Shorttitle               = {Data Engineering, 2005. ICDE 2005. Proceedings. 21},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1410105}
}

@Conference{Bulut2005a,
  Title                    = {A unified framework for monitoring data streams in real time},
  Author                   = {Bulut, A. and Singh, A.K.},
  Year                     = {2005},
  Note                     = {cited By (since 1996)27},
  Pages                    = {44-55},

  Abstract                 = {Online monitoring of data streams poses a challenge in many data-centric applications, such as telecommunications networks, traffic management, trend-related analysis, web-click streams, intrusion detection, and sensor networks. Mining techniques employed in these applications have to be efficient in terms of space usage and per-item processing time while providing a high quality of answers to (1) aggregate monitoring queries, such as finding surprising levels of a data stream, detecting bursts, and to (2) similarity queries, such as detecting correlations and finding interesting patterns. The most important aspect of these tasks is their need for flexible query lengths, i.e., it is difficult to set the appropriate lengths a priori. For example, bursts of events can occur at variable temporal modalities from hours to days to weeks. Correlated trends can occur at various temporal scales. The system has to discover "interesting" behavior online and monitor over flexible window sizes. In this paper, we propose a multi-resolution indexing scheme, which handles variable length queries efficiently. We demonstrate the effectiveness of our framework over existing techniques through an extensive set of experiments. Ã‚Â© 2005 IEEE.},
  Affiliation              = {Department of Computer Science, UC Santa Barbara, Santa Barbara, CA 93106-5110, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bulut2005. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-28444433714&partnerID=40&md5=80b36de94e2a8f0f62e8d419e63f63c6}
}

@Misc{Bulut,
  Title                    = {{Chapter 1 1 INDEXING AND QUERYING DATA STREAMS}},

  Author                   = {Bulut, Ahmet and Singh, Ambuj K.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Online monitoring of data streams poses a challenge in many data-centric applications including network traffic management, trend analysis, web-click streams, intrusion detection, and sensor networks. Indexing techniques used in these applications have to be time and space efficient while providing a high quality of answers to user queries: (I) queries that monitor aggregates, such as finding surprising levels ("volatility " of a data stream), and detecting bursts, and (2) queries that monitor trends, such as detecting correlations and finding similar patterns. Data stream indexing becomes an even more challenging task, when we take into account the dynamic nature of underlying raw data. For example, bursts of events can occur at variable temporal modalities from hours to days to weeks. We focus on a multi-resolution indexing architecture. The architecture enables the discovery of "interesting " behavior online, provides flexibility in user query definitions, and interconnects registered queries for real-time and in-depth analysis. stream indexing, monitoring real-time systems, mining continuous data flows, multi-resolution index, synopsis maintenance, trend analysis, network traffic},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {First chapter of a book, not focusing on an issue. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.352.3572}
}

@Misc{Buluta,
  Title                    = {{Stardust: Fast Stream Indexing using Incremental Wavelet Approximations}},

  Author                   = {Bulut, Ahmet and Singh, Ambuj K.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Discarded. Has been removed from Citeseerx.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.5526}
}

@Misc{Bulut2004,
  Title                    = {{Monitoring multiple data streams in real time}},

  Author                   = {Bulut, Ahmet and Singh, Ambuj K.},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Online monitoring of data streams poses a challenge in many data-centric applications, such as telecommunications networks, traffic management, trend-related analysis, webclick streams, intrusion detection, and sensor networks. Mining techniques employed in these applications have to be efficient in terms of space usage and per-item processing time while providing a high quality of answers to (1) aggregate monitoring queries, such as finding surprising levels, i.e., "volatility" of a data stream, and detecting bursts, and to (2) similarity queries, such as detecting correlations and finding similar patterns. We propose},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Bulut2005. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.6490}
}

@Article{Bulut2003,
  Title                    = {{Stardust: Data stream indexing for sensor networks (demo}},
  Author                   = {Bulut, Ahmet and Singh, Ambuj K.},
  Journal                  = {IN ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS},
  Year                     = {2003},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Monitoring thousands of data streams online poses a challenge in many data-centric applications such as telecommunications networks, traffic management, trend-related analysis, web-click streams, and sensor networks. Stream mining techniques employed in these applications have to be efficient in terms of space usage and per-item processing time, while providing a high quality of answers to similarity queries such as detecting correlations and finding similar patterns. We propose a new approach for summarizing a set of data streams, and for constructing a composite index structure to answer similarity queries. The features of a stream are extracted incrementally on the fly at multiple resolutions, and inserted into a family of index structures for later querying.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Not article, just demo. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.8243}
}

@InProceedings{Cabanes2013,
  Title                    = {{Unsupervised Learning for Analyzing the Dynamic Behavior of Online Banking Fraud}},
  Author                   = {Cabanes, Guenael and Bennani, Younes and Grozavu, Nistor},
  Booktitle                = {2013 IEEE 13th International Conference on Data Mining Workshops},
  Year                     = {2013},
  Month                    = dec,
  Pages                    = {513--520},
  Publisher                = {IEEE},

  Abstract                 = {In many cases, databases are in constant evolution, new data is arriving continuously. Data streams pose several unique problems that make obsolete the applications of classical data analysis methods. Indeed, these databases are constantly on-line, growing with the arrival of new data. In addition, the probability distribution associated with the data may change over time. In online banking, fraud is one of the major ethical issues. For this challenge, the main aims of the data mining approaches are, firstly, to identify the different types of credit card fraud, and, secondly, for the fraud detection. We propose in this paper a method of synthetic representation of the data structure for efficient storage of information, and a measure of dissimilarity between these representations for the detection of change in the stream structure, in order to detect different types of fraud during the a period of time. The proposed approach was validated on a real application for the on-line credit card fraud detection.},
  Doi                      = {10.1109/ICDMW.2013.109},
  ISBN                     = {978-1-4799-3142-2},
  Keywords                 = {Credit cards,Data mining,Data models,Databases,Density functional theory,Density measurement,Prototypes,banking,credit card fraud,data analysis,data analysis method,data mining,data streams,data structure synthetic representation,fraud detection,learning (artificial intelligence),online banking fraud,probability distribution,security of data,statistical distributions,unsupervised learning},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Focus on fraud in online banking. Propose a method of synthetic representation of the data structure for efficient storage of information, and a measure of dissimilarity between these representations for the detection of change in the stream structure, in order to detect different types of fraud during the a period of time. . The proposed approach was validated on a real application for the on-line credit card fraud detection. Approved 1,3,6},
  Shorttitle               = {Data Mining Workshops (ICDMW), 2013 IEEE 13th Inte},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6753964}
}

@Conference{Cabanes2013a,
  Title                    = {Unsupervised learning for analyzing the dynamic behavior of online banking fraud},
  Author                   = {Cabanes, G. and Bennani, Y. and Grozavu, N.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {513-520},

  Abstract                 = {In many cases, databases are in constant evolution, new data is arriving continuously. Data streams pose several unique problems that make obsolete the applications of classical data analysis methods. Indeed, these databases are constantly on-line, growing with the arrival of new data. In addition, the probability distribution associated with the data may change over time. In online banking, fraud is one of the major ethical issues. For this challenge, the main aims of the data mining approaches are, firstly, to identify the different types of credit card fraud, and, secondly, for the fraud detection. We propose in this paper a method of synthetic representation of the data structure for efficient storage of information, and a measure of dissimilarity between these representations for the detection of change in the stream structure, in order to detect different types of fraud during the a period of time. The proposed approach was validated on a real application for the on-line credit card fraud detection. Ã‚Â© 2013 IEEE.},
  Affiliation              = {LIPN-UMR CNRS 7030, UniversitÃƒÂ© de Paris 13, Sorbonne Paris CitÃƒÂ©, France},
  Art_number               = {6753964},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE 13th International Conference on Data Mining Workshops, ICDMW 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Cabanes2013. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84898031819&partnerID=40&md5=d86206edd8ef910aa83afad8e31f4271}
}

@Misc{Cai,
  Title                    = {{MAIDS: Mining Alarming Incidents from Data Streams}},

  Author                   = {Cai, Y. Dora and Clutter, David and Pape, Greg and Han, Jiawei and Welge, Michael and Auvil, Loretta},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Real-time surveillance systems, network and telecommunication systems, and other dynamic processes often generate tremendous (potentially infinite) volume of stream data. Effective analysis of such stream data poses great challenges to database and data mining researchers, due to its unique features, such as single-scan algorithm, multi-dimensional online analysis, fast response time, etc.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper we propose to demonstrate our stream data mining system, MAIDS—Mining Alarming Incidents from Data Streams. distinct features: (1) a tilted time window framework and multi-resolution model, (2) a stream “data cube” for multi-dimensional anal- ysis, (3) online stream classiﬁcation, (4) online frequent pat- tern mining, (5) online clustering of data streams, and (6) stream mining visualization. Tested on network instrusion data set. Approved 3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.8981}
}

@Book{Calders2012,
  Title                    = {Technologies for Dealing with Information Overload: An Engineer's Point of View},
  Author                   = {Calders, T. and Fletcher, G.H.L. and Kamiran, F. and Pechenizkiy, M.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {In this chapter, we provide an overview of the technological side of the information overload problem. We discuss the challenges and opportunities offered by the ever-growing and emerging stream of information from an engineering point of view. More concretely, we survey storage and querying techniques for semistructured data, data mining, and information retrieval for analyzing large data collections, and then survey stream processing techniques for online handling of continuously flowing data. In this way, we cover a whole spectrum of different levels of "structuredness" of data. At one end of the spectrum, there is data that, although only loosely structured, can still be organized in some way. At the other end, there are data streams that come in at such a fast pace that even storing them is no longer a valid option. Rather, we need to rely on immediate processing and approximate methods in order to be able to distill information from them. In between these two extremes, we have information retrieval and data mining. For all four domains, we survey the main challenges and give some insights into recent developments and techniques. We also show that from an engineering point of view, information overload is not always considered to be a problem, but that it can also offer many opportunities. Ã‚Â© 2012 the Institute of Electrical and Electronics Engineers.},
  Affiliation              = {Eindhoven University of Technology, Netherlands},
  Author_keywords          = {Challenges and opportunities, from engineering viewpoint; Information retrieval to data mining, absence of user query; Retrieving information, IR, LSI, HITS and page rank; Storing and querying semistructured data; Technologies, for dealing with information overload},
  Document_type            = {Book Chapter},
  Journal                  = {Information Overload: An International Challenge for Professional Engineers and Technical Communicators},
  Owner                    = {Alexander},
  Pages                    = {175-202},
  Qualityassured           = {qualityAssured},
  Review                   = {Chapter from a book. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84886342438&partnerID=40&md5=e5812a35df0776e7052f2b83521df86e}
}

@Misc{Calders2013,
  Title                    = {{Author manuscript, published in "Real-World Challenges for Data Stream Mining Workshop-Discussion Czech Republic (2013)" Analysis of Videos using Tile Mining}},

  Author                   = {Calders, Toon and Fromont, Elisa and Jeudy, Baptiste and Lam, Hoang Thanh and {De Lyon}, Universit\'{e} and Jean, Universit\'{e} and Saint-etienne, Monnet},
  Year                     = {2013},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We investigate how mining top-k largest tiles in a data stream under the sliding window model can be useful for (real-time) analysis of videos and, in particular, for tracking. We ﬁrst explain how a track- ing problem can be cast into a stream pattern mining problem. We then show some preliminary results on tracking in the particular context where both the objects and the camera are moving and where the user does not specify the regions of interest in the ﬁrst frames of the videos},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {investigate how mining top-k largest tiles in a data stream under the sliding window model can be useful for (real-time) analysis of videos and tracking in particular, and how it is a stream pattern mining problem. Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.406.2639}
}

@Misc{Campagna,
  Title                    = {{Frequent Pairs in Data Streams: Exploiting Parallelism and Skew}},

  Author                   = {Campagna, Andrea and Kutzkov, Konstantin and Pagh, Rasmus},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We introduce the Pair Streaming Engine (PairSE) that detects frequent pairs in a data stream of transactions. Our algorithm finds the most frequent pairs with high probability, and gives tight bounds on their frequency. It is particularly space efficient for skewed distribution of pair supports, confirmed for several real-world datasets. Additionally, the algorithm parallelizes easily, which opens up for real-time processing of large transactions. Unlike previous algorithms we make no assumptions on the order of arrival of transactions and pairs. Our algorithm builds upon approaches for frequent items mining in data streams. We show how to efficiently scale these approaches to handle large transactions. We report experimental results showcasing precision and recall of our method. In particular, we find that often our method achieves excellent precision, returning identical upper and lower bounds on the supports of the most frequent pairs.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Detecting frequent pairs in data stream of transactions. Finds most frequent with high probability. Parallizes easily. Unlike previous algorithms we make no assumptions on the order of arrival of transactions and pairs. experimental results showcasing precision and recall of our method, often excellent precision. Approved 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.221.7056}
}

@InProceedings{Campagna2011,
  Title                    = {{Frequent Pairs in Data Streams: Exploiting Parallelism and Skew}},
  Author                   = {Campagna, Andrea and Kutzkov, Konstantin and Pagh, Rasmus},
  Booktitle                = {2011 IEEE 11th International Conference on Data Mining Workshops},
  Year                     = {2011},
  Month                    = dec,
  Pages                    = {145--150},
  Publisher                = {IEEE},

  Abstract                 = {We introduce the Pair Streaming Engine (PairSE) that detects frequent pairs in a data stream of transactions. Our algorithm finds the most frequent pairs with high probability, and gives tight bounds on their frequency. It is particularly space efficient for skewed distribution of pair supports, confirmed for several real-world datasets. Additionally, the algorithm parallelizes easily, which opens up for real-time processing of large transactions. Unlike previous algorithms we make no assumptions on the order of arrival of transactions and pairs. Our algorithm builds upon approaches for frequent items mining in data streams. We show how to efficiently scale these approaches to handle large transactions. We report experimental results showcasing precision and recall of our method. In particular, we find that often our method achieves excellent precision, returning identical upper and lower bounds on the supports of the most frequent pairs.},
  Doi                      = {10.1109/ICDMW.2011.87},
  ISBN                     = {978-1-4673-0005-6},
  Keywords                 = {Accidents,Accuracy,Data mining,Data structures,Frequency estimation,Itemsets,PairSE,Radiation detectors,algorithm,association rule,data handling,data stream,data stream mining,pair streaming engine,parallel,probability,probability analysis,real-time processing,real-world datasets,sharednothing,skewed distribution},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Campagna2011 Discarded.},
  Shorttitle               = {Data Mining Workshops (ICDMW), 2011 IEEE 11th Inte},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6137373}
}

@Conference{Campagna2011a,
  Title                    = {Frequent pairs in data streams: Exploiting parallelism and skew},
  Author                   = {Campagna, A. and Kutzkov, K. and Pagh, R.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Pages                    = {145-150},

  Abstract                 = {We introduce the Pair Streaming Engine (PairSE) that detects frequent pairs in a data stream of transactions. Our algorithm finds the most frequent pairs with high probability, and gives tight bounds on their frequency. It is particularly space efficient for skewed distribution of pair supports, confirmed for several real-world datasets. Additionally, the algorithm parallelizes easily, which opens up for real-time processing of large transactions. Unlike previous algorithms we make no assumptions on the order of arrival of transactions and pairs. Our algorithm builds upon approaches for frequent items mining in data streams. We show how to efficiently scale these approaches to handle large transactions. We report experimental results showcasing precision and recall of our method. In particular, we find that often our method achieves excellent precision, returning identical upper and lower bounds on the supports of the most frequent pairs. Ã‚Â© 2011 IEEE.},
  Affiliation              = {IT University of Copenhagen, Copenhagen, Denmark},
  Art_number               = {6137373},
  Author_keywords          = {Algorithm; Association rule; Data stream; Parallel; Sharednothing},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Campagna2011 Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84857144663&partnerID=40&md5=2a62d98a555df4fe89f355e6770bcb68}
}

@InProceedings{Campanile2007,
  Title                    = {{Adaptable Parsing of Real-Time Data Streams}},
  Author                   = {Campanile, Ferdinando and Cilardo, Alessandro and Coppolino, Luigi and Romano, Luigi},
  Booktitle                = {15th EUROMICRO International Conference on Parallel, Distributed and Network-Based Processing (PDP'07)},
  Year                     = {2007},
  Month                    = feb,
  Pages                    = {412--418},
  Publisher                = {IEEE},

  Abstract                 = {Today's business processes are rarely accomplished inside the companies domains. More often they involve entities geographically distributed which interact in a loosely coupled cooperation. While cooperating, these entities generate transactional data streams, such as sequences of stock-market buy/sell orders, credit-card purchase records, Web server entries, and electronic fund transfer orders. Such streams are often collections of events stored and processed locally, and they thus have typically ad-hoc, heterogeneous formats. On the other hand, elements in such data streams usually share a common semantics and indeed they can be profitably mined in order to obtain combined global events. In this paper, we present an approach to the parsing of heterogeneous data streams based on the definition of format-dependent grammars and automatic production of ad-hoc parsers. The stream-dependent parsers can be obtained dynamically in a totally automatic way, provided that the appropriate grammar, written in a common format, is fed into the system. We also present a fully working implementation, that has been successfully integrated into a telecommunication environment for real-time processing of billing information flows},
  Doi                      = {10.1109/PDP.2007.16},
  ISBN                     = {0-7695-2784-1},
  ISSN                     = {1066-6192},
  Keywords                 = {Biomedical monitoring,Companies,Data analysis,Data mining,Medical diagnostic imaging,Production,Real time systems,Scalability,Web server,XML,ad-hoc parsers,adaptable parsing,billing information flows,business data processing,business processes,format-dependent grammars,geographically distributed,grammars,heterogeneous data streams,loosely coupled cooperation,program compilers,real-time data streams,real-time processing,stream-dependent parsers,telecommunication environment,transaction processing,transactional data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Transactions between companies, such as sequences of stock-market buy/sell orders, credit-card purchase records, Web server entries, and electronic fund transfer orders. often collections of events stored and processed locally. An approach to the parsing of heterogeneous data streams based on the definition of format-dependent grammars and automatic production of ad-hoc parsers. Not sure if ML, but interesting and novel. Approved 1},
  Shorttitle               = {Parallel, Distributed and Network-Based Processing},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4135304}
}

@InProceedings{Canzian2014,
  Title                    = {{A network of cooperative learners for data-driven stream Mining}},
  Author                   = {Canzian, Luca and van der Schaar, Mihaela},
  Booktitle                = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  Year                     = {2014},
  Month                    = may,
  Pages                    = {2908--2912},
  Publisher                = {IEEE},

  Abstract                 = {We propose and analyze a distributed learning system to classify data captured from distributed and dynamic data streams. Our scheme consists of multiple distributed learners that are interconnected via an exogenously-determined network. Each learner observes a specific data stream, which is correlated to a common event that needs to be classified, and maintains a set of local classifiers and a weight for each local classifier. We propose a cooperative online learning scheme in which the learners exchange information through the network both to compute an aggregate prediction and to adapt the weights to the dynamic characteristics of the data streams. The information dissemination protocol is designed to minimize the time required to compute the final prediction. We determine an upper bound for the worst-case misclas-sification probability of our scheme, which depends on the misclassification probability of the best (unknown) static aggregation rule. Importantly, such bound tends to zero if the misclassification probability of the best static aggregation rule tends to zero. When applied to well-known data sets experiencing concept drifts, our scheme exhibits gains ranging from 20\% to 70\% with respect to state-of-the-art solutions.},
  Doi                      = {10.1109/ICASSP.2014.6854132},
  ISBN                     = {978-1-4799-2893-4},
  Keywords                 = {Big Data,Classification,Concept Drift,Data mining,Data-Driven Application,Delays,Distributed databases,Educational institutions,Networked Learners,Online Learning,Protocols,Stream Mining,Upper bound,Vectors,cooperative learners,data driven stream mining,data mining,distributed learning system,information dissemination,information dissemination protocol,learning (artificial intelligence),local classifiers,probability},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We propose and analyze a distributed learning system to classify data captured from distributed and dynamic data streams. Systems cooperate and exchange information and adapt their local weights to the dynamic charachteristics of the data streams When applied to well-known data sets experiencing concept drifts, our scheme exhibits gains ranging from 20\% to 70\% with respect to state-of-the-art solutions Approved. 1,3,4,5,6},
  Shorttitle               = {Acoustics, Speech and Signal Processing (ICASSP), },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6854132}
}

@Misc{Cao,
  Title                    = {{Tracking Quantiles of Network Data Streams with Dynamic Operations}},

  Author                   = {Cao, Jin and Li, Li Erran and Chen, Aiyou and Bu, Tian},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Quantiles are very useful in characterizing the data distribution of an evolving dataset in the process of data mining or network monitoring. The method of Stochastic Approximation (SA) tracks quantiles online by incrementally deriving and updating local approximations of the underly distribution function at the quantiles of interest. In this paper, we propose a generalization of the SA method for quantile estimation that allows not only data insertions, but also dynamic data operations such as deletions and updates},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Stochastic Approximation (SA) tracks quantiles online by incrementally deriving and updating local approximations of the underly distribution function at the quantiles.we propose a generalization of the SA method for quantile estimation that allows not only data insertions, but also dynamic data operations such as deletions and updates. Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.366.4312}
}

@InProceedings{Cao2010,
  Title                    = {{Tracking Quantiles of Network Data Streams with Dynamic Operations}},
  Author                   = {Cao, Jin and Li, Li Erran and Chen, Aiyou and Bu, Tian},
  Booktitle                = {2010 Proceedings IEEE INFOCOM},
  Year                     = {2010},
  Month                    = mar,
  Pages                    = {1--5},
  Publisher                = {IEEE},

  Abstract                 = {Quantiles are very useful in characterizing the data distribution of an evolving dataset in the process of data mining or network monitoring. The method of Stochastic Approximation (SA) tracks quantiles online by incrementally deriving and updating local approximations of the underly distribution function at the quantiles of interest. In this paper, we propose a generalization of the SA method for quantile estimation that allows not only data insertions, but also dynamic data operations such as deletions and updates.},
  Doi                      = {10.1109/INFCOM.2010.5462241},
  ISBN                     = {978-1-4244-5836-3},
  ISSN                     = {0743-166X},
  Keywords                 = {Approximation algorithms,Communications Society,Data mining,Distribution functions,High-speed networks,Linear approximation,Memory,Monitoring,Stochastic processes,Telecommunication traffic,data communication,data mining,distribution function,dynamic operations,network data streams,network monitoring,stochastic approximation,stochastic processes,telecommunication traffic},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Cao. Discarded.},
  Shorttitle               = {INFOCOM, 2010 Proceedings IEEE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5462241}
}

@Conference{Cao2012,
  Title                    = {Mining accurate top-K frequent closed itemset from data stream},
  Author                   = {Cao, X.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {180-184},
  Volume                   = {2},

  Abstract                 = {Frequent Closed Item set mining on data streams is of great significance. Though a minimum support threshold is assumed to be available in classical mining, it is hard to determine it in data streams. Hence, it is more reasonable to ask users to set a bound on the result size. Therefore, a real-time single-pass algorithm, called Top-k frequent closed item sets and a new way of updating the minimum support were proposed for mining top-K closed item sets from data streams efficiently. A novel algorithm, called Can(T), is developed for mining the essential candidate of closed item sets generated so far. Experimental results show that the proposed the algorithm in this paper is an efficient method for mining top-K frequent item sets from data streams. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Information Engineering School, Lanzhou University of Finance and Economic, Lanzhou, 730020, China},
  Art_number               = {6187930},
  Author_keywords          = {closed frequent itemsets; data streams; top-K},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2012 International Conference on Computer Science and Electronics Engineering, ICCSEE 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Top-k frequent closed item sets and a new way of updating the minimum support were proposed for mining top-K closed item sets from data streams efficiently. A novel algorithm, called Can(T), is developed for mining the essential candidate of closed item sets generated so far. Experimental results show that the proposed the algorithm in this paper is an efficient method Approved 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861078254&partnerID=40&md5=7d7ac3ef75a586ee78fc8def61ed91bc}
}

@Article{Cardei2000,
  Title                    = {{Hierarchical feedback adaptation for real time sensor-based distributed applications}},
  Author                   = {Cardei, Mihaela and Cardei, Ionut and Jha, Rakesh and Pavan, Allalaghatta},
  Journal                  = {IN PROC. 3RD IEEE INT. SYMP. OBJECT-ORIENTED REAL-TIME DISTRIBUTED COMPUTING, 2000 (ISORC 2000},
  Year                     = {2000},
  Pages                    = {181 -- 188},
  Volume                   = {2000},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper presents an innovative hierarchical feedback adaptation method that efficiently controls the dynamic QoS behavior of real-time distributed data-flow applications, such as sensor-based data streams or mission-critical command and control applications. We applied this method in the context of the Real Time Adaptive Resource Management 1 system, a middleware architecture for resource management with support for integrated services, developed at the Honeywell Technology Center. We present the analytical model for feedback adaptation for periodic distributed data-flow applications and we describe experimental results for an Automatic Target Recognition pipeline application and the impact of hierarchical feedback adaptation on the},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {innovative hierarchical feedback adaptation method that efficiently controls the dynamic QoS behavior of real-time distributed data-flow application. We present the analytical model for feedback adaptation for periodic distributed data-flow applications and we describe experimental results for an Automatic Target Recognition pipeline application and the impact of hierarchical feedback adaptation. Not clear ML, but sounds like it based on title. Approved 1,3},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.111.7859}
}

@Book{Carley2005,
  Title                    = {Organizational Design and Assessment in Cyber-Space},
  Author                   = {Carley, K.M.a b c },
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Organizations are complex dynamic systems composed of an ecology of networks connecting agents (people and intelligent artificial agents), knowledge, resources, and tasks/projects. Organizational management can be characterized as the science of managing the relationships in these networks so as to meet organizational goals such as high performance, minimal costs, and adaptability. Even the most effective managers often have little understanding of the underlying networks and have access only to out of date information on the state of the organization. Consequently, they rely on experience, hearsay, and tradition in designing teams and assessing the vulnerabilities in the organization, often leading to catastrophic errors. Such catastrophc errors can occur as a management change creates either a less than effective team or destroys the competency of an existing team in forming a new team. These problems are exacerbated for organizations in dynamic environments where there is volatility, changing missions, high turnover, and rapidly advancing technology. Advances in network analysis, multi-agent modeling, data-mining and information capture now open the possibility of effective real time monitoring and design of teams, organizations, and games. This enables reasoning about organizations using up-to-date information on the current state of the organization ("actual" or gamed) including who knows who, who knows what, who has done what, what needs to be done and so on. In this chapter, a meta-matrix view of organizations is presented and the process of using measures and tools based on this formulation for team design for "actual" and/or gamed organizations are described and illustrated using data from a dynamic organization. New approaches to assessing organizational vulnerability are described. Finally, the way in which such tools could be linked into existing real time data streams and the values of such linkage are discussed both for actual and gamed organizations. Copyright Ã‚Â© 2005 John Wiley & Sons, Inc.},
  Affiliation              = {Institute for Software Research International, Carnegie Mellon University, United States; Center for Computational Analysis of Social and Organizational Systems, United States; NAACSOS - North American Association for Computational Social and Organizational Science, United States},
  Author_keywords          = {Illustrative organizations; Mata-matrix view; Organizational dynamics; Organizational management; Organizational vulnerability},
  Document_type            = {Book Chapter},
  Journal                  = {Organizational Simulation},
  Owner                    = {Alexander},
  Pages                    = {389-423},
  Qualityassured           = {qualityAssured},
  Review                   = {Book. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84889467727&partnerID=40&md5=9a1d23b4e13b3c7a937cdf3db3404358}
}

@Misc{Carmona,
  Title                    = {{Online Techniques for Dealing with Concept Drift in Process Mining}},

  Author                   = {Carmona, Josep and Gavald\`{a}, Ricard},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Concept drift is an important concern for any data analysis scenario involving temporally ordered data. In the last decade Process mining arose as a discipline that uses the logs of information systems in order to mine, analyze and enhance the process dimension. There is very little work dealing with concept drift in process mining. In this paper we present the first online mechanism for detecting and managing concept drift, which is based on abstract interpretation and sequential sampling, together with recent learning techniques on data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Process mining arose as a discipline that uses the logs of information systems in order to mine, analyze and enhance the process dimension. There is very little work dealing with concept drift in process mining. First online mechanism for detecting and managing concept drift in this context. Approved. 1,2,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.251.3099}
}

@Article{Carmona2012,
  Title                    = {Online techniques for dealing with concept drift in process mining},
  Author                   = {Carmona, J. and GavaldÃƒÂ , R.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2012},
  Note                     = {cited By (since 1996)2},
  Pages                    = {90-102},
  Volume                   = {7619 LNCS},

  Abstract                 = {Concept drift is an important concern for any data analysis scenario involving temporally ordered data. In the last decade Process mining arose as a discipline that uses the logs of information systems in order to mine, analyze and enhance the process dimension. There is very little work dealing with concept drift in process mining. In this paper we present the first online mechanism for detecting and managing concept drift, which is based on abstract interpretation and sequential sampling, together with recent learning techniques on data streams. Ã‚Â© Springer-Verlag Berlin Heidelberg 2012.},
  Affiliation              = {Universitat PolitÃƒÂ¨cnica de Catalunya, Barcelona, Spain},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Carmona. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84868029147&partnerID=40&md5=8fb7fad793063da067eecea455a4e022}
}

@Article{Carmona-Cejudo2011,
  Title                    = {Online evaluation of email streaming classifiers using GNUsmail},
  Author                   = {Carmona-Cejudo, J.M.a and Baena-GarcÃƒÂ­a, M.a and Del Campo-Ãƒï¿½vila, J.a and Bifet, A.b and Gama, J.c and Morales-Bueno, R.a},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {90-100},
  Volume                   = {7014 LNCS},

  Abstract                 = {Real-time email classification is a challenging task because of its online nature, subject to concept-drift. Identifying spam, where only two labels exist, has received great attention in the literature. We are nevertheless interested in classification involving multiple folders, which is an additional source of complexity. Moreover, neither cross-validation nor other sampling procedures are suitable for data streams evaluation. Therefore, other metrics, like the prequential error, have been proposed. However, the prequential error poses some problems, which can be alleviated by using mechanisms such as fading factors. In this paper we present GNUsmail, an open-source extensible framework for email classification, and focus on its ability to perform online evaluation. GNUsmail's architecture supports incremental and online learning, and it can be used to compare different online mining methods, using state-of-art evaluation metrics. We show how GNUsmail can be used to compare different algorithms, including a tool for launching replicable experiments. Ã‚Â© 2011 Springer-Verlag.},
  Affiliation              = {Universidad de MÃƒÂ¡laga, Spain; University of Waikato, New Zealand; University of Porto, Portugal},
  Author_keywords          = {Concept Drift; Email Classification; Online Methods; Text Mining},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Carmona-cejudo. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80455129960&partnerID=40&md5=48a8e64bf922d1b7d062f893a44151a4}
}

@Misc{Carmona-cejudo,
  Title                    = {{2nd Workshop on Applications of Pattern Analysis Using GNUsmail to Compare Data Stream Mining Methods for On-line Email Classification}},

  Author                   = {Carmona-cejudo, Jos\'{e} M. and Baena-garc\'{\i}a, Manuel and Gama, Jo\~{a}o and Bifet, Albert and Diethe, Tom and Balc\'{a}zar, Jos\'{e} L. and Shawe-taylor, John and T\^{\i}rnÄƒucÄƒ, Cristina},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Real-time classification of emails is a challenging task because of its online nature, and also because email streams are subject to concept drift. Identifying email spam, where only two different labels or classes are defined (spam or not spam), has received great attention in the literature. We are nevertheless interested in a more specific classification where multiple folders exist, which is an additional source of complexity: the class can have a very large number of different values. Moreover, neither cross-validation nor other sampling procedures are suitable for evaluation in data stream contexts, which is why other metrics, like the prequential error, have been proposed. In this paper, we present GNUsmail, an open-source extensible framework for email classification, and we focus on its ability to perform online evaluation. GNUsmails architecture supports incremental and online learning, and it can be used to compare different data stream mining methods, using state-of-art online evaluation metrics. Besides describing the framework, characterized by two overlapping phases, we show how it can be used to compare different algorithms in order to find the most appropriate one. The GNUsmail source code includes a tool for launching replicable experiments.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we present GNUsmail, an open-source extensible framework for email classification, focus on online evaluation. Supports incremental and online learning. We show how it can be used to compare different algorithms in order to find the most appropriate one. Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.421.5309}
}

@Misc{Castillo,
  Title                    = {{Online Matching of Web Content to Closed Captions in IntoNow}},

  Author                   = {Castillo, Carlos and De, Gianmarco and Morales, Francisci and Shekhawat, Ajay},

  __markedentry            = {[Alexander:]},
  Abstract                 = {IntoNow is a mobile application that provides a secondscreen experience to television viewers. IntoNow uses the microphone of the companion device to sample the audio coming from the TV set, and compares it against a database of TV shows in order to identify the program being watched. The system we demonstrate is activated by IntoNow for specific types of shows. It retrieves information related to the program the user is watching by using closed captions, which are provided by each broadcasting network along the TV signal. It then matches the stream of closed captions in real-time against multiple sources of content. More specifically, during news programs it displays links to online news articles and the profiles of people and organizations in the news, and during music shows it displays links to songs. The matching models are machine-learned from editorial judgments, and tuned to achieve approximately 90 % precisionx},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {IntoNow is a mobile application that provides a secondscreen experience to television viewers. during news programs it displays links to online news articles and the profiles of people and organizations in the news, and during music shows it displays links to songs. and tuned to achieve approximately 90 % precision. Approved 1,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.374.6680}
}

@Misc{Ceci,
  Title                    = {{Relational Frequent Patterns Mining for Novelty Detection from Data Streams}},

  Author                   = {Ceci, Michelangelo and Loglisci, Corrado and Caruso, Costantina and Fumarola, Fabio and Valente, Carmine and Malerba, Donato},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We face the problem of novelty detection from stream data, that is, the identification of new or unknown situations in an ordered sequence of objects which arrive on-line, at consecutive time points. We extend previous solutions by considering the case of objects modeled by multiple database relations. Frequent relational patterns are efficiently extracted at each time point, and a time window is used to filter out novelty patterns. An application of the proposed algorithm to the problem of detecting anomalies in network traffic is described and quantitative and qualitative results obtained by analyzing real stream of data collected from the firewall logs are reported.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Novelty detection from streams. Looking for database relational patterns, frequent patterns are extracted and a time window is used to find novelty patterns. Possible application: anomalies in network traffic. Experiments on real stream from firewall logs. Approved. 1,2,3,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.215.6627}
}

@Article{Cesario2014,
  Title                    = {A Multi-Domain Architecture for Mining Frequent Items and Itemsets from Distributed Data Streams},
  Author                   = {Cesario, E.a and Mastroianni, C.a and Talia, D.b },
  Journal                  = {Journal of Grid Computing},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {1},
  Pages                    = {153-168},
  Volume                   = {12},

  Abstract                 = {Real-time analysis of distributed data streams is a challenging task since it requires scalable solutions to handle streams of data that are generated very rapidly by multiple sources. This paper presents the design and the implementation of an architecture for the analysis of data streams in distributed environments. In particular, data stream analysis has been carried out for the computation of items and itemsets that exceed a frequency threshold. The mining approach is hybrid, that is, frequent items are calculated with a single pass, using a sketch algorithm, while frequent itemsets are calculated by a further multi-pass analysis. The architecture combines parallel and distributed processing to keep the pace with the rate of distributed data streams. In order to keep computation close to data, miners are distributed among the domains where data streams are generated. The paper reports the experimental results obtained with a prototype of the architecture, tested on a Grid composed of three domains each one handling a data stream. Ã‚Â© 2013 Springer Science+Business Media Dordrecht.},
  Affiliation              = {ICAR-CNR, Via P. Bucci 41C, Rende (CS), 87036, Italy; ICAR-CNR and DIMES, University of Calabria, Via P. Bucci 41C, Rende (CS), 87036, Italy},
  Author_keywords          = {Distributed data mining; Frequent items; Frequent itemsets; Grid; Stream mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Architecture for analysis of streams in distributed environment. Finding itemsets above frequency threshold. Hybrid single pass and multi-pass. Distributed miners for locality. Experimental results with three separate streams. Approved 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84899436704&partnerID=40&md5=c39da5bd70de15cfd9e38b3511c5b6d0}
}

@Article{Chandrasekaran2004,
  Title                    = {{Remembrance of Streams Past: Overload-Sensitive Management of Archived Streams}},
  Author                   = {Chandrasekaran, Sirish and Franklin, Michael},
  Journal                  = {IN VLDB},
  Year                     = {2004},
  Pages                    = {348 -- 359},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper studies Data Stream Management Systems that combine real-time data streams with historical data, and hence access incoming streams and archived data simultaneously. A significant problem for these systems is the I/O cost of fetching historical data which inhibits processing of the live data streams. Our solution is to reduce the I/O cost for accessing the archive by retrieving only a reduced (summarized or sampled) version of the historical data. This paper does not propose new summarization or sampling techniques, but rather a framework in which multiple resolutions of summarization /sampling can be generated efficiently. The query engine can select the appropriate level of summarization to use depending on the resources currently available. The central research problem studied is whether to generate the multiple representations of archived data eagerly upon data-arrival, lazily at query-time, or in a hybrid fashion. Concrete techniques for each approach are presented, which are tied to a specific data reduction technique (random sampling). The tradeoffs among the three approaches are studied both analytically and experimentally.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Data stream management system. Framework for summarization and sampling of data streams. Focus on how to handle the stream. No ML. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.1096}
}

@Conference{Chandrika2011a,
  Title                    = {A novel conceptual framework for mining high speed data streams},
  Author                   = {Chandrika, J.a and Ananda Kumar, K.R.b },
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {211-215},

  Abstract                 = {Many scenarios, such as network analysis, real time surveillance systems, sensor networks and financial applications generate massive streams of data. These streams consist of millions or billions of updates and must be processed to extract the useful information to enable timely strategic decisions. Mining data streams have many inherent challenges among which the most important challenges are adapting to available resources and assuring quality of the output result. Recent work in the area of data stream mining addresses these two challenges separately. Algorithms in the area of stream mining lack the combination of resource and quality awareness. That means, although they deal with resource adaptation, they do not take quality aspects into consideration. The purpose of this paper is to discuss the importance of resource adaptation and quality awareness with respect to data stream mining and then propose a novel framework that accounts for both quality awareness and resource adaptation. The proposed framework can be generalized for any stream mining technique. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Dept. of Computer Science and Engineering, MCE, Hassan, India; Dept. of Computer Science and Engineering, SJBIT, Bangalore, India},
  Art_number               = {5994246},
  Author_keywords          = {adaptation factors; Algorithm granularity; Data streams; Methodical quality; resource adaptation; Synopsis; temporal quality},
  Document_type            = {Conference Paper},
  Journal                  = {ICBEIA 2011 - 2011 International Conference on Business, Engineering and Industrial Applications},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chandrika2011. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052574742&partnerID=40&md5=58058f0a7170334babc890e9bd164d81}
}

@InProceedings{Chandrika2011,
  Title                    = {{A novel conceptual framework for mining high speed data streams}},
  Author                   = {Chandrika, J. and {Ananda Kumar}, K. R.},
  Booktitle                = {2011 International Conference on Business, Engineering and Industrial Applications},
  Year                     = {2011},
  Month                    = jun,
  Pages                    = {211--215},
  Publisher                = {IEEE},

  Abstract                 = {Many scenarios, such as network analysis, real time surveillance systems, sensor networks and financial applications generate massive streams of data. These streams consist of millions or billions of updates and must be processed to extract the useful information to enable timely strategic decisions. Mining data streams have many inherent challenges among which the most important challenges are adapting to available resources and assuring quality of the output result. Recent work in the area of data stream mining addresses these two challenges separately. Algorithms in the area of stream mining lack the combination of resource and quality awareness. That means, although they deal with resource adaptation, they do not take quality aspects into consideration. The purpose of this paper is to discuss the importance of resource adaptation and quality awareness with respect to data stream mining and then propose a novel framework that accounts for both quality awareness and resource adaptation. The proposed framework can be generalized for any stream mining technique.},
  Doi                      = {10.1109/ICBEIA.2011.5994246},
  ISBN                     = {978-1-4577-1279-1},
  Keywords                 = {Algorithm design and analysis,Algorithm granularity,Approximation algorithms,Classification algorithms,Clustering algorithms,Data mining,Data models,Data streams,Methodical quality,Monitoring,Synopsis,adaptation factors,data mining,high speed data stream mining,information retrieval,quality assurance,quality awareness,resource adaptation,resource allocation,strategic decision,temporal quality,useful information extraction},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Propose a novel frameowkr to help account for quality AND resource adaptation when learning from streams. Approved 1,6},
  Shorttitle               = {Business, Engineering and Industrial Applications },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5994246}
}

@Article{Chang2006c,
  Title                    = {Finding recently frequent itemsets adaptively over online transactional data streams,},
  Author                   = {Chang, J.H. and Lee, W.S.},
  Journal                  = {Information Systems},
  Year                     = {2006},
  Note                     = {cited By (since 1996)18},
  Number                   = {8},
  Pages                    = {849-869},
  Volume                   = {31},

  Abstract                 = {A data stream is a massive unbounded sequence of data elements continuously generated at a rapid rate. Consequently, the knowledge embedded in a data stream is more likely to be changed as time goes by. Identifying the recent change of a data stream, especially for an online data stream, can provide valuable information for the analysis of the data stream. However, most of mining algorithms or frequency approximation algorithms over a data stream do not differentiate the information of recently generated data elements from the obsolete information of old data elements which may be no longer useful or possibly invalid at present. Therefore, they are not able to extract the recent change of information in a data stream adaptively. This paper proposes a data mining method for finding recently frequent itemsets adaptively over an online transactional data stream. The effect of old transactions on the current mining result of a data steam is diminished by decaying the old occurrences of each itemset as time goes by. Furthermore, several optimization techniques are devised to minimize processing time as well as memory usage. Finally, the performance of the proposed method is analyzed by a series of experiments to identify its various characteristics. Ã‚Â© 2006 Elsevier B.V. All rights reserved.},
  Affiliation              = {Department of Computer Science, Yonsei University, 134 Shinchon-dong Seodaemun-gu, Seoul, 120-749, South Korea},
  Author_keywords          = {Data streams; Decay rate; Delayed insertion; Information decay; Itemset pruning; Lexicographic tree; Recently frequent itemsets},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Finding frequent itemsets over an online data stream. Set of monitored itemsets in an online data stream is minimized by delayed-insertion and pruning. Thresholded number of itemsets monitored, tunable. Experiments are performed. Approved 1,2,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33748676847&partnerID=40&md5=7f03c6be6e3f852b7a65da357b9a7cf7}
}

@Article{Chang2005,
  Title                    = {Effect of count estimation in finding frequent itemsets over online transactional data streams},
  Author                   = {Chang, J.H. and Lee, W.S.},
  Journal                  = {Journal of Computer Science and Technology},
  Year                     = {2005},
  Note                     = {cited By (since 1996)2},
  Number                   = {1},
  Pages                    = {63-69},
  Volume                   = {20},

  Abstract                 = {A data stream is a massive unbounded sequence of data elements continuously generated at a rapid rate. Due to this reason, most algorithms for data streams sacrifice the correctness of their results for fast processing time. The processing time is greatly influenced by the amount of information that should be maintained. This issue becomes more serious in finding frequent itemsets or frequency counting over an online transactional data stream since there can be a large number of itemsets to be monitored. We have proposed a method called theestDec method for finding frequent itemsets over an online data stream. In order to reduce the number of monitored itemsets in this method, monitoring the count of an itemset is delayed until its support is large enough to become a frequent itemset in the near future. For this purpose, the count of an itemset should be estimated. Consequently, how to estimate the count of an itemset is a critical issue in minimizing memory usage as well as processing time. In this paper, the effects of various count estimation methods for finding frequent itemsets are analyzed in terms of mining accuracy, memory usage and processing time. Ã‚Â© 2005 Springer Science + Business Media, Inc.},
  Affiliation              = {Department of Computer Science, Yonsei University, Seoul 120-749, South Korea},
  Author_keywords          = {Count estimation; Frequent itemsets; Transactional data streams},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Frequent itemsets only counting sets above a certain frequency, which is estimated with various estimation methods tested in this paper. Approved. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-18544366849&partnerID=40&md5=4ca6a92998984b516e39fac629aed217}
}

@Article{Chang2004,
  Title                    = {A sliding window method for finding recently frequent itemsets over online data streams},
  Author                   = {Chang, J.H. and Lee, W.S.},
  Journal                  = {Journal of Information Science and Engineering},
  Year                     = {2004},
  Note                     = {cited By (since 1996)82},
  Number                   = {4},
  Pages                    = {753-762},
  Volume                   = {20},

  Abstract                 = {A data stream is a massive unbounded sequence of data elements continuously generated at a rapid rate. Consequently, the knowledge embedded in a data stream is likely to be changed as time goes by. However, most of mining algorithms or frequency approximation algorithms for a data stream do not able to extract the recent change of information in a data stream adaptively. This paper proposes a sliding window method of finding recently frequent itemsets over an online data stream. The size of a window defines a desired life-time of the information of a transaction in a data stream.},
  Affiliation              = {Department of Computer Science, Yonsei University, Seoul, 120-749, South Korea},
  Author_keywords          = {Change of data stream; Data stream; Mining data stream; Recently frequent itemsets; Sliding window},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Sliding window frequent itemsets mining in streams. Approved. 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-3142639461&partnerID=40&md5=e0a2aedfd2feb363ee43c1d83a1407df}
}

@Conference{Chang2003,
  Title                    = {Finding recent frequent itemsets adaptively over online data streams},
  Author                   = {Chang, J.H. and Lee, W.S.},
  Year                     = {2003},
  Note                     = {cited By (since 1996)138},
  Pages                    = {487-492},

  Abstract                 = {A data stream is a massive unbounded sequence of data elements continuously generated at a rapid rate. Consequently, the knowledge embedded in a data stream is more likely to be changed as time goes by. Identifying the recent change of a data stream, specially for an online data stream, can provide valuable information for the analysis of the data stream. In addition, monitoring the continuous variation of a data stream enables to find the gradual change of embedded knowledge. However, most of mining algorithms over a data stream do not differentiate the information of recently generated transactions from the obsolete information of old transactions which may be no longer useful or possibly invalid at present. This paper proposes a data mining method for finding recent frequent itemsets adaptively over an online data stream. The effect of old transactions on the mining result of the data steam is diminished by decaying the old occurrences of each itemset as time goes by. Furthermore, several optimization techniques are devised to minimize processing time as well as main memory usage. Finally, the proposed method is analyzed by a series of experiments. Copyright 2003 ACM.},
  Affiliation              = {Department of Computer Science, Yonsei University, 134 Shinchon-dong, Seodaemun-gu Seoul, 120-749, South Korea},
  Author_keywords          = {Data stream; Decay mechanism; Delayed-insertion; Pruning of itemsets; Recent frequent itemsets},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {New data mining method for frequent itemsets adaptively from stream. The effect of old transactions on the mining result of the data steam is diminished by decaying Finally, the proposed method is analyzed by a series of experiments Approved. 1, 2, 3},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77952414052&partnerID=40&md5=b89f30cce04aa87efe4f12cdc2b5fb43}
}

@Conference{Chang2003a,
  Title                    = {estWin: Adaptively monitoring the recent change of frequent itemsets over online data streams},
  Author                   = {Chang, J.H. and Lee, W.S.},
  Year                     = {2003},
  Note                     = {cited By (since 1996)18},
  Pages                    = {536-539},

  Abstract                 = {Knowledge embedded in a data stream is likely to be changed as time goes by. Consequently, identifying the recent change of the knowledge quickly can provide valuable information for the analysis of the data stream. However, most of mining algorithms or frequency approximation algorithms for a data stream do not able to extract the recent change of information in a data stream adaptively. This paper proposes a sliding window-based method that finds recently frequent itemsets over an online data stream adaptively. The size of a window defines a desired life-time of the information in a newly generated transaction. Consequently, only recently generated transactions in the range of the window are considered to find the frequent itemsets of a data stream. Copyright 2003 ACM.},
  Affiliation              = {Department of Computer Science, Yonsei University, 134 Shinchon-dong, Seodaemun-gu Seoul, 120-749, South Korea},
  Author_keywords          = {Data streams; Delayed-insertion; Pruning; Recent change of frequent itemsets; Sliding window},
  Document_type            = {Conference Paper},
  Journal                  = {International Conference on Information and Knowledge Management, Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Old version of Chang2005b. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-18744361866&partnerID=40&md5=dace5ccc1100b29c7097dfb483215a7d}
}

@Article{Chang2005a,
  Title                    = {Efficient mining method for retrieving sequential patterns over online data streams},
  Author                   = {Chang, J.H.a b and Lee, W.S.a },
  Journal                  = {Journal of Information Science},
  Year                     = {2005},
  Note                     = {cited By (since 1996)24},
  Number                   = {5},
  Pages                    = {420-432},
  Volume                   = {31},

  Abstract                 = {With the usefulness of data mining in various fields of information science, various mining methods have been proposed in previous research. Recently, in these fields, data has taken the form of continuous data streams rather than finite stored data sets. In this paper, a mining method of sequential patterns over an online sequence data stream is proposed, which is useful for retrieving embedded knowledge in the data stream. The proposed method can minimize memory usage of the mining process while an error is allowed in its mining result, and supports flexible trade-off between memory usage and mining accuracy. However, the error is minimized by an accurate estimation method for the count of a sequence, which considers the ordering information of items. The proposed method can catch a recent change in a sequence data stream in a short time, by a decaying mechanism gracefully discarding old information that may be no longer useful. Ã‚Â© CILIP.},
  Affiliation              = {Yonsei University, 134 Shinchon-dong, Seodaemun-gu Seoul, 120-749, South Korea; Department of Computer Science, Yonsei University, 134 Shinchon-dong, Seodaemun-gu Seoul, 120-749, South Korea},
  Author_keywords          = {Data stream; Embedded knowledge; Information retrieval; Sequential pattern; Significant sequence},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining method of sequential patterns over an online sequence data stream. Minimizing memory usage, with flexible memory or accuracy tradeoff. Decaying mechanism for discarding old information. Approved. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-30544441623&partnerID=40&md5=c10af30f5434c84bd687a5a75716a0a3}
}

@Article{Chang2005b,
  Title                    = {estWin: Online data stream mining of recent frequent itemsets by sliding window method},
  Author                   = {Chang, J.H.a b and Lee, W.S.a },
  Journal                  = {Journal of Information Science},
  Year                     = {2005},
  Note                     = {cited By (since 1996)33},
  Number                   = {2},
  Pages                    = {76-90},
  Volume                   = {31},

  Abstract                 = {Knowledge embedded in a data stream is likely to be changed as time goes by. Identifying the recent change of the knowledge quickly can provide valuable information for the analysis of the data stream. However, most mining algorithms over a data stream are not able to extract the recent change of knowledge in a data stream adaptively. This is because the obsolete information of old data elements which may be no longer useful or possibly invalid at present is regarded as being as important as that of recent data elements. This paper proposes a sliding window method that finds recently frequent itemsets over a transactional online data stream adaptively. The size of a sliding window defines the desired life-time of information in a newly generated transaction. Consequently, only recently generated transactions in the range of the window are considered to find the recently frequent itemsets of a data stream. Ã‚Â© CILIP.},
  Affiliation              = {Yonsei University, 134 Shinchon-dong, Seodaemun-gu Seoul, 120-749, South Korea; Department of Computer Science, Yonsei University, 134 Shinchon-dong, Seodaemun-gu Seoul, 120-749, South Korea},
  Author_keywords          = {Data streams; Delayed-insertion; Itemset pruning; Recent change of data streams; Sliding window},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Finding frequent itemsets in data stream adaptively, with sliding window. Approved 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-30344444271&partnerID=40&md5=455b9765d51cd401ec7e73a504257b00}
}

@Article{Chang2009,
  Title                    = {Frequency-based load shedding over a data stream of tuples },
  Author                   = {Joong Hyuk Chang and Hye-Chung (Monica) Kum},
  Journal                  = {Information Sciences },
  Year                     = {2009},
  Number                   = {21},
  Pages                    = {3733 - 3744},
  Volume                   = {179},

  Abstract                 = {Usually the data generation rate of a data stream is unpredictable, and some data elements of the data stream cannot be processed in real time if the generation rate exceeds the capacity of a data stream processing algorithm. In order to overcome this situation gracefully, a load shedding technique is recommended. This paper proposes a frequency-based load shedding technique over a data stream of tuples. In many data stream processing applications, such as mining frequent patterns, data elements having high frequency can be considered more significant than others having low frequency. Based on this observation, in the proposed technique, only frequent elements of a data stream are processed in real time while the others are trimmed. The decision to shed a load from the data stream or not is controlled automatically by the data generation rate of a data stream. Consequently, an unnecessary load shedding operation is not allowed in the proposed technique. },
  Doi                      = {http://dx.doi.org/10.1016/j.ins.2009.01.014},
  ISSN                     = {0020-0255},
  Keywords                 = {Load shedding},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Frequency based load shedding in data streams. Throw away what is not common. Not ML. Discarded.},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0020025509000231}
}

@Article{Chang2006,
  Title                    = {Finding frequent itemsets over online data streams },
  Author                   = {Joong Hyuk Chang and Won Suk Lee},
  Journal                  = {Information and Software Technology },
  Year                     = {2006},
  Number                   = {7},
  Pages                    = {606 - 618},
  Volume                   = {48},

  Abstract                 = {Conventional data mining methods for finding frequent itemsets require considerable computing time to produce their results from a large data set. Due to this reason, it is almost impossible to apply them to an analysis task in an online data stream where a new transaction is continuously generated at a rapid rate. An algorithm for finding frequent itemsets over an online data stream should support flexible trade-off between processing time and mining accuracy. Furthermore, the most up-to-date resulting set of frequent itemsets should be available quickly at any moment. To satisfy these requirements, this paper proposes a data mining method for finding frequent itemsets over an online data stream. The proposed method examines each transaction one-by-one without any candidate generation process. The count of an itemset that appears in each transaction is monitored by a lexicographic tree resided in main memory. The current set of monitored itemsets in an online data stream is minimized by two major operations: delayed-insertion and pruning. The former is delaying the insertion of a new itemset in recent transactions until the itemset becomes significant enough to be monitored. The latter is pruning a monitored itemset when the itemset turns out to be insignificant. The number of monitored itemsets can be flexibly controlled by the thresholds of these two operations. As the number of monitored itemsets is decreased, frequent itemsets in the online data stream are more rapidly traced while they are less accurate. The performance of the proposed method is analyzed through a series of experiments in order to identify its various characteristics.},
  Doi                      = {http://dx.doi.org/10.1016/j.infsof.2005.06.004},
  ISSN                     = {0950-5849},
  Keywords                 = {Data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chang2006c. Discarded.},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0950584905000984}
}

@InProceedings{Chang2003b,
  Title                    = {{Finding recent frequent itemsets adaptively over online data streams}},
  Author                   = {Chang, Joong Hyuk and Lee, Won Suk},
  Booktitle                = {Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '03},
  Year                     = {2003},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {487},
  Publisher                = {ACM Press},

  Abstract                 = {data stream is a massive unbounded sequence of data elements continuously generated at a rapid rate. Consequently, the knowledge embedded in a data stream is more likely to be changed as time goes by. Identifying the recent change of a data stream, specially for an online data stream, can provide valuable information for the analysis of the data stream. In addition, monitoring the continuous variation of a data stream enables to find the gradual change of embedded knowledge. However, most of mining algorithms over a data stream do not differentiate the information of recently generated transactions from the obsolete information of old transactions which may be no longer useful or possibly invalid at present. This paper proposes a data mining method for finding recent frequent itemsets adaptively over an online data stream. The effect of old transactions on the mining result of the data steam is diminished by decaying the old occurrences of each itemset as time goes by. Furthermore, several optimization techniques are devised to minimize processing time as well as main memory usage. Finally, the proposed method is analyzed by a series of experiments.},
  Doi                      = {10.1145/956750.956807},
  ISBN                     = {1581137370},
  Keywords                 = {data stream,decay mechanism,delayed-insertion,pruning of itemsets,recent frequent itemsets},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chang2003. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=956750.956807}
}

@InProceedings{Chang2003c,
  Title                    = {{estWin}},
  Author                   = {Chang, Joong Hyuk and Lee, Won Suk},
  Booktitle                = {Proceedings of the twelfth international conference on Information and knowledge management - CIKM '03},
  Year                     = {2003},

  Address                  = {New York, New York, USA},
  Month                    = nov,
  Pages                    = {536},
  Publisher                = {ACM Press},

  Abstract                 = {Knowledge embedded in a data stream is likely to be changed as time goes by. Consequently, identifying the recent change of the knowledge quickly can provide valuable information for the analysis of the data stream. However, most of mining algorithms or frequency approximation algorithms for a data stream do not able to extract the recent change of information in a data stream adaptively. This paper proposes a sliding window-based method that finds recently frequent itemsets over an online data stream adaptively. The size of a window defines a desired life-time of the information in a newly generated transaction. Consequently, only recently generated transactions in the range of the window are considered to find the frequent itemsets of a data stream.},
  Doi                      = {10.1145/956863.956967},
  ISBN                     = {1581137230},
  Keywords                 = {data streams,delayed-insertion,pruning,recent change of frequent itemsets,sliding window},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chang2003a. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=956863.956967}
}

@Article{Chang2013,
  Title                    = {Efficient subset-lattice algorithms for mining closed frequent itemsets and maximal frequent itemsets in data streams},
  Author                   = {Chang, Y.-I. and Li, C.-E. and Peng, W.-H. and Wang, S.-Y.},
  Journal                  = {International Journal of Electrical Engineering},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {2},
  Pages                    = {51-63},
  Volume                   = {20},

  Abstract                 = {There are multiple applications for using association rules in data streams, such as market analysis, sensor networks and web tracking. Because data streams are continuous, high speed, unbounded and in real time, we can only scan once for data streams. Mining closed frequent itemsets is a further work of mining association rules, where a closed frequent itemset is a frequent itemset which has no superset with the same support. One well-known algorithm for mining closed frequent itemsets based on the sliding window model is the NewMoment algorithm. However, the NewMoment algorithm could not efficiently mine closed frequent itemsets in data streams, since they will generate closed frequent itemsets and many unclosed frequent itemsets. Moreover, when data in the sliding window is incrementally updated, the NewMoment algorithm needs to reconstruct the whole tree structure. On the other hand, a frequent itemset is called maximal, if it is not a subset of any other frequent itemset. One well-known algorithm for mining maximal frequent itemsets based on the sliding window model is called the MFIoSSW algorithm. The MFIoSSW algorithm uses a compact structure to mine the maximal frequent itemsets. However, when the new transaction comes, the number of comparisons between the new transaction and the old transactions is too much. Therefore, in this paper, we propose the Subset-Lattice algorithm, which embed the property of subsets into the lattice structure to efficiently mine closed frequent itemsets and maximal frequent itemsets over a data stream sliding window. Moreover, when data in the sliding window is incrementally updated, our Subset-Lattice algorithms will not reconstruct the whole lattice structure. From our simulation results, we show that our algorithm for mining closed frequent itemsets outperforms the NewMoment algorithm, and our algorithm for mining maximal frequent itemsets also outperforms the MFIoSSW algorithm.},
  Affiliation              = {Dept. of Computer Science and Engineering, National Sun Yat-Sen University Kaohsiung, Taiwan},
  Author_keywords          = {Closed frequent itemsets; Data streams; Lattice structure; Maximal frequent itemsets; Sliding window.},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Make an algorithm to efficiently mine closed frequent itemsets and maximal frequent itemsets over a data stream sliding window. From our simulation results, we show that our algorithm for mining closed frequent itemsets outperforms the well known NewMoment algorithm, also outperforms the MFIoSSW algorithm (a maximal set mining algorithm) Approved. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84886907972&partnerID=40&md5=4d989eac948fca3b5f553e0994efa7af}
}

@Article{Chang2013a,
  Title                    = {A set-checking algorithm for mining maximal frequent itemsets from data streams},
  Author                   = {Chang, Y.-I. and Tsai, M.-H. and Li, C.-E. and Lin, P.-Y.},
  Journal                  = {Lecture Notes in Electrical Engineering},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {235-241},
  Volume                   = {234 LNEE},

  Abstract                 = {Online mining the maximal frequent itemsets over data streams is an important problem in data mining. In order to solve mining maximal frequent itemsets from data streams using the Landmark Window model, Mao et al. propose the INSTANT algorithm. The structure of the INSTANT algorithm is simple and it can save much memory space. But it takes long time in mining the maximal frequent itemsets. When the new transaction comes, the number of comparisons between the old transactions of the INSTANT algorithm is too much. Therefore, in this chapter, we propose the Set-Checking algorithm to mine frequent itemsets from data streams using the Landmark Window model. We use the structure of the lattice to store our information. The structure of the lattice records the subset relationship between the child node and the parent node. From our simulation results, we show that the process time of our Set-Checking algorithm is faster than that of the INSTANT algorithm. Ã‚Â© 2013 Springer Science+Business Media New York.},
  Affiliation              = {Department of Computer Science and Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan},
  Author_keywords          = {Data stream; Itemset; Landmark Window model; Lattice; Maximal frequent itemset},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Almost seems like a duplicate of Chang2013, but not sufficiently so. Mining maximal frequent itemsets from data streams. Their Set-Checking algorithm is faster than that of the INSTANT algorithm, designed by a different author. Uses a lattice structure to make it faster. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84881060196&partnerID=40&md5=e5a5051bc99036ceaaa31ff9b3dd7a3e}
}

@InProceedings{Chang-peng2009,
  Title                    = {{Detection for Anomaly Data in Microseismic Survey}},
  Author                   = {Chang-peng, Ji and Li-li, Liu},
  Booktitle                = {2009 Third International Symposium on Intelligent Information Technology Application},
  Year                     = {2009},
  Pages                    = {106--109},
  Publisher                = {IEEE},
  Volume                   = {2},

  Abstract                 = {With the development and application of modern science and technology, many new technical measurement methods have been put forward successively which are of high resolution and high collection rate about microseismic monitoring. We urgently need an effective detection method of abnormal data (mine earthquake) to collect lots of data to make real-time detection. In the past, we usually depend on experienced professional staff to solve this kind of problems. They make judgments by comparing numerical size or analysis change trend of factors. The key problem in this paper is how to find abnormal data automatically by linear autoregressive analysis (include gross error) and point out the position of abnormal data. Through this way, we can give prediction model and prediction mechanism of data stream in coal mine microseism. On the basic of this prediction model, we put out a detecting method of abnormal data, and we can detect whether data at this moment is abnormal by calculating the ratio of prediction error and average forecasting error at this moment. The results of the experiments show correctness and efficiency, and it indicates this model can make real-time detection of mine earthquake abnormal event.},
  Doi                      = {10.1109/IITA.2009.26},
  ISBN                     = {978-0-7695-3859-4},
  Keywords                 = {Acoustic noise,Data mining,Earthquakes,Event detection,Interference,Intrusion detection,Linear regression,Monitoring,Predictive models,Signal to noise ratio,anomaly data detection,anomaly events,average forecasting error,coal mine microseism,data stream,earthquake engineering,linear autoregressive analysis,microseismic monitoring,microseismic survey,mine earthquake abnormal event,real-time prediction mechanism,science and technology,seismology},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Finding abnormal data in a stream automatically by linear autoregressive analysis. Relates it to coal mine earthquake detection. They make a prediction model and alert of abnormality when ratio of prediction and average forecasting error is changing. Results of the experiments show correctness and efficiency, and it indicates this model can make real-time detection of mine earthquake abnormal event. Approved 1,2,3,4,6},
  Shorttitle               = {Intelligent Information Technology Application, 20},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5370632}
}

@InProceedings{Chao2012,
  Title                    = {{Resource-Aware Density-and-Grid-Based Clustering in Ubiquitous Data Streams}},
  Author                   = {Chao, Ching-Ming and Chao, Guan-Lin},
  Booktitle                = {2012 26th International Conference on Advanced Information Networking and Applications Workshops},
  Year                     = {2012},
  Month                    = mar,
  Pages                    = {1203--1208},
  Publisher                = {IEEE},

  Abstract                 = {Because data streams are massive, fast, real-time, and unpredictable, traditional data mining techniques are not suitable for data streams. Hence, data stream mining has attracted much research attention from the data mining community. On the other hand, the increasing processing power of mobile devices has made it possible to run lightweight data mining algorithms on mobile devices. Hence, the concept of ubiquitous data mining has been proposed recently. Because of the constrained resources of mobile devices, however, existing data stream mining algorithms cannot be used on mobile devices and may lead to mining interruption as resources are insufficient. Therefore, in this paper we propose the RA-DCluster al-gorithm that adapts to currently available memory and battery as well as adopts both density-based and grid-based clustering methods so that mobile devices can continue with clustering data streams even under lower memory and battery. Experimental results show that RA-DCluster not only has better stream processing efficiency and mining accuracy than RA-Cluster, but also uses less battery and maintains lower and stable usage of memory.},
  Doi                      = {10.1109/WAINA.2012.19},
  ISBN                     = {978-1-4673-0867-0},
  Keywords                 = {Accuracy,Batteries,Clustering algorithms,Data mining,Mobile handsets,Monitoring,Partitioning algorithms,RA-Dcluster,data mining,data mining community,data streams clustering,memory usage,mobile computing,mobile device,pattern clustering,real-time systems,resource allocation,resource-aware density-based clustering method,resource-aware grid-based clustering method,resources mining,storage management,ubiquitous data streams mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {lightweight data mining algorithms on mobile. ubiquitous data mining has been proposed recently. Current mining algorithms are too resource intensive. Adaptive clustering algorithm, adaptive to memory and battery. RA-DCluster. Based on a previous algorithm RA-Cluster, it seems. Experimental results show that RA-DCluster not only has better stream processing efficiency and mining accuracy than RA-Cluster, but also uses less battery and maintains lower and stable usage of memory. Approved 1,2,3,4,6},
  Shorttitle               = {Advanced Information Networking and Applications W},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6185413}
}

@Conference{Chao2012a,
  Title                    = {Resource-aware density-and-grid-based clustering in ubiquitous data streams},
  Author                   = {Chao, C.-M.a and Chao, G.-L.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1203-1208},

  Abstract                 = {Because data streams are massive, fast, real-time, and unpredictable, traditional data mining techniques are not suitable for data streams. Hence, data stream mining has attracted much research attention from the data mining community. On the other hand, the increasing processing power of mobile devices has made it possible to run lightweight data mining algorithms on mobile devices. Hence, the concept of ubiquitous data mining has been proposed recently. Because of the constrained resources of mobile devices, however, existing data stream mining algorithms cannot be used on mobile devices and may lead to mining interruption as resources are insufficient. Therefore, in this paper we propose the RA-DCluster al-gorithm that adapts to currently available memory and battery as well as adopts both density-based and grid-based clustering methods so that mobile devices can continue with clustering data streams even under lower memory and battery. Experimental results show that RA-DCluster not only has better stream processing efficiency and mining accuracy than RA-Cluster, but also uses less battery and maintains lower and stable usage of memory. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Dept. of Computer Science and Information Management, Soochow University, Taiwan; Department of Electrical Engineering, National Taiwan University, Taiwan},
  Art_number               = {6185413},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 26th IEEE International Conference on Advanced Information Networking and Applications Workshops, WAINA 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chao2012. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84860704579&partnerID=40&md5=68a280bc2dad6576dcd6893c68311763}
}

@InProceedings{Chao2011,
  Title                    = {{An Online Web Usage Mining System Using Stochastic Timed Petri Nets}},
  Author                   = {Chao, Ching-Ming and Yang, Shih-Yang and Chen, Po-Zung and Sun, Chu-Hao},
  Booktitle                = {2011 Fourth International Conference on Ubi-Media Computing},
  Year                     = {2011},
  Month                    = jul,
  Pages                    = {241--246},
  Publisher                = {IEEE},

  Abstract                 = {Web personalization systems are typical applications of Web usage mining. The Web personalization process is structured according to an online component and an off-line component. The off-line component is aimed at building the knowledge base by analyzing past user profiles that is then used in the online component. General Web personalization systems mainly use offline data preprocessing and the mining process is not time-limited. How-ever, this approach is not suitable in real-time dynamic environments. Therefore, we need high-performance online Web usage mining techniques to provide solutions to these problems. In this paper, we present how to implement a complete online data preprocessing process using STPN. We pro-pose the architecture of online Web usage mining in the data stream environment and develop an online Web us-age mining system using STPN that provides Web personalized online services.},
  Doi                      = {10.1109/U-MEDIA.2011.30},
  ISBN                     = {978-1-4577-1174-9},
  Keywords                 = {Data mining,Data preprocessing,Internet,Markov processes,Monitoring,Navigation,Petri nets,STPN,Web pages,Web personalization systems,data mining,data stream environment,high-performance online Web usage mining technique,offline data preprocessing,online data preprocessing process,stochastic processes,stochastic timed Petri nets},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Web personalization. High-performance online web usage mining architecture. Using STPN (Stochastic Timed Petri Nets) Approved 1,2,6},
  Shorttitle               = {Ubi-Media Computing (U-Media), 2011 4th Internatio},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5992079}
}

@Conference{Chao2011a,
  Title                    = {An online web usage mining system using stochastic timed Petri Nets},
  Author                   = {Chao, C.-M.a and Yang, S.-Y.b and Chen, P.-Z.c and Sun, C.-H.c },
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Pages                    = {241-246},

  Abstract                 = {Web personalization systems are typical applications of Web usage mining. The Web personalization process is structured according to an online component and an offline component. The off-line component is aimed at building the knowledge base by analyzing past user profiles that is then used in the online component. General Web personalization systems mainly use offline data preprocessing and the mining process is not time-limited. However, this approach is not suitable in real-time dynamic environments. Therefore, we need high-performance online Web usage mining techniques to provide solutions to these problems. In this paper, we present how to implement a complete online data preprocessing process using STPN. We propose the architecture of online Web usage mining in the data stream environment and develop an online Web usage mining system using STPN that provides Web personalized online services. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Department of Computer Science and Information Management, Soochow University, Taipei 100, Taiwan; Department of Media Art, Kang-Ning Junior College of Medical Care and Management, Taipei 114, Taiwan; Department of Computer Science and Information Engineering, Tamkang University, Tamshui 25137, Taiwan},
  Art_number               = {5992079},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 4th International Conference on Ubi-Media Computing, U-Media 2011},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chao2011. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052584431&partnerID=40&md5=0bd4cff6f2305ee8c6bf05086a87af35}
}

@Misc{Chauhan,
  Title                    = {{Performance Evaluation of Yahoo! S4: A First Look}},

  Author                   = {Chauhan, Jagmohan and Chowdhury, Shaiful Alam and Makaroff, Dwight},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Processing large data sets has been dominated recently by the map/reduce programming model [3], originally proposed by Google and widely adopted through the Apache Hadoop 1 implementation. Over the years, developers have identified weaknesses of processing data sets in batches as in MapReduce and have proposed alternatives. One such alternative is continuous processing of data streams. This is particularly suitable for applications in online analytics, monitoring, financial data processing and fraud detection that require timely processing of data, making the delay introduced by batch processing highly undesirable. This processing paradigm has led to the development of systems such as Yahoo! S4 [1] and Twitter Storm. 2 Yahoo! S4 is a general-purpose, distributed and scalable platform that allows programmers to easily develop applications for processing continuous unbounded streams of data. As these frameworks are quite young and new, there is a need to understand their performance for real time applications and find out the existing issues in terms of scalability, execution time and fault tolerance. We did an empirical evaluation of one application on Yahoo! S4 and focused on the performance in terms of scalability, lost events and fault tolerance. Findings of our analyses can be helpful towards understanding the challenges in developing stream-based data intensive computing tools and thus providing a guideline for the future development.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Performance evaluation of Yahoo! S4, streaming processing framework. No contribution otherwise. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.248.7602}
}

@InProceedings{Chauhan2012,
  Title                    = {{Performance Evaluation of Yahoo! S4: A First Look}},
  Author                   = {Chauhan, Jagmohan and Chowdhury, Shaiful Alam and Makaroff, Dwight},
  Booktitle                = {2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing},
  Year                     = {2012},
  Month                    = nov,
  Pages                    = {58--65},
  Publisher                = {IEEE},

  Abstract                 = {Processing large data sets has been dominated recently by the map/reduce programming model [1], originally proposed by Google and widely adopted through the Apache Hadoop1 implementation. Over the years, developers have identified weaknesses of processing data sets in batches as in MapReduce and have proposed alternatives. One such alternative is continuous processing of data streams. This is particularly suitable for applications in online analytics, monitoring, financial data processing and fraud detection that require timely processing of data, making the delay introduced by batch processing highly undesirable. This processing paradigm has led to the development of systems such as Yahoo! S4 [2] and Twitter Storm.2 Yahoo! S4 is a general-purpose, distributed and scalable platform that allows programmers to easily develop applications for processing continuous unbounded streams of data. As these frameworks are quite young and new, there is a need to understand their performance for real time applications and find out the existing issues in terms of scalability, execution time and fault tolerance. We did an empirical evaluation of one application on Yahoo! S4 and focused on the performance in terms of scalability, lost events and fault tolerance. Findings of our analyses can be helpful towards understanding the challenges in developing stream-based data intensive computing tools and thus providing a guideline for the future development.},
  Doi                      = {10.1109/3PGCIC.2012.55},
  ISBN                     = {978-1-4673-2991-0},
  Keywords                 = {Apache Hadoop1 implementation,Computational modeling,Data models,Data processing,Fault tolerance,Fault tolerant systems,Google,MapReduce programming model,Performance,Real-time systems,Scalability,Stream-based Data Intensive computing,Twitter Storm,Yahoo! S4,Yahoo! S4 performance evaluation,batch processing,continuous unbounded data stream processing,data handling,distributed programming,general-purpose distributed scalable platform,online analytics,online financial data processing,online fraud detection,online monitoring,public domain software,real time applications,software fault tolerance,software performance evaluation,stream-based data intensive computing tools},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chauhan2012. Discarded.},
  Shorttitle               = {P2P, Parallel, Grid, Cloud and Internet Computing },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6362950}
}

@Conference{Chauhan2012a,
  Title                    = {Performance evaluation of Yahoo! S4: A first look},
  Author                   = {Chauhan, J. and Chowdhury, S.A. and Makaroff, D.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)2},
  Pages                    = {58-65},

  Abstract                 = {Processing large data sets has been dominated recently by the map/reduce programming model [1], originally proposed by Google and widely adopted through the Apache Hadoop1 implementation. Over the years, developers have identified weaknesses of processing data sets in batches as in MapReduce and have proposed alternatives. One such alternative is continuous processing of data streams. This is particularly suitable for applications in online analytics, monitoring, financial data processing and fraud detection that require timely processing of data, making the delay introduced by batch processing highly undesirable. This processing paradigm has led to the development of systems such as Yahoo! S4 [2] and Twitter Storm.2 Yahoo! S4 is a general-purpose, distributed and scalable platform that allows programmers to easily develop applications for processing continuous unbounded streams of data. As these frameworks are quite young and new, there is a need to understand their performance for real time applications and find out the existing issues in terms of scalability, execution time and fault tolerance. We did an empirical evaluation of one application on Yahoo! S4 and focused on the performance in terms of scalability, lost events and fault tolerance. Findings of our analyses can be helpful towards understanding the challenges in developing stream-based data intensive computing tools and thus providing a guideline for the future development. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Department of Computer Science, University of Saskatchewan, Saskatoon, SK S7N 3C9, Canada},
  Art_number               = {6362950},
  Author_keywords          = {Performance; Stream-based Data Intensive computing; Yahoo! S4},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2012 7th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing, 3PGCIC 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chauhan2012. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84871548577&partnerID=40&md5=f142ecfc2941c2de9864f0997091dc62}
}

@Article{Chen2014a,
  Title                    = {Knowledge discovery using genetic algorithm for maritime situational awareness},
  Author                   = {Chen, C.-H.a and Khoo, L.P.a and Chong, Y.T.b and Yin, X.F.c },
  Journal                  = {Expert Systems with Applications},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {6},
  Pages                    = {2742-2753},
  Volume                   = {41},

  Abstract                 = {Due to the large volume of data related to vessels, to manually pore through and to analyze the information in a bid to identify potential maritime threat is tedious, if at all possible. This study aims to enhance maritime situational awareness through the use of computational intelligence techniques in detecting anomalies. A knowledge discovery system based on genetic algorithm termed as GeMASS was proposed and investigated in this research. In the development of GeMASS, a machine learning approach was applied to discover knowledge that is applicable in characterizing maritime security threats. Such knowledge is often implicit in datasets and difficult to discover by human analysts. As the knowledge relevant to maritime security may vary from time to time, GeMASS was specified to learn from streaming data and to generate up-to-date knowledge in a dynamic fashion. Based on the knowledge discovered, the system functions to screen vessels for anomalies in real-time. Traditionally in maritime security studies, datasets that are applied as knowledge sources are related to vessels' geographical and movement information. This study investigated a novel leverage of multiple data sources, including Automatic Identification System, classification societies, and port management and security systems for the enhancement of maritime security. A prototype of GeMASS was developed and employed as a vehicle to study and demonstrate the functions of the proposed methodology. Ã‚Â© 2013 Elsevier Ltd. All rights reserved.},
  Affiliation              = {School of Mechanical and Aerospace Engineering, Nanyang Technological University, 50 Nanyang Avenue, Singapore 639798, Singapore; Department of Industrial and Systems Engineering, National University of Singapore, Faculty of Engineering, 1 Engineering Drive 2, Singapore 117576, Singapore; Computing Science Department, Institute of High Performance Computing, 1 Fusionopolis Way, #16-16 Connexis, Singapore 138632, Singapore},
  Author_keywords          = {Decision support; Defense; Genetic algorithm; Knowledge discovery; Machine learning; Maritime security},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Maritime situational awareness. Anomaly detection. In the development of GeMASS, a machine learning approach was applied to discover knowledge that is applicable in characterizing maritime security threats. Approved. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84890570927&partnerID=40&md5=80885a566256abaf7515652f9580ec1e}
}

@InProceedings{Chen2010,
  Title                    = {{Efficiently Mining the Recent Frequent Patterns over Online Data Streams}},
  Author                   = {Chen, Hui},
  Booktitle                = {2010 2nd International Workshop on Intelligent Systems and Applications},
  Year                     = {2010},
  Month                    = may,
  Pages                    = {1--4},
  Publisher                = {IEEE},

  Abstract                 = {In order to mine the frequent patterns in the recent time windows of the data stream than the historic, a new method was proposed to mine the recent frequent patterns in the sliding window of an online data stream. It calculated the approximate frequencies of patterns in the sliding window with a conservative strategy. Also, it built a Recent Frequent Pattern tree(RFP-tree for short) to incrementally capture the patterns in the sliding window and mine them by scanning the stream only once. Extensive experiments show that the proposed method is more efficient and scalable than other analogous algorithms.},
  Doi                      = {10.1109/IWISA.2010.5473377},
  ISBN                     = {978-1-4244-5872-1},
  Keywords                 = {Data engineering,Data mining,Data structures,Design methodology,Finance,Frequency,History,Itemsets,Monitoring,Tree data structures,data mining,frequent patterns mining,online data streams sliding window,pattern classification,recent frequent pattern tree},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chen2009. Discarded.},
  Shorttitle               = {Intelligent Systems and Applications (ISA), 2010 2},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5473377}
}

@Conference{Chen2010a,
  Title                    = {Efficiently mining the recent frequent patterns over online data streams},
  Author                   = {Chen, H.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {In order to mine the frequent patterns in the recent time windows of the data stream than the historic, a new method was proposed to mine the recent frequent patterns in the sliding window of an online data stream. It calculated the approximate frequencies of patterns in the sliding window with a conservative strategy. Also, it built a Recent Frequent Pattern tree(RFP-tree for short) to incrementally capture the patterns in the sliding window and mine them by scanning the stream only once. Extensive experiments show that the proposed method is more efficient and scalable than other analogous algorithms. Ã‚Â©2010 IEEE.},
  Affiliation              = {School of Software and Communication Engineering, Jiangxi University of Finance and Economics, China},
  Art_number               = {5473377},
  Author_keywords          = {Data stream; Recent frequent pattern; Sliding window},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2010 2nd International Workshop on Intelligent Systems and Applications, ISA 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chen2009. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954416557&partnerID=40&md5=963ed4e3440e01a439c8b9d37159ac22}
}

@Article{Chen2009,
  Title                    = {Efficiently mining recent frequent patterns over online transactional data streams},
  Author                   = {Chen, H.},
  Journal                  = {International Journal of Software Engineering and Knowledge Engineering},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Number                   = {5},
  Pages                    = {707-725},
  Volume                   = {19},

  Abstract                 = {Recent emerging applications, such as network traffic analysis, web click stream mining, power consumption measurement, sensor network data analysis, and dynamic tracing of stock fluctuation, call for study of a new kind of data, stream data. Many data stream management systems, prototype systems and software components have been developed to manage the streams or extract knowledge from stream data. Mining frequent patterns is a foundational job for the methods of data mining and knowledge discovery. This paper proposes an algorithm for mining the recent frequent patterns over an online data stream. This method uses RFP-tree to store compactly the recent frequent patterns of a stream. The content of each transaction is incrementally updated into the pattern tree upon its arrival by scanning the stream only once. Moreover, the strategy of conservative computation and time decaying model are used to ensure the correctness of the mining results. Finally, the performance results of extensive simulation show that our work can reduce the average processing time of stream data element and it is superior to other analogous algorithms. Ã‚Â© 2009 World Scientific Publishing Company.},
  Affiliation              = {School of Software, Jiangxi University of Finance and Economics, Nanchang, 330013, China},
  Author_keywords          = {Data stream; Frequent pattern mining; Sliding window},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining frequent patterns. This method uses RFP-tree to store compactly the recent frequent patterns. Single pass, incremental update of tree. Finally, the performance results of extensive simulation show that our work can reduce the average processing time of stream data element and it is superior to other analogous algorithms Approved 1,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70350316093&partnerID=40&md5=c7cd1edf09abfe606f95e626315e6c34}
}

@Article{Chen2012,
  Title                    = {Mining frequent patterns in a varying-size sliding window of online transactional data streams },
  Author                   = {Hui Chen and LihChyun Shu and Jiali Xia and Qingshan Deng},
  Journal                  = {Information Sciences },
  Year                     = {2012},
  Number                   = {0},
  Pages                    = {15 - 36},
  Volume                   = {215},

  Abstract                 = {In some data stream applications, the information embedded in the data arriving in the most recent time period is of particular interest. This paper proposes a method for efficiently mining the frequent patterns in a varying-size sliding window of online data streams. To highlight recent frequent patterns in the data stream, a time decay model is used to differentiate the patterns of recently generated transactions from historical transactions. The derived concrete bounds of the decay factor can achieve either 100% recall or 100% precision. A summary data structure, named SWP-tree, is proposed for capturing the content of the transactions in the sliding window by scanning the stream only once. In order to speed up online processing of new transactions, the information of frequent patterns recorded in the SWP-tree is updated in an incrementally way. To make the mining operation efficient, the SWP-tree is periodically pruned by identifying insignificant patterns, which include two kinds of obsolete pattern and two kinds of infrequent pattern. Since the sliding window can change its size, the effect of window size is examined. The performance of the proposed technique is evaluated via simulation experiments. The results show that the proposed method is both efficient and scalable, and that it outperforms comparable algorithms.},
  Doi                      = {http://dx.doi.org/10.1016/j.ins.2012.05.007},
  ISSN                     = {0020-0255},
  Keywords                 = {Transactional data stream},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {efficiently mining the frequent patterns in a varying-size sliding window of online data streams. The derived concrete bounds of the decay factor can achieve either 100% recall or 100% precision. Summary data structure, named SWP-tree, is proposed for capturing the content of the transactions in the sliding window by scanning the stream only once. Uses pruning of tress. The results show that the proposed method is both efficient and scalable, and that it outperforms comparable algorithms. 1,3,4,5,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0020025512003349}
}

@Article{Chen2009a,
  Title                    = {Wavelet-based amnesic synopses for data streams},
  Author                   = {Chen, H.a b and Shi, B.a },
  Journal                  = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Number                   = {2},
  Pages                    = {268-279},
  Volume                   = {46},

  Abstract                 = {Maintaining a synopsis data structure dynamically from data stream is vital for a variety of streaming data applications, such as approximate query or data mining. In many cases, the significance of data item in streams decays with age: this item perhaps conveys critical information first, but, as time goes by, it gets less and less important until it eventually becomes useless. This feature is termed amnesic. Discrete wavelet transform is often used in construction of synopses for streaming data. Proposed in this paper is a wavelet-based hierarchical amnesic synopsis (W-HAS), which includes the amnesic feature of data stream in the generation of wavelet synopses. W-HAS can provide a better approximate representation for data streams with amnesic feature than conventional wavelet synopses. To maintain W-HAS online for evolving data streams, the authors first explore the merger process of two wavelet decompositions, and then implement the addition of data nodes in W-HAS structure based on the merger process. Using the addition of data nodes, W-HAS grows dynamically and hierarchically. The construction methods of W-HAS under sum of squared error (sse) and maximum absolute error metrics are discussed. Further, W-HAS with error control is also explore. Finally, experiments on real and synthetic datasets validated the proposed methods.},
  Affiliation              = {Department of Computing and Information Technology, Fudan University, Shanghai 200433, China; School of Information Science and Engineering, Ningbo University, Ningbo 315211, China},
  Author_keywords          = {Amnesic feature; Approximation representation; Data stream; Discrete wavelet transform; Synopses},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {wavelet-based hierarchical amnesic synopsis (W-HAS). Generates wavelets, dealing with data streams that has decaying relevance with age. Coined amnesic data streams. Finally, experiments on real and synthetic datasets validated the proposed methods. Approved. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-62549117793&partnerID=40&md5=a4bd7ae2c32f5af62ddc7169a54c0490}
}

@Article{Chen2007,
  Title                    = {GC-tree: A fast online algorithm for mining frequent closed itemsets},
  Author                   = {Chen, J. and Li, S.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {457-468},
  Volume                   = {4819 LNAI},

  Abstract                 = {Frequent closed itemsets is a complete and condensed representaion for all the frequent itemsets, and it's important to generate non-redundant association rules. It has been studied extensively in data mining research, but most of them are done based on traditional transaction database environment and thus have performance issue under data stream environment. In this paper, a novel approach is proposed to mining closed frequent itemsets over data streams. It is an online algorithm which update frequent closed itemsets incrementally, and can output the current closed frequent itemsets in real time based on users specified thresholds. The experimental evaluation shows that our proposed method is both time and space efficient, compared with the state of art online frequent closed itemsets algorithm FCI-Stream [3]. Ã‚Â© Springer-Verlag Berlin Heidelberg 2007.},
  Affiliation              = {Department of Computer Science, ZheJiang University, Zhejiang University YuQuan Campus, Dorm 10, 5035, Hangzhou City, Zhejiang Province, China},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, a novel approach is proposed to mining closed frequent itemsets over data streams. It is an online algorithm which update frequent closed itemsets incrementally. can output the current closed frequent itemsets in real time based on users specified thresholds. The experimental evaluation shows that our proposed method is both time and space efficient, compared with the state of art online frequent closed itemsets algorithm FCI-Stream. Approved. 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38549181501&partnerID=40&md5=e4a372d0307c246b580da04ee8c295b0}
}

@Conference{Chen2006,
  Title                    = {Supporting self-adaptation in streaming data mining applications},
  Author                   = {Chen, L. and Agrawal, G.},
  Year                     = {2006},
  Note                     = {cited By (since 1996)0},
  Volume                   = {2006},

  Abstract                 = {There are many application classes where the users are flexible with respect to the output quality. At the same time, there are other constraints, such as the need for real-time or interactive response, which are more crucial. This paper presents and evaluates a runtime algorithm for supporting adaptive execution for such applications. The particular domain we target is distributed data mining on streaming data. This work has been done in the context of a middleware system called GATES (Grid-based AdapTive Execution on Streams) that we have been developing. The self-adaptation algorithm we present and evaluate in this paper has the following characteristics. First, it carefully evaluates the long-term load at each processing stage. It considers different possibilities for the load at a processing stage and its next stages, and decides if the value of an adaptation parameter needs to be modified, and if so, in which direction. To find the ideal new value of an adaptation parameter, it performs a binary search on the specified range of the parameter. To evaluate the self-adaptation algorithm in our middleware, we have implemented two streaming data mining applications. The main observations from our experiments are as follows. First, our algorithm is able to quickly converge to stable values of the adaptation parameter, for different data arrival rates, and independent of the specified initial value. Second, in a dynamic environment, the algorithm is able to adapt the processing rapidly. Finally, in both static and dynamic environments, the algorithm clearly outperforms the algorithm described in our earlier work and an obvious alternative, which is based on linear-updates. Ã‚Â© 2006 IEEE.},
  Affiliation              = {Department of Computer Science and Engineering, Ohio State University, Columbus, OH 43210, United States},
  Art_number               = {1639312},
  Document_type            = {Conference Paper},
  Journal                  = {20th International Parallel and Distributed Processing Symposium, IPDPS 2006},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Adaptive execution of data mining from streams, depending on user preferences. To evaluate the self-adaptation algorithm in our middleware, we have implemented two streaming data mining applications. Converges quickly to stable value of adapatation parameters according to data rates. Outperforms their earlier work. Approved. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33847151783&partnerID=40&md5=39134a87509fed30911a3bf70341eea8}
}

@Article{Chen2006a,
  Title                    = {{Supporting self-adaptation in streaming data mining applications}},
  Author                   = {Chen, Liang and Agrawal, Gagan},
  Journal                  = {IN PROCEEDINGS OF IEEE INTERNATIONAL PARALLEL \& DISTRIBUTED PROCESSING SYMPOSIUM(IPDPS},
  Year                     = {2006},

  __markedentry            = {[Alexander:]},
  Abstract                 = {There are many application classes where the users are flexible with respect to the output quality. At the same time, there are other constraints, such as the need for real-time or interactive response, which are more crucial. This paper presents and evaluates a runtime algorithm for supporting adaptive execution for such applications. The particular domain we target is distributed data mining on streaming data. This work has been done in the context of a middleware system called GATES (Grid-based AdapTive Execution on Streams) that we have been developing. The self-adaptation algorithm we present and evaluate in this paper has the following characteristics. First, it carefully evaluates the long-term load at each processing stage. It consider different possibilities for the load at a processing stage and its next stages, and decides if the value of an adaptation parameter needs to be modified, and if so, in which direction. To find the ideal new value of an adaptation parameter, it performs a binary search on the specified range of the parameter. To evaluate the self-adaptation algorithm in our middleware, we have implemented two streaming data mining applications. The main observations from our experiments are as follows. First, our algorithm is able to quickly converge to stable values of the adaptation parameter, for different data arrival rates, and independent of the specified initial value. Second, in a dynamic environment, the algorithm is able to adapt the processing rapidly. Finally, in both static and dynamic environments, the algorithm clearly outperforms the algorithm described in our earlier work and an obvious alternative, which is based on linear-updates.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chen2006. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.133.8060}
}

@Article{Chen2011a,
  Title                    = {SQL streaming process in query engine net},
  Author                   = {Chen, Q. and Hsu, M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 1},
  Pages                    = {403-411},
  Volume                   = {7044 LNCS},

  Abstract                 = {The massively growing data volume and the pressing need for low latency are pushing the traditional store-first-query-later data warehousing technologies beyond their limits. Many enterprise applications are now based on continuous analytics of data streams. While integrating stream processing with query processing takes advantage of SQL's expressive power and DBMS's data management capability, it raises serious challenges in dealing with complex dataflow, applying queries to unbounded stream data, and providing highly scalable, dynamically configurable, elastic infrastructure. To solve these problems, we model the general graph-structured, continuous dataflow analytics as a SQL Streaming Process with multiple connected and stationed continuous queries; then we extend the query engine to support cyclebased query execution for processing unbounded stream data chunk-wise with sound semantics; and finally, we develop the Query Engine Net (QE-Net) over the Distributed Caching Platforms (DCP) as a dynamically configurable elastic infrastructure for parallel and distributed execution of SQL Streaming Processes. We extended the PostgreSQL engines for building the QE-Net infrastructure. Our experience shows its merit in leveraging SQL and query processing to analyze real-time, graph-structured and unbounded streams. Integrating it with a commercial and proprietary MPP based database cluster is being investigated. Ã‚Â© 2011 Springer-Verlag.},
  Affiliation              = {HP Labs., Hewlett Packard Co., Palo Alto, CA, United States},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Query Engine Net (QE-Net) over the Distributed Caching Platforms (DCP) as a dynamically configurable elastic infrastructure for parallel and distributed execution of SQL Streaming Processes. Stream processing of data. Not ML usage. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-81255153930&partnerID=40&md5=1adb979c164b475ad83370e45288e79c}
}

@Misc{Chena,
  Title                    = {{Experience in Continuous analytics as a Service (CaaaS)}},

  Author                   = {Chen, Qiming and Hsu, Meichun and Zeller, Hans},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Mobile applications, such as those on WebOS, increasingly depend on continuous analytics results of real-time events, for monitoring oil & gas production, watching traffic status and detecting accident, etc, which has given rise to the need of providing Continuous analytics as a Service (CaaaS). While representing a paradigm shift in cloud computing, CaaaS poses several challenges in scalability, latency, time-window semantics, transaction control and result-set staging. A data stream is infinite thus can only be analyzed in granules. We propose a continuous query model over both static relations and dynamic streaming data, which allows a long-standing SQL query instance to run cycle by cycle, each cycle for a chunk of data from the data stream, using a cut-and-rewind mechanism. We further support the cycle-based transaction model with cyclebased isolation and visibility, for delivering analytics results to the clients continuously while the query is running. To have the continuously generated analytics results staged efficiently, we developed the table-ring and label switching mechanism characterized by staging data through metadata manipulation without physical data moving and copying. To scale-out analytics computation, we support both parallel database based and network distributed Map-Reduce based infrastructure with multiple cooperating engines. We have built the proposed infrastructure by extending the PostgreSQL engine. We tested the throughput and latency of this service based on a well-known stream processing benchmark; the results show that the proposed approach is highly competitive. Our experiments indicate that the database technology can be extended and applied to real-time continuous analytics service provisioning.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They have built a continous analytics as a service (CaaS). Mostly how the infrastructure must be setup, especially regarding underlying databases. Does not appear to deal with machine learning, but rather performing analytics on streams. Accepted due to doubt. Approved. 1,3,4},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.429.2482}
}

@Conference{Chen2011b,
  Title                    = {Experience in Continuous analytics as a Service (CaaaS)},
  Author                   = {Chen, Q.a and Hsu, M.a and Zeller, H.b },
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Pages                    = {509-514},

  Abstract                 = {Mobile applications, such as those on WebOS, increasingly depend on continuous analytics results of real-time events, for monitoring oil & gas production, watching traffic status and detecting accident, etc, which has given rise to the need of providing Continuous analytics as a Service (CaaaS). While representing a paradigm shift in cloud computing, CaaaS poses several challenges in scalability, latency, time-window semantics, transaction control and result-set staging. A data stream is infinite thus can only be analyzed in granules. We propose a continuous query model over both static relations and dynamic streaming data, which allows a long-standing SQL query instance to run cycle by cycle, each cycle for a chunk of data from the data stream, using a cut-and-rewind mechanism. We further support the cycle-based transaction model with cycle-based isolation and visibility, for delivering analytics results to the clients continuously while the query is running. To have the continuously generated analytics results staged efficiently, we developed the table-ring and label switching mechanism characterized by staging data through metadata manipulation without physical data moving and copying. To scale-out analytics computation, we support both parallel database based and network distributed Map-Reduce based infrastructure with multiple cooperating engines. We have built the proposed infrastructure by extending the PostgreSQL engine. We tested the throughput and latency of this service based on a well-known stream processing benchmark; the results show that the proposed approach is highly competitive. Our experiments indicate that the database technology can be extended and applied to real-time continuous analytics service provisioning.},
  Affiliation              = {HP Labs, Palo Alto CA, United States; HP SW NED, Cupertino CA, United States},
  Author_keywords          = {Cloud service; Continuous query; Stream analytics},
  Document_type            = {Conference Paper},
  Journal                  = {ACM International Conference Proceeding Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chena. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79953868814&partnerID=40&md5=7757b6397a1b9a86ebafec7a5fe74310}
}

@InProceedings{Chen2011d,
  Title                    = {{Experience in Continuous analytics as a Service (CaaaS)}},
  Author                   = {Chen, Qiming and Hsu, Meichun and Zeller, Hans},
  Booktitle                = {Proceedings of the 14th International Conference on Extending Database Technology - EDBT/ICDT '11},
  Year                     = {2011},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {509},
  Publisher                = {ACM Press},

  Abstract                 = {Mobile applications, such as those on WebOS, increasingly depend on continuous analytics results of real-time events, for monitoring oil & gas production, watching traffic status and detecting accident, etc, which has given rise to the need of providing Continuous analytics as a Service (CaaaS). While representing a paradigm shift in cloud computing, CaaaS poses several challenges in scalability, latency, time-window semantics, transaction control and result-set staging. A data stream is infinite thus can only be analyzed in granules. We propose a continuous query model over both static relations and dynamic streaming data, which allows a long-standing SQL query instance to run cycle by cycle, each cycle for a chunk of data from the data stream, using a cut-and-rewind mechanism. We further support the cycle-based transaction model with cycle-based isolation and visibility, for delivering analytics results to the clients continuously while the query is running. To have the continuously generated analytics results staged efficiently, we developed the table-ring and label switching mechanism characterized by staging data through metadata manipulation without physical data moving and copying. To scale-out analytics computation, we support both parallel database based and network distributed Map-Reduce based infrastructure with multiple cooperating engines. We have built the proposed infrastructure by extending the PostgreSQL engine. We tested the throughput and latency of this service based on a well-known stream processing benchmark; the results show that the proposed approach is highly competitive. Our experiments indicate that the database technology can be extended and applied to real-time continuous analytics service provisioning.},
  Doi                      = {10.1145/1951365.1951426},
  ISBN                     = {9781450305280},
  Keywords                 = {cloud service,continuous query,stream analytics},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chena. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1951365.1951426}
}

@Article{Chen2009b,
  Title                    = {An in-database streaming solution to multi-camera fusion},
  Author                   = {Chen, Q.a and Li, Q.b and Hsu, M.a and Yu, T.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {136-149},
  Volume                   = {5697 LNCS},

  Abstract                 = {Multi-camera based video object tracking is a multi-stream data fusion and analysis problem. With the current technology, video analysis software architecture generally separates the analytics layer from the data management layer, which has become the performance bottleneck because of large scaled data transfer, inefficient data access and duplicate data buffering and management. Motivated by providing a convergent platform, we use user-defined Relation Valued Functions (RVFs) to have visual data computation naturally integrated to SQL queries, and pushed down to the database engine; we model complex applications with general graph based data-flows and control-flows at the process level where "actions" are performed by RVFs and "linked" in SQL queries. We further introduce Stream Query Process with stream data input and continuous execution. Our solutions to multi-camera video surveillance also include a new tracking method that is based on P2P time-synchronization of video streams and P2P target fusion. These techniques represent a major shift in process management from one-time execution to data stream driven, open-ended execution, and constitute a novel step to the use of a query engine for running processes, towards the "In-DB Streaming" paradigm. We have prototyped the proposed approaches by extending the open-sourced database engine Postgres, and plan to transfer the implementation to a commercial and proprietary parallel database system. The empirical study in a surveillance setting reveals their advantages in scalability, real-time performance and simplicity. Ã‚Â© 2009 Springer.},
  Affiliation              = {Hewlett Packard Co., HP Labs., Palo Alto, CA, United States; Hewlett Packard Co., HP Labs., Beijing, China},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Multi-camera based video object tracking solution, novel because data management and analytics are not separted in different layers. These techniques represent a major shift in process management from one-time execution to data stream driven. The empirical study in a surveillance setting reveals their advantages in scalability, real-time performance and simplicity. Approved. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70350587345&partnerID=40&md5=fc7d2daa31aa4676ac7d3326fea70948}
}

@Article{Chen2011c,
  Title                    = {Query engine grid for executing SQL streaming process},
  Author                   = {Chen, Q.a b and Hsu, M.a b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {95-107},
  Volume                   = {6864 LNCS},

  Abstract                 = {Many enterprise applications are based on continuous analytics of data streams. Integrating data-intensive stream processing with query processing allows us to take advantage of SQL's expressive power and DBMS's data management capability. However, it also raises serious challenges in dealing with complex dataflow, applying queries to unbounded stream data, and providing highly scalable, dynamically configurable, elastic infrastructure. In this project we tackle these problems in three dimensions. First, we model the general graph-structured, continuous dataflow analytics as a SQL Streaming Process with multiple connected and stationed continuous queries. Next, we extend the query engine to support cycle-based query execution for processing unbounded stream data in bounded chunks with sound semantics. Finally, we develop the Query Engine Grid (QE-Grid) over the Distributed Caching Platforms (DCP) as a dynamically configurable elastic infrastructure for parallel and distributed execution of SQL Streaming Processes. The proposed infrastructure is preliminarily implemented using PostgreSQL engines. Our experience shows its merit in leveraging SQL and query engines to analyze real-time, graph-structured and unbounded streams. Integrating it with a commercial and proprietary MPP based database cluster is being investigated. Ã‚Â© 2011 Springer-Verlag.},
  Affiliation              = {HP Labs., Palo Alto, CA, United States; Hewlett Packard Co., United States},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {infrastructure for dealing with complex data flow. Query engine, not ML. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052773915&partnerID=40&md5=ad370b7f2b383a8bd4aa99eb0d9fdf82}
}

@Article{Chen2001,
  Title                    = {{An approach to online Bayesian learning from multiple data streams}},
  Author                   = {Chen, R. and Sivakumar, K. and Kargupta, H.},
  Journal                  = {IN PROCEEDINGS OF WORKSHOP ON MOBILE AND DISTRIBUTED DATA MINING, PKDD â€™01},
  Year                     = {2001},
  Pages                    = {31 -- 45},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We present a collective approach to mine Bayesian networks from distributed heterogenous web-log data streams. In this approach we first learn a local Bayesian network at each site using the local data. Then each site identifies the observations that are most likely to be evidence of coupling between local and non-local variables and transmits a subset of these observations to a central site. Another Bayesian network is learnt at the central site using the data transmitted from the local site. The local and central Bayesian networks are combined to obtain a collective Bayesian network, that models the entire data. This technique is then suitably adapted to an online Bayesian learning technique, where the network parameters are updated sequentially based on new data from multiple streams. We applied this technique to mine multiple data streams where data centralization is difficult because of large response time and scalability issues. This approach is particularly suitable for mining applications with distributed sources of data streams in an environment with non-zero communication cost (e.g. wireless networks). Experimental results and theoretical justification that demonstrate the feasibility of our approach are presented.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mine Bayesian networks from distributed heterogenous web-log data streams. Distributed solution, to mine multiple data streams where data centralization is difficult because of large response time and scalability issues. Useful when communication cost is non-zero, like wireless networks. Experimental results and theoretical justification that demonstrate the feasibility of our approach are presented Approved 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.9967}
}

@Misc{Chen,
  Title                    = {{Stop Chasing Trends: Discovering High Order Models in Evolving Data}},

  Author                   = {Chen, Shixi and Wang, Haixun and Zhou, Shuigeng and Yu, Philip S.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Many applications are driven by evolving data — patterns in web traffic, program execution traces, network event logs, etc., are often non-stationary. Building prediction models for evolving data becomes an important and challenging task. Currently, most approaches work by “chasing trends”, that is, they keep learning or updating models from the evolving data, and use these impromptu models for online prediction. In many cases, this proves to be both costly and ineffective — much time is wasted on re-learning recurring concepts, yet the classifier may remain one step behind the current trend all the time. In this paper, we propose to mine high-order models in evolving data. More often than not, there are a limited number of concepts, or stable distributions, in the data stream, and concepts switch between each other constantly. We mine all such concepts offline from a historical stream, and build high quality models for each of them. At run time, combining historical concept change patterns and cues provided by an online training stream, we find the most likely current concept and use its corresponding models to classify data in an unlabeled stream. The primary advantage of the high-order model approach is its high accuracy. Experiments show that in benchmark datasets, classification error of the highorder model is only a small fraction of that of the current best approaches. Another important benefit is that, unlike state-of-theart approaches, our approach does not require users to tune any parameters to achieve a satisfying result on streams of different characteristics.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chen2008. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.6648}
}

@InProceedings{Chen2008,
  Title                    = {{Stop Chasing Trends: Discovering High Order Models in Evolving Data}},
  Author                   = {Chen, Shixi and Wang, Haixun and Zhou, Shuigeng and Yu, Philip S.},
  Booktitle                = {2008 IEEE 24th International Conference on Data Engineering},
  Year                     = {2008},
  Month                    = apr,
  Pages                    = {923--932},
  Publisher                = {IEEE},

  Abstract                 = {Many applications are driven by evolving data - patterns in Web traffic, program execution traces, network event logs, etc., are often non-stationary. Building prediction models for evolving data becomes an important and challenging task. Currently, most approaches work by "chasing trends", that is, they keep learning or updating models from the evolving data, and use these impromptu models for online prediction. In many cases, this proves to be both costly and ineffective - much time is wasted on re-learning recurring concepts, yet the classifier may remain one step behind the current trend all the time. In this paper, we propose to mine high-order models in evolving data. More often than not, there are a limited number of concepts, or stable distributions, in the data stream, and concepts switch between each other constantly. We mine all such concepts offline from a historical stream, and build high quality models for each of them. At run time, combining historical concept change patterns and cues provided by an online training stream, we find the most likely current concept and use its corresponding models to classify data in an unlabeled stream. The primary advantage of the high-order model approach is its high accuracy. Experiments show that in benchmark datasets, classification error of the high-order model is only a small fraction of that of the current best approaches. Another important benefit is that, unlike state-of-the-art approaches, our approach does not require users to tune any parameters to achieve a satisfying result on streams of different characteristics.},
  Doi                      = {10.1109/ICDE.2008.4497501},
  ISBN                     = {978-1-4244-1836-7},
  Keywords                 = {Learning systems,Monitoring,Power system modeling,Predictive models,Road accidents,Sequential analysis,Switches,Telecommunication traffic,Testing,Traffic control,benchmark datasets,change patterns,chasing trends,data handling,data stream,evolving data,online training stream,pattern classification,prediction models},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Currently, most approaches work by “chasing trends”, that is, they keep learning or updating models from the evolving data. Much time is wasted on re-learning recurring concepts. Mine concepts offline and combine offline concepts with online. Experiments show that in benchmark datasets, classification error of the highorder model is only a small fraction of that of the current best approaches. And unlike state-of-theart approaches, our approach does not require users to tune any parameters to achieve a satisfying result on streams of different characteristics Approved 1,2,3,4,5,6},
  Shorttitle               = {Data Engineering, 2008. ICDE 2008. IEEE 24th Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4497501}
}

@Article{Chen2002a,
  Title                    = {{Online Analytical Processing Stream Data: Is It Feasible?}},
  Author                   = {Chen, Yixin and Dong, Guozhu and Han, Jiawei and Pe, Jian and Wah, Benjamin W. and Wang, Jianyong},
  Journal                  = {IN DMKD},
  Year                     = {2002},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Real-time surveillance systems and other dynamic environ- ments often generate tremendous (potentially infinite) vol- ume of stream data: the volume is too huge to be scanned multiple times. However, much of such data resides at rather low level of abstraction, whereas most analysts are interested in dynamic changes (such as trends and outliers) at relatively high levels of abstraction. To discover such high level characteristics, one may need to perform on-line multi-level analysis of stream data, similar to OLAP (on-line analytical processing) of relational or data warehouse data.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Huge volumes of data are generated by real-time surveillance systems, but is mostly low level, while analysts care about dynamic changes at higher level of abstraction.They present an architecture for doing multi-level, multi-dimensional processing and mining. Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.3360}
}

@Article{Chen2002,
  Title                    = {{Multi-dimensional regression analysis of time-series data streams}},
  Author                   = {Chen, Yixin and Dong, Guozhu and Han, Jiawei and Wah, Benjamin W. and Wang, Jianyong},
  Year                     = {2002},

  Month                    = aug,
  Pages                    = {323--334},

  Abstract                 = {Real-time production systems and other dynamic environments often generate tremendous (potentially infinite) amount of stream data; the volume of data is too huge to be stored on disks or scanned multiple times. Can we perform on-line, multi-dimensional analysis and data mining of such data to alert people about dramatic changes of situations and to initiate timely, high-quality responses? This is a challenging task. In this paper, we investigate methods for on-line, multi-dimensional regression analysis of time-series stream data, with the following contributions: (1) our analysis shows that only a small number of compressed regression measures instead of the complete stream of data need to be registered for multi-dimensional linear regression analysis, (2) to facilitate on-line stream data analysis, a partially materialized data cube model, with regression as measure, and a tilt time frame as its time dimension, is proposed to minimize the amount of data to be retained in memory or stored on disks, and (3) an exception-guided drilling approach is developed for on-line, multi-dimensional exception-based regression analysis. Based on this design, algorithms are proposed for efficient analysis of time-series data streams. Our performance study compares the proposed algorithms and identifies the most memory- and time- efficient one for multi-dimensional stream data analysis.},
  Owner                    = {alex},
  Publisher                = {VLDB Endowment},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Can we perform on-line, multi-dimensional analysis and data mining of such data to alert people about dramatic changes of situations and to initiate timely, high-quality responses. They make optimizations for efficiency, and exception-guided drilling approach is developed for on-line, multi-dimensional exception-based regression analysis.Based on this design, algorithms are proposed for efficient analysis of time-series data streams. Our performance study compares the proposed algorithms and identifies the most memory- and time- efficient one for multi-dimensional stream data analysis. Approved. 1,3,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1287369.1287398}
}

@Misc{Chen2002b,
  Title                    = {{Multi-Dimensional Regression Analysis of Time-Series Data Streams}},

  Author                   = {Chen, Yixin and Dong, Guozhu and Han, Jiawei and Wah, Benjamin W. and Wang, Jianyong},
  Year                     = {2002},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Real-time production systems and other dynamic environments often generate tremendous (potentially infinite) amount of stream data; the volume of data is too huge to be stored on disks or scanned multiple times. Can we perform on-line, multi-dimensional analysis and data mining of such data to alert people about dramatic changes of situations and to initiate timely, high-quality responses? This is a challenging task. In this paper,},
  Booktitle                = {PROC. VLDB 02},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chen2002. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.146.51}
}

@InProceedings{Chen2011,
  Title                    = {{Online fractal dimensionality reduction in time decaying stream environment}},
  Author                   = {Chen, Zhizhong and He, Ruichun and Li, Yinzhen},
  Booktitle                = {2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)},
  Year                     = {2011},
  Month                    = jul,
  Pages                    = {1480--1484},
  Publisher                = {IEEE},
  Volume                   = {3},

  Abstract                 = {Dimensionality reduction, the process of reduce the number of dimension of the original feature set, plays an important role in a wide variety of contexts such as classification, Prediction and clustering. It is common to introduce the dimensionality reduction prior to the subsequent data mining tasks in the classical static data. However, this aforehand option can not capture the essence of datum because of the inherent time variety and one-pass constraint of data stream. In this case, dimensionality reduction should interact with the evolution of stream data with time elapsed. We introduced the interaction between dimensionality reduction in the time decaying high dimensional stream environment and propose the on-line fractal dimensionality reduction technique. Our performance experiments over a number of real and synthetic data sets illustrate the effectiveness and efficiency provided by our approach.},
  Doi                      = {10.1109/FSKD.2011.6019844},
  ISBN                     = {978-1-61284-180-9},
  Keywords                 = {Correlation,Data mining,Dimensionality reduction,Educational institutions,Equations,Feature extraction,Fractal,Fractals,Mathematical model,Time decaying,classical static data mining,data evolution,data mining,data reduction,data stream,datum essence,inherent time variety,one-pass constraint,online fractal dimensionality reduction technique,original feature set,real data set,synthetic data set,time decaying high dimensional stream environment},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Fractal dimensionality reduction technique, dimensionality reduction that adapts to streaming data as time passes. Our performance experiments over a number of real and synthetic data sets illustrate the effectiveness and efficiency provided by our approach. Approved. 1,2,3,4,6},
  Shorttitle               = {Fuzzy Systems and Knowledge Discovery (FSKD), 2011},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6019844}
}

@Conference{Cheng2013a,
  Title                    = {Peckalytics: Analyzing experts and interests on twitter},
  Author                   = {Cheng, A. and Bansal, N. and Koudas, N.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {973-976},

  Abstract                 = {We provide a description of Peckalytics, its technology and functionality. Peckalytics processes the entire Twitter data stream in real time and provides a flexible search interface to identify experts in any topic area as well as users with interests in any topic. It provides flexible analytics around sets of experts, their followers as well as sets of users with specific interests. The system is implemented to scale for large data sizes. At the time of this writing it operates on an archive of 30 billion tweets, with 220, 000 new tweets crawled every minute. In addition to raw tweets, the social graph of users, and profile information, Peckalytics makes novel use of Twitter lists to assess the expertise of different users. Our aim is to facilitate targeting and optimization of advertising campaigns on the Twitter platform. Copyright Ã‚Â© 2013 ACM.},
  Affiliation              = {Computer Science, University of Toronto, Canada},
  Author_keywords          = {Experts Analysis; Interest Analysis; Twitter Analytics},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Analysis system used for tweets, identifying topic experts and topic interested users. Approved 1},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880538166&partnerID=40&md5=e46b389fb0d59e610e8415f2ad3c1952}
}

@InProceedings{Cheng2013b,
  Title                    = {{Peckalytics}},
  Author                   = {Cheng, Alex and Bansal, Nilesh and Koudas, Nick},
  Booktitle                = {Proceedings of the 2013 international conference on Management of data - SIGMOD '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = jun,
  Pages                    = {973},
  Publisher                = {ACM Press},

  Abstract                 = {We provide a description of Peckalytics, its technology and functionality. Peckalytics processes the entire Twitter data stream in real time and provides a flexible search interface to identify experts in any topic area as well as users with interests in any topic. It provides flexible analytics around sets of experts, their followers as well as sets of users with specific interests. The system is implemented to scale for large data sizes. At the time of this writing it operates on an archive of 30 billion tweets, with 220,000 new tweets crawled every minute. In addition to raw tweets, the social graph of users, and profile information, Peckalytics makes novel use of Twitter lists to assess the expertise of different users. Our aim is to facilitate targeting and optimization of advertising campaigns on the Twitter platform.},
  Doi                      = {10.1145/2463676.2463679},
  ISBN                     = {9781450320375},
  Keywords                 = {experts analysis,interest analysis,twitter analytics},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Cheng2013a. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2463676.2463679}
}

@Misc{Cheng,
  Title                    = {{A Survey on Algorithms for Mining Frequent Itemsets over Data Streams}},

  Author                   = {Cheng, James and Ke, Yiping and Ng, Wilfred},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The increasing prominence of data streams arising in a wide range of advanced applications such as fraud detection and trend learning has led to the study of online mining of frequent itemsets (FIs). Unlike mining static databases, mining data streams poses many new challenges. In addition to the one-scan nature, the unbounded memory requirement and the high data arrival rate of data streams, the combinatorial explosion of itemsets exacerbates the mining task. The high complexity of the FI mining problem hinders the application of the stream mining techniques. We recognize that a critical review of existing techniques is needed in order to design and develop efficient mining algorithms and data structures that are able to match the processing rate of the mining with the high arrival rate of data streams. Within a unifying set of notations and terminologies, we describe in this paper the efforts and main techniques for mining data streams and present a compre-hensive survey of a number of the state-of-the-art algorithms on mining frequent itemsets over data streams. We classify the stream-mining techniques into two categories based on the window model that they adopt in order to provide in-sights into how and why the techniques are useful. Then, we further analyze the algorithms according to whether they are exact or approximate and, for approxi-mate approaches, whether they are false-positive or false-negative. We also discuss various interesting issues, including the merits and limitations in existing research and substantive areas for future research.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {Survey on algorithms for mining frequent itemsets from streams. Discarded, but put aside.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.96.8249}
}

@Article{Cheng2008,
  Title                    = {A survey on algorithms for mining frequent itemsets over data streams},
  Author                   = {Cheng, J. and Ke, Y. and Ng, W.},
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2008},
  Note                     = {cited By (since 1996)49},
  Number                   = {1},
  Pages                    = {1-27},
  Volume                   = {16},

  Abstract                 = {The increasing prominence of data streams arising in a wide range of advanced applications such as fraud detection and trend learning has led to the study of online mining of frequent itemsets (FIs). Unlike mining static databases, mining data streams poses many new challenges. In addition to the one-scan nature, the unbounded memory requirement and the high data arrival rate of data streams, the combinatorial explosion of itemsets exacerbates the mining task. The high complexity of the FI mining problem hinders the application of the stream mining techniques. We recognize that a critical review of existing techniques is needed in order to design and develop efficient mining algorithms and data structures that are able to match the processing rate of the mining with the high arrival rate of data streams. Within a unifying set of notations and terminologies, we describe in this paper the efforts and main techniques for mining data streams and present a comprehensive survey of a number of the state-of-the-art algorithms on mining frequent itemsets over data streams. We classify the stream-mining techniques into two categories based on the window model that they adopt in order to provide insights into how and why the techniques are useful. Then, we further analyze the algorithms according to whether they are exact or approximate and, for approximate approaches, whether they are false-positive or false-negative. We also discuss various interesting issues, including the merits and limitations in existing research and substantive areas for future research. Ã‚Â© Springer-Verlag London Limited 2007.},
  Affiliation              = {Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, HKUST, Clear Water Bay, Kowloon, Hong Kong},
  Author_keywords          = {Approximate algorithms; Frequent itemsets; Stream mining; Window models},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Cheng. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-47249155714&partnerID=40&md5=9774ca983f3cead523eb1c3530a46415}
}

@Article{Cheng2010,
  Title                    = {Analysis model over data stream based on radial basis statistical network},
  Author                   = {Cheng, Y.-H. and Liu, B. and Wang, X.-S.},
  Journal                  = {Kongzhi yu Juece/Control and Decision},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Number                   = {6},
  Pages                    = {879-883+888},
  Volume                   = {25},

  Abstract                 = {A kind of radial basis statistical network (RBSN) over data stream is proposed based on traditional radial basis function network. The RBSN adopts a compound and multidimensional Gaussian function to fit probability densities of different areas located in input space. The learning algorithm of RBSN is designed based on a mathematical statistics method. Both the time complexity and space complexity of the network learning algorithm are linear with the product of the dimensionality of input variables and the number of hidden units, which are irrelative with the scale of data stream. Therefore, the learning algorithm of RBSN can satisfy the real-time requirement of the analysis of data stream. Simulation results show that the proposed RBSN can effectively solve both regression and classification problems over data stream.},
  Affiliation              = {School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou 221116, China},
  Author_keywords          = {Data stream; Gaussian function; Mathematical statistics; Radial basis statistical network; Regression estimation},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A kind of radial basis statistical network (RBSN). The learning algorithm of RBSN is designed based on a mathematical statistics method. Therefore, the learning algorithm of RBSN can satisfy the real-time requirement of the analysis of data stream. Simulation results show that the proposed RBSN can effectively solve both regression and classification problems over data stream. Approved. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954368584&partnerID=40&md5=49f5e693d8ca3fe488fd3f481325bc4a}
}

@InProceedings{CZPJJBCKZ2012,
  Title                    = {{Real-time analytics processing with MapReduce}},
  Author                   = {{Cheng-Zhang Peng} and {Ze-Jun Jiang} and {Xiao-Bin Cai} and {Zhi-Ke Zhang}},
  Booktitle                = {2012 International Conference on Machine Learning and Cybernetics},
  Year                     = {2012},
  Month                    = jul,
  Pages                    = {1308--1311},
  Publisher                = {IEEE},
  Volume                   = {4},

  Abstract                 = {Many real-time analytical applications over massive data streams were performed by usually introducing a specific stream processing core. In general, these SPCs were not popularly applied to enterprises same as MapReduce, even if now real-time analytics applications are taken into attention more and more. For reversing this tide, we developed a new analytics system. Our system modified the stock Hadoop's MapReduce programming model and execution framework, and used Chord model as temporary data, Cassandra as its persistent storage. With our system, we can develop data stream processing application with the familiar MapReduce programming model.},
  Doi                      = {10.1109/ICMLC.2012.6359554},
  ISBN                     = {978-1-4673-1487-9},
  ISSN                     = {2160-133X},
  Keywords                 = {Abstracts,Adaptation models,Cassandra,Chord model,Computational modeling,Data stream processing,Internet,JOL,MapReduce,MapReduce programming,Monitoring,Programming,Real-time analytics,Real-time systems,SPC,Storms,data handling,massive data streams,persistent storage,real-time analytics processing,real-time systems,stream processing core},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Our system modified the stock Hadoop's MapReduce programming model and execution framework, and used Chord model as temporary data, Cassandra as its persistent storage Duplicate of Peng2012. Discarded.},
  Shorttitle               = {Machine Learning and Cybernetics (ICMLC), 2012 Int},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6359554}
}

@Conference{Chok2009,
  Title                    = {An online spatio-temporal association rule mining framework for analyzing and estimating sensor data},
  Author                   = {Chok, H. and Gruenwald, L.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {217-226},

  Abstract                 = {A sensor network is a valuable new form of collective computational instrumentation by virtue of its ability to sense physical quantities of interest and to transmit such readings via sub-networks of nodes/computers for processing. Such computing environment typically generates massive amounts of data rapidly in real-time. These infinite volumes of online time-series are formally characterized as data streams. The wealth of fast incoming data streams presents both overhead and logistic challenges for sensor network applications. In this research, we introduce an online data mining framework to serve as an overhead-bounded knowledge discovery tool for sensornet applications. Our framework extends the notions of traditional association rules to multivariate continuous data and uses spatiotemporal correlations to make intelligent inferences about the monitored variables. Our mining framework is additionally pertinent to data estimation, which is an important capability given the inevitability of data loss/corruption with the current sensornet technology. Experimentation shows efficiency of our approach both in terms of overhead cost and quality of missing data estimates. Copyright Ã‚Â© 2009 ACM.},
  Affiliation              = {School of Computer Science, University of Oklahoma, 200 Felgar Street, Norman, OK 73019-6151, United States},
  Art_number               = {1620455},
  Author_keywords          = {Data estimation; Knowledge discovery; Sensor databases; Spatio-temporal data mining},
  Document_type            = {Conference Paper},
  Journal                  = {ACM International Conference Proceeding Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this research, we introduce an online data mining framework to serve as an overhead-bounded knowledge discovery tool for sensornet applications. Experimentation shows efficiency of our approach both in terms of overhead cost and quality of missing data estimates. Approved 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70350675561&partnerID=40&md5=7d7c0ef382ffe393e32821da2ecfbc7b}
}

@InProceedings{Chok2009a,
  Title                    = {{An online spatio-temporal association rule mining framework for analyzing and estimating sensor data}},
  Author                   = {Chok, Hamed and Gruenwald, Le},
  Booktitle                = {Proceedings of the 2009 International Database Engineering \& Applications Symposium on - IDEAS '09},
  Year                     = {2009},

  Address                  = {New York, New York, USA},
  Month                    = sep,
  Pages                    = {217},
  Publisher                = {ACM Press},

  Abstract                 = {A sensor network is a valuable new form of collective computational instrumentation by virtue of its ability to sense physical quantities of interest and to transmit such readings via sub-networks of nodes/computers for processing. Such computing environment typically generates massive amounts of data rapidly in real-time. These infinite volumes of online time-series are formally characterized as data streams. The wealth of fast incoming data streams presents both overhead and logistic challenges for sensor network applications. In this research, we introduce an online data mining framework to serve as an overhead-bounded knowledge discovery tool for sensornet applications. Our framework extends the notions of traditional association rules to multivariate continuous data and uses spatio-temporal correlations to make intelligent inferences about the monitored variables. Our mining framework is additionally pertinent to data estimation, which is an important capability given the inevitability of data loss/corruption with the current sensornet technology. Experimentation shows efficiency of our approach both in terms of overhead cost and quality of missing data estimates.},
  Doi                      = {10.1145/1620432.1620455},
  ISBN                     = {9781605584027},
  Keywords                 = {data estimation,knowledge discovery,sensor databases,spatio-temporal data mining},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chok2009. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1620432.1620455}
}

@InProceedings{Chok2009b,
  Title                    = {{Spatio-temporal association rule mining framework for real-time sensor network applications}},
  Author                   = {Chok, Hamed and Gruenwald, Le},
  Booktitle                = {Proceeding of the 18th ACM conference on Information and knowledge management - CIKM '09},
  Year                     = {2009},

  Address                  = {New York, New York, USA},
  Month                    = nov,
  Pages                    = {1761},
  Publisher                = {ACM Press},

  Abstract                 = {In this paper, we present a data mining framework to estimate missing or corrupted data in sensor network applications - a frequently occurring phenomenon in this domain. The framework is naturally germane to the spatio-temporal analysis of relational data stream evolution. Our method utilizes association rules to capture spatio-temporal correlations in multivariate, dynamically evolving, and unbounded sensor data streams. Existing approaches that tackled this problem do not account for the multi-dimensionality of the node data and their relationship; furthermore they entail simplistic and/or premature assumptions on the temporal and spatial factors to overcome the complexity of the streaming environment. Our technique, called Mining Autonomously Spatio-Temporal Environmental Rules (MASTER), comprehensively formulates the problem of mining patterns in sensor data streams, and yet remains provably adaptive to bounded time and space costs while probabilistically assuring a bounded estimation error. Simulation experiments show MASTER's efficiency in terms of overhead as well as the quality of estimation.},
  Doi                      = {10.1145/1645953.1646224},
  ISBN                     = {9781605585123},
  Keywords                 = {data estimation,sensor databases,spatio-temporal data mining},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chok2009. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1645953.1646224}
}

@Conference{Choudhury2011,
  Title                    = {Large-scale continuous subgraph queries on streams},
  Author                   = {Choudhury, S.a and Holder, L.b and Chin, G.a and Feo, J.a },
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Pages                    = {29-32},

  Abstract                 = {Graph pattern matching involves finding exact or approximate matches for a query subgraph in a larger graph. It has been studied extensively and has strong applications in domains such as computer vision, computational biology, social networks, security and finance. The problem of exact graph pattern matching is often described in terms of subgraph isomorphism which is NP-complete. The exponential growth in streaming data from online social networks, news and video streams and the continual need for situational awareness motivates a solution for finding patterns in streaming updates. This is also the prime driver for the real-time analytics market. Development of incremental algorithms for graph pattern matching on streaming inputs to a continually evolving graph is a nascent area of research. Some of the challenges associated with this problem are the same as found in continuous query (CQ) evaluation on streaming databases. This paper reviews some of the representative work from the exhaustively researched field of CQ systems and identifies important semantics, constraints and architectural features that are also appropriate for HPC systems performing real-time graph analytics. For each of these features we present a brief discussion of the challenge encountered in the database realm, the approach to the solution and state their relevance in a high-performance, streaming graph processing framework. Ã‚Â© 2011 ACM.},
  Affiliation              = {Pacific Northwest National Laboratory, 902 Battelle Boulevard, Richland, WA 99352, United States; School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, United States},
  Author_keywords          = {Continuous queries; Graph databases; Subgraph matching},
  Document_type            = {Conference Paper},
  Journal                  = {HPCDB'11 - Proceedings of the 2011 Workshop on High-Performance Computing Meets Databases, Co-located with SC'11},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Graph pattern matching. Development of incremental algorithms for graph pattern matching on streaming inputs to a continually evolving graph is a nascent area of research. Some of the challenges associated with this problem are the same as found in continuous query (CQ) evaluation on streaming databases. This paper reviews some of the representative work from the exhaustively researched field of CQ systems. A review of CQ systems. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84857944561&partnerID=40&md5=2337ec5117fa2b1f64eb7f4b5c64acd0}
}

@Conference{Choudhury2013,
  Title                    = {Streamworks - A system for dynamic graph search},
  Author                   = {Choudhury, S.a and Holder, L.b and Chin, G.a and Ray, A.b and Beus, S.a and Feo, J.a },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1101-1104},

  Abstract                 = {Acting on time-critical events by processing ever growing social media, news or cyber data streams is a major technical challenge. Many of these data sources can be modeled as multi-relational graphs. Mining and searching for subgraph patterns in a continuous setting requires an efficient approach to incremental graph search. The goal of our work is to enable real-time search capabilities for graph databases. This demonstration will present a dynamic graph query system that leverages the structural and semantic characteristics of the underlying multi-relational graph. Copyright Ã‚Â© 2013 ACM.},
  Affiliation              = {Pacific Northwest National Laboratory, United States; Washington State University, United States},
  Author_keywords          = {Continuous Queries; Dynamic Graph Search; Subgraph Matching},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {The goal of our work is to enable real-time search capabilities for graph databases. Graph search. Mining and searching for subgraph patterns in a continuous setting requires an efficient approach to incremental graph search. Approved. 1},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880548349&partnerID=40&md5=7a200226b3285aef693725b702f93725}
}

@InProceedings{Choudhury2013a,
  Title                    = {{StreamWorks}},
  Author                   = {Choudhury, Sutanay and Holder, Lawrence and Chin, George and Ray, Abhik and Beus, Sherman and Feo, John},
  Booktitle                = {Proceedings of the 2013 international conference on Management of data - SIGMOD '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = jun,
  Pages                    = {1101},
  Publisher                = {ACM Press},

  Abstract                 = {Acting on time-critical events by processing ever growing social media, news or cyber data streams is a major technical challenge. Many of these data sources can be modeled as multi-relational graphs. Mining and searching for subgraph patterns in a continuous setting requires an efficient approach to incremental graph search. The goal of our work is to enable real-time search capabilities for graph databases. This demonstration will present a dynamic graph query system that leverages the structural and semantic characteristics of the underlying multi-relational graph.},
  Doi                      = {10.1145/2463676.2463697},
  ISBN                     = {9781450320375},
  Keywords                 = {continuous queries,dynamic graph search,subgraph matching},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Choudhury2013. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2463676.2463697}
}

@Article{Chrupala2012,
  Title                    = {{Learning from evolving data streams: online triage of bug reports}},
  Author                   = {Chrupala, Grzegorz},
  Year                     = {2012},

  Month                    = apr,
  Pages                    = {613--622},

  Abstract                 = {Open issue trackers are a type of social media that has received relatively little attention from the text-mining community. We investigate the problems inherent in learning to triage bug reports from time-varying data. We demonstrate that concept drift is an important consideration. We show the effectiveness of online learning algorithms by evaluating them on several bug report datasets collected from open issue trackers associated with large open-source projects. We make this collection of data publicly available.},
  ISBN                     = {978-1-937284-19-0},
  Owner                    = {alex},
  Publisher                = {Association for Computational Linguistics},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Open issue trackers are a type of social media that has received relatively little attention from the text-mining community. We investigate the problems inherent in learning to triage bug reports from time-varying data. We show the effectiveness of online learning algorithms by evaluating them on several bug report datasets Approved. 1,2,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2380816.2380891}
}

@InProceedings{Chu2004,
  Title                    = {{Data stream mining architecture for network intrusion detection}},
  Author                   = {Chu, N.C.N. and Williams, A. and Alhaj, R. and Barker, K.},
  Booktitle                = {Proceedings of the 2004 IEEE International Conference on Information Reuse and Integration, 2004. IRI 2004.},
  Year                     = {2004},
  Pages                    = {363--368},
  Publisher                = {IEEE},

  Abstract                 = {In this paper, we propose a stream mining architecture which is based on a single-pass approach. Our approach can be used to develop efficient, effective, and active intrusion detection mechanisms which satisfy the near real-time requirements of processing data streams on a network with minimal overhead. The key idea is that new patterns can now be detected on-the-fly. They are flagged as network attacks or labeled as normal traffic, based on the current network trend, thus reducing the false alarm rates prevalent in active network intrusion systems and increasing the low detection rate which characterizes passive approaches.},
  Doi                      = {10.1109/IRI.2004.1431488},
  ISBN                     = {0-7803-8819-4},
  Keywords                 = {Availability,Computer architecture,Computer networks,Computer science,Computerized monitoring,Data mining,Information resources,Intrusion detection,Telecommunication traffic,Telephony,active network intrusion detection systems,computer networks,data mining,data stream mining architecture,false alarm rates,network attacks,security of data,single-pass approach,telecommunication security},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {stream mining architecture which is based on a single-pass approach. can be used to develop efficient, effective, and active intrusion detection mechanisms which satisfy the near real-time requirements of processing data streams on a network with minimal overhead. The key idea is that new patterns can now be detected on-the-fly. They are flagged as network attacks or labeled as normal traffic, based on the current network trend, thus reducing the false alarm rates prevalent in active network intrusion systems and increasing the low detection rate which characterizes passive approaches. Approved. 1,2,6},
  Shorttitle               = {Information Reuse and Integration, 2004. IRI 2004.},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1431488}
}

@Conference{Chu2004a,
  Title                    = {Data stream mining architecture for network intrusion detection},
  Author                   = {Chu, N.C.N. and Williams, A. and Alhajj, R. and Barker, K.},
  Year                     = {2004},
  Note                     = {cited By (since 1996)2},
  Pages                    = {363-368},

  Abstract                 = {In this paper, we propose a stream mining architecture which is based on a single-pass approach. Our approach can be used to develop efficient, effective, and active intrusion detection mechanisms which satisfy the near real-time requirements of processing data streams on a network with minimal overhead. The key idea is that new patterns can now be detected on-the-fly. They are flagged as network attacks or labeled as normal traffic, based on the current network trend, thus reducing the false alarm rates prevalent in active network intrusion systems and increasing the low detection rate which characterizes passive approaches. Ã‚Â© 2004 IEEE.},
  Affiliation              = {Department of Computer Science, University of Calgary, Calgary, Alta., Canada},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2004 IEEE International Conference on Information Reuse and Integration, IRI-2004},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Chu2004. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-16244390893&partnerID=40&md5=3a9c9a02889e5a855e454b2ba3da22c1}
}

@Misc{Ciampi,
  Title                    = {{Discovering Trend-Based Clusters in Spatially Distributed Data Streams}},

  Author                   = {Ciampi, Anna and Malerba, Donato},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Many emerging applications are characterized by real-time stream data acquisition through sensors which have geographical locations and/or spatial extents. Streaming prevents from storing all data from the stream and performing multiple scans of the entire data sets as normally done in traditional applications. The drift of data distribution poses additional challenges to the spatio-temporal data mining techniques. We address these challenges for a class of spatio-temporal patterns, called trend-clusters, which combine the semantics of both clusters and trends in spatio-temporal environments. We propose an algorithm to interleave spatial clustering and trend discovery in order to continuously cluster geo-referenced data which vary according to a similar trajectory (trend) in the recent past (window time). An experimental study demonstrates the effectiveness of our algorithm.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining in the context of distributed sensors with concept drift in stream. We address these challenges for a class of spatio-temporal patterns, called trend-clusters, which combine the semantics of both clusters and trends in spatio-temporal environments. Continuously cluster geo-referenced data which vary according to a similar trajectory (trend) in the recent past. An experimental study demonstrates the effectiveness of our algorithm. Approved 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.431.4086}
}

@Misc{Clifton,
  Title                    = {{CERIAS Tech Report 2005-133 Dependable real-time data mining}},

  Author                   = {Clifton, Christopher and Thuraisingham, Bhavani and Khan, Latifur and Clifton, Chris and Maurer, John},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In this paper we discuss the need for real-time data mining for many applications in government and industry and describe resulting research issues. We also discuss dependability issues including incorporating security, integrity, timeliness and fault tolerance into data mining. Several different data mining outcomes are described with regard to their implementation in a real-time environment. These outcomes include clustering, association-rule mining, link analysis and anomaly detection. The paper describes how they would be used together in various parallel-processing architectures. Stream mining is discussed with respect to the challenges of performing data mining on stream data from sensors. The paper concludes with a summary and discussion of directions in this emerging area.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {In this paper we discuss the need for real-time data mining for many applications in government and industry and describe resulting research issues. No tangible contribution. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.158.5723}
}

@Article{Cohen2004,
  Title                    = {{Incremental Info-Fuzzy Algorithm for Real Time Data Mining}},
  Author                   = {Cohen, Lior and Avrahami, Gil and Last, Mark},
  Journal                  = {OF NON-STATIONARY DATA STREAMSâ€�, TDM WORKSHOP},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Most real-world data streams are generated by nonstationary processes that may change drastically over time. In our previous work, we have presented a real-time data mining algorithm called OLIN (On-Line Information Network), which adapts itself automatically to the rate of concept drift in a non-stationary data stream by repeatedly constructing a new model from a sliding window of latest examples. In this paper, we introduce an incremental version of the OLIN algorithm, which saves a significant amount of computational effort by updating an existing model as long as no concept drift is detected. The approach is evaluated on large real-world streams of traffic and stock data.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Older version of Cohen2008b. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.110.920}
}

@Article{Cohen2008b,
  Title                    = {Info-fuzzy algorithms for mining dynamic data streams},
  Author                   = {Cohen, L.a and Avrahami, G.a and Last, M.a and Kandel, A.b },
  Journal                  = {Applied Soft Computing Journal},
  Year                     = {2008},
  Note                     = {cited By (since 1996)18},
  Number                   = {4},
  Pages                    = {1283-1294},
  Volume                   = {8},

  Abstract                 = {Most data-mining algorithms assume static behavior of the incoming data. In the real world, the situation is different and most continuously collected data streams are generated by dynamic processes, which may change over time, in some cases even drastically. The change in the underlying concept, also known as concept drift, causes the data-mining model generated from past examples to become less accurate and relevant for classifying the current data. Most online learning algorithms deal with concept drift by generating a new model every time a concept drift is detected. On one hand, this solution ensures accurate and relevant models at all times, thus implying an increase in the classification accuracy. On the other hand, this approach suffers from a major drawback, which is the high computational cost of generating new models. The problem is getting worse when a concept drift is detected more frequently and, hence, a compromise in terms of computational effort and accuracy is needed. This work describes a series of incremental algorithms that are shown empirically to produce more accurate classification models than the batch algorithms in the presence of a concept drift while being computationally cheaper than existing incremental methods. The proposed incremental algorithms are based on an advanced decision-tree learning methodology called "Info-Fuzzy Network" (IFN), which is capable to induce compact and accurate classification models. The algorithms are evaluated on real-world streams of traffic and intrusion-detection data. Ã‚Â© 2008 Elsevier B.V. All rights reserved.},
  Affiliation              = {Ben-Gurion University of the Negev, Department of Information Systems Engineering, Beer-Sheva, 84105, Israel; Department of Computer Science and Engineering, University of South-Florida, Tampa, FL 33620, United States},
  Author_keywords          = {Concept drift; Data streams; Incremental learning; Info-Fuzzy Networks; Online learning; Real-time data mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Nonstationary streams. This work describes a series of incremental algorithms that are shown empirically to produce more accurate classification models than the batch algorithms in the presence of a concept drift while being computationally cheaper than existing incremental methods. The algorithms are evaluated on real-world streams of traffic and intrusion-detection data Approved 1,2,3,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-50149120100&partnerID=40&md5=dcddb6702c85be738e3f40932b0cf705}
}

@InProceedings{Cohen2006,
  Title                    = {{Efficient Learning Algorithms for Agents Mining Time-Changing Data Streams}},
  Author                   = {Cohen, Lior and Avrahami, Gil and Last, Mark and Kandel, Abraham},
  Booktitle                = {2006 International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce (CIMCA'06)},
  Year                     = {2006},
  Pages                    = {257--257},
  Publisher                = {IEEE},

  Abstract                 = {Many continuously recorded data streams are generated by non-stationary processes, which may change over time, in some cases even drastically. Some adaptive learning agents deal with time-changing data streams by generating a new model from every incoming window of training examples. Though this solution should ensure an accurate and relevant model at all times, it may waste significant computational resources on continuous re-generation of nearly identical models during periods of stability. In this paper, we evaluate a series of efficient incremental algorithms that are nearly as accurate as existing online methods, sometimes even outperforming them, while being considerably cheaper in terms of the processing time. The proposed incremental techniques are based on the Information Network classification algorithm. The incremental methods efficiency is demonstrated on real-world streams of road traffic and intrusion detection data.},
  Doi                      = {10.1109/CIMCA.2006.92},
  ISBN                     = {0-7695-2731-0},
  Keywords                 = {Classification algorithms,Computational intelligence,Data engineering,Data mining,Gas insulated transmission lines,Information systems,Intelligent networks,Learning systems,Predictive models,Systems engineering and theory,adaptive learning agents,agents mining,computational resources,continuous regeneration,data mining,incremental algorithms,information network classification algorithm,information networks,intrusion detection data,learning (artificial intelligence),learning algorithms,online methods,road traffic,software agents,stability,time-changing data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Non staionary streams. Older version of Cohen2008b. Discarded.},
  Shorttitle               = {Computational Intelligence for Modelling, Control },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4052864}
}

@Article{Cohen2008a,
  Title                    = {Real-time data mining of non-stationary data streams from sensor networks },
  Author                   = {Lior Cohen and Gil Avrahami-Bakish and Mark Last and Abraham Kandel and Oscar Kipersztok},
  Journal                  = {Information Fusion },
  Year                     = {2008},
  Note                     = {Special Issue on Distributed Sensor Networks },
  Number                   = {3},
  Pages                    = {344 - 353},
  Volume                   = {9},

  Abstract                 = {In real-world sensor networks, the monitored processes generating time-stamped data may change drastically over time. An online data-mining algorithm called \{OLIN\} (on-line information network) adapts itself automatically to the rate of concept drift in a non-stationary data stream by repeatedly constructing a classification model from every sliding window of training examples. In this paper, we introduce a new real-time data-mining algorithm called \{IOLIN\} (incremental on-line information network), which saves a significant amount of computational effort by updating an existing model as long as no major concept drift is detected. The proposed algorithm builds upon the oblivious decision-tree classification model called Ã¢â‚¬Å“information networkÃ¢â‚¬ï¿½ (IN) and it implements three different types of model updating operations. In the experiments with multi-year streams of traffic sensors data, no statistically significant difference between the accuracy of the incremental algorithm (IOLIN) vs. the regenerative one (OLIN) has been observed.},
  Doi                      = {http://dx.doi.org/10.1016/j.inffus.2005.05.005},
  ISSN                     = {1566-2535},
  Keywords                 = {Real-time data mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Cohen2004 or Cohen2006. Older version of Cohen2008b. Discarded.},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1566253505000655}
}

@InProceedings{ConferenceChair-Chandola2011,
  Title                    = {{Proceedings of the Fifth International Workshop on Knowledge Discovery from Sensor Data}},
  Author                   = {{Conference Chair-Chandola}, Varun and {Conference Chair-Omitaomu}, Olufemi A. and {Conference Chair-Steinhaeuser}, Karsten and {Conference Chair-Ganguly}, Auroop R. and {Conference Chair-Gama}, Joao and {Conference Chair-Vatsavai}, Ranga Raju and {Conference Chair-Chawla}, Nitesh V. and {Conference Chair-Gaber}, Mohamed Medhat},
  Booktitle                = {Proceedings of the Fifth International Workshop on Knowledge Discovery from Sensor Data},
  Year                     = {2011},
  Month                    = aug,
  Publisher                = {ACM},

  Abstract                 = {Wide-area sensor infrastructures, remote sensors, RFIDs, phasor measurements, and wireless sensor networks yield massive volumes of disparate, dynamic, and geographically distributed data. With the recent proliferation of smart-phones and similar GPS enabled mobile devices with several onboard sensors, collection of sensor data is no longer limited to scientific communities, but has reached general public. As such sensors are becoming ubiquitous, a set of broad requirements is beginning to emerge across high-priority applications including adaptability to national or homeland security, critical infrastructures monitoring, smart grids, disaster preparedness and management, greenhouse emissions and climate change, and transportation. The raw data from sensors need to be efficiently managed and transformed to usable information through data fusion, which in turn must be converted to predictive insights via knowledge discovery, ultimately facilitating automated or human-induced tactical decisions or strategic policy based on decision sciences and decision support systems. The challenges for the knowledge discovery community are expected to be immense. On the one hand are dynamic data streams or events that require real-time analysis methodologies and systems, while on the other hand are static data that require high end computing for generating offline predictive insights, which in turn can facilitate real-time analysis. The online and real-time knowledge discovery imply immediate opportunities as well as intriguing short- and long-term challenges for practitioners and researchers in knowledge discovery. The opportunities would be to develop new data mining approaches and adapt traditional and emerging knowledge discovery methodologies to the requirements of the emerging problems. In addition, emerging societal problems require knowledge discovery solutions that are designed to investigate anomalies, rare events, hotspots, changes, extremes and nonlinear processes, and departures from the normal. According to the data mining and domain experts present at the NSF-sponsored Next Generation Data Mining Summit (NGDM '09) held in October 2009, "finding the next generation of solutions to these challenges is critical to sustain our world and civilization." The SensorKDD series of workshops, held in conjunction with the prestigious ACM SIGKDD International Conference of Knowledge Discovery and Data Mining from 2007-2010, have aimed at bringing researchers, from different academic and applied communities, together to address these challenges and moving toward the development of the next generation data mining solutions require to address these challenges. The proposed 5th International Workshop on Knowledge Discovery from Sensor Data (SensorKDD-2011) is the next step in this successful series of workshops with the objective of providing a platform for researchers to present and discuss their research in the area of knowledge discovery from sensor data.},
  ISBN                     = {978-1-4503-0832-8},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Proceedings only. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2003653}
}

@InProceedings{ConferenceChair-Das2012,
  Title                    = {{Proceedings of the Sixth International Workshop on Knowledge Discovery from Sensor Data}},
  Author                   = {{Conference Chair-Das}, Debasish and {Conference Chair-Ganguly}, Auroop R. and {Conference Chair-Chandola}, Varun and {Conference Chair-Omitaomu}, Olufemi A. and {Conference Chair-Steinhaeuser}, Karsten and {Conference Chair-Gama}, Joao and {Conference Chair-Vatsavai}, Ranga Raju and {Conference Chair-Gaber}, Mohamed Medhat and {Conference Chair-Chawla}, Nitesh V.},
  Booktitle                = {Proceedings of the Sixth International Workshop on Knowledge Discovery from Sensor Data},
  Year                     = {2012},
  Month                    = aug,
  Publisher                = {ACM},

  Abstract                 = {Wide-area sensor infrastructures, remote sensors, RFIDs, phasor measurements, and wireless sensor networks yield massive volumes of disparate, dynamic, and geographically distributed data. With the recent proliferation of smart-phones and similar GPS enabled mobile devices with several onboard sensors, collection of sensor data is no longer limited to scientific communities, but has reached general public. As such sensors are becoming ubiquitous, a set of broad requirements is beginning to emerge across high-priority applications including adaptability to national or homeland security, critical infrastructures monitoring, smart grids, disaster preparedness and management, greenhouse emissions and climate change, and transportation. The raw data from sensors need to be efficiently managed and transformed to usable information through data fusion, which in turn must be converted to predictive insights via knowledge discovery, ultimately facilitating automated or human-induced tactical decisions or strategic policy based on decision sciences and decision support systems. The challenges for the knowledge discovery community are expected to be immense. On the one hand are dynamic data streams or events that require real-time analysis methodologies and systems, while on the other hand are static data that require high end computing for generating offline predictive insights, which in turn can facilitate real-time analysis. The online and real-time knowledge discovery imply immediate opportunities as well as intriguing short- and long-term challenges for practitioners and researchers in knowledge discovery. The opportunities would be to develop new data mining approaches and adapt traditional and emerging knowledge discovery methodologies to the requirements of the emerging problems. In addition, emerging societal problems require knowledge discovery solutions that are designed to investigate anomalies, rare events, hotspots, changes, extremes and nonlinear processes, and departures from the normal.},
  ISBN                     = {978-1-4503-1554-8},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2350182}
}

@Misc{Conjunction2009,
  Title                    = {{Proceedings of the Third International Workshop on Knowledge Discovery from Sensor Data (SensorKDDâ€™09)}},

  Author                   = {Conjunction, Held In},
  Year                     = {2009},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Wide-area sensor infrastructures, remote sensors, RFIDs, and wireless sensor networks yield massive volumes of disparate, dynamic, and geographically distributed data. As such sensors are becoming ubiquitous, a set of broad requirements is beginning to emerge across high-priority applications including adaptability to climate change, electric grid monitoring, disaster preparedness and management, national or homeland security, and the management of critical infrastructures. The raw data from sensors need to be efficiently managed and transformed to usable information through data fusion, which in turn must be converted to predictive insights via knowledge discovery, ultimately facilitating automated or humaninduced tactical decisions or strategic policy based on decision sciences and decision support systems. The challenges for the knowledge discovery community are expected to be immense. On the one hand, dynamic data streams or events require real-time analysis methodologies and systems, while on the other hand centralized processing through high end computing is also required for generating offline predictive insights, which in turn can facilitate real-time analysis. The online and real-time knowledge discovery imply immediate opportunities as well as intriguing short- and long-term challenges for practitioners and researchers in knowledge discovery. The opportunities would be to develop new data mining approaches and adapt traditional and emerging knowledge discovery methodologies to the requirements of the},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Proceedings overview only. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.212.1743}
}

@Misc{Cook,
  Title                    = {{1 Activity Discovery and Activity Recognition: A New Partnership}},

  Author                   = {Cook, Diane and Krishnan, Narayanan and Rashidi, Parisa},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Activity recognition has received increasing attention from the machine learning community. Of particular interest is the ability to recognize activities in real time from streaming data, but this presents a number of challenges not faced by traditional offline approaches. Among these challenges is handling the large amount of data that does not belong to a predefined class. In this paper, we describe a method by which activity discovery can be used to identify behavioral patterns in observational data. Discovering patterns in the data that does not belong to a predefined class aids in understanding this data and segmenting it into learnable classes. We demonstrate that activity discovery not only sheds light on behavioral patterns, but it can also boost the performance of recognition algorithms. We introduce this partnership between activity discovery and online activity recognition in the context of the CASAS smart home project and validate our approach using CASAS datasets.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Activity recognition.In this paper, we describe a method by which activity discovery can be used to identify behavioral patterns in observational data. Discovering patterns in the data that does not belong to a predefined class aids in understanding this data and segmenting it into learnable classes. We introduce this partnership between activity discovery and online activity recognition in the context of the CASAS smart home project and validate our approach using CASAS datasets. Approved 1,2,3,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.299.5988}
}

@Article{Cook2013a,
  Title                    = {Activity discovery and activity recognition: A new partnership},
  Author                   = {Cook, D.J.a and Krishnan, N.C.a and Rashidi, P.b },
  Journal                  = {IEEE Transactions on Cybernetics},
  Year                     = {2013},
  Note                     = {cited By (since 1996)7},
  Number                   = {3},
  Pages                    = {820-828},
  Volume                   = {43},

  Abstract                 = {Activity recognition has received increasing attention from the machine learning community. Of particular interest is the ability to recognize activities in real time from streaming data, but this presents a number of challenges not faced by traditional offline approaches. Among these challenges is handling the large amount of data that does not belong to a predefined class. In this paper, we describe a method by which activity discovery can be used to identify behavioral patterns in observational data. Discovering patterns in the data that does not belong to a predefined class aids in understanding this data and segmenting it into learnable classes. We demonstrate that activity discovery not only sheds light on behavioral patterns, but it can also boost the performance of recognition algorithms. We introduce this partnership between activity discovery and online activity recognition in the context of the CASAS smart home project and validate our approach using CASAS data sets. Ã‚Â© 2012 IEEE.},
  Affiliation              = {School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA 99163, United States; Computer and Information Science and Engineering Department, University of Florida, Gainesville, FL 32611, United States},
  Author_keywords          = {Activity recognition; Out of vocabulary detection; Sequence discovery},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Cook. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84881180779&partnerID=40&md5=af9922a9efa87cbb071dd40146ed2026}
}

@Article{Cook2013,
  Title                    = {{Activity discovery and activity recognition: a new partnership.}},
  Author                   = {Cook, Diane J and Krishnan, Narayanan C and Rashidi, Parisa},
  Journal                  = {IEEE transactions on cybernetics},
  Year                     = {2013},

  Month                    = jun,
  Number                   = {3},
  Pages                    = {820--8},
  Volume                   = {43},

  Abstract                 = {Activity recognition has received increasing attention from the machine learning community. Of particular interest is the ability to recognize activities in real time from streaming data, but this presents a number of challenges not faced by traditional offline approaches. Among these challenges is handling the large amount of data that does not belong to a predefined class. In this paper, we describe a method by which activity discovery can be used to identify behavioral patterns in observational data. Discovering patterns in the data that does not belong to a predefined class aids in understanding this data and segmenting it into learnable classes. We demonstrate that activity discovery not only sheds light on behavioral patterns, but it can also boost the performance of recognition algorithms. We introduce this partnership between activity discovery and online activity recognition in the context of the CASAS smart home project and validate our approach using CASAS data sets.},
  Doi                      = {10.1109/TSMCB.2012.2216873},
  ISSN                     = {2168-2275},
  Keywords                 = {Actigraphy,Actigraphy: methods,Activities of Daily Living,Algorithms,Artificial Intelligence,Humans,Monitoring, Ambulatory,Monitoring, Ambulatory: methods,Movement,Movement: physiology,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Telemedicine,Telemedicine: methods},
  Owner                    = {Alexander},
  Pmid                     = {23033328},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Cook. Discarded.},
  Shorttitle               = {Cybernetics, IEEE Transactions on},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3772991\&tool=pmcentrez\&rendertype=abstract}
}

@Article{Costa2011,
  Title                    = {Blending OLAP processing with real-time data streams},
  Author                   = {Costa, J.a and CecÃƒÂ­lio, J.b and Martins, P.b and Furtado, P.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 2},
  Pages                    = {446-449},
  Volume                   = {6588 LNCS},

  Abstract                 = {CEP and Databases share some characteristics but traditionally are treated as two separate worlds, one oriented towards real-time event processing and the later oriented towards long-term data management. However many real-time data and business intelligence analysis do need to confront streaming data with long-term stored one. For instance, how do current power consumption and power grid distribution compare with last year's for the same day? StreamNetFlux is a novel system that recently emerged to the market designed to integrate CEP and database functionalities. This blending allows the processing of queries that need such capabilities with top efficiency and scalability features. Ã‚Â© 2011 Springer-Verlag.},
  Affiliation              = {Polytechnic of Coimbra, Coimbra, Portugal; University of Coimbra, Coimbra, Portugal},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Costa2010. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79955084238&partnerID=40&md5=f2397f8169e131fae4ed596e155869a5}
}

@Conference{Costa2010,
  Title                    = {StreamNetFlux: Birth of transparent integrated CEP-DBs},
  Author                   = {Costa, J.P.a and Martins, P.b and CecÃƒÂ­lio, J.b and Furtado, P.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)1},
  Pages                    = {101-102},

  Abstract                 = {CEP and Databases have traditionally been viewed as two separate entities, the first one oriented towards real-time event processing and the second one oriented towards long-term management of data. But in fact many real-time data and business intelligence analysis do need to confront streaming data with long-term stored one. For instance, how do today's sales compare with last year's sales for the same day? We demonstrate StreamNetFlux, a new system being commercialized that integrates CEP and databases in a way that is smooth and transparent to the user. Our demonstration will show that the new system is able to process queries that need such capabilities in an integrated fashion and with top efficiency and scalability features. The demonstration will use a Telco case study and will show that not only the system is able to provide integrated processing, as it is also extremely efficient and scalable. Ã‚Â© 2010 ACM.},
  Affiliation              = {ISEC-IPC, Rua Pedro Nunes-Qta Nora, 3030-199 Coimbra, Portugal; University of Coimbra, Dept. Eng. InformÃƒÂ¡tica, Polo II, Portugal},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 4th ACM International Conference on Distributed Event-Based Systems, DEBS 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Complex event processing integrated into databases. To support business intelligence with both offline and incoming data. The demonstration will use a Telco case study and will show that not only the system is able to provide integrated processing, as it is also extremely efficient and scalable. Approved 1,2,4},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77955809471&partnerID=40&md5=935de00dd7223403003fd878dbe04a83}
}

@InProceedings{Couceiro2012,
  Title                    = {{Stream analytics for utilities. Predicting power supply and demand in a smart grid}},
  Author                   = {Couceiro, Manuel and Ferrando, Roman and Manzano, David and Lafuente, Luis},
  Booktitle                = {2012 3rd International Workshop on Cognitive Information Processing (CIP)},
  Year                     = {2012},
  Month                    = may,
  Pages                    = {1--6},
  Publisher                = {IEEE},

  Abstract                 = {In today's networked society, getting knowledge from the data becomes in a key task for many support decisions making processes. Such kind of decisions could imply serious consequences in business and life and as more information is available about the problem, more accurate will be the decision. A largely untested hypothesis of modern society is that it is important to record data as it may contain valuable information. However, we are living in the information age and it has gone into how this quantity of data might be analyzed. The number of data sources increases, which makes harder and, in some cases, unfeasible the approach of storing every piece of data. Actually, the amount of available storage capacity could be not enough in order to record all the digital info generated in the world and this could become one the main triggers for a paradigm shift. Another aspect is that it is necessary to react instantly to meaningful changes in data and detect complex patterns over time. Data stream paradigm was born as an answer to the continuous data problem that cannot be stored and analyzed in efficient manner. Data Streams can handle bigger data sizes than memory, and can extend to challenging real-time applications not previously tackled by e.g. time series analysis, traditional, databases, machine learning and data mining techniques. The assumption is that processing examples can be processed on the fly, that is, as soon as they arrive within a high speed stream, and then, must be discarded in order to make room for subsequent data (e.g. examples in a learning scenario). In this article we will discuss the application of data stream techniques in the Smart Grid use case. The new smart grids will require real time reaction and make distribution decision very fast in order to cover unexpected demand peaks and renewable generation peaks.},
  Doi                      = {10.1109/CIP.2012.6232904},
  ISBN                     = {978-1-4673-1878-5},
  Keywords                 = {Data mining,Electricity,Forecasting,Load forecasting,Predictive models,Smart grids,Wind forecasting,complex patterns,data mining techniques,data stream paradigm,decision making,decision making processes,demand peaks,digital info,machine learning,paradigm shift,power supply and demand prediction,renewable generation peaks,smart grid,smart power grids,storage capacity,stream analytics,supply and demand,time series analysis},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {In this article we will discuss the application of data stream techniques in the Smart Grid use case. Not certain about contribution and novelty, but title suggests they do prediction. Approved no points.},
  Shorttitle               = {Cognitive Information Processing (CIP), 2012 3rd I},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6232904}
}

@Conference{Couceiro2012a,
  Title                    = {Stream analytics for utilities. Predicting power supply and demand in a smart grid},
  Author                   = {Couceiro, M. and Ferrando, R. and Manzano, D. and Lafuente, L.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {In today's networked society, getting knowledge from the data becomes in a key task for many support decisions making processes. Such kind of decisions could imply serious consequences in business and life and as more information is available about the problem, more accurate will be the decision. A largely untested hypothesis of modern society is that it is important to record data as it may contain valuable information. However, we are living in the information age and it has gone into how this quantity of data might be analyzed. The number of data sources increases, which makes harder and, in some cases, unfeasible the approach of storing every piece of data. Actually, the amount of available storage capacity could be not enough in order to record all the digital info generated in the world and this could become one the main triggers for a paradigm shift. Another aspect is that it is necessary to react instantly to meaningful changes in data and detect complex patterns over time. Data stream paradigm was born as an answer to the continuous data problem that cannot be stored and analyzed in efficient manner. Data Streams can handle bigger data sizes than memory, and can extend to challenging real-time applications not previously tackled by e.g. time series analysis, traditional, databases, machine learning and data mining techniques. The assumption is that processing examples can be processed on the fly, that is, as soon as they arrive within a high speed stream, and then, must be discarded in order to make room for subsequent data (e.g. examples in a learning scenario). In this article we will discuss the application of data stream techniques in the Smart Grid use case. The new smart grids will require real time reaction and make distribution decision very fast in order to cover unexpected demand peaks and renewable generation peaks. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Ericsson Research Madrid Branch, Ericsson Spain, S.A., Madrid, Spain},
  Art_number               = {6232904},
  Document_type            = {Conference Paper},
  Journal                  = {2012 3rd International Workshop on Cognitive Information Processing, CIP 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Couceiro2012. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864661435&partnerID=40&md5=039fd656f2aa4d02ba9db934d953832b}
}

@Conference{Cunha2013,
  Title                    = {SHStream: Self-healing framework for HTTP video-streaming},
  Author                   = {Cunha, C.A. and Moura E. Silva, L.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {514-520},

  Abstract                 = {HTTP video-streaming is leading delivery of video content over the Internet. This phenomenon is explained by the ubiquity of web browsers, the permeability of HTTP traffic and the recent video technologies around HTML5. However, the inclusion of multimedia requests imposes new requirements on web servers due to responses with lifespans that can reach dozens of minutes and timing requirements for data fragments transmitted during the response period. Consequently, web-servers require real-time performance control to avoid playback outages caused by overloading and performance anomalies. We present SHStream, a self-healing framework for web servers delivering video-streaming content that provides (1) load admittance to avoid server overloading; (2) prediction of performance anomalies using online data stream learning algorithms; (3) continuous evaluation and selection of the best algorithm for prediction; and (4) proactive recovery by migrating the server to other hosts using container-based virtualization techniques. Evaluation of our framework using several variants of Hoeffding trees and ensemble algorithms showed that with a small number of learning instances, it is possible to achieve approximately 98% of recall and 99% of precision for failure predictions. Additionally, proactive failover can be performed in less than 1 second. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Centre for Informatics and Systems, University of Coimbra, Portugal},
  Art_number               = {6546133},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing, CCGrid 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {SHStream: Self-healing framework for HTTP video-streaming. Includes (2) prediction of performance anomalies using online data stream learning algorithms; (3) continuous evaluation and selection of the best algorithm for prediction;Evaluation of our framework using several variants of Hoeffding trees and ensemble algorithms showed that with a small number of learning instances, it is possible to achieve approximately 98% of recall and 99% of precision for failure predictions. Additionally, proactive failover can be performed in less than 1 second. Approved 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84881286348&partnerID=40&md5=1b0b1008f7c3b37857405bbc09885979}
}

@Article{Czarnowski2014,
  Title                    = {Online learning based on prototypes},
  Author                   = {Czarnowski, I. and JÃˆÂ©drzejowicz, P.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 2},
  Pages                    = {187-196},
  Volume                   = {8398 LNAI},

  Abstract                 = {The problem addressed in this paper concerns learning form data streams with concept drift. The goal of the paper is to propose a framework for the online learning. It is assumed that classifiers are induced from incoming blocks of prototypes, called data chunks. Eachdata chunk consists of prototypes including also information as to whether the class prediction of these instances was correct or not. When a new data chunk is formed, classifier ensembles formed at an earlier stage are updated. Three online learning algorithms for performing machine learning on data streams based on three different prototype selection approaches to forming data chunks are considered. The proposed approach is validated experimentally and the computational experiment results are discussed. Ã‚Â© 2014 Springer International Publishing Switzerland.},
  Affiliation              = {Department of Information Systems, Gdynia Maritime University, Morska 83, 81-225 Gdynia, Poland},
  Author_keywords          = {data streams; incremental learning; online learning},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {learning form data streams with concept drift. It is assumed that classifiers are induced from incoming blocks of prototypes, called data chunks. When a new data chunk is formed, classifier ensembles formed at an earlier stage are updated. The proposed approach is validated experimentally Approved 3},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84900482872&partnerID=40&md5=ec3ae3e265998bbc4fbf60653daefb25}
}

@Misc{Da,
  Title                    = {{Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence A Lossy Counting Based Approach for Learning on Streams of Graphs on a Budget}},

  Author                   = {Da, Giovanni and Martino, San and Navarin, Nicol\`{o} and Sperduti, Ro},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In many problem settings, for example on graph domains, online learning algorithms on streams of data need to respect strict time constraints dictated by the throughput on which the data arrive. When only a limited amount of memory (budget) is available, a learning algorithm will eventually need to discard some of the information used to represent the current solution, thus negatively affecting its classification performance. More importantly, the overhead due to budget management may significantly increase the computational burden of the learning algorithm. In this paper we present a novel approach inspired by the Passive Aggressive and the Lossy Counting algorithms. Our algorithm uses a fast procedure for deleting the less influential features. Moreover, it is able to estimate the weighted frequency of each feature and use it for prediction.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {online learning algorithms on streams of data need to respect strict time constraints dictated by the throughput on which the data arrive. In this paper we present a novel approach inspired by the Passive Aggressive and the Lossy Counting algorithms. Our algorithm uses a fast procedure for deleting the less influential features. Moreover, it is able to estimate the weighted frequency of each feature and use it for prediction. Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.417.4797}
}

@InProceedings{DLL2005,
  Title                    = {{Finding Maximal Frequent Itemsets over Online Data Streams Adaptively}},
  Author                   = {{Daesu Lee} and {Wonsuk Lee}},
  Booktitle                = {Fifth IEEE International Conference on Data Mining (ICDM'05)},
  Year                     = {2005},
  Pages                    = {266--273},
  Publisher                = {IEEE},

  Abstract                 = {Due to the characteristics of a data stream, it is very important to confine the memory usage of a data mining process regardless of the amount of information generated in the data stream. For this purpose, this paper proposes a CP-tree (compressed-prefix tree) that can be effectively used in finding either frequent or maximal frequent itemsets over an online data stream. Unlike a prefix tree, a node of a CP-tree can maintain the information of several item-sets together. Based on this characteristic, the size of a CP-tree can be flexibly controlled by merging or splitting nodes. In this paper, a mining method employing a CP-tree is proposed and an adaptive memory utilization scheme is also presented in order to maximize the mining accuracy of the proposed method for confined memory space at all times. Finally, the performance of the proposed method is analyzed by a series of experiments to identify its various characteristics.},
  Doi                      = {10.1109/ICDM.2005.68},
  ISBN                     = {0-7695-2278-5},
  ISSN                     = {1550-4786},
  Keywords                 = {Buffer storage,CP-tree,Character generation,Computer science,Data analysis,Data mining,Itemsets,Merging,Performance analysis,Size control,Space technology,adaptive memory utilization,compressed-prefix tree,data mining,maximal frequent itemsets,mining method,online data streams,trees (mathematics)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {CP-tree, finding frequent or maximal frquent itemsets in stream, confined to memory usage. Unlike a prefix tree, a node of a CP-tree can maintain the information of several item-sets together. Adaptive to maximize the mining accuracy of the proposed method for confined memory space at all times. Finally, the performance of the proposed method is analyzed by a series of experiments to identify its various characteristics. Approved 1,3,4,6},
  Shorttitle               = {Data Mining, Fifth IEEE International Conference o},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1565688}
}

@Conference{Dai2004,
  Title                    = {Clustering on demand for multiple data streams},
  Author                   = {Dai, B.-R. and Huang, J.-W. and Yeh, M.-Y. and Chen, M.-S.},
  Year                     = {2004},
  Note                     = {cited By (since 1996)16},
  Pages                    = {367-370},

  Abstract                 = {In the data stream environment, the patterns generated by the mining techniques are usually distinct at different time because of the evolution of data. In order to deal with various types of multiple data streams and to support flexible mining requirements, we devise in this paper a Clustering on Demand framework, abbreviated as COD framework, to dynamically cluster multiple data streams. While providing a general framework of clustering on multiple data streams, the COD framework has two major features, namely one data scan for online statistics collection and compact multi-resolution approximations, which are designed to address, respectively, the time and the space constraints in a data stream environment. Furthermore, with the multi-resolution approximations of data streams, flexible clustering demands can be supported. Ã‚Â© 2004 IEEE.},
  Affiliation              = {Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - Fourth IEEE International Conference on Data Mining, ICDM 2004},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicateo f BRDWHYYSC2004. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-19544393527&partnerID=40&md5=d6d4e96e1b6d4c997fa33b3a5c1eb867}
}

@Article{Dam2007,
  Title                    = {Evolutionary online data mining: An investigation in a dynamic environment},
  Author                   = {Dam, H.H. and Lokan, C. and Abbass, H.A.},
  Journal                  = {Studies in Computational Intelligence},
  Year                     = {2007},
  Note                     = {cited By (since 1996)6},
  Pages                    = {153-178},
  Volume                   = {51},

  Abstract                 = {Recently, traditional data mining algorithms are challenged by two main problems: streaming data, and changes in the hidden context. These challenges emerged from real-world applications such as network intrusion detection, credit card fraud detection, etc. Online or incremental learning becomes more important than ever for dealing with these problems. This chapter investigates XCS, a genetics-based learning classifier system, which offers an incremental learning ability and also is able to handle an infinite amount of continuously arriving data. XCS has been tested on many data mining problems and demonstrated as a potential online data mining approach. Most experiments with XCS assume a static environment. Since environments are more likely to be dynamic in real life, noise and environmental factors need to be taken into account in a good data mining approach. This chapter investigates XCS in dynamic environments, in the presence of noise in the training data. An essential requirement of an algorithm in dynamic environments is to be able to recover quickly from hidden changes, while reusing previous knowledge. Our results show that XCS is capable of recovering quickly from small changes in the underlying concepts. However, it requires significant time to re-learn a model after severe changes. We propose several strategies to force the system to learn quickly after severe changes. These are adaptive learning rate; re-initializing the parameters; and re-initializing the population. Experiments show improvement in the predictive performance of XCS, when compared to the traditional XCS, in both noisy and noise-free environments. Ã‚Â© Springer-Verlag Berlin Heidelberg 2007.},
  Affiliation              = {Artificial Life and Adaptive Robotics Laboratory, School of Information Technology, The University of New South Wales, Canberra, ACT 2600, Australia},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This chapter investigates XCS in dynamic environments, in the presence of noise in the training data. We propose several strategies to force the system to learn quickly after severe changes. These are adaptive learning rate; re-initializing the parameters; and re-initializing the population. Experiments show improvement in the predictive performance of XCS, when compared to the traditional XCS, in both noisy and noise-free environments Approved. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34147154466&partnerID=40&md5=ab585f9e6b7140c429fe82e8d4f3cb87}
}

@Misc{Dam,
  Title                    = {{Evolutionary Online Data Mining An Investigation in a Dynamic Environment}},

  Author                   = {Dam, Hai H. and Abbass, Hussein A. and Lokan, Chris},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Recently, traditional data mining algorithms are challenged by two problems: streaming data, and changes in the hidden context. These challenges emerged from real-world applications such as network intrusion detection, credit card fraud detection, etc. Online or incremental learning becomes more important than ever for dealing with these problems. This chapter investigates XCS, an evolutionary learning classifier system, that offers an incremental learning ability and also is able to handle an infinite amount of continuously arriving data. XCS has been tested on many data mining problems and demonstrated as a potential online data mining approach. Most experiments with XCS assume a static environment. Since environments are more likely to be dynamic in real life, noise and environmental factors need to be taken into account in a good data mining approach. This chapter investigates XCS in dynamic environments, in the presence of noise in the training data. An essential requirement of an algorithm in dynamic environments is to be able to recover quickly from hidden changes, while reusing previous knowledge. Our results show that XCS is capable of recovering quickly from small changes in the underlying concepts. However, it requires significant time to re-learn a model after severe changes. We propose several strategies to force the system to learn quickly after severe changes. There are adaptive learning; re-initializing the parameters; and re-initializing the population. Experiments show improvement in the predictive performance of XCS, when compared to the traditional XCS.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Dam2007. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.87.8627}
}

@InProceedings{Daneshmand2011,
  Title                    = {{Keynote 1: Intelligent Network Operations and Management Ã¢â‚¬â€� It's about the data}},
  Author                   = {Daneshmand, Mahmoud},
  Booktitle                = {2011 IEEE Symposium on Computers and Communications (ISCC)},
  Year                     = {2011},
  Month                    = jun,
  Pages                    = {1--1},
  Publisher                = {IEEE},

  Abstract                 = {Intelligent Operations and Management, in general, and, Intelligent Network Operations and Management, in particular, is increasingly about End-to-End control across multiple networks/services; across multiple layers in network, computing, and software stacks; and, across a variety of time-frames. It is, therefore, a problem of integration and analysis of huge amounts of very heterogeneous data in real time. This talk will contain an overview of AT\&T Shannon Labs research, and a discussion of our work in Information Mining and Software Research with applications in telecommunications industry including network operations, network security, IP network management, fraud detection, marketing, and business \& consumer markets analysis. The emphasis will be on near real-time analysis and mining of large scale data streams. Selected future research direction will be presented.},
  Doi                      = {10.1109/ISCC.2011.5984766},
  ISBN                     = {978-1-4577-0680-6},
  ISSN                     = {1530-1346},
  Keywords                 = {AT\&T Shannon Labs research,IP network management,IP networks,business,computer network management,consumer markets analysis,data mining,end-to-end control,fraud detection,information mining,intelligent network management,intelligent network operation,marketing,multiple networks,multiple services,network security,software research,telecommunication security,telecommunications industry},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Talk giving overview of AT&T research, talking about several issues. Discarded.},
  Shorttitle               = {Computers and Communications (ISCC), 2011 IEEE Sym},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5984766}
}

@Article{Dang2008,
  Title                    = {Online mining of frequent sets in data streams with error guarantee},
  Author                   = {Dang, X.H.a and Ng, W.-K.a and Ong, K.-L.b },
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2008},
  Note                     = {cited By (since 1996)12},
  Number                   = {2},
  Pages                    = {245-258},
  Volume                   = {16},

  Abstract                 = {For most data stream applications, the volume of data is too huge to be stored in permanent devices or to be thoroughly scanned more than once. It is hence recognized that approximate answers are usually sufficient, where a good approximation obtained in a timely manner is often better than the exact answer that is delayed beyond the window of opportunity. Unfortunately, this is not the case for mining frequent patterns over data streams where algorithms capable of online processing data streams do not conform strictly to a precise error guarantee. Since the quality of approximate answers is as important as their timely delivery, it is necessary to design algorithms to meet both criteria at the same time. In this paper, we propose an algorithm that allows online processing of streaming data and yet guaranteeing the support error of frequent patterns strictly within a user-specified threshold. Our theoretical and experimental studies show that our algorithm is an effective and reliable method for finding frequent sets in data stream environments when both constraints need to be satisfied. Ã‚Â© Springer-Verlag London Limited 2007.},
  Affiliation              = {School of Computer Engineering, Nanyang Technological University, Nanyang Avenue, Singapore 639798, Singapore; School of Engineering and IT, Deakin University, Waurn Ponds, VIC 3217, Australia},
  Author_keywords          = {Data mining; Data stream; Error guarantee; Frequent set mining; Online algorithm},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Algorithms capable of online processing do not conform strictly to a precise error guarantee. We present a novel algorithm that allows online processing while producing results strictly within the error bound given by user,. Our theoretical and experimental studies show that our algorithm is an effective and reliable method for finding frequent sets in data stream environments when both constraints need to be satisfied 1,2,3,4,5,6 Approved},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-48649098791&partnerID=40&md5=b2ea6dd3900cd536bff6c13b86d00979}
}

@Article{Dang2006,
  Title                    = {EStream: Online mining of frequent sets with precise error guarantee},
  Author                   = {Dang, X.H.a and Ng, W.-K.a and Ong, K.-L.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2006},
  Note                     = {cited By (since 1996)0},
  Pages                    = {312-321},
  Volume                   = {4081 LNCS},

  Abstract                 = {In data stream applications, a good approximation obtained in a timely manner is often better than the exact answer that's delayed beyond the window of opportunity. Of course, the quality of the approximate is as important as its timely delivery. Unfortunately, algorithms capable of online processing do not conform strictly to a precise error guarantee. Since online processing is essential and so is the precision of the error, it is necessary that stream algorithms meet both criteria. Yet, this is not the case for mining frequent sets in data streams. We present EStream, a novel algorithm that allows online processing while producing results strictly within the error bound. Our theoretical and experimental results show that EStream is a better candidate for finding frequent sets in data streams, when both constraints need to be satisfied. Ã‚Â© Springer-Verlag Berlin Heidelberg 2006.},
  Affiliation              = {School of Computer Engineering, Nanyang Technological University, Singapore, Singapore; School of Engineering and IT, Deakin University, Australia},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Older version of Dang2008. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33751381445&partnerID=40&md5=547654e36af9f7ab993d9c83c341dd9a}
}

@Conference{Dang2007,
  Title                    = {Discovering frequent sets from data streams with CPU constraint},
  Author                   = {Dang, X.H.a and NG, W.-K.a and Ong, K.-L.b and Lee, V.C.S.c},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {121-128},
  Volume                   = {70},

  Abstract                 = {Data streams are usually generated in an online fashion characterized by huge volume, rapid unpre-dictable rates, and fast changing data characteristics. It has been hence recognized that mining over stream-ing data requires the problem of limited computa-tional resources to be adequately addressed. Since the arrival rate of data streams can significantly in-crease and exceed the CPU capacity, the machinery must adapt to this change to guarantee the timeli-ness of the results. We present an online algorithm to approximate a set of frequent patterns from a slid-ing window over the underlying data stream - given apriori CPU capacity. The algorithm automatically detects overload situations and can adaptively shed unprocessed data to guarantee the timely results. We theoretically prove, using probabilistic and determin-istic techniques, that the error on the output results is bounded within a pre-specified threshold. The em-pirical results on various datasets also confirmed the feasiblity of our proposal. Ã‚Â© 2007, Australian Computer Society, Inc.},
  Affiliation              = {School of Computer Engineering, Nanyang Technological University, Singapore; School of Engineering and IT, Deakin University, Australia; Clayton School of Information Technology, Monash University, Australia},
  Author_keywords          = {Data stream; Error approximation; Frequent set mining; Load shedding; Online algorithm},
  Document_type            = {Article},
  Journal                  = {Conferences in Research and Practice in Information Technology Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Algorithm sensitive to overload situations. We present an online algorithm to approximate a set of frequent patterns from a sliding window over the underlying data stream – given apriori CPU capacity. We theoretically prove, using probabilistic and deterministic techniques, that the error on the output results is bounded within a pre-specified threshold. The empirical results on various datasets also confirmed the feasiblity of our proposal. Approved 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870530329&partnerID=40&md5=ba372d71832dca17725ec4216c0b9f60}
}

@Misc{Dang,
  Title                    = {{Discovering Frequent Sets from Data Streams with CPU Constraint}},

  Author                   = {Dang, Xuan Hong and Ng, Wee-keong and Ong, Kok-leong and Lee, Vincent C S},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Data streams are usually generated in an online fashion characterized by huge volume, rapid unpredictable rates, and fast changing data characteristics. It has been hence recognized that mining over streaming data requires the problem of limited computational resources to be adequately addressed. Since the arrival rate of data streams can significantly increase and exceed the CPU capacity, the machinery must adapt to this change to guarantee the timeliness of the results. We present an online algorithm to approximate a set of frequent patterns from a sliding window over the underlying data stream – given apriori CPU capacity. The algorithm automatically detects overload situations and can adaptively shed unprocessed data to guarantee the timely results. We theoretically prove, using probabilistic and deterministic techniques, that the error on the output results is bounded within a pre-specified threshold. The empirical results on various datasets also confirmed the feasiblity of our proposal.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Dang2007. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.296.3015}
}

@Article{Dang2007a,
  Title                    = {{Discovering frequent sets from data streams with CPU constraint}},
  Author                   = {Dang, Xuan Hong and Ng, Wee-Keong and Ong, Kok-Leong and Lee, Vincent C S},
  Year                     = {2007},

  Month                    = dec,
  Pages                    = {121--128},

  Abstract                 = {Data streams are usually generated in an online fashion characterized by huge volume, rapid unpredictable rates, and fast changing data characteristics. It has been hence recognized that mining over streaming data requires the problem of limited computational resources to be adequately addressed. Since the arrival rate of data streams can significantly increase and exceed the CPU capacity, the machinery must adapt to this change to guarantee the timeliness of the results. We present an online algorithm to approximate a set of frequent patterns from a sliding window over the underlying data stream -- given apriori CPU capacity. The algorithm automatically detects overload situations and can adaptively shed unprocessed data to guarantee the timely results. We theoretically prove, using probabilistic and deterministic techniques, that the error on the output results is bounded within a pre-specified threshold. The empirical results on various datasets also confirmed the feasiblity of our proposal.},
  ISBN                     = {978-1-920682-51-4},
  Keywords                 = {data stream,error approximation,frequent set mining,load shedding,online algorithm},
  Owner                    = {alex},
  Publisher                = {Australian Computer Society, Inc.},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Dang2007. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1378245.1378262}
}

@InProceedings{Dass2010,
  Title                    = {{Kaal - A Real Time Stream Mining Algorithm}},
  Author                   = {Dass, Rajanish and Kumar, Varun},
  Booktitle                = {2010 43rd Hawaii International Conference on System Sciences},
  Year                     = {2010},
  Pages                    = {1--10},
  Publisher                = {IEEE},

  Abstract                 = {Finding frequent patterns in a data stream has been one of the daunting tasks since its inception. Mining data streams are allowed only one look at the data, and techniques have to keep pace with the arrival of new data. Furthermore, dynamic data streams pose new challenges, because their underlying distribution might be changing. Most importantly, the stream mining algorithm must be fast enough to adapt itself to slow as well as very fast data streams. In this paper, we have introduced a new stream mining algorithm called Kaal - Sanskrit word for time - that is significantly better than existing classical algorithms. Further, Kaal is capable of adapting well to variable batch sizes. The batches are decided by a fixed time quanta, any number of transactions coming in that time interval constitutes that batch. Previous stream mining algorithms demand fixed batch sizes, which in real world scenario becomes difficult to realize or fail to provide periodic real-time results.},
  Doi                      = {10.1109/HICSS.2010.246},
  ISBN                     = {978-1-4244-5509-6},
  ISSN                     = {1530-1605},
  Keywords                 = {Conference management,Data mining,Data security,Information analysis,Itemsets,Kaal,Marketing and sales,Oceans,Real time systems,Research and development,Web and internet services,classical algorithms,data mining,fixed batch sizes,frequent pattern finding,real time stream mining algorithm,real-time systems},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining data streams are allowed only one look at the data, and techniques have to keep pace with the arrival of new data. In this paper, we have introduced a new stream mining algorithm called Kaal that is significantly better than existing classical algorithms. Kaal is capable of adapting well to variable batch sizes. The batches are decided by a fixed time quanta, any number of transactions coming in that time interval constitutes that batch. Previous stream mining algorithms demand fixed batch sizes, which in real world scenario becomes difficult to realize or fail to provide periodic real-time results. Approved 1,2,4,5,6},
  Shorttitle               = {System Sciences (HICSS), 2010 43rd Hawaii Internat},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5428644}
}

@Conference{Dass2010a,
  Title                    = {Kaal - A real time stream mining algorithm},
  Author                   = {Dass, R.a and Kumar, V.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Finding frequent patterns in a data stream has been one of the daunting tasks since its inception. Mining data streams are allowed only one look at the data, and techniques have to keep pace with the arrival of new data. Furthermore, dynamic data streams pose new challenges, because their underlying distribution might be changing. Most importantly, the stream mining algorithm must be fast enough to adapt itself to slow as well as very fast data streams. In this paper, we have introduced a new stream mining algorithm called Kaal - Sanskrit word for time - that is significantly better than existing classical algorithms. Further, Kaal is capable of adapting well to variable batch sizes. The batches are decided by a fixed time quanta, any number of transactions coming in that time interval constitutes that batch. Previous stream mining algorithms demand fixed batch sizes, which in real world scenario becomes difficult to realize or fail to provide periodic real-time results. Ã‚Â© 2010 IEEE.},
  Affiliation              = {Indian Institute of Management, Ahmedabad, India; Yahoo India R and D, India},
  Art_number               = {5428644},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the Annual Hawaii International Conference on System Sciences},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Dass2010. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77951813857&partnerID=40&md5=47cc00c85ccbd17bbdd87bcedb3b9aa1}
}

@Misc{David,
  Title                    = {{MAIDS: Mining Alarming Incidents from Data Streams}},

  Author                   = {David, Dora Cai and Clutter, David and Pape, Greg and Han, Jiawei and Welge, Michael},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper presents a demonstration of our recent research and development of the MAIDS system, which mines alarming incidents from data streams, with the following major analysis functions: (1) multi-resolution modeling using a tilted time window framework, (2) multi-dimensional analysis using a stream "data cube" model, (3) online stream classification, (4) online frequent pattern mining, (5) online clustering of data streams, and (6) stream mining visualization},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Cai. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.3.7635}
}

@Conference{DeFrancisciMorales2013,
  Title                    = {SAMOA: A platform for mining big data streams},
  Author                   = {De Francisci Morales, G.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Pages                    = {777-778},

  Abstract                 = {Social media and user generated content are causing an ever growing data deluge. The rate at which we produce data is growing steadily, thus creating larger and larger streams of continuously evolving data. Online news, micro-blogs, search queries are just a few examples of these continuous streams of user activities. The value of these streams relies in their freshness and relatedness to ongoing events. However, current (de-facto standard) solutions for big data analysis are not designed to deal with evolving streams. In this talk, we offer a sneak preview of samoa, an up- coming platform for mining dig data streams. samoa is a platform for online mining in a cluster/cloud environment. It features a pluggable architecture that allows it to run on several distributed stream processing engines such as S4 and Storm. samoa includes algorithms for the most common machine learning tasks such as classification and clustering. Finally, samoa will soon be open sourced in order to foster collaboration and research on big data stream mining.},
  Affiliation              = {Yahoo Research, Barcelona, Spain},
  Author_keywords          = {Big data; Data streams; Distributed com- puting; Machine learning; Open source; Stream mining},
  Document_type            = {Conference Paper},
  Journal                  = {WWW 2013 Companion - Proceedings of the 22nd International Conference on World Wide Web},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {A talk with sneak preview about big data mining platform SAMOA. Not a science paper. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893053113&partnerID=40&md5=3ca9e0cba94a971c973383da6587a3b0}
}

@Article{DeFrancisciMorales2013a,
  Title                    = {{SAMOA: a platform for mining big data streams}},
  Author                   = {{De Francisci Morales}, Gianmarco},
  Year                     = {2013},

  Month                    = may,
  Pages                    = {777--778},

  Abstract                 = {Social media and user generated content are causing an ever growing data deluge. The rate at which we produce data is growing steadily, thus creating larger and larger streams of continuously evolving data. Online news, micro-blogs, search queries are just a few examples of these continuous streams of user activities. The value of these streams relies in their freshness and relatedness to ongoing events. However, current (de-facto standard) solutions for big data analysis are not designed to deal with evolving streams. In this talk, we offer a sneak preview of SAMOA, an upcoming platform for mining dig data streams. SAMOA is a platform for online mining in a cluster/cloud environment. It features a pluggable architecture that allows it to run on several distributed stream processing engines such as S4 and Storm. SAMOA includes algorithms for the most common machine learning tasks such as classification and clustering. Finally, SAMOA will soon be open sourced in order to foster collaboration and research on big data stream mining.},
  ISBN                     = {978-1-4503-2038-2},
  Keywords                 = {big data,data streams,distributed computing,machine learning,open source,stream mining},
  Owner                    = {alex},
  Publisher                = {International World Wide Web Conferences Steering Committee},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of DeFrancisciMorales2013. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2487788.2488042}
}

@Misc{De,
  Title                    = {{SAMOA: A Platform for Mining Big Data Streams}},

  Author                   = {De, Gianmarco and Morales, Francisci},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Social media and user generated content are causing an ever growing data deluge. The rate at which we produce data is growing steadily, thus creating larger and larger streams of continuously evolving data. Online news, micro-blogs, search queries are just a few examples of these continuous streams of user activities. The value of these streams relies in their freshness and relatedness to ongoing events. However, current (de-facto standard) solutions for big data analysis are not designed to deal with evolving streams. In this talk, we offer a sneak preview of samoa, an upcoming platform for mining dig data streams. samoa is a platform for online mining in a cluster/cloud environment. It features a pluggable architecture that allows it to run on several distributed stream processing engines such as S4 and Storm. samoa includes algorithms for the most common machine learning tasks such as classification and clustering. Finally, samoa will soon be open sourced in order to foster collaboration and research on big data stream mining.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of DeFrancisciMorales2013. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.402.4525}
}

@Book{Demers2005,
  Title                    = {{Intelligence and Security Informatics}},
  Author                   = {Demers, Alan and Gehrke, Johannes and Hong, Mingsheng and Riedewald, Mirek},
  Editor                   = {Kantor, Paul and Muresan, Gheorghe and Roberts, Fred and Zeng, Daniel D. and Wang, Fei-Yue and Chen, Hsinchun and Merkle, Ralph C.},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2005},

  Address                  = {Berlin, Heidelberg},
  Month                    = may,
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {3495},

  Abstract                 = {Intelligence organizations face the daunting task of collecting all relevant pieces of information and to draw conclusions about potential threats in a timely manner. Typical information sources range from news tickers, financial transaction logs and message logs to satellite images and speech recordings. This wealth of data is continuously updated and arrives in high-speed data streams; it needs to be analyzed both in real-time (e.g., to estimate the importance of the information and to generate early threat alerts) and offline by sophisticated data mining tools. This work focuses on the real-time aspects of processing these massive streams of intelligence data. We also show how real-time and data mining components can interact effectively.},
  Doi                      = {10.1007/b136511},
  ISBN                     = {978-3-540-25999-2},
  Owner                    = {alex},
  Pages                    = {617--618},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Intelligence organizations face the daunting task of collecting all relevant pieces of information and to draw conclusions about potential threats in a timely manner. This work focuses on the real-time aspects of processing these massive streams of intelligence data. We also show how real-time and data mining components can interact effectively. Approved 6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2154644.2154734}
}

@Misc{Deng,
  Title                    = {{On Sample Selection Bias in Large-Scale Online Stream Mining: a Model Indexing Approach}},

  Author                   = {Deng, Xiong and Ghanem, Moustafa M. and Guo, Yike},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Large-scale data stream applications including network intrusion detection pose the non-trivial problem of sample selection bias to online data mining. The problem greatly degrades state-of-the-art data mining models including C4.5 and soft margin SVM, incremental data mining algorithms including CVFDT, and online ensemble model methods including the weight-by-accuracy approach. Inspired by the web search engine technology, this paper proposes an index-based ensemble model approach to ease this problem. During online training, we summarize the variable distribution characteristics of each data sample before training a model on it, and then index the models to their corresponding distribution characteristics. During online classification, we indentify the most appropriate models for chunks of incoming unlabeled instances by matching their variable distribution characteristics. Experiments studied on both synthetic datasets and network intrusion detection domain demonstrate substantial advantages of the proposed approach over state-of-the-art stream mining algorithms in terms of easing the sample selection bias problem and therefore improving classification accuracy.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Large scale data stream applications pose the non-trivial problem of sample selection bias to online data mining. The problem greatly degrades state-of-the-art data mining models including C4.5 and soft margin SVM, incremental data mining algorithms including CVFDT, and online ensemble model methods including the weight-by-accuracy approach. this paper proposes an index-based ensemble model approach to ease this problem. Experiments show that this approcah has advantages over state of the art stream mining. Approved 1,2,3,4,5,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.217.8028}
}

@Misc{DiYang,
  Title                    = {{CLUES: A Unified Framework Supporting Interactive Exploration of Density-Based Clusters in Streams}},

  Author                   = {{Di Yang} and Yang, Di and Guo, Zhenyu and Rundensteiner, Elke A. and Ward, Matthew O.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Although various mining algorithms have been proposed in the literature to efficiently compute clusters, few strides have been made to date in helping analysts to interactively explore such patterns in the stream context. We present a framework called CLUES to both computationally and visually support the process of real-time mining of density-based clusters. CLUES is composed of three major components. First, as foundation of CLUES, we develop an evolution model of density-based clusters in data streams that captures the complete spectrum of cluster evolution types across streaming windows. Second, to equip CLUES with the capability of efficiently tracking cluster evolution, we design a novel algorithm to piggy-back the evolution tracking process into the underlying cluster detection process. Third, CLUES organizes the detected clusters and their evolution interrelationships into a multidimensional pattern space – presenting clusters at different time horizons and across different abstraction levels. It provides a rich set of visualization and interaction techniques to allow the analyst to explore this multi-dimensional pattern space in real-time. Our experimental evaluation, including performance studies and a user study, using real streams from ground group movement monitoring and from stock transaction domains confirm both the efficiency and effectiveness of our proposed CLUES framework.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {stream clustering framework CLUES. using cluster evolution models. Rich set of visualization. Experimental results confirm efficiency and effectiveness. Also user testing. Approved 1,2,3,4},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.309.5600}
}

@Misc{DiYangc,
  Title                    = {{Interactive Visual Exploration of Neighbor-Based Patterns in Data Streams âˆ—}},

  Author                   = {{Di Yang} and Yang, Di and Guo, Zhenyu and Xie, Zaixian and Rundensteiner, Elke and Ward, Matthew},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We will demonstrate our system, called V iStream, supporting interactive visual exploration of neighbor-based patterns [7] in data streams. V istream does not only apply innovative multi-query strategies to compute a broad range of popular patterns, such as clusters and outliers, in a highly efficient manner, but it also provides a rich set of visual interfaces and interactions to enable real-time pattern exploration. In our demonstration, we will illustrate that with ViStream, analysts can easily interact with the pattern mining processes by navigating along the time horizons, abstraction levels and parameter spaces, and thus better understand the phenomena of interest.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {interactive visual exploration of neighbor-based patterns [7] in data streams. ViStream, analysts can easily interact with the pattern mining processes by navigating along the time horizons, abstraction levels and parameter spaces Approved 1},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.309.5624}
}

@Misc{DiYangb,
  Title                    = {{Summarization and Matching of Density-Based Clusters in Streaming Environments âˆ—}},

  Author                   = {{Di Yang} and Yang, Di and Rundensteiner, Elke A. and Ward, Matthew O.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Density-basedclusterminingisknowntoserveabroadrange of applications ranging from stock trade analysis to moving object monitoring. Although methods for efficient extraction of density-based clusters have been studied in the literature, the problem of summarizing and matching of such clusters with arbitrary shapes and complex cluster structures remains unsolved. Therefore, the goal of our work is to extend the state-of-art of density-based cluster mining in streams from cluster extraction only to now also support analysis and management of the extracted clusters. Our work solves three major technical challenges. First, we propose anovelmulti-resolutioncluster summarization method, called Skeletal Grid Summarization (SGS), which captures the key features of density-based clusters, covering both their external shape and internal cluster structures. Second, in order to summarize the extracted clusters in real-time, we present an integrated computation strategy C-SGS, which piggybacks the generation of cluster summarizations within the online clustering process. Lastly, we design a mechanism to efficiently execute cluster matching queries, which identify similar clusters for given cluster of analyst’s interest from clusters extractedearlier inthe stream history. Our experimental study using real streaming data shows the clear superiority of our proposed methods in both efficiency and effectiveness for cluster summarization and cluster matching queries to other potential alternatives.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Although methods for efficient extraction of density-based clusters have been studied in the literature, the problem of summarizing and matching of such clusters with arbitrary shapes and complex cluster structures remains unsolved. They contribute cluster summarization, integrated computing strategy and cluster matching querying. Our experimental study using real streaming data shows the clear superiority of our proposed methods in both efficiency and effectiveness for cluster summarization and cluster matching queries Approved 1,2,3,4,5,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.227.5440}
}

@Misc{DiYanga,
  Title                    = {{Mining and Linking Patterns across Live Data Streams and Stream Archives âˆ—}},

  Author                   = {{Di Yang} and Yang, Di and Zhao, Kaiyu and Lu, Hanyuan and Hasan, Maryam and Rundensteiner, Elke and Ward, Matthew},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We will demonstrate the visual analytics system V istream T, that supports interactive mining of complex patterns within and across live data streams and stream pattern archives. Our system is equipped with both computational pattern mining and visualization techniques, which allow it to not only efficiently discover and manage patterns but also effectively convey the mining results to human analysts through visual displays. In our demonstration, we will illustrate that with V istream T, analysts can easily submit, monitor and interact with a broad range of query types for pattern mining. This includes novel strategies for extracting complex patterns from streams in real time, summarizing neighborbased patterns using multi-resolution compression strategies, selectively pushing patterns into the stream archive, validating the popularity or rarity of stream patterns by stream archive matching, and pattern evolution tracking to link patterns across time.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {visual analytics system V istream T, that supports interactive mining of complex patterns within and across live data streams and stream pattern archives. In our demonstration, we will illustrate that with V istream T, analysts can easily submit, monitor and interact with a broad range of query types for pattern mining. Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.309.6539}
}

@Misc{DiYangWpi,
  Title                    = {{39 Shared Execution Strategy for Neighbor-Based Pattern Mining Requests over Streaming Windows}},

  Author                   = {{Di Yang Wpi} and Wpi, Di Yang and Rundensteiner, Elke A. and Ward, Matthew O.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In diverse applications ranging from stock trading to traffic monitoring, data streams are continuously monitored by multiple analysts for extracting patterns of interest in real-time. These analysts often submit similar pattern mining requests yet customized with different parameter settings. In this work, we present shared execution strategies for processing a large number of neighbor-based pattern mining requests of the same type yet with arbitrary parameter settings. Such neighbor-based pattern mining requests cover a broad range of popular mining query types, including detection of clusters, outliers and nearest neighbors. Given the high algorithmic complexity of the mining process, serving multiple such queries in a single system is extremely resource intensive. The naive method of detecting and maintaining patterns for different queries independently is often infeasible in practice, as its demands on system resources increase dramatically with the cardinality of the query workload. In order to maximize the efficiency of the system resource utilization for executing multiple queries simultaneous, we analyze the commonalities of the neighbor-based pattern mining queries, and identify several general optimization principles which lead to significant system resource sharing among multiple queries. In particular, as a preliminary sharing effort, we observe that the computation needed for the range query searches (the process of searching the neighbors for each object) can be shared among multiple queries and thus saves the CPU consumption. Then we analyze the},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {In this work, we present shared execution strategies for processing a large number of neighbor-based pattern mining requests of the same type yet with arbitrary parameter settings. Query optimization. Not ML. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.309.4481}
}

@Conference{Dilectin2012a,
  Title                    = {Classification and dynamic class detection of real time data for tsunami warning system},
  Author                   = {Dilectin, H.D. and Mercy, R.B.V.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {124-129},

  Abstract                 = {Advances in data storage technology have led to the ability to store the data for real-time transactions. Such processes lead to data which often grow without limit and are referred to as data streams. In addition, the development of sensor technology has resulted in the possibility of measuring many events in real time. While data mining has become a fairly well established field now, the data stream problem poses a number of unique challenges which are not easily solvable by traditional mining methods. In a traditional data mining classification task, it is assumed that the total number of classes is fixed. This assumption may not be valid in a real streaming environment, where new classes may evolve at any time. Another problem ignored by the existing data stream techniques is Concept-drift, which occurs in the stream when the underlying concept of the data changes over time. Thus, the classification model must be designed to reflect the most recent concept. The proposed system aims to enhance the existing Tsunami warning system by applying data stream mining Techniques to the real-time sea-level data. The sensors record the various sea level reading and pass it to the buoy located at deep sea. Feature extraction is performed for the training data collected from deep sea buoys. Data are observed every 15 seconds and classified using KNN algorithm. Data that are identified as outliers contribute to the automatic detection of novel class in the presence of concept drift. It also deals with the detection of recurring class, which reappears in the stream after a long time interval. Finally the system is designed to generate Tsunami alerts with maps and evacuation routes. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Department of Computer Science and Engineering Easwari, Engineering College, Chennai, India},
  Art_number               = {6212710},
  Author_keywords          = {Classification; Feature Extraction; Novel class},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2012 International Conference on Recent Advances in Computing and Software Systems, RACSS 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Dilectin2012a. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864046302&partnerID=40&md5=3d7d4c4b08ce0bd775e008e9530d19bb}
}

@InProceedings{Dilectin2012,
  Title                    = {{Classification and dynamic class detection of real time data for tsunami warning system}},
  Author                   = {Dilectin, H. D. and Mercy, R. B. V.},
  Booktitle                = {2012 International Conference on Recent Advances in Computing and Software Systems},
  Year                     = {2012},
  Month                    = apr,
  Pages                    = {124--129},
  Publisher                = {IEEE},

  Abstract                 = {Advances in data storage technology have led to the ability to store the data for real-time transactions. Such processes lead to data which often grow without limit and are referred to as data streams. In addition, the development of sensor technology has resulted in the possibility of measuring many events in real time. While data mining has become a fairly well established field now, the data stream problem poses a number of unique challenges which are not easily solvable by traditional mining methods. In a traditional data mining classification task, it is assumed that the total number of classes is fixed. This assumption may not be valid in a real streaming environment, where new classes may evolve at any time. Another problem ignored by the existing data stream techniques is Concept-drift, which occurs in the stream when the underlying concept of the data changes over time. Thus, the classification model must be designed to reflect the most recent concept. The proposed system aims to enhance the existing Tsunami warning system by applying data stream mining Techniques to the real-time sea-level data. The sensors record the various sea level reading and pass it to the buoy located at deep sea. Feature extraction is performed for the training data collected from deep sea buoys. Data are observed every 15 seconds and classified using KNN algorithm. Data that are identified as outliers contribute to the automatic detection of novel class in the presence of concept drift. It also deals with the detection of recurring class, which reappears in the stream after a long time interval. Finally the system is designed to generate Tsunami alerts with maps and evacuation routes.},
  Doi                      = {10.1109/RACSS.2012.6212710},
  ISBN                     = {978-1-4673-0255-5},
  Keywords                 = {Accuracy,Classification,Classification algorithms,Data mining,Feature Extraction,Feature extraction,KNN algorithm,Novel class,Real time systems,Training,Tsunami,alarm systems,concept-drift problem,data mining,data mining classification,data storage technology,data stream mining,deep sea buoys,dynamic class detection,emergency services,evacuation routes,feature extraction,outlier identification,pattern classification,real-time sea-level data,recurring class detection,sensor fusion,sensor technology,tsunami,tsunami warning system},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The proposed system aims to enhance the existing Tsunami warning system by applying data stream mining Techniques to the real-time sea-level data. Data are observed every 15 seconds and classified using KNN algorithm. Data that are identified as outliers contribute to the automatic detection of novel class in the presence of concept drift. Finally the system is designed to generate Tsunami alerts with maps and evacuation routes. Approved 1,2,6},
  Shorttitle               = {Recent Advances in Computing and Software Systems },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6212710}
}

@Misc{Ding,
  Title                    = {{2013 IEEE 33rd International Conference on Distributed Computing Systems Workshops A Data Analytic Engine Towards Self-Management of Cyber-Physical Systems}},

  Author                   = {Ding, Min and Chen, Haifeng and Sharma, Abhishek and Yoshihira, Kenji and Jiang, Guofei},

  __markedentry            = {[Alexander:]},
  Abstract                 = {With the increasing complexity of cyber-physical systems, it is essential to enhance their self-management capabilities (e.g., self-protection, self-optimization). This paper presents a data-oriented approach to achieving that goal, given that a large amount of measurements can be collected in current systems. We investigate typical data characteristics in physical systems, and identify that the collected data from those systems exhibit a wide range of diversities. Following those observations, a new analytic engine is proposed and developed to extract knowledge from measurement data streams in physical systems. The engine treats each attribute in measurements as a time series and contains an ensemble of models, each attempting to discover a specific data property accordingly, such as periodicity, pairwise dependency and so on. Therefore time series are profiled based on their properties captured by engine models. The extracted data profiles can be further used to facilitate several management tasks of system status monitoring and online anomaly detection. Our experimental results in a real power plant have demonstrated that our analytic engine can correctly profile heterogeneous time series in the system, and successfully detect a number of abnormal situations in the system operation including some system inspection events as well as component faults.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents a data-oriented approach to achieving self-management. The engine treats each attribute in measurements as a time series and contains an ensemble of models, each attempting to discover a specific data property accordingly, such as periodicity, pairwise dependency and so on. Our experimental results in a real power plant have demonstrated that our analytic engine can correctly profile heterogeneous time series in the system, and successfully detect a number of abnormal situations Approved 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.417.6538}
}

@Article{Ding2013,
  Title                    = {Research on data stream clustering algorithms},
  Author                   = {Ding, S.a b and Wu, F.a and Qian, J.a and Jia, H.a and Jin, F.c },
  Journal                  = {Artificial Intelligence Review},
  Year                     = {2013},
  Note                     = {cited By (since 1996)2; Article in Press},
  Pages                    = {1-8},

  Abstract                 = {Data stream is a potentially massive, continuous, rapid sequence of data information. It has aroused great concern and research upsurge in the field of data mining. Clustering is an effective tool of data mining, so data stream clustering will undoubtedly become the focus of the study in data stream mining. In view of the characteristic of the high dimension, dynamic, real-time, many effective data stream clustering algorithms have been proposed. In addition, data stream information are not deterministic and always exist outliers and contain noises, so developing effective data stream clustering algorithm is crucial. This paper reviews the development and trend of data stream clustering and analyzes typical data stream clustering algorithms proposed in recent years, such as Birch algorithm, Local Search algorithm, Stream algorithm and CluStream algorithm. We also summarize the latest research achievements in this field and introduce some new strategies to deal with outliers and noise data. At last, we put forward the focal points and difficulties of future research for data stream clustering. Ã‚Â© 2013 Springer Science+Business Media Dordrecht.},
  Affiliation              = {School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Science, Beijing, 100190, China; College of Geomatics, Shandong University of Science and Technology, Qingdao, 266590, China},
  Author_keywords          = {Clustering; Data mining; Data model; Data stream},
  Document_type            = {Article in Press},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {Survey paper on data stream mining. This paper reviews the development and trend of data stream clustering and analyzes typical data stream clustering algorithms proposed in recent years, such as Birch algorithm, Local Search algorithm, Stream algorithm and CluStream algorithm. We also summarize the latest research achievements in this field and introduce some new strategies to deal with outliers and noise data Discarded, but put aside.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84873398227&partnerID=40&md5=738336825f91fe7360a824c5a80f7023}
}

@InProceedings{Dingping2013,
  Title                    = {{Application of Data Stream Outlier Mining Techniques in Steam Generator Safety Early Warning System of Nuclear Power Plant}},
  Author                   = {Dingping, Liu and Kaitao, Zheng and Qiqi, Yan},
  Booktitle                = {2013 Fifth International Conference on Measuring Technology and Mechatronics Automation},
  Year                     = {2013},
  Month                    = jan,
  Pages                    = {287--290},
  Publisher                = {IEEE},

  Abstract                 = {Mining outliers in data streams is a popular research issue in data mining field, which can help to find outliers under abnormal condition and then corresponding measures can be taken. The security guarantee of nuclear power plant is the center topic for discussion of the development of nuclear power plant (NPP). As an important equipment of NPP, steam generator (SG) will produce large amounts of real-time data streams in the process of running every day, such as temperature streams of U-shaped tubes. Mining temperature stream outliers (TSO) of U-shaped tubes is helpful to the implementation of early warning behavior, which contributes to the safety of NPP. In this paper, the authors propose a novel algorithm for mining TSO of U-shaped tubes. By using data stream labels to mark the abnormal frequent items, the data stream is considered to be abnormal if it is marked three times continuously. The proposed algorithm is tested by experiments. And experimental results show that the algorithm has higher accuracy and better scalability.},
  Doi                      = {10.1109/ICMTMA.2013.74},
  ISBN                     = {978-1-4673-5652-7},
  Keywords                 = {NPP,SG,TSO,abnormal frequent items,alarm systems,data mining,data stream,data stream labels,data stream outlier mining techniques,early warning behavior,nuclear power plant,nuclear power stations,outlier mining,power engineering computing,safety early warning system,steam generator safety early warning system,temperature stream outliers,u-shaped tubes},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining outliers in data streams. In this paper, the authors propose a novel algorithm for mining temperature stream outliers. The proposed algorithm is tested by experiments. And experimental results show that the algorithm has higher accuracy and better scalability. Approved 1,3,4,6},
  Shorttitle               = {Measuring Technology and Mechatronics Automation (},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6493723}
}

@InProceedings{Ditzler2011,
  Title                    = {{Semi-supervised learning in nonstationary environments}},
  Author                   = {Ditzler, Gregory and Polikar, Robi},
  Booktitle                = {The 2011 International Joint Conference on Neural Networks},
  Year                     = {2011},
  Month                    = jul,
  Pages                    = {2741--2748},
  Publisher                = {IEEE},

  Abstract                 = {Learning in nonstationary environments, also called learning concept drift, has been receiving increasing attention due to increasingly large number of applications that generate data with drifting distributions. These applications are usually associated with streaming data, either online or in batches, and concept drift algorithms are trained to detect and track the drifting concepts. While concept drift itself is a significantly more complex problem than the traditional machine learning paradigm of data coming from a fixed distribution, the problem is further complicated when obtaining labeled data is expensive, and training must rely, in part, on unlabelled data. Independently from concept drift research, semi-supervised approaches have been developed for learning from (limited) labeled and (abundant) unlabeled data; however, such approaches have been largely absent in concept drift literature. In this contribution, we describe an ensemble of classifiers based approach that takes advantage of both labeled and unlabeled data in addressing concept drift: available labeled data are used to generate classifiers, whose voting weights are determined based on the distances between Gaussian mixture model components trained on both labeled and unlabeled data in a drifting environment.},
  Doi                      = {10.1109/IJCNN.2011.6033578},
  ISBN                     = {978-1-4244-9635-8},
  ISSN                     = {2161-4393},
  Keywords                 = {Algorithm design and analysis,Classification algorithms,Clustering algorithms,Data models,Gaussian mixture model,Gaussian processes,Testing,Training,Training data,concept drift,data analysis,data classifier,drifting distribution,ensemble systems,incremental learning,learning (artificial intelligence),learning concept drift,machine learning,non-stationary environments,nonstationary environment,pattern classification,semisupervised learning,streaming data,unlabeled data,unlabelled data,voting weight},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Independently from concept drift research, semi-supervised approaches have been developed for learning from (limited) labeled and (abundant) unlabeled data; however, such approaches have been largely absent in concept drift literature. Ensemble method that takes advantage of both labeled and unlabeled data in addressing concept drift: labeled data are used to generate classifiers, whose voting weights are determined based on the distances between Gaussian mixture model components trained on both labeled and unlabeled data in a drifting environment. Approved 1,2,5,6},
  Shorttitle               = {Neural Networks (IJCNN), The 2011 International Jo},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6033578}
}

@Conference{Ditzler2011a,
  Title                    = {Semi-supervised learning in nonstationary environments},
  Author                   = {Ditzler, G. and Polikar, R.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)7},
  Pages                    = {2741-2748},

  Abstract                 = {Learning in nonstationary environments, also called learning concept drift, has been receiving increasing attention due to increasingly large number of applications that generate data with drifting distributions. These applications are usually associated with streaming data, either online or in batches, and concept drift algorithms are trained to detect and track the drifting concepts. While concept drift itself is a significantly more complex problem than the traditional machine learning paradigm of data coming from a fixed distribution, the problem is further complicated when obtaining labeled data is expensive, and training must rely, in part, on unlabelled data. Independently from concept drift research, semi-supervised approaches have been developed for learning from (limited) labeled and (abundant) unlabeled data; however, such approaches have been largely absent in concept drift literature. In this contribution, we describe an ensemble of classifiers based approach that takes advantage of both labeled and unlabeled data in addressing concept drift: available labeled data are used to generate classifiers, whose voting weights are determined based on the distances between Gaussian mixture model components trained on both labeled and unlabeled data in a drifting environment. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Signal Processing and Pattern Recognition Laboratory in the Electrical, Computer Engineering Department, Rowan University Located, Glassboro, NJ 08028, United States},
  Art_number               = {6033578},
  Author_keywords          = {concept drift; ensemble systems; incremental learning; non-stationary environments; unlabeled data},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the International Joint Conference on Neural Networks},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ditzler2011. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054770829&partnerID=40&md5=29bf58a3a84c69b773a5c18d46fdbfbd}
}

@Article{Ditzler2011b,
  Title                    = {{Semi-supervised Learning in Nonstationary Environments}},
  Author                   = {Ditzler, Gregory and Polikar, Robi},
  Journal                  = {INT.JOINT CONF.NEURAL NETWORKS},
  Year                     = {2011},
  Pages                    = {2741 -- 2748},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Learning in nonstationary environments, also called learning concept drift, has been receiving increasing attention due to increasingly large number of applications that generate data with drifting distributions. These applications are usually associated with streaming data, either online or in batches, and concept drift algorithms are trained to detect and track the drifting concepts. While concept drift itself is a significantly more complex problem than the traditional machine learning paradigm of data coming from a fixed distribution, the problem is further complicated when obtaining labeled data is expensive, and training must rely, in part, on unlabelled data. Independently from concept drift research, semi-supervised approaches have been developed for learning from (limited) labeled and (abundant) unlabeled data; however, such approaches have been largely absent in concept drift literature. In this contribution, we describe an ensemble of classifiers based approach that takes advantage of both labeled and unlabeled data in addressing concept drift: available labeled data are used to generate classifiers, whose voting weights are determined based on the distances between Gaussian mixture model components trained on both labeled and unlabeled data in a drifting environment.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ditzler2011. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.387.5855}
}

@InProceedings{Dongre2014,
  Title                    = {{A review on real time data stream classification and adapting to various concept drift scenarios}},
  Author                   = {Dongre, Priyanka B. and Malik, Latesh G.},
  Booktitle                = {2014 IEEE International Advance Computing Conference (IACC)},
  Year                     = {2014},
  Month                    = feb,
  Pages                    = {533--537},
  Publisher                = {IEEE},

  Abstract                 = {Data streams are viewed as a sequence of relational tuples (e.g., sensor readings,call records, web page visits) that continuously arrive at time-varying and possibly unbound streams. These data streams are potentially huge in size and thus it is impossible to process many data mining techniques and approaches. Classification techniques fail to successfully process data streams because of two factors: their overwhelming volume and their distinctive feature known as concept drift. Concept drift is a term used to describe changes in the learned structure that occur over time. The occurance of concept drift leads to a drastic drop in classification accuracy. The recognition of concept drift in data streams has led to sliding-window approaches also different approaches to mining data streams with concept drift include instance selection methods, drift detection, ensemble classifiers, option trees and using Hoeffding boundaries to estimate classifier performance. This paper describes the various types of concept drifts that affect the data examples and discusses various approaches in order to handle concept drift scenarios. The aim of this paper is to review and compare single classifier and ensemble approaches to data stream mining respectively.},
  Doi                      = {10.1109/IAdCC.2014.6779381},
  ISBN                     = {978-1-4799-2572-8},
  Keywords                 = {Accuracy,Algorithm design and analysis,Bagging,Classification algorithms,Conferences,Data mining,Data stream mining,Heuristic algorithms,Hoeffding boundary,Web page visits,call records,classification accuracy,classification techniques,classifier performance estimation,concept drift,concept drift scenarios,data mining,data mining techniques,data stream mining,drastic drop,drift detection,dynamic environment,ensemble classifier,estimation theory,instance selection method,option trees,pattern classification,possibly unbound streams,real time data stream classification,relational tuples,sensor readings,sliding-window approach,time-varying stream,time-varying systems,trees (mathematics)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {This paper describes the various types of concept drifts that affect the data examples and discusses various approaches in order to handle concept drift scenarios. The aim of this paper is to review and compare single classifier and ensemble approaches to data stream mining respectively. Survey paper. Discarded, put aside.},
  Shorttitle               = {Advance Computing Conference (IACC), 2014 IEEE Int},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6779381}
}

@Article{Du2007,
  Title                    = {Fast curve segmentation in real time},
  Author                   = {Du, Y.a b and Lu, D.a b and Li, D.a b and Wei, W.a b },
  Journal                  = {Journal of Computational Information Systems},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Number                   = {1},
  Pages                    = {17-24},
  Volume                   = {3},

  Abstract                 = {Traditional segmenting algorithm of time series cannot be used in the environment of data streams effectively. A new online algorithm for segmenting time series, called SC (Sequential Clustering), is presented here. The traditional clustering methods are confronted with the large challenge in the domain of mining time series. By considering the time attribute of temporal data, a novel clustering method is designed in this present study. Through constructing an in-memory List for saving segmenting information, SC can online segments time series with a single scan of the data points. The I/O cost is linear to the size of the sequential dataset. Using several experiments, SC's time efficiency and segmentation quality are evaluated in detail. Theory analysis and experimental Results show that SC is superior to other existed segmenting algorithms.},
  Affiliation              = {Institute of Engineering and Science Software, University of Science and Technology of China, Hefei 230027, China; Anhui Province Key Laboratory of Software in Computing and Communication, Hefei 230027, China},
  Author_keywords          = {Online segmentation; Sequential clustering; SF-List; Time series},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Traditional segmenting algorithm of time series cannot be used in the environment of data streams effectively. They make an online algorhtm, Sequential Clustering. The I/O cost is linear to the size of the sequential dataset. several experiments, SC's time efficiency and segmentation quality are evaluated in detail. Theory analysis and experimental Results show that SC is superior to other existed segmenting algorithms. Approved 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34248639900&partnerID=40&md5=d33204f4fe8b50dc147e9327041cd5b8}
}

@Article{Ducasse2010,
  Title                    = {{Adaptive Topologic Optimization for Large-Scale Stream Mining}},
  Author                   = {Ducasse, Raphael and Turaga, Deepak S and van der Schaar, Mihaela},
  Journal                  = {IEEE Journal of Selected Topics in Signal Processing},
  Year                     = {2010},

  Month                    = jun,
  Number                   = {3},
  Pages                    = {620--636},
  Volume                   = {4},

  Abstract                 = {Real-time classification and identification of specific features in high-volume data streams are critical for a plethora of applications, including large-scale multimedia analysis, processing, and retrieval. Content of interest is filtered using a collection of binary classifiers that are deployed on distributed resource-constrained infrastructure. In this paper, we focus on selecting the optimal topology (chain) of classifiers, and present algorithms for classifier ordering and configuration, to tradeoff accuracy of feature identification with filtering delay. The order selection is dependent on the data characteristics, system resource constraints as well as the performance and complexity characteristics of each classifier. We first develop centralized algorithms for joint ordering and individual classifier operating point selection. We then propose a decentralized approach and use reinforcement learning methods to design a dynamic routing based order selection strategy. We investigate different learning strategies that lead to rapid convergence, while requiring minimum coordination and message exchange.},
  Doi                      = {10.1109/JSTSP.2009.2039180},
  ISSN                     = {1932-4553},
  Keywords                 = {Classifier topology construction,adaptive topologic optimization,binary classifier,centralized algorithms,classifier configuration,classifier ordering,data mining,dynamic routing,feature identification,filtering delay,large scale multimedia analysis,large-scale stream mining,learning (artificial intelligence),multi-concept detection,optimisation,optimization,order selection strategy,pattern classification,reinforcement learning,topology},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Content of interest is filtered using a collection of binary classifiers that are deployed on distributed resource-constrained infrastructure. In this paper, we focus on selecting the optimal topology (chain) of classifiers, and present algorithms for classifier ordering and configuration, to tradeoff accuracy of feature identification with filtering delay. Approved 1,2,6},
  Shorttitle               = {Selected Topics in Signal Processing, IEEE Journal},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5447618}
}

@InProceedings{Ediger2014,
  Title                    = {{Scalable Infrastructures for Data in Motion}},
  Author                   = {Ediger, David and McColl, Rob and Poovey, Jason and Campbell, Dan},
  Booktitle                = {2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
  Year                     = {2014},
  Month                    = may,
  Pages                    = {875--882},
  Publisher                = {IEEE},

  Abstract                 = {Analytics applications for reporting and human interaction with big data rely upon scalable frameworks for data ingest, storage, and computation. Batch processing of analytic workloads increases latency of results and can perform redundant computation. In real-world applications, new data points are continuously arriving and a suite of algorithms must be updated to reflect the changes. Reducing the latency of re-computation by keeping algorithms online and up-to-date enables fast query, experimentation, and drill-down. In this paper, we share our experiences designing and implementing scalable infrastructure around No SQL databases for social media analytics applications. We propose a new heterogeneous architecture and execution model for streaming data applications that focuses on throughput and modularity.},
  Doi                      = {10.1109/CCGrid.2014.91},
  ISBN                     = {978-1-4799-2784-5},
  Keywords                 = {Algorithm design and analysis,Big Data,Clustering algorithms,Computational modeling,Data structures,Databases,Media,NoSQL databases,SQL,Servers,analytic workloads,batch processing,big data,data analysis,data in motion,data ingest,data storage,execution model,heterogeneous architecture,recomputation latency reduction,redundant computation,scalable infrastructures,social media analytics applications,social networking (online),streaming data applications},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ediger2014a. Discarded.},
  Shorttitle               = {Cluster, Cloud and Grid Computing (CCGrid), 2014 1},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6846541}
}

@Conference{Ediger2014a,
  Title                    = {Scalable infrastructures for data in motion},
  Author                   = {Ediger, D. and McColl, R. and Poovey, J. and Campbell, D.},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {875-882},

  Abstract                 = {Analytics applications for reporting and human interaction with big data rely upon scalable frameworks for data ingest, storage, and computation. Batch processing of analytic workloads increases latency of results and can perform redundant computation. In real-world applications, new data points are continuously arriving and a suite of algorithms must be updated to reflect the changes. Reducing the latency of re-computation by keeping algorithms online and up-to-date enables fast query, experimentation, and drill-down. In this paper, we share our experiences designing and implementing scalable infrastructure around No SQL databases for social media analytics applications. We propose a new heterogeneous architecture and execution model for streaming data applications that focuses on throughput and modularity. Ã‚Â© 2014 IEEE.},
  Affiliation              = {Georgia Tech Research Institute, Atlanta, GA, United States},
  Art_number               = {6846541},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing, CCGrid 2014},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Approved under uncertainty 1},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84904559467&partnerID=40&md5=036ca777e4386de955a45f53b9cbf7d7}
}

@Misc{Ediger,
  Title                    = {{2011 IEEE International Parallel \& Distributed Processing Symposium Tracking Structure of Streaming Social Networks}},

  Author                   = {Ediger, David and Riedy, Jason and Bader, David A. and Meyerhenke, Henning},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Current online social networks are massive and still growing. For example, Facebook has over 500 million active users sharing over 30 billion items per month. The scale within these data streams has outstripped traditional graph analysis methods. Real-time monitoring for anomalies may require dynamic analysis rather than repeated static analysis. The massive state behind multiple persistent queries requires shared data structures and flexible representations. We present a framework based on the STINGER data structure that can monitor a global property, connected components, on a graph of 16 million vertices at rates of up to 240 000 updates per second on 32 processors of a Cray XMT. For very large scale-free graphs, our implementation uses novel batching techniques that exploit the scale-free nature of the data and run over three times faster than prior methods. Our framework handles, for the first time, real-world data rates, opening the door to higher-level analytics such as community and anomaly detection.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ediger2011a. Discarded},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.307.8678}
}

@InProceedings{Ediger2011,
  Title                    = {{Tracking Structure of Streaming Social Networks}},
  Author                   = {Ediger, David and Riedy, Jason and Bader, David A. and Meyerhenke, Henning},
  Booktitle                = {2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
  Year                     = {2011},
  Month                    = may,
  Pages                    = {1691--1699},
  Publisher                = {IEEE},

  Abstract                 = {Current online social networks are massive and still growing. For example, Face book has over 500 million active users sharing over 30 billion items per month. The scale within these data streams has outstripped traditional graph analysis methods. Real-time monitoring for anomalies may require dynamic analysis rather than repeated static analysis. The massive state behind multiple persistent queries requires shared data structures and flexible representations. We present a framework based on the STINGER data structure that can monitor a global property, connected components, on a graph of 16 million vertices at rates of up to 240,000 updates per second on 32 processors of a Cray XMT. For very large scale-free graphs, our implementation uses novel batching techniques that exploit the scale-free nature of the data and run over three times faster than prior methods. Our framework handles, for the first time, real-world data rates, opening the door to higher-level analytics such as community and anomaly detection.},
  Doi                      = {10.1109/IPDPS.2011.326},
  ISBN                     = {978-1-61284-425-1},
  ISSN                     = {1530-2075},
  Keywords                 = {Arrays,Cray XMT,Facebook,Hardware,Image color analysis,Program processors,STINGER data structure,batch processing (computers),batching techniques,data streams,data structures,fault tolerant computing,flexible representations,graph analysis,media streaming,multiple persistent queries,real-time anomaly monitoring,shared data structures,social networking (online),streaming social networks,tracking structure},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ediger2011a. Discarded},
  Shorttitle               = {Parallel and Distributed Processing Workshops and },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6009035}
}

@Conference{Ediger2011a,
  Title                    = {Tracking structure of streaming social networks},
  Author                   = {Ediger, D. and Riedy, J. and Bader, D.A. and Meyerhenke, H.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)3},
  Pages                    = {1691-1699},

  Abstract                 = {Current online social networks are massive and still growing. For example, Facebook has over 500 million active users sharing over 30 billion items per month. The scale within these data streams has outstripped traditional graph analysis methods. Real-time monitoring for anomalies may require dynamic analysis rather than repeated static analysis. The massive state behind multiple persistent queries requires shared data structures and flexible representations. We present a framework based on the STINGER data structure that can monitor a global property, connected components, on a graph of 16 million vertices at rates of up to 240 000 updates per second on 32 processors of a Cray XMT. For very large scale-free graphs, our implementation uses novel batching techniques that exploit the scale-free nature of the data and run over three times faster than prior methods. Our framework handles, for the first time, real-world data rates, opening the door to higher-level analytics such as community and anomaly detection. Ã‚Â© 2011 IEEE.},
  Affiliation              = {College of Computing, Georgia Institute of Technology, Atlanta, GA, United States},
  Art_number               = {6009035},
  Document_type            = {Conference Paper},
  Journal                  = {IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {We present a framework based on the STINGER data structure that can monitor a global property, connected components on big graphs. For very large scale-free graphs, our implementation uses novel batching techniques that exploit the scale-free nature of the data and run over three times faster than prior methods. The framework handles real world data rates coming from social media. Identifying connected components, not using ML. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-83455246442&partnerID=40&md5=f5ed94bc5f58338bd2946607d5d2f39e}
}

@InProceedings{Elfeky2006,
  Title                    = {{STAGGER: Periodicity Mining of Data Streams Using Expanding Sliding Windows}},
  Author                   = {Elfeky, Mohamed and Aref, Walid and Elmagarmid, Ahmed},
  Booktitle                = {Sixth International Conference on Data Mining (ICDM'06)},
  Year                     = {2006},
  Month                    = dec,
  Pages                    = {188--199},
  Publisher                = {IEEE},

  Abstract                 = {Sensor devices are becoming ubiquitous, especially in measurement and monitoring applications. Because of the real-time, append-only and semi-infinite natures of the generated sensor data streams, an online incremental approach is a necessity for mining stream data types. In this paper, we propose STAGGER: a one-pass, online and incremental algorithm for mining periodic patterns in data streams. STAGGER does not require that the user pre-specify the periodicity rate of the data. Instead, STAGGER discovers the potential periodicity rates. STAGGER maintains multiple expanding sliding windows staggered over the stream, where computations are shared among the multiple overlapping windows. Small-length sliding windows are imperative for early and real-time output, yet are limited to discover short periodicity rates. As streamed data arrives continuously, the sliding windows expand in length in order to cover the whole stream. Larger-length sliding windows are able to discover longer periodicity rates. STAGGER incrementally maintains a tree-like data structure for the frequent periodic patterns of each discovered potential periodicity rate. In contrast to the Fourier/Wavelet-based approaches used for discovering periodicity rates, STAGGER not only discovers a wider, more accurate set of periodicities, but also discovers the periodic patterns themselves. In fact, experimental results with real and synthetic data sets show that STAGGER outperforms Fourier/Wavelet-based approaches by an order of magnitude in terms of the accuracy of the discovered periodicity rates. Moreover, real-data experiments demonstrate the practicality of the discovered periodic patterns.},
  Doi                      = {10.1109/ICDM.2006.153},
  ISBN                     = {0-7695-2701-7},
  ISSN                     = {1550-4786},
  Keywords                 = {Computerized monitoring,Data mining,Frequency,History,Hysteresis,Inspection,Pervasive computing,STAGGER,Telephony,Tree data structures,Windows,data mining,data streams mining,expanding sliding windows,online incremental approach,periodicity mining,periodicity rates discovering,sensor devices,tree data structures,tree-like data structure},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Elfeky2006a. Discarded.},
  Shorttitle               = {Data Mining, 2006. ICDM '06. Sixth International C},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4053047}
}

@Conference{Elfeky2006a,
  Title                    = {STAGGER: Periodicity mining of data streams using expanding sliding windows},
  Author                   = {Elfeky, M.G.a and Aref, W.G.b and Elmagarmid, A.K.b },
  Year                     = {2006},
  Note                     = {cited By (since 1996)3},
  Pages                    = {188-199},

  Abstract                 = {Sensor devices are becoming ubiquitous, especially in measurement and monitoring applications. Because of the real-time, append-only and semi-infinite natures of the generated sensor data streams, an online incremental approach is a necessity for mining stream data types. In this paper, we propose STAGGER: a one-pass, online and incremental algorithm for mining periodic patterns in data streams. STAGGER does not require that the user pre-specify the periodicity rate of the data. Instead, STAGGER discovers the potential periodicity rates. STAGGER maintains multiple expanding sliding windows staggered over the stream, where computations are shared among the multiple overlapping windows. Small-length sliding windows are imperative for early and real-time output, yet are limited to discover short periodicity rates. As streamed data arrives continuously, the sliding windows expand in length in order to cover the whole stream. Larger-length sliding windows are able to discover longer periodicity rates. STAGGER incrementally maintains a tree-like data structure for the frequent periodic patterns of each discovered potential periodicity rate. In contrast to the Fourier/Wavelet-based approaches used for discovering periodicity rates, STAGGER not only discovers a wider, more accurate set of periodicities, but also discovers the periodic patterns themselves. In fact, experimental results with real and synthetic data sets show that STAGGER outperforms Fourier/Wavelet-based approaches by an order of magnitude in terms of the accuracy of the discovered periodicity rates. Moreover, real-data experiments demonstrate the practicality of the discovered periodic patterns. Ã‚Â© 2006 IEEE.},
  Affiliation              = {Google Inc.; Department of Computer Sciences, Purdue University, United States},
  Art_number               = {4053047},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank2},
  Relevance                = {relevant},
  Review                   = {In this paper, we propose STAGGER: a one-pass, online and incremental algorithm for mining periodic patterns in data streams. Periodicity mining of data streams using expanding sliding windows. . In contrast to the Fourier/Wavelet-based approaches used for discovering periodicity rates, STAGGER not only discovers a wider, more accurate set. Approved 1,2,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70449349698&partnerID=40&md5=ad2e8029d6c8e680d4cfcfe03a0d522a}
}

@Article{Elfeky2004,
  Title                    = {Using convolution to mine obscure periodic patterns in one pass},
  Author                   = {Elfeky, M.G. and Aref, W.G. and Elmagarmid, A.K.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2004},
  Note                     = {cited By (since 1996)2},
  Pages                    = {606-620},
  Volume                   = {2992},

  Abstract                 = {The mining of periodic patterns in time series databases is an interesting data mining problem that can be envisioned as a tool for forecasting and predicting the future behavior of time series data. Existing periodic patterns mining algorithms either assume that the periodic rate (or simply the period) is user-specified, or try to detect potential values for the period in a separate phase. The former assumption is a considerable disadvantage, especially in time series databases where the period is not known a priori. The latter approach results in a multi-pass algorithm, which on the other hand is to be avoided in online environments (e.g., data streams). In this paper, we develop an algorithm that mines periodic patterns in time series databases with unknown or obscure periods such that discovering the period is part of the mining process. Based on convolution, our algorithm requires only one pass over a time series of length n, with O(nlogn) time complexity. Ã‚Â© Springer-Verlag 2004.},
  Affiliation              = {Department of Computer Sciences, Purdue University, United States},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining periodic paetterns. We cannot know periodic threshold, so we should do multi pass - but we prefer not to do multi pass on streams. In this paper, we develop an algorithm that mines periodic patterns in time series databases with unknown or obscure periods such that discovering the period is part of the mining process. Approved 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-35048882067&partnerID=40&md5=af4b7d55eb80ed9f2bd4afd9cdfb7195}
}

@Article{Elfeky2004a,
  Title                    = {{Using Convolution to Mine Obscure Periodic Patterns In One Pass}},
  Author                   = {Elfeky, Mohamed G. and Aref, Walid G. and Elmagarmid, Ahmed K.},
  Journal                  = {PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON EXTENDING DATABASE TECHNOLOGY (EDBTâ€™04},
  Year                     = {2004},
  Pages                    = {605 -- 620},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The mining of periodic patterns in time series databases is an interesting data mining problem that can be envisioned as a tool for forecasting and predicting the future behavior of time series data. Existing periodic patterns mining algorithms either assume that the periodic rate (or simply the period) is user-specified, or try to detect potential values for the period in a separate phase. The former assumption is a considerable disadvantage, especially in time series databases where the period is not known a priori. The latter approach results in a multi-pass algorithm, which on the other hand is to be avoided in online environments (e.g., data streams). In this paper, we develop an algorithm that mines periodic patterns in time series databases with unknown or obscure periods such that discovering the period is part of the mining process. Based on},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Elfeky2004. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.5829}
}

@Conference{Elgamal2005,
  Title                    = {Large scale simulation and data analysis},
  Author                   = {Elgamal, A. and Yan, L. and Fraser, M. and Lu, J. and Conte, J.P.},
  Year                     = {2005},
  Note                     = {cited By (since 1996)1},
  Pages                    = {21-32},

  Abstract                 = {Information Technologies (IT) are increasingly allowing for advances in monitoring and analysis of structural response. Sensor networks can provide real-time data streams, as a basis for system identification and decision-making. Fusion of video-derived information along with motion and strain sensors is already showing much promise. An integrated analysis framework encompasses data acquisition, database archiving, and model-free/model-based system identification/data mining techniques, towards the development of practical decision-making tools. Within this framework, data from experiments continues to provide much needed physical insight, as a basis for calibration of appropriate numerical models. In this regard, large-scale parallel computing and powerful visualization tools of soil-structure systems are a necessity.},
  Affiliation              = {Department of Structural Engineering, University of California, San Diego, 9500 Gilman Dr., San Diego, CA 92093-0085, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2005 ASCE International Conference on Computing in Civil Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-27144496692&partnerID=40&md5=284a2b3d13447b3547844a788f696747}
}

@Conference{Engel2009,
  Title                    = {Mining for emerging technologies within text streams and documents},
  Author                   = {Engel, D. and Whitney, P. and Calapristi, G. and Brockman, F.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1291-1301},
  Volume                   = {3},

  Abstract                 = {Text streams, collections of documents or messages that axe generated and observed over time, axe ubiquitous. Our research and development is targeted at developing algorithms to find and characterize changes in topic within text streams. To date, this research has demonstrated the ability to detect and describe 1) short duration, atypical events and 2) the emergence of longer term shifts in topical content. This technology has been applied to pre-defined temporally ordered document collections but is also suitable for application to near real-time textual data streams. The underlying event and emergence detection algorithms have been interfaced to an event detection software user interface named SURPRISE. This software provides an interactive graphical user interface and tools for manipulating and correlating the terms and scores identified by the algorithms. Additionally, SURPRISE has been interfaced with the IN-SPIRE text analytics tool to enable an analyst to evaluate the surprising or emerging terms via a visualization of the entire document collection. IN-SPIRE assists in the exploration of related topics, events and views currently based on single term events. The focus of this research is to contribute to detecting, and preventing, strategic surprise.},
  Affiliation              = {Pacific Northwest National Laboratory, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Society for Industrial and Applied Mathematics - 9th SIAM International Conference on Data Mining 2009, Proceedings in Applied Mathematics},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {To date, this research has demonstrated the ability to detect and describe 1) short duration, atypical events and 2) the emergence of longer term shifts in topical content. Event detection software user interface named SURPRISE. Not clear if they have contributed SURPRISE or if they are merely describing it, approved on doubt. Approved 6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-73449093864&partnerID=40&md5=8709393e8279341dff357ccec6ef03b9}
}

@Article{Erhan2010,
  Title                    = {Why does unsupervised pre-training help deep learning?},
  Author                   = {Erhan, D. and Courville, A. and Bengio, Y. and Vincent, P.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},
  Note                     = {cited By (since 1996)10},
  Pages                    = {201-208},
  Volume                   = {9},

  Abstract                 = {Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants with impressive results being obtained in several areas, mostly on vision and language datasets. The best results obtained on supervised learning tasks often involve an unsupervised learning component, usually in an unsupervised pre-training phase. The main question investigated here is the following: why does unsupervised pre-training work so well? Through extensive experimentation, we explore several possible explanations discussed in the literature including its action as a regularizer (Erhan et al., 2009b) and as an aid to optimization (Bengio et al., 2007). Our results build on the work of Erhan et al. (2009b), showing that unsupervised pre-training appears to play predominantly a regularization role in subsequent supervised training. However our results in an online setting, with a virtually unlimited data stream, point to a somewhat more nuanced interpretation of the roles of optimization and regularization in the unsupervised pre-training effect. Copyright 2010 by the authors.},
  Affiliation              = {DIRO, UniversitÃƒÂ© de MontrÃƒÂ©al, 2920 chemin de la Tour, MontrÃƒÂ©al, QC H3T 1J8, Canada},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Deep architectures has been popular lately, best results with unsupervised pre-training. Why does it work so well? Through extensive experimentation, we explore several possible explanations discussed in the literature including its action as a regularizer. They test this in an online setting. Approved 2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80055055551&partnerID=40&md5=971001a9550252ed974cc39d05c41761}
}

@Misc{Erhan2010a,
  Title                    = {{Why does unsupervised pre-training help deep learning?}},

  Author                   = {Erhan, Dumitru and Courville, Aaron and Bengio, Yoshua and Vincent, Pascal},
  Year                     = {2010},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of autoencoder variants with impressive results being obtained in several areas, mostly on vision and language datasets. The best results obtained on supervised learning tasks often involve an unsupervised learning component, usually in an unsupervised pre-training phase. The main question investigated here is the following: why does unsupervised pre-training work so well? Through extensive experimentation, we explore several possible explanations discussed in the literature including its action as a regularizer (Erhan et al., 2009b) and as an aid to optimization (Bengio et al., 2007). Our results build on the work of Erhan et al. (2009b), showing that unsupervised pre-training appears to play predominantly a regularization role in subsequent supervised training. However our results in an online setting, with a virtually unlimited data stream, point to a somewhat more nuanced interpretation of the roles of optimization and regularization in the unsupervised pre-training effect.},
  Owner                    = {Alexander},
  Pages                    = {625 -- 660},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Erhan2010. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.207.1102}
}

@InProceedings{Ericson2012,
  Title                    = {{On the Performance of Virtualized Infrastructures for Processing Realtime Streaming Data}},
  Author                   = {Ericson, Kathleen and Pallickara, Shrideep},
  Booktitle                = {2012 IEEE Fifth International Conference on Utility and Cloud Computing},
  Year                     = {2012},
  Month                    = nov,
  Pages                    = {176--183},
  Publisher                = {IEEE},

  Abstract                 = {Clouds have become ubiquitous and several data processing tasks have migrated to these settings. The dominant approach in cloud settings is to provision virtual machines (VMs) rather than provision direct access to the physical machine. One artifact of such provisioning is that multiple VMs may be collocated on the same physical machine and possibly interfere with each other. In this paper, we focus on the impact of virtualized infrastructures on real time stream processing, we use the classification of electrocardiograms (ECG) as a motivating example. Stream processing in such a setting strains resources differently than the traditional web services or analytics on large datasets traditionally performed in the cloud. In streaming environments all processing per packet needs to be completed in a timely manner, and the number and rate at which these packets are generated is high. Our focus is to study the implications of various combinations of virtualization strategies on the performance of real time stream processing. We have done extensive performance benchmarks (using Xen and KVM) the results of which form the basis for our recommendations for the trade-offs involved in these settings.},
  Doi                      = {10.1109/UCC.2012.15},
  ISBN                     = {978-1-4673-4432-6},
  Keywords                 = {Cloud computing,Conferences,ECG,Granules,KVM,Medical services,Mercury (metals),Xen,classification,cloud computing,cloud settings,data handling,electrocardiograms,electrocardiography,health streams,realtime streaming data processing,stream processing,ubiquitous computing,ubiquitous setting,virtual machines,virtualization,virtualized infrastructures},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They analyse the impact of virtualization on processing tasks, and use the classification of electrocardiograms (ECG) as a motivating example.Our focus is to study the implications of various combinations of virtualization strategies on the performance of real time stream processing. Main contribution is not relevant, but their example might be. Approved 1,3,6},
  Shorttitle               = {Utility and Cloud Computing (UCC), 2012 IEEE Fifth},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6424943}
}

@InProceedings{Ezeife2007,
  Title                    = {{SSM : A Frequent Sequential Data Stream Patterns Miner}},
  Author                   = {Ezeife, C.I. and Monwar, Mostafa},
  Booktitle                = {2007 IEEE Symposium on Computational Intelligence and Data Mining},
  Year                     = {2007},
  Pages                    = {120--126},
  Publisher                = {IEEE},

  Abstract                 = {Data stream applications like sensor network data, click stream data, have data arriving continuously at high speed rates and require online mining process capable of delivering current and near accurate results on demand without full access to all historical stored data. Frequent sequential mining is the process of discovering frequent sequential patterns in data sequences as found in applications like Web log access sequences. Mining frequent sequential patterns on data stream applications contend with many challenges such as limited memory for unlimited data, inability of algorithms to scan infinitely flowing original dataset more than once and to deliver current and accurate result on demand. Existing work on mining frequent patterns on data streams are mostly for non-sequential patterns. This paper proposes SSM-algorithm (sequential stream mining-algorithm), that uses three types of data structures (D-List, PLWAP tree and FSP-tree) to handle the complexities of mining frequent sequential patterns in data streams. It summarizes frequency counts of items with the D-list, continuously builds PLWAP tree and mines frequent sequential patterns of batches of stream records, maintains mined frequent sequential patterns incrementally with FSP tree. The proposed algorithm can be deployed to analyze e-commerce data where the primary source of data is click stream data.},
  Doi                      = {10.1109/CIDM.2007.368862},
  ISBN                     = {1-4244-0705-2},
  Keywords                 = {Application software,Click Steam Data,Computational intelligence,Computer displays,Computer science,Content addressable storage,Customer Access Sequence,D-List data structures,Data mining,Data structures,FSP-tree data structures,Frequency,Frequent Sequential patterns,Intelligent sensors,PLWAP tree data structures,SSM-Algorithm,Stream Mining,TV,Web Sequential Mining,Web log access sequences,Web sequential mining,customer access sequence,data mining,data sequences,data stream applications,frequent sequential data stream pattern miner,frequent sequential pattern discovery,online mining,sequential stream mining-algorithm,tree data structures},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ezeife2007a. Discarded.},
  Shorttitle               = {Computational Intelligence and Data Mining, 2007. },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4221286}
}

@Conference{Ezeife2007a,
  Title                    = {SSM: A frequent sequential data stream patterns miner},
  Author                   = {Ezeife, C.I. and Monwar, M.},
  Year                     = {2007},
  Note                     = {cited By (since 1996)8},
  Pages                    = {120-126},

  Abstract                 = {Data stream applications like sensor network data, click stream data, have data arriving continuously at high speed rates and require online mining process capable of delivering current and near accurate results on demand without full access to all historical stored data. Frequent sequential mining is the process of discovering frequent sequential patterns in data sequences as found in applications like web log access sequences. Mining frequent sequential patterns on data stream applications contend with many challenges such as limited memory for unlimited data, inability of algorithms to scan infinitely flowing original dataset more than once and to deliver current and accurate result on demand. Existing work on mining frequent patterns on data streams are mostly for non-sequential patterns. This paper proposes SSM-Algorithm (Sequential Stream Mining-algorithm), that uses three types of data structures (D-List, PLWAP tree and FSP-tree) to handle the complexities of mining frequent sequential patterns in data streams. It summarizes frequency counts of items with the D-List, continuously builds PLWAP tree and mines frequent sequential patterns of batches of stream records, maintains mined frequent sequential patterns incrementally with FSP tree. The proposed algorithm can be deployed to analyze E-commerce data where the primary source of data is click stream data. Ã‚Â© 2007 IEEE.},
  Affiliation              = {School of Computer Science, University of Windsor},
  Art_number               = {4221286},
  Author_keywords          = {Click steam data; Customer access sequence; Frequent sequential patterns; Stream mining; Web sequential mining},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2007 IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2007},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Existing work on mining frequent patterns on data streams are mostly for non-sequential patterns. SSM: A frequent sequential data stream patterns miner. Uses three types of data structures to handle the complexities of mining frequent sequential patterns in data streams. The proposed algorithm can be deployed to analyze E-commerce data where the primary source of data is click stream data. Approved. 1,2,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34548767855&partnerID=40&md5=f5a19c39f2e99151288d6e29b62f361d}
}

@Conference{Farid2012a,
  Title                    = {Novel class detection in concept-drifting data stream mining employing decision tree},
  Author                   = {Farid, D.Md. and Rahman, C.M.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)4},
  Pages                    = {630-633},

  Abstract                 = {In this paper, we propose a new approach for detecting novel class in data stream mining using decision tree classifier that can determine whether an unseen or new instance belongs to a novel class. Most existing data mining classifiers can not detect and classify the novel class instances in real-time data stream mining problems like weather conditions, economical changes, astronomical, and intrusion detection etc, untill the classification models are trained with the labeled instances of the novel class. Arrival of a novel class in concept-drift occurs in data stream mining when new data introduce the new concept classes or remove the old ones. The proposed approach for incremental learning of concept drift considers mining, where the streaming data distributions change over time. It build a decision tree model from training dataset, which continuously updates so that the tree represents the most recent concept in data stream. The experiments on real benchmark data evaluate the efficiency of the proposed approach in both detecting the novel class and classification accuracy with comparisons of traditional data mining classifiers. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Department of Computer Science and Engineering, United International University, Dhaka-1209, Bangladesh},
  Art_number               = {6471629},
  Author_keywords          = {Conpect drift; data stream mining; decision tree; incremental learning; novel class},
  Document_type            = {Conference Paper},
  Journal                  = {2012 7th International Conference on Electrical and Computer Engineering, ICECE 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Most existing data mining classifiers can not detect and classify the novel class instances in real-time data stream mining problems untill the classification models are trained with the labeled instances of the novel class. The proposed approach for incremental learning of concept drift considers mining, where the streaming data distributions change over time. Online Decision Tree. The experiments on real benchmark data evaluate the efficiency of the proposed approach in both detecting the novel class and classification accuracy with comparisons of traditional data mining classifiers. Approved 1,2,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84875539980&partnerID=40&md5=dc81de5f01bb9f7f24b4f2e5f108b871}
}

@Article{Farid2013a,
  Title                    = {An adaptive ensemble classifier for mining concept drifting data streams},
  Author                   = {Farid, D.M.a and Zhang, L.a and Hossain, A.a and Rahman, C.M.b and Strachan, R.a and Sexton, G.a and Dahal, K.c },
  Journal                  = {Expert Systems with Applications},
  Year                     = {2013},
  Note                     = {cited By (since 1996)5},
  Number                   = {15},
  Pages                    = {5895-5906},
  Volume                   = {40},

  Abstract                 = {It is challenging to use traditional data mining techniques to deal with real-time data stream classifications. Existing mining classifiers need to be updated frequently to adapt to the changes in data streams. To address this issue, in this paper we propose an adaptive ensemble approach for classification and novel class detection in concept drifting data streams. The proposed approach uses traditional mining classifiers and updates the ensemble model automatically so that it represents the most recent concepts in data streams. For novel class detection we consider the idea that data points belonging to the same class should be closer to each other and should be far apart from the data points belonging to other classes. If a data point is well separated from the existing data clusters, it is identified as a novel class instance. We tested the performance of this proposed stream classification model against that of existing mining algorithms using real benchmark datasets from UCI (University of California, Irvine) machine learning repository. The experimental results prove that our approach shows great flexibility and robustness in novel class detection in concept drifting and outperforms traditional classification models in challenging real-life data stream applications. Ã‚Â© 2013 Elsevier Ltd. All rights reserved.},
  Affiliation              = {Computational Intelligence Group, Department of Computer Science and Digital Technology, Northumbria University, Newcastle upon Tyne, United Kingdom; Department of Computer Science and Engineering, United International University, Bangladesh; Artificial Intelligence Research Group, School of Computing, Informatics and Media, University of Bradford, United Kingdom},
  Author_keywords          = {Adaptive ensembles; Clustering; Concept drift; Data streams; Decision trees; Novel classes},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {this paper propose an adaptive ensemble approach for classification and novel class detection in concept drifting data streams. The proposed approach uses traditional mining classifiers and updates the ensemble model automatically so that it represents the most recent concepts in data streams They tested the performance against agains existing mining algorithms},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84878825414&partnerID=40&md5=5ccfc0caf7a3dcf7859cb6f9d45b7a66}
}

@InProceedings{Farid2012,
  Title                    = {{Novel class detection in concept-drifting data stream mining employing decision tree}},
  Author                   = {Farid, Dewan Md. and Rahman, Chowdhury Mofizur},
  Booktitle                = {2012 7th International Conference on Electrical and Computer Engineering},
  Year                     = {2012},
  Month                    = dec,
  Pages                    = {630--633},
  Publisher                = {IEEE},

  Abstract                 = {In this paper, we propose a new approach for detecting novel class in data stream mining using decision tree classifier that can determine whether an unseen or new instance belongs to a novel class. Most existing data mining classifiers can not detect and classify the novel class instances in real-time data stream mining problems like weather conditions, economical changes, astronomical, and intrusion detection etc, untill the classification models are trained with the labeled instances of the novel class. Arrival of a novel class in concept-drift occurs in data stream mining when new data introduce the new concept classes or remove the old ones. The proposed approach for incremental learning of concept drift considers mining, where the streaming data distributions change over time. It build a decision tree model from training dataset, which continuously updates so that the tree represents the most recent concept in data stream. The experiments on real benchmark data evaluate the efficiency of the proposed approach in both detecting the novel class and classification accuracy with comparisons of traditional data mining classifiers.},
  Doi                      = {10.1109/ICECE.2012.6471629},
  ISBN                     = {978-1-4673-1436-7},
  Keywords                 = {Biological system modeling,Conpect drift,Data mining,Data models,Decision trees,Intrusion detection,Real-time systems,Training,classification models,concept drifting data stream mining,data mining,data mining classifiers,data stream mining,decision tree,decision tree classifier,decision trees,incremental learning,learning (artificial intelligence),novel class,novel class labeled instances,real-time data stream mining,real-time systems,streaming data distributions},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Farid2012a. Discarded.},
  Shorttitle               = {Electrical \& Computer Engineering (ICECE), 2012 7t},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6471629}
}

@Article{Farzanyar2013,
  Title                    = {P2P-FISM: Mining (recently) frequent item sets from distributed data streams over \{P2P\} network },
  Author                   = {Zahra Farzanyar and Mohammadreza Kangavari and Nick Cercone},
  Journal                  = {Information Processing Letters },
  Year                     = {2013},
  Number                   = {19Ã¢â‚¬â€œ21},
  Pages                    = {793 - 798},
  Volume                   = {113},

  Abstract                 = {Abstract Data intensive large-scale distributed systems like peer-to-peer (P2P) networks are finding large number of applications for social networking, file sharing networks, etc. Global data mining in such \{P2P\} environments may be very costly due to the high scale and the asynchronous nature of the \{P2P\} networks. The cost further increases in the distributed data stream scenario where peers receive continuous sequence of transactions rapidly. In this paper, we develop an efficient local algorithm, P2P-FISM, for discovering of the network-wide recent frequent itemsets. The algorithm works in a completely asynchronous manner, imposes low communication overhead, a necessity for scalability, transparently tolerates network topology changes, and quickly adapts to changes in the data stream. The paper demonstrates experimental results to corroborate the theoretical claims.},
  Doi                      = {http://dx.doi.org/10.1016/j.ipl.2013.07.016},
  ISSN                     = {0020-0190},
  Keywords                 = {Data stream},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining in P2P networks. Distirbuted algorithm for finding network wide recent frequent itemsets. Async. Shows experimental results. Approved 1,3,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0020019013002056}
}

@InProceedings{FLL2008,
  Title                    = {{An Improved Algorithm of Decision Trees for Streaming Data Based on VFDT}},
  Author                   = {{Feixiong Li} and {Quan Liu}},
  Booktitle                = {2008 International Symposium on Information Science and Engineering},
  Year                     = {2008},
  Month                    = dec,
  Pages                    = {597--600},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Decision tree is a good model of Classification. Recently, there has been much interest in mining streaming data. Because streaming data is large and no limited, it is unpractical that passing the entire data over more than one time. A one pass online algorithm is necessary. One of the most successful algorithms for mining data streams is VFDT(Very Fast Decision Tree).we extend the VFDT system to EVFDT(Efficient-VFDT) in two directions: (1)We present Uneven Interval Numerical Pruning (shortly UINP) approach for efficiently processing numerical attributes. (2)We use naive Bayes classifiers associated with the node to process the samples to detect the outlying samples and reduce the scale of the trees. From the experimental comparison, the two techniques significantly improve the efficiency and the accuracy of decision tree construction on streaming data.},
  Doi                      = {10.1109/ISISE.2008.256},
  ISBN                     = {978-0-7695-3494-7},
  Keywords                 = {Bayes methods,Decision Trees,Naive Bayes Classifiers,Naive Bayes classifier,Streaming Data Mining,UINP approach,Unequal Interval Numerical Pruning(UINP),VFDT system,data mining,data stream mining,decision trees,one pass online algorithm,pattern classification,uneven interval numerical pruning,very fast decision tree},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Add ueven interval numerical pruning and outlier detection to improve Very Fast Decision Tree algorithm. From the experimental comparison, the two techniques significantly improve the efficiency and the accuracy of decision tree construction on streaming data. Approved 1,2,3,4,6},
  Shorttitle               = {Information Science and Engineering, 2008. ISISE '},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4732288}
}

@Article{Feng2005,
  Title                    = {Neural network learning algorithms for tracking minor subspace in high-dimensional data stream},
  Author                   = {Feng, D.-Z.a and Zheng, W.-X.b and Jia, Y.c },
  Journal                  = {IEEE Transactions on Neural Networks},
  Year                     = {2005},
  Note                     = {cited By (since 1996)18},
  Number                   = {3},
  Pages                    = {513-521},
  Volume                   = {16},

  Abstract                 = {A novel random-gradient-based algorithm is developed for online tracking the minor component (MC) associated with the smallest eigenvalue of the autocorrelation matrix of the input vector sequence. The five available learning algorithms for tracking one MC are extended to those for tracking multiple MCs or the minor subspace (MS). In order to overcome the dynamical divergence properties of some available random-gradient-based algorithms, we propose a modification of the Oja-type algorithms, called OJAm, which can work satisfactorily. The averaging differential equation and the energy function associated with the OJAm are given. It is shown that the averaging differential equation will globally asymptotically converge to an invariance set. The corresponding energy or Lyapunov functions exhibit a unique global minimum attained if and only if its state matrices span the MS of the autocorrelation matrix of a vector data stream. The other stationary points are saddle (unstable) points. The globally convergence of OJAm is also studied. The OJAm provides an efficient online learning for tracking the MS. It can track an orthonormal basis of the MS while the other five available algorithms cannot track any orthonormal basis of the MS. The performances of the relative algorithms are shown via computer simulations. Ã‚Â© 2005 IEEE.},
  Affiliation              = {National Laboratory for Radar Signal Processing, Xidian University, 710071 Xi'an, China; School of QMMS, University of Western Sydney, Penrith South DC, NSW 1797, Australia; Intel China Research Center, Beijing 100080, China},
  Author_keywords          = {Convergence; Eigenvalue decomposition (EVD); Energy function; Invariance set; Learning algorithm; Lyapunov function; Minor subspace (MS); Neural network; Stability; Stationary point},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {novel random-gradient-based algorithm is developed for online tracking the minor component (MC) associated with the smallest eigenvalue of the autocorrelation matrix. In order to overcome the dynamical divergence properties of some available random-gradient-based algorithms, we propose a modification of the Oja-type algorithms. It can track an orthonormal basis of the MS while the other five available algorithms cannot track any orthonormal basis of the MS. The performances of the relative algorithms are shown via computer simulations. Approved 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-19344367700&partnerID=40&md5=0257b560c45596e2c40244942c4ec3ab}
}

@InProceedings{Feng2009,
  Title                    = {{MFISW: A New Method for Mining Frequent Itemsets in Time and Transaction Sensitive Sliding Window}},
  Author                   = {Feng, Jiayin and Yan, Zhongwen and Kang, Yan and Wang, Jing and An, Lihong},
  Booktitle                = {2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery},
  Year                     = {2009},
  Pages                    = {270--274},
  Publisher                = {IEEE},
  Volume                   = {5},

  Abstract                 = {It is challenge to design an efficient summary data structure and an online approximation algorithms to limit the memory usage and the scan times in streaming data mining. In this paper, we present a CST(compressed suffix tree) structure to store arriving itemsets in the SC model. Then, our MFISW (mining frequent itemsets in sliding window) algorithm with the top-down traversal strategy can only scan data once to mine frequent itemsets in sliding window. Next, MFISW algorithm can update the mining result incrementally. Experiment shows that MFISW is efficient and scalable.},
  Doi                      = {10.1109/FSKD.2009.844},
  ISBN                     = {978-0-7695-3735-1},
  Keywords                 = {Algorithm design and analysis,Approximation algorithms,Computer science,Data Stream,Data mining,Data structures,Educational institutions,Fading,Frequent itemsets,Fuzzy systems,Itemsets,Windows,compressed suffix tree,data mining,mining frequent itemsets,online approximation algorithms,streaming data mining,summary data structure,time sensitive sliding window,transaction sensitive sliding window,tree data structures},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Feng2009a. Discarded.},
  Shorttitle               = {Fuzzy Systems and Knowledge Discovery, 2009. FSKD },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5360616}
}

@Conference{Feng2009a,
  Title                    = {MFISW: A new method for mining frequent itemsets in time and transaction sensitive sliding window},
  Author                   = {Feng, J. and Yan, Z. and Kang, Y. and Wang, J. and An, L.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {270-274},
  Volume                   = {5},

  Abstract                 = {It is challenge to design an efficient summary data structure and an online approximation algorithms to limit the memory usage and the scan times in streaming data mining. In this paper, we present a CST(compressed Suffix Tree) structure to store arriving itemsets in the SC model. Then, our MFISW (Mining Frequent Itemsets in Sliding Window) algorithm with the top-down traversal strategy can only scan data once to mine frequent itemsets in sliding window. Next, MFISW algorithm can update the mining result incrementally. Experiment shows that MFISW is efficient and scalable. Ã‚Â© 2009 IEEE.},
  Affiliation              = {Computer Science Department, Foreign Languages Department, College of HeBei Normal University of Science and Technology, Qin Huangdao, HeBei Province, China},
  Art_number               = {5360616},
  Author_keywords          = {Data mining; Data stream; Frequent itemsets},
  Document_type            = {Conference Paper},
  Journal                  = {6th International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining Frequent Itemsets in Sliding Window, to efficently limit memory usage and scan time for frequent itemsets. Experiment shows that MFISW is efficient and scalable. Approved. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-76549123957&partnerID=40&md5=3c9bf6b329baf13c4cdb4dee5b6463be}
}

@Misc{Ferrera€“troyano,
  Title                    = {{Incremental Rule Learning and Border Examples Selection from Numerical Data Streams}},

  Author                   = {Ferrerâ€“troyano, Francisco J. and Aguilarâ€“ruiz, Jes\'{u}s S. and Riquelme, Jos\'{e} C.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Mining data streams is a challenging task that requires online systems based on incremental learning approaches. This paper describes a classification system based on decision rules that may store up–to–date border examples to avoid unnecessary revisions when virtual drifts are present in data. Consistent rules classify new test examples by covering and inconsistent rules classify them by distance as the nearest neighbour algorithm. In addition, the system provides an implicit forgetting heuristic so that positive and negative examples are removed from a rule when they are not near one another.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper describes a classification system based on decision rules that may store up–to–date border examples to avoid unnecessary revisions when virtual drifts are present in data Discarded due to abstract not relating the system/software to any specific problem or algorithm. Seems to have nothing innovative. Weak abstract.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.95.7881}
}

@Article{Ferrer-Troyano2005,
  Title                    = {Incremental rule learning and border examples selection from numerical data streams},
  Author                   = {Ferrer-Troyano, F.J. and Aguilar-Ruiz, J.S. and Riquelme, J.C.},
  Journal                  = {Journal of Universal Computer Science},
  Year                     = {2005},
  Note                     = {cited By (since 1996)19},
  Number                   = {8},
  Pages                    = {1426-1439},
  Volume                   = {11},

  Abstract                 = {Mining data streams is a challenging task that requires online systems based on incremental learning approaches. This paper describes a classification system based on decision rules that may store up-to-date border examples to avoid unnecessary revisions when virtual drifts are present in data. Consistent rules classify new test examples by covering and inconsistent rules classify them by distance as the nearest neighbour algorithm. In addition, the system provides an implicit forgetting heuristic so that positive and negative examples are removed from a rule when they are not near one another. Ã‚Â© J.UCS.},
  Affiliation              = {Computer Science Dept., Univ. of Seville, 41012 Sevilla, Spain},
  Author_keywords          = {Classification; Concept drift; Data streams; Decision rules; Incremental learning},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being duplicate of 353.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-25444465382&partnerID=40&md5=dc77a2824fd7a9fe0b276719097afff1}
}

@Conference{Ferrer-Troyano2005a,
  Title                    = {Incremental rule learning based on example nearness from numerical data streams},
  Author                   = {Ferrer-Troyano, F. and Aguilar-Ruiz, J.S. and Riquelme, J.C.},
  Year                     = {2005},
  Note                     = {cited By (since 1996)10},
  Pages                    = {568-572},
  Volume                   = {1},

  Abstract                 = {Mining data streams is a challenging task that requires online systems based on incremental learning approaches. This paper describes a classification system based on decision rules that may store up-to-date border examples to avoid unnecessary revisions when virtual drifts are present in data. Consistent rules classify new test examples by covering and inconsistent rules classify them by distance as the nearest neighbor algorithm. In addition, the system provides an implicit forgetting heuristic so that positive and negative examples are removed from a rule when they are not near one another. Copyright 2005 ACM.},
  Affiliation              = {Dept. of Computer Science, Av. Reina Mercedes S/N, 41012, Seville, Spain},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM Symposium on Applied Computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ferrerâ€“troyano. DIscarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33644551188&partnerID=40&md5=8adc7d2de405fbf454e60742045cb88e}
}

@InProceedings{Ferrer-Troyano2006,
  Title                    = {{Data streams classification by incremental rule learning with parameterized generalization}},
  Author                   = {Ferrer-Troyano, Francisco and Aguilar-Ruiz, Jesus S. and Riquelme, Jose C.},
  Booktitle                = {Proceedings of the 2006 ACM symposium on Applied computing - SAC '06},
  Year                     = {2006},

  Address                  = {New York, New York, USA},
  Month                    = apr,
  Pages                    = {657},
  Publisher                = {ACM Press},

  Abstract                 = {Mining data streams is a challenging task that requires online systems based on incremental learning approaches. This paper describes a classification system based on decision rules that may store up--to--date border examples to avoid unnecessary revisions when virtual drifts are present in data. Consistent rules classify new test examples by covering and inconsistent rules classify them by distance as the nearest neighbor algorithm. In addition, the system provides an implicit forgetting heuristic so that positive and negative examples are removed from a rule when they are not near one another.},
  Doi                      = {10.1145/1141277.1141428},
  ISBN                     = {1595931082},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ferrerâ€“troyano. DIscarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1141277.1141428}
}

@InProceedings{Ferrer-Troyano2005b,
  Title                    = {{Incremental rule learning based on example nearness from numerical data streams}},
  Author                   = {Ferrer-Troyano, Francisco and Aguilar-Ruiz, Jesus S. and Riquelme, Jose C.},
  Booktitle                = {Proceedings of the 2005 ACM symposium on Applied computing - SAC '05},
  Year                     = {2005},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {568},
  Publisher                = {ACM Press},

  Abstract                 = {Mining data streams is a challenging task that requires online systems based on incremental learning approaches. This paper describes a classification system based on decision rules that may store up-to-date border examples to avoid unnecessary revisions when virtual drifts are present in data. Consistent rules classify new test examples by covering and inconsistent rules classify them by distance as the nearest neighbor algorithm. In addition, the system provides an implicit forgetting heuristic so that positive and negative examples are removed from a rule when they are not near one another.},
  Doi                      = {10.1145/1066677.1066808},
  ISBN                     = {1581139640},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ferrerâ€“troyano. DIscarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1066677.1066808}
}

@Article{Finlay2014a,
  Title                    = {Data stream mining for predicting software build outcomes using source code metrics},
  Author                   = {Finlay, J. and Pears, R. and Connor, A.M.},
  Journal                  = {Information and Software Technology},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {2},
  Pages                    = {183-198},
  Volume                   = {56},

  Abstract                 = {Context Software development projects involve the use of a wide range of tools to produce a software artifact. Software repositories such as source control systems have become a focus for emergent research because they are a source of rich information regarding software development projects. The mining of such repositories is becoming increasingly common with a view to gaining a deeper understanding of the development process. Objective This paper explores the concepts of representing a software development project as a process that results in the creation of a data stream. It also describes the extraction of metrics from the Jazz repository and the application of data stream mining techniques to identify useful metrics for predicting build success or failure. Method This research is a systematic study using the Hoeffding Tree classification method used in conjunction with the Adaptive Sliding Window (ADWIN) method for detecting concept drift by applying the Massive Online Analysis (MOA) tool. Results The results indicate that only a relatively small number of the available measures considered have any significance for predicting the outcome of a build over time. These significant measures are identified and the implication of the results discussed, particularly the relative difficulty of being able to predict failed builds. The Hoeffding Tree approach is shown to produce a more stable and robust model than traditional data mining approaches. Conclusion Overall prediction accuracies of 75% have been achieved through the use of the Hoeffding Tree classification method. Despite this high overall accuracy, there is greater difficulty in predicting failure than success. The emergence of a stable classification tree is limited by the lack of data but overall the approach shows promise in terms of informing software development activities in order to minimize the chance of failure. Ã‚Â© 2013 Elsevier B.V. All rights reserved.},
  Affiliation              = {Auckland University of Technology, Auckland, New Zealand},
  Author_keywords          = {Concept drift detection; Data stream mining; Hoeffding tree; Jazz; Software metrics; Software repositories},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper explores the concepts of representing a software development project as a process that results in the creation of a data stream. They try to use data stream mining techniques to identify useful metrics for predicting build success or failure. Conclusion Overall prediction accuracies of 75% have been achieved through the use of the Hoeffding Tree classification method. Despite this high overall accuracy, there is greater difficulty in predicting failure than success. Approved 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84889885864&partnerID=40&md5=087be4408f7ed304cb3566298dd7539f}
}

@Conference{Fischer2012,
  Title                    = {Real-time visual analytics for event data streams},
  Author                   = {Fischer, F. and Mansmann, F. and Keim, D.A.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)3},
  Pages                    = {801-806},

  Abstract                 = {Real-time analysis of data streams has become an important factor for success in many domains such as server and system administration, news analysis and finance to name just a few. Introducing real-time visual analytics into such application areas promises a lot of benefits since the rate of new incoming information often exceeds human perceptual limits when displayed linearly in raw formats such as textual lines and automatic aggregation often hides important details. This paper presents a system to tackle some of the visualization challenges when analyzing such dynamic event data streams. In particular, we introduce the Event Visualizer, which is a loosely coupled modular system for collecting, processing, analyzing and visualizing dynamic real-time event data streams. Due to the variety of different analysis tasks the system provides an extensible framework with several interactive linked visualizations to focus on different aspects of the event data stream. Data streams with logging data from a computer network are used as a case study to demonstrate the advantages of visual exploration. Ã‚Â© 2012 ACM.},
  Affiliation              = {University of Konstanz, Germany},
  Author_keywords          = {data streams; event processing; event streams; real-time; visual analytics; visualization},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM Symposium on Applied Computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper presents a system to tackle some of the visualization challenges when analyzing such dynamic event data streams. . Data streams with logging data from a computer network are used as a case study to demonstrate the advantages of visual exploration. No indication of ML. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861046531&partnerID=40&md5=c7d8f836d66fdfb4f54d47610b8847ff}
}

@InProceedings{Fischer2012a,
  Title                    = {{Real-time visual analytics for event data streams}},
  Author                   = {Fischer, Fabian and Mansmann, Florian and Keim, Daniel A.},
  Booktitle                = {Proceedings of the 27th Annual ACM Symposium on Applied Computing - SAC '12},
  Year                     = {2012},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {801},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/2245276.2245432},
  ISBN                     = {9781450308571},
  Keywords                 = {data streams,event processing,event streams,real-time,visual analytics,visualization},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Fischer2012. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2245276.2245432}
}

@InProceedings{Folino2007,
  Title                    = {{An Adaptive Distributed Ensemble Approach to Mine Concept-Drifting Data Streams}},
  Author                   = {Folino, Gianluigi and Pizzuti, Clara and Spezzano, Giandomenico},
  Booktitle                = {19th IEEE International Conference on Tools with Artificial Intelligence(ICTAI 2007)},
  Year                     = {2007},
  Month                    = oct,
  Pages                    = {183--188},
  Publisher                = {IEEE},
  Volume                   = {2},

  Abstract                 = {An adaptive boosting ensemble algorithm for classifying homogeneous distributed data streams is presented. The method builds an ensemble of classifiers by using Genetic Programming (GP) to inductively generate decision trees, each trained on different parts of the distributed training set. The approach adopts a co-evolutionary platform to support a cooperative model of GP. A change detection strategy, based on self-similarity of the ensemble behavior, and measured by its fractal dimension, permits to capture time- evolving trends and patterns in the stream, and to reveal changes in evolving data streams. The approach tracks online ensemble accuracy deviation over time and decides to recompute the ensemble if the deviation has exceeded a pre- specified threshold. This allows the maintenance of an accurate and up-to-date ensemble of classifiers for continuous flows of data with concept drifts. Experimental results on a real life data set show the validity of the approach.},
  Doi                      = {10.1109/ICTAI.2007.51},
  ISBN                     = {0-7695-3015-X},
  ISSN                     = {1082-3409},
  Keywords                 = {Boosting,Computer networks,Concurrent computing,Data mining,Decision trees,Fractals,Genetic programming,Large-scale systems,Peer to peer computing,Telephony,adaptive boosting ensemble algorithm,adaptive distributed ensemble approach,concept-drifting data streams,data mining,decision trees,distributed training set,genetic algorithms,genetic programming,homogeneous distributed data streams,pattern classification},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {An adaptive boosting ensemble algorithm for classifying homogeneous distributed data streams is presented. Uses genetic programming. The approach tracks online ensemble accuracy deviation over time and decides to recompute the ensemble if the deviation has exceeded a pre- specified threshold. Experimental results on a real life data set show the validity of the approach. Approved 1,3,4,6},
  Shorttitle               = {Tools with Artificial Intelligence, 2007. ICTAI 20},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4410377}
}

@Conference{Fong2013a,
  Title                    = {Incremental learning algorithms for fast classification in data stream},
  Author                   = {Fong, S.a and Luo, Z.a and Yap, B.W.b },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {186-190},

  Abstract                 = {Classification is one of the most commonly used data mining methods which can make a prediction by modeling from the known data. However, in traditional classification, we need to acquire the whole dataset and then build a training model which may take a lot of time and resource consumption. Another drawback of the traditional classification is that it cannot process the dataset timely and efficiently, especially for real-time data stream or big data. In this paper, we evaluate a lightweight method based on incremental learning algorithms for fast classification. We use this method to do outlier detection via several popular incremental learning algorithms, like Decision Table, NaÃƒÂ¯ve Bayes, J48, VFI, KStar, etc. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Department of Computer and Information Science, University of Macau, Macau; Faculty Computer and Mathematical Sciences, Universiti Teknologi MARA, 40450 Shah Alam, Selangor, Malaysia},
  Art_number               = {6724350},
  Author_keywords          = {Classification; Data Mining; Incremental Learning; Lightweight Processing; Oulier Dectction},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2013 International Symposium on Computational and Business Intelligence, ISCBI 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Fong2013. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84894439689&partnerID=40&md5=929d5738ea0563d877942a53ea95dce4}
}

@InProceedings{Fong2013,
  Title                    = {{Incremental Learning Algorithms for Fast Classification in Data Stream}},
  Author                   = {Fong, Simon and Luo, Zhicong and Yap, Bee Wah},
  Booktitle                = {2013 International Symposium on Computational and Business Intelligence},
  Year                     = {2013},
  Month                    = aug,
  Pages                    = {186--190},
  Publisher                = {IEEE},

  Abstract                 = {Classification is one of the most commonly used data mining methods which can make a prediction by modeling from the known data. However, in traditional classification, we need to acquire the whole dataset and then build a training model which may take a lot of time and resource consumption. Another drawback of the traditional classification is that it cannot process the dataset timely and efficiently, especially for real-time data stream or big data. In this paper, we evaluate a lightweight method based on incremental learning algorithms for fast classification. We use this method to do outlier detection via several popular incremental learning algorithms, like Decision Table, NaiÃŒË†ve Bayes, J48, VFI, KStar, etc.},
  Doi                      = {10.1109/ISCBI.2013.45},
  ISBN                     = {978-0-7695-5066-4},
  Keywords                 = {Accuracy,Big Data,Classification,Classification algorithms,Computational modeling,Data Mining,Data mining,Data models,Incremental Learning,J48,KStar,Lightweight Processing,Oulier Dectction,Real-time systems,Training,VFI,big data,data mining,data mining method,data stream,decision table,fast classification,incremental learning algorithm,learning (artificial intelligence),naiÃŒË†ve Bayes,outlier detection,pattern classification,training model},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Relevance                = {relevant},
  Review                   = {However, in traditional classification, we need to acquire the whole dataset and then build a training model which may take a lot of time and resource consumption. In this paper, we evaluate a lightweight method based on incremental learning algorithms for fast classification. We use this method to do outlier detection via several popular incremental learning algorithms, like Decision Table, Naïve Bayes, J48, VFI, KStar, etc. A bit unclear what their novelty is, but possibly interesting Approved 2,6},
  Shorttitle               = {Computational and Business Intelligence (ISCBI), 2},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6724350}
}

@Article{Fong2011,
  Title                    = {The six technical gaps between intelligent applications and real-time data mining: A critical review},
  Author                   = {Fong, S. and Yang, H.},
  Journal                  = {Journal of Emerging Technologies in Web Intelligence},
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Number                   = {2},
  Pages                    = {63-73},
  Volume                   = {3},

  Abstract                 = {Intelligent application is characterized by its ability to make decision autonomously. Some examples are distributed agents that collaboratively complete a complex task, yet each one of them is able to work and reason independently given the dynamic situation where they are in. The underlying think tank is often a collection of core mechanisms that include environment sensing, data capturing, data mining, ETL, knowledge processing, and decision making etc. All these techniques when placed and function together as a whole intelligent system, they will have to fulfill stringent deadlines imposed by the requirements of a real-time system. In the literature many research papers can be found on a wide variety of data mining techniques that enable intelligent applications operating in real-time. This report offers a critical review of the relevant literature, and contributes to the knowledge of identifying their shortcomings, so-called the technical gaps between the real-time requirements of a general intelligent system and the supporting components. A discussion follows on the possibilities of future intelligent applications that are empowered by data stream mining. Ã‚Â© 2011 ACADEMY PUBLISHER.},
  Affiliation              = {Faculty of Science and Technology, University of Macau, Macau},
  Author_keywords          = {Data stream mining; Intelligent applications; Real-time data mining},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {In the literature many research papers can be found on a wide variety of data mining techniques that enable intelligent applications operating in real-time. This report offers a critical review of the relevant literature, and contributes to the knowledge of identifying their shortcomings. A discussion follows on the possibilities of future intelligent applications that are empowered by data stream mining. Survey paper. Discarded, but put aside.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84863371839&partnerID=40&md5=310d12fe32019156a535ba5d90bf7b56}
}

@Article{Fong2013b,
  Title                    = {Evaluation of stream mining classifiers for real-time clinical decision support system: A case study of blood glucose prediction in diabetes therapy},
  Author                   = {Fong, S.a and Zhang, Y.a and Fiaidhi, J.b and Mohammed, O.b and Mohammed, S.b },
  Journal                  = {BioMed Research International},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Volume                   = {2013},

  Abstract                 = {Earlier on, a conceptual design on the real-time clinical decision support system (rt-CDSS) with data stream mining was proposed and published. The new system is introduced that can analyze medical data streams and can make real-time prediction. This system is based on a stream mining algorithm called VFDT. The VFDT is extended with the capability of using pointers to allow the decision tree to remember the mapping relationship between leaf nodes and the history records. In this paper, which is a sequel to the rt-CDSS design, several popular machine learning algorithms are investigated for their suitability to be a candidate in the implementation of classifier at the rt-CDSS. A classifier essentially needs to accurately map the events inputted to the system into one of the several predefined classes of assessments, such that the rt-CDSS can follow up with the prescribed remedies being recommended to the clinicians. For a real-time system like rt-CDSS, the major technological challenges lie in the capability of the classifier to process, analyze and classify the dynamic input data, quickly and upmost reliably. An experimental comparison is conducted. This paper contributes to the insight of choosing and embedding a stream mining classifier into rt-CDSS with a case study of diabetes therapy. Ã‚Â© 2013 Simon Fong et al.},
  Affiliation              = {Department of Computer and Information Science, University of Macau, Macau; Department of Computer Science, Lakehead University, Thunder Bay, ON P7B 5E1, Canada},
  Art_number               = {274193},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The new system is introduced that can analyze medical data streams and can make real-time prediction, based on a stream mining algorithm called VFDT. An experimental comparison is conducted. Diabetes case study. Approved 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84885610048&partnerID=40&md5=65f7fd20b952ff5ea32afd7546c5b561}
}

@Article{Foo2010,
  Title                    = {{A distributed approach for optimizing cascaded classifier topologies in real-time stream mining systems.}},
  Author                   = {Foo, Brian and van der Schaar, Mihaela},
  Journal                  = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
  Year                     = {2010},

  Month                    = nov,
  Number                   = {11},
  Pages                    = {3035--48},
  Volume                   = {19},

  Abstract                 = {In this paper, we discuss distributed optimization techniques for configuring classifiers in a real-time, informationally-distributed stream mining system. Due to the large volume of streaming data, stream mining systems must often cope with overload, which can lead to poor performance and intolerable processing delay for real-time applications. Furthermore, optimizing over an entire system of classifiers is a difficult task since changing the filtering process at one classifier can impact both the feature values of data arriving at classifiers further downstream and thus, the classification performance achieved by an ensemble of classifiers, as well as the end-to-end processing delay. To address this problem, this paper makes three main contributions: 1) Based on classification and queuing theoretic models, we propose a utility metric that captures both the performance and the delay of a binary filtering classifier system. 2) We introduce a low-complexity framework for estimating the system utility by observing, estimating, and/or exchanging parameters between the inter-related classifiers deployed across the system. 3) We provide distributed algorithms to reconfigure the system, and analyze the algorithms based on their convergence properties, optimality, information exchange overhead, and rate of adaptation to non-stationary data sources. We provide results using different video classifier systems.},
  Doi                      = {10.1109/TIP.2010.2051866},
  ISSN                     = {1941-0042},
  Keywords                 = {Multiagent systems,binary filtering classifier system,cascaded classifier topologies,classification model,data mining,distributed algorithms,distributed optimization techniques,end-to-end processing delay,image classification,multimedia communication,multimedia stream classification,optimisation,queueing theory,queuing theoretic model,queuing theory,real-time informationally-distributed stream minin,systems,video classifier systems,video signal processing},
  Owner                    = {Alexander},
  Pmid                     = {20519152},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Optimization of stream mining, resource dependent. Propose a utility metric that captures both the performance and the delay of a binary filtering classifier system. 2) We introduce a low-complexity framework for estimating the system utility by observing, estimating, and/or exchanging parameters between the inter-related classifiers deployed across the system. 3) We provide distributed algorithms to reconfigure the system, and analyze the algorithms based on their convergence properties, optimality, information exchange overhead, and rate of adaptation to non-stationary data sources. We provide results using different video classifier systems. Approved. 1,6},
  Shorttitle               = {Image Processing, IEEE Transactions on},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/20519152}
}

@InProceedings{Fortino2012,
  Title                    = {{BodyCloud: Integration of Cloud Computing and body sensor networks}},
  Author                   = {Fortino, Giancarlo and Pathan, Mukaddim and {Di Fatta}, Giuseppe},
  Booktitle                = {4th IEEE International Conference on Cloud Computing Technology and Science Proceedings},
  Year                     = {2012},
  Month                    = dec,
  Pages                    = {851--856},
  Publisher                = {IEEE},

  Abstract                 = {Spatially distributed sensor nodes can be used to monitor systems and humans conditions in a wide range of application domains. A network of body sensors in a community of people generates large amounts of contextual data that requires a scalable approach for storage and processing. Cloud computing can provide a powerful, scalable storage and processing infrastructure to perform both online and offline analysis and mining of body sensor data streams. This paper presents BodyCloud, a system architecture based on Cloud Computing for the management and monitoring of body sensor data streams. It incorporates key concepts such as scalability and flexibility of resources, sensor heterogeneity, and the dynamic deployment and management of user and community applications.},
  Doi                      = {10.1109/CloudCom.2012.6427537},
  ISBN                     = {978-1-4673-4510-1},
  Keywords                 = {Biomedical monitoring,Body Sensors,BodyCloud,Cloud Computing,Cloud computing,Computer architecture,Data Mining,Medical services,Monitoring,Real-time systems,Wireless sensor networks,body sensor data stream management,body sensor data stream mining,body sensor data stream monitoring,body sensor networks,cloud computing,community applications,contextual data,data mining,health care,healthcare scenario,offline analysis,online analysis,patient monitoring,processing infrastructure,resource flexibility,resource scalability,sensor heterogeneity,spatially distributed sensor nodes,storage infrastructure,user dynamic deployment,user management},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {BodyCloud, a system architecture based on Cloud Computing for the management and monitoring of body sensor data streams. It incorporates key concepts such as scalability and flexibility of resources, sensor heterogeneity, and the dynamic deployment and management of user and community applications. Approved 1},
  Shorttitle               = {Cloud Computing Technology and Science (CloudCom),},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6427537}
}

@Conference{Fortino2012a,
  Title                    = {BodyCloud: Integration of Cloud Computing and body sensor networks},
  Author                   = {Fortino, G.a and Pathan, M.b and Di Fatta, G.c },
  Year                     = {2012},
  Note                     = {cited By (since 1996)11},
  Pages                    = {851-856},

  Abstract                 = {Spatially distributed sensor nodes can be used to monitor systems and humans conditions in a wide range of application domains. A network of body sensors in a community of people generates large amounts of contextual data that requires a scalable approach for storage and processing. Cloud computing can provide a powerful, scalable storage and processing infrastructure to perform both online and offline analysis and mining of body sensor data streams. This paper presents BodyCloud, a system architecture based on Cloud Computing for the management and monitoring of body sensor data streams. It incorporates key concepts such as scalability and flexibility of resources, sensor heterogeneity, and the dynamic deployment and management of user and community applications. Ã‚Â© 2012 IEEE.},
  Affiliation              = {DEIS-University of Calabria, 87036 Rende (CS), Italy; Telstra Corporation Limited, Melbourne, VIC 3000, Australia; SSE-The University of Reading, Reading RG6 6AX, United Kingdom},
  Art_number               = {6427537},
  Author_keywords          = {Body Sensors; Cloud Computing; Data Mining},
  Document_type            = {Conference Paper},
  Journal                  = {CloudCom 2012 - Proceedings: 2012 4th IEEE International Conference on Cloud Computing Technology and Science},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Fortino2012. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84874226703&partnerID=40&md5=68fe7ad79d6b5bf16688724865744756}
}

@InProceedings{Franklin2010,
  Title                    = {{Continuous analytics}},
  Author                   = {Franklin, Michael J.},
  Booktitle                = {Proceedings of the Fourth ACM International Conference on Distributed Event-Based Systems - DEBS '10},
  Year                     = {2010},

  Address                  = {New York, New York, USA},
  Month                    = jul,
  Pages                    = {1},
  Publisher                = {ACM Press},

  Abstract                 = {Stream query processing has been one of the more popular topics in database research so far this century. The basic idea is to provide database-style query processing over data on-the-fly as they arrive at the system,. Compared to the store-first, query-later approach followed by traditional database systems, stream query processing holds the promise for dramatically improved efficiency and reduced latency. Work in this area was originally motivated by "real-time" data-intensive scenarios such as sensor networks, financial trading applications, and network security. Lately, stream processing has been moving from the research lab into the real world through efforts at start-up companies, traditional database vendors, and open source projects. Not surprisingly, the practical uses and advantages of the technology are turning out to be different than many had originally expected. In this talk, I'll survey the state of the art in stream query processing and related technologies such as event processing, discuss some of the implications for data-intensive system architectures, and provide my views on the future role of this technology from both a research and a commercial perspective. In particular, I'll describe the notion of Continuous Analytics, which leverages Stream Query Processing techniques to solve some of the inherent bottlenecks that have existed in database systems since their inception. I will also discuss several implementation issues that arose through experience with specific application deployments including the need to handle out-of-order data and high-cardinality dimensions.},
  Doi                      = {10.1145/1827418.1827420},
  ISBN                     = {9781605589275},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {Just overview of a keynote talk. Survey the state of the art in stream query processing and related technologies such as event processing Discarded, put aside for later discussion.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1827418.1827420}
}

@Article{Frias-Blanco2014,
  Title                    = {{Online and Non-parametric Drift Detection Methods Based on HoeffdingÃ¢â‚¬â„¢s Bounds}},
  Author                   = {Frias-Blanco, Isvani and del Campo-Avila, Jose and Ramos-Jimenez, Gonzalo and Morales-Bueno, Rafael and Ortiz-Diaz, Agustin and Caballero-Mota, Yaile},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2014},
  Number                   = {99},
  Pages                    = {1--1},
  Volume                   = {PP},

  Abstract                 = {Incremental and online learning algorithms are more relevant in the data mining context because of the increasing necessity to process data streams. In this context, the target function may change over time, an inherent problem of online learning (known as concept drift). In order to handle concept drift regardless of the learning model, we propose new methods to monitor the performance metrics measured during the learning process, to trigger drift signals when a significant variation has been detected. To monitor this performance, we apply some probability inequalities that assume only independent, univariate and bounded random variables to obtain theoretical guarantees for the detection of such distributional changes. Some common restrictions for the online change detection as well as relevant types of change (abrupt and gradual) are considered. Two main approaches are proposed, the first one involves moving averages and is more suitable to detect abrupt changes. The second one follows a widespread intuitive idea to deal with gradual changes using weighted moving averages. The simplicity of the proposed methods, together with the computational efficiency make them very advantageous. We use a Na\"{\i}ve Bayes classifier and a Perceptron to evaluate the performance of the methods over synthetic and real data.},
  Doi                      = {10.1109/TKDE.2014.2345382},
  ISSN                     = {1041-4347},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {we propose new methods to monitor the performance metrics measured during the learning process to handle concept drift. Trigger drift signals when a significant variation has been detected. We use a Naïve Bayes classifier and a Perceptron to evaluate the performance of the methods over synthetic and real data. Approved 1,3,6},
  Shorttitle               = {Knowledge and Data Engineering, IEEE Transactions },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6871418}
}

@Article{Gaber2012,
  Title                    = {Advances in data stream mining},
  Author                   = {Gaber, M.M.},
  Journal                  = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  Year                     = {2012},
  Note                     = {cited By (since 1996)16},
  Number                   = {1},
  Pages                    = {79-85},
  Volume                   = {2},

  Abstract                 = {Mining data streams has been a focal point of research interest over the past decade. Hardware and software advances have contributed to the significance of this area of research by introducing faster than ever data generation. This rapidly generated data has been termed as data streams. Credit card transactions, Google searches, phone calls in a city, and many others\are typical data streams. In many important applications, it is inevitable to analyze this streaming data in real time. Traditional data mining techniques have fallen short in addressing the needs of data stream mining. Randomization, approximation, and adaptation have been used extensively in developing new techniques or adopting exiting ones to enable them to operate in a streaming environment. This paper reviews key milestones and state of the art in the data stream mining area. Future insights are also be presented. Ã‚Â© 2011 Wiley Periodicals, Inc.},
  Affiliation              = {School of Computing, University of Portsmouth, Portsmouth, Hampshire, United Kingdom},
  Document_type            = {Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {This paper reviews key milestones and state of the art in the data stream mining area. Future insights are also be presented. Potentially VERY interesting and closely related survey. Discarded, but put aside.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867621965&partnerID=40&md5=26dea30b5703c1fe7beb8e84f9289104}
}

@Book{Gaber2007,
  Title                    = {Data stream processing in sensor networks},
  Author                   = {Gaber, M.M.},
  Year                     = {2007},
  Note                     = {cited By (since 1996)7},

  Abstract                 = {A sensor network consists of small computational devices that are able to communicate over wireless connection channels [44,40]. Each of these computational devices is equipped with sensing, processing and communication facilities. The sensing facility can sense physical values about the environment such as temperature, humidity and light. The processing part is able to do computation on the sensed values and/or other received values from the neighbors. The communication part is able to listen and send to other sensor nodes. The adoption of the sensor network technology will revolutionize our daily activities. Sensor networks will form a new world wide web that can read the physical world in real time [15]. Applications of sensor networks range from personal applications to scientific, industrial and business uses [11]. These applications will impact decision making at all levels, personally and professionally. Examples of these applications include habitat monitoring [31,39], animal control on a farm [10,38], traffic monitoring [19], underwater monitoring [41], fire detection [6], and smart homes [33]. Sensor networks generate data streams that need to be processed in real time for a wide range of applications. Therefore, there are two main aspects to this technology. The first is the scientific and technological aspect of sensor networks, which are discussed in Chap. 2. The other aspect is processing the resulting data streams, which is discussed in Chap. 3. This chapter is devoted to introducing data stream processing in sensor networks. The distinction between traditional data stream processing and sensory data stream processing is important because sensory data streams have their own features. Elnahrawy [14] distinguished sensor streaming from traditional streaming in the following way: Ã¢â‚¬Â¢ The sensor data are a sample of the entire population. On the other hand, traditional streaming data such as web logs and stock market data streams represent the entire population of the data. Basically the sensor data depends on the sampling rate. Some applications require higher rate than the others. For example, a sensor network that measures the temperature for meteorological purposes could sample the data every five minutes. However, if we deploy the same sensor network for physical experimentation in a scientific laboratory, the sampling rate could be several times per second. Thus, the sampling rate is an applicationdependent factor. The main theme in sensor networks is to convert continuous sensor readings to discrete ones. Ã¢â‚¬Â¢ The sensor data streams are considered noisy by comparison with other traditional streaming data. The state-of-the-art sensing equipment onboard sensor nodes requires data verification and validation. The environmental effect on the deployed sensor networks can also play a negative role on the sensed values. For example, web logs and web click streams are considered accurate values compared with data generated from sensor networks. Data quality assurance and cleaning are important to ensure the reliability of sensor networks. Ã¢â‚¬Â¢ The sizes of sensor data streams are usually less than traditional streaming data. This is valid for the current experimental deployment of wireless sensor networks. This will change in the near future with the expected large deployment of sensor networks to serve different applications. These features combined with new research challenges have introduced a new field of study, data stream processing in sensor networks. This field is concerned with handling and processing sensed data streams in wireless sensor networks. We can broadly classify the processing tasks in this area into data management and data analysis/mining. This chapter is organized as follows. Section 4.2 provides details about each class of data processing in sensor networks (data management and data mining). Section 4.3 highlights the research issues in data processing. Finally the chapter is summarized in Sect. 4.4. Ã‚Â© 2007 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {Tasmanian ICT Centre, CSIRO ICT Centre, GPO Box 1538, Hobart, TAS 7001, Australia},
  Document_type            = {Book Chapter},
  Journal                  = {Learning from Data Streams: Processing Techniques in Sensor Networks},
  Owner                    = {Alexander},
  Pages                    = {41-48},
  Qualityassured           = {qualityAssured},
  Review                   = {Abstract for a book chapter. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84886240196&partnerID=40&md5=0ff0aa6d7982fb70cd30a290232ae51f}
}

@Conference{Gaber2010b,
  Title                    = {Adaptive clutter-aware visualization for mobile data stream mining},
  Author                   = {Gaber, M.M.a and Krishnaswamy, S.b and Gillick, B.b and Nicoloudis, N.b and Liono, J.b and AlTaiar, H.b and Zaslavsky, A.c },
  Year                     = {2010},
  Note                     = {cited By (since 1996)2},
  Pages                    = {304-311},
  Volume                   = {2},

  Abstract                 = {There is an emerging focus on real-time data stream analysis on mobile devices. A wide range of data stream processing applications are targeted to run on mobile handheld devices with limited computational capabilities such as patient monitoring, driver monitoring, providing real-time analysis and visualization for emergency and disaster management, real-time optimization for courier pick-up and delivery etc. There are many challenges in visualization of the analysis/data stream mining results on a mobile device. These include coping with the small screen real-estate and effective presentation of highly dynamic and real-time analysis. This paper proposes a generic theory for visualization on small screens that we term Adaptive Clutter Reduction ACR. Based on ACR, we have developed and experimentally validated a novel data stream clustering result visualization technique that we term Clutter-Aware Clustering Visualizer (CACV). Experimental results on both synthetic and real datasets using the Google Andriod platform are presented proving the effectiveness of the proposed techniques. Ã‚Â© 2010 IEEE.},
  Affiliation              = {School of Computing, University of Portsmouth, United Kingdom; Centre for Distributed Systems and Software Engineering, Monash University, VIC, Australia; Lulea University of Technology, Lulea, Sweden},
  Art_number               = {5670093},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gaber2010. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78751493043&partnerID=40&md5=92394b082ee28cdadde10f98df826fd3}
}

@Conference{Gaber2010a,
  Title                    = {Distributed data stream classification for wireless sensor networks},
  Author                   = {Gaber, M.M.a and Shiddiqi, A.M.b},
  Year                     = {2010},
  Note                     = {cited By (since 1996)2},
  Pages                    = {1629-1630},

  Abstract                 = {It has been established experimentally that in-network processing in wireless sensor networks is the acceptable mode of operation. However, this solution is faced by resource constraints of the sensor nodes, especially when running traditional data mining techniques that tend to consume the resources rapidly. On the other hand, data stream mining algorithms still fall short with the limited computational capabilities of the nodes. These algorithms need real-time adaptation to availability of resources. Distributed processing is also essential to produce a global model of the data streams emanated from the network. In this paper, we propose a novel distributed data stream classification technique that is able to adapt to availability of resources in wireless sensor networks. Ã‚Â© 2010 ACM.},
  Affiliation              = {Centre for Distributed Systems and Software Engineering, Monash University, Australia; Clayton School of Information Technology, Monash University, Australia},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM Symposium on Applied Computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Traditional data mining techniques that tend to consume the resources rapidly. In this paper, we propose a novel distributed data stream classification technique that is able to adapt to availability of resources in wireless sensor networks. Approved 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954743457&partnerID=40&md5=4b0fa0ff7c7a3057b4abdbc829f519dd}
}

@Article{Gaber2006,
  Title                    = {Detection and classification of changes in evolving data streams},
  Author                   = {Gaber, M.M.a and Yu, P.S.b },
  Journal                  = {International Journal of Information Technology and Decision Making},
  Year                     = {2006},
  Note                     = {cited By (since 1996)17},
  Number                   = {4},
  Pages                    = {659-670},
  Volume                   = {5},

  Abstract                 = {Data stream mining has attracted considerable attention over the past few years owing to the significance of its applications. Streaming data is often evolving ewer time. Capturing changes could be used for detecting an event or a phenomenon in various applications. Weather conditions, economical changes, astronomical, and scientific phenomena are among a wide range of applications. Because of the high volume and speed of data streams, it is computationally hard to capture these changes from raw data in real-time. In this paper, we propose a novel algorithm that we term as STREAM-DETECT to capture these changes in data stream distribution and/or domain using clustering result deviation. STREAM-DETECT is followed by a process of offline classification CHANGE-CLASS. This classification is concerned with the association of the history of change characteristics with the observed event or phenomenon. Experimental results show the efficiency of the proposed framework in both detecting the changes and classification accuracy. Ã‚Â© World Scientific Publishing Company.},
  Affiliation              = {School of Information Technologies, University of Sydney, NSW 2006, Australia; IBM Thomas J. Watson Research Center, 19, Skyline Drive, Hawthorne, NY 10532, United States},
  Author_keywords          = {Change detection; Classification and clustering; Data streams},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we propose a novel algorithm that we term as STREAM-DETECT to capture changes in data stream distribution and/or domain using clustering result deviation.STREAM-DETECT is followed by a process of offline classification CHANGE-CLASS, to associate history of change.Experimental results show the efficiency of the proposed framework in both detecting the changes and classification accuracy. Approved. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33845501194&partnerID=40&md5=696f946dd4281f0cea5d30f68b5a837e}
}

@Article{Gaber2013,
  Title                    = {Interactive self-adaptive clutter-aware visualisation for mobile data mining },
  Author                   = {Mohamed Medhat Gaber and Shonali Krishnaswamy and Brett Gillick and Hasnain AlTaiar and Nicholas Nicoloudis and Jonathan Liono and Arkady Zaslavsky},
  Journal                  = {Journal of Computer and System Sciences },
  Year                     = {2013},
  Note                     = {Theoretical and Practical Aspects of Warehousing, Querying and Mining Sensor and Streaming Data },
  Number                   = {3},
  Pages                    = {369 - 382},
  Volume                   = {79},

  Abstract                 = {There is an emerging focus on real-time data stream analysis on mobile devices. A wide range of data stream processing applications are targeted to run on mobile handheld devices with limited computational capabilities such as patient monitoring, driver monitoring, providing real-time analysis and visualisation for emergency and disaster management, real-time optimisation for courier pick-up and delivery etc. There are many challenges in visualisation of the analysis/data stream mining results on a mobile device. These include coping with the small screen real-estate and effective presentation of highly dynamic and real-time analysis. This paper proposes a generic theory for visualisation on small screens that we term Adaptive Clutter Reduction ACR. Based on ACR, we have developed and experimentally validated a novel data stream clustering result visualisation technique that we term Clutter-Aware Clustering Visualiser \{CACV\} and its enhancement of enabling user interactivity that we term iCACV. Experimental results on both synthetic and real datasets using the Google Android platform are presented proving the effectiveness of the proposed techniques.},
  Doi                      = {http://dx.doi.org/10.1016/j.jcss.2012.09.009},
  ISSN                     = {0022-0000},
  Keywords                 = {Visualisation},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We have developed and experimentally validated a novel data stream clustering result visualization technique that we term Clutter-Aware Clustering Visualizer (CACV). Experimental results on both synthetic and real datasets using the Google Andriod platform are presented proving the effectiveness of the proposed techniques. Approved 1,3,4},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0022000012001456}
}

@InProceedings{Gaber2010,
  Title                    = {{Adaptive Clutter-Aware Visualization for Mobile Data Stream Mining}},
  Author                   = {Gaber, Mohamed Medhat and Krishnaswamy, Shonali and Gillick, Brett and Nicoloudis, Nicholas and Liono, Jonathan and AlTaiar, Hasnain and Zaslavsky, Arkady},
  Booktitle                = {2010 22nd IEEE International Conference on Tools with Artificial Intelligence},
  Year                     = {2010},
  Month                    = oct,
  Pages                    = {304--311},
  Publisher                = {IEEE},
  Volume                   = {2},

  Abstract                 = {There is an emerging focus on real-time data stream analysis on mobile devices. A wide range of data stream processing applications are targeted to run on mobile handheld devices with limited computational capabilities such as patient monitoring, driver monitoring, providing real-time analysis and visualization for emergency and disaster management, real-time optimization for courier pick-up and delivery etc. There are many challenges in visualization of the analysis/data stream mining results on a mobile device. These include coping with the small screen real-estate and effective presentation of highly dynamic and real-time analysis. This paper proposes a generic theory for visualization on small screens that we term Adaptive Clutter Reduction ACR. Based on ACR, we have developed and experimentally validated a novel data stream clustering result visualization technique that we term Clutter-Aware Clustering Visualizer (CACV). Experimental results on both synthetic and real datasets using the Google Andriod platform are presented proving the effectiveness of the proposed techniques.},
  Doi                      = {10.1109/ICTAI.2010.116},
  ISBN                     = {978-1-4244-8817-9},
  ISSN                     = {1082-3409},
  Keywords                 = {Adaptive Clutter Reduction,Clustering algorithms,Clutter,Data mining,Data visualization,Mining Data Streams,Mobile Data Mining,Mobile communication,Mobile handsets,Real time systems,Visualization,adaptive clutter aware visualization,computational capabilities,data mining,data stream processing applications,data visualisation,disaster management,mobile computing,mobile data stream mining,mobile devices,mobile handheld devices,real-time analysis,real-time systems},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Older version of Gaber2013. Discarded.},
  Shorttitle               = {Tools with Artificial Intelligence (ICTAI), 2010 2},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5670093}
}

@Misc{Gaber,
  Title                    = {{A Wireless Data Stream Mining Model}},

  Author                   = {Gaber, Mohamed Medhat and Krishnaswamy, Shonali and Zaslavsky, Arkady},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The sensor networks, web click stream and astronomical applications generate a continuous flow of data streams. Most likely data streams are generated in a wireless environment. These data streams challenge our ability to store and process them in real-time with limited computing capabilities of the wireless environment. Querying and mining data streams have attracted attention in the past two years. The main idea behind the proposed techniques in mining data streams in to develop efficient approximate algorithms with an acceptable accuracy. Recently, we have proposed algorithm output granularity as an approach in mining data streams. This approach has the advantage of being resource-aware in addition to its generality. In this paper, a model for mining data streams in a wireless environment has been proposed. The model contains two novel contributions; a ubiquitous data mining system architecture and algorithm output granularity approach in mining data streams.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Gaber2004 used in a framework for streams. The sensor networks, web click stream and astronomical applications generate a continuous flow of data streams. Querying and mining data streams have attracted attention in the past two years. The main idea behind the proposed techniques in mining data streams in to develop efficient approximate algorithms with an acceptable accuracy. The model contains two novel contributions; a ubiquitous data mining system architecture and algorithm output granularity approach in mining data streams. Approved 1,2,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.146.4848}
}

@Article{Gaber2004,
  Title                    = {{Cost-efficient mining techniques for data streams}},
  Author                   = {Gaber, Mohamed Medhat and Krishnaswamy, Shonali and Zaslavsky, Arkady},
  Year                     = {2004},

  Month                    = jan,
  Pages                    = {109--114},

  Abstract                 = {A data stream is a continuous and high-speed flow of data items. High speed refers to the phenomenon that the data rate is high relative to the computational power. The increasing focus of applications that generate and receive data streams stimulates the need for online data stream analysis tools. Mining data streams is a real time process of extracting interesting patterns from high-speed data streams. Mining data streams raises new problems for the data mining community in terms of how to mine continuous high-speed data items that you can only have one look at. In this paper, we propose algorithm output granularity as a solution for mining data streams. Algorithm output granularity is the amount of mining results that fits in main memory before any incremental integration. We show the application of the proposed strategy to build efficient clustering, frequent items and classification techniques. The empirical results for our clustering algorithm are presented and discussed which demonstrate acceptable accuracy coupled with efficiency in running time.},
  Keywords                 = {classification and algorithm output granularity,clustering,frequent items,mining data streams},
  Owner                    = {alex},
  Publisher                = {Australian Computer Society, Inc.},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we propose algorithm output granularity as a solution for mining data streams, where granularity is the amount of mining results that fits in main memory before any incremental integration. We show the application of the proposed strategy to build efficient clustering, frequent items and classification techniques. The empirical results for our clustering algorithm are presented and discussed which demonstrate acceptable accuracy coupled with efficiency in running time. Approved 1,3,4,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=976440.976456}
}

@Article{Gaber2004a,
  Title                    = {{Cost-Efficient Mining Techniques for Data Streams}},
  Author                   = {Gaber, Mohamed Medhat and Krishnaswamy, Shonali and Zaslavsky, Arkady},
  Journal                  = {IN PROC. AUSTRALASIAN WORKSHOP ON DATA MINING AND WEB INTELLIGENCE (DMWI2004},
  Year                     = {2004},
  Pages                    = {109 -- 114},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A data stream is a continuous and high-speed flow of data items. High speed refers to the phenomenon that the data rate is high relative to the computational power. The increasing focus of applications that generate and receive data streams stimulates the need for online data stream analysis tools. Mining data streams is a real time process of extracting interesting patterns from high-speed data streams. Mining data streams raises new problems for the data mining community in terms of how to mine continuous high-speed data items that you can only have one look at. In this paper, we propose algorithm output granularity as a solution for mining data streams. Algorithm output granularity is the amount of mining results that fits in main memory before any incremental integration. We show the application of the proposed strategy to build efficient clustering, frequent items and classification techniques. The empirical results for our clustering algorithm are presented and discussed which demonstrate acceptable accuracy coupled with efficiency in running time.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gaber2004. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.71.6129}
}

@InProceedings{Gaber2010c,
  Title                    = {{Distributed data stream classification for wireless sensor networks}},
  Author                   = {Gaber, Mohamed Medhat and Shiddiqi, Ary Mazharuddin},
  Booktitle                = {Proceedings of the 2010 ACM Symposium on Applied Computing - SAC '10},
  Year                     = {2010},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {1629},
  Publisher                = {ACM Press},

  Abstract                 = {It has been established experimentally that in-network processing in wireless sensor networks is the acceptable mode of operation. However, this solution is faced by resource constraints of the sensor nodes, especially when running traditional data mining techniques that tend to consume the resources rapidly. On the other hand, data stream mining algorithms still fall short with the limited computational capabilities of the nodes. These algorithms need real-time adaptation to availability of resources. Distributed processing is also essential to produce a global model of the data streams emanated from the network. In this paper, we propose a novel distributed data stream classification technique that is able to adapt to availability of resources in wireless sensor networks.},
  Doi                      = {10.1145/1774088.1774439},
  ISBN                     = {9781605586397},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gaber2010a. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1774088.1774439}
}

@Article{GagneII2009,
  Title                    = {Classification of convective areas using decision trees},
  Author                   = {Gagne II, D.J.a and McGovern, A.b and Brotzge, J.c },
  Journal                  = {Journal of Atmospheric and Oceanic Technology},
  Year                     = {2009},
  Note                     = {cited By (since 1996)9},
  Number                   = {7},
  Pages                    = {1341-1353},
  Volume                   = {26},

  Abstract                 = {This paper presents an automated approach for classifying storm type from weather radar reflectivity using decision trees. Recent research indicates a strong relationship between storm type (morphology) and severe weather, and such information can aid in the warning process. Furthermore, new adaptive sensing tools, such as the Center for Collaborative Adaptive Sensing of the Atmosphere's (CASA's) weather radar, can make use of storm-type information in real time. Given the volume of weather radar data from those tools, manual classification of storms is not possible when dealing with real-time data streams. An automated system can more quickly and efficiently sort through real-time data streams and return value-added output in a form that can be more easily manipulated and understood. The method of storm classification in this paper combines two machine learning techniques: K-means clustering and decision trees. K-means segments the reflectivity data into clusters, and decision trees classify each cluster. The K means was used to separate isolated cells from linear systems. Each cell received labels such as "isolated pulse," "isolated strong," or "multicellular." Linear systems were labeled as "trailing stratiform," "leading stratiform," and "parallel stratiform." The classification scheme was tested using both simulated and observed storms. The simulated training and test datasets came from the Advanced Regional Prediction System (ARPS) simulated reflectivity data, and observed data were collected from composite reflectivity mosaics from the CASA Integrative Project One (IP1) network. The observations from the CASA network showed that the classification scheme is now ready for operational use. Ã‚Â© 2009 American Meteorological Society.},
  Affiliation              = {School of Meteorology, The University of Oklahoma, Norman, Oklahoma, United States; School of Computer Science, The University of Oklahoma, Norman, Oklahoma, United States; Center for Analysis and Prediction of Storms, The University of Oklahoma, Norman, Oklahoma, United States},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents an automated approach for classifying storm type from weather radar reflectivity using decision trees and k means clustering. Manual classification of storms is not possible when dealing with real-time data streams. The simulated training and test datasets came from the Advanced Regional Prediction System (ARPS) simulated reflectivity data, and observed data were collected. Approved 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-73049100431&partnerID=40&md5=192bcb186ab622ce12c427f86fbc7630}
}

@Misc{Galagate,
  Title                    = {{Using R to Model Click-Stream Data to Understand Users ' Path To Conversion}},

  Author                   = {Galagate, Douglas and Jank, Professor Wolfgang},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Advertisers spend a lot of time and effort directing consumers ' attention to their client's website, enticing them to purchase a product or a service. While most models attribute a consumer's conversion only to the last site they visited ("last click model"), it is generally accepted that all of the information in a consumer's search path (i.e. in the sequence of all websites visited) play some role in the ultimate purchase decision. In this project, we use data mining techniques to characterize and model a consumer's "path to conversion. " That is, we characterize the network of websites and sequence of clicks in order to gauge the impact of different types of online content, its order and its relationship to one another on the probability},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {While most models attribute a consumer's conversion only to the last site they visited ("last click model"), in this project, we use data mining techniques to characterize and model a consumer's "path to conversion. ", to understand what makes consumers end up purchasing. Approved 1,2,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.374.4858}
}

@Article{Gama2003b,
  Title                    = {{Accurate decision trees for mining high-speed data streams}},
  Author                   = {Gama, Jo\~{a}o},
  Journal                  = {IN PROC. SIGKDD},
  Year                     = {2003},
  Pages                    = {523 -- 528},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gama2003. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.118.6092}
}

@Article{Gama2005,
  Title                    = {{Learning decision trees from dynamic data streams}},
  Author                   = {Gama, Jo\~{a}o and Medas, Pedro},
  Journal                  = {IN SAC},
  Year                     = {2005},
  Pages                    = {573 -- 577},
  Volume                   = {11},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper presents a system for induction of forest of functional trees from data streams able to detect concept drift. The Ultra Fast Forest of Trees (UFFT) is an incremental algorithm, which works online, processing each example in constant time, and performing a single scan over the training examples. It uses analytical techniques to choose the splitting criteria, and the information gain to estimate the merit of each possible splitting-test. For multi-class problems the algorithm builds a binary tree for each possible pair of classes, leading to a forest of trees. Decision nodes and leaves contain naive-Bayes classifiers playing different roles during the induction process. Naive-Bayes in leaves are used to classify test examples. Naive-Bayes in inner nodes play two different roles. They can be used as multivariate splitting-tests if chosen by the splitting criteria, and used to detect changes in the class-distribution of the examples that traverse the node. When a change in the class-distribution is detected, all the sub-tree rooted at that node will be pruned. The use of naive-Bayes classifiers at leaves to classify test examples, the use of splitting-tests based on the outcome of naive-Bayes, and the use of naive-Bayes classifiers at decision nodes to detect changes in the distribution of the examples are directly obtained from the sufficient statistics required to compute the splitting criteria, without no additional computations. This aspect is a main advantage in the context of high-speed data streams. This methodology was tested with artificial and real-world data sets. The experimental results show a very good performance in comparison to a batch decision tree learner, and high capacity to detect drift in the distribution of the examples.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents a system for induction of forest of functional trees from data streams able to detect concept drift. This methodology was tested with artificial and real-world data sets. The experimental results show a very good performance in comparison to a batch decision tree learner, and high capacity to detect drift in the distribution of the examples. Approved 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.104.7938}
}

@InProceedings{Gama2003a,
  Title                    = {{Accurate decision trees for mining high-speed data streams}},
  Author                   = {Gama, Jo\~{a}o and Rocha, Ricardo and Medas, Pedro},
  Booktitle                = {Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '03},
  Year                     = {2003},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {523},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/956750.956813},
  ISBN                     = {1581137370},
  Keywords                 = {data streams,functional leaves,incremental decision trees},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gama2003. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=956750.956813}
}

@Article{Gama2006,
  Title                    = {Decision trees for mining data streams},
  Author                   = {Gama, J.a and Fernandes, R.b and Rocha, R.b },
  Journal                  = {Intelligent Data Analysis},
  Year                     = {2006},
  Note                     = {cited By (since 1996)38},
  Number                   = {1},
  Pages                    = {23-45},
  Volume                   = {10},

  Abstract                 = {In this paper we study the problem of constructing accurate decision tree models from data streams. Data streams are incremental tasks that require incremental, online, and any-time learning algorithms. One of the most successful algorithms for mining data streams is VFDT. We have extended VFDT in three directions: the ability to deal with continuous data; the use of more powerful classification techniques at tree leaves, and the ability to detect and react to concept drift. VFDTc system can incorporate and classify new information online, with a single scan of the data, in time constant per example. The most relevant property of our system is the ability to obtain a performance similar to a standard decision tree algorithm even for medium size datasets. This is relevant due to the any-time property. We also extend VFDTc with the ability to deal with concept drift, by continuously monitoring differences between two class-distribution of the examples: the distribution when a node was built and the distribution in a time window of the most recent examples. We study the sensitivity of VFDTc with respect to drift, noise, the order of examples, and the initial parameters in different problems and demonstrate its utility in large and medium data sets. Ã‚Â© 2006-IOS Press and the authors. All rights reserved.},
  Affiliation              = {LIACC, FEP-University of Porto, Rua de Ceuta, 118-6, 4050-190 Porto, Portugal; Department of Mathematics, University of Aveiro, Aveiro, Portugal},
  Author_keywords          = {concept drift; Data streams; incremental decision trees},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Extend one of the most successful algorithms for mining data streams with the ability to deal with continuous data and the use of more powerful classification techniques at tree leaves. The proposed system, VFDTc, can incorporate and classify new information online, with a single scan of the data, in time constant per example. We demonstrate its utility in large and medium data sets. Under a bias-variance analysis we observe that VFDTc in comparison to C4.5 is able to reduce the variance component. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33749419375&partnerID=40&md5=08ea3e53b4b77db99e70f2aa3695b1e9}
}

@Conference{Gama2003,
  Title                    = {Accurate decision trees for mining high-speed data streams},
  Author                   = {Gama, J.a and Rocha, R.b and Medas, P.c },
  Year                     = {2003},
  Note                     = {cited By (since 1996)106},
  Pages                    = {523-528},

  Abstract                 = {In this paper we study the problem of constructing accurate decision tree models from data streams. Data streams are incremental tasks that require incremental, online, and any-time learning algorithms. One of the most successful algorithms for mining data streams is VFDT. In this paper we extend the VFDT system in two directions: the ability to deal with continuous data and the use of more powerful classification techniques at tree leaves. The proposed system, VFDTc, can incorporate and classify new information online, with a single scan of the data, in time constant per example. The most relevant property of our system is the ability to obtain a performance similar to a standard decision tree algorithm even for medium size datasets. This is relevant due to the any-time property. We study the behaviour of VFDTc in different problems and demonstrate its utility in large and medium data sets. Under a bias-variance analysis we observe that VFDTc in comparison to C4.5 is able to reduce the variance component. Copyright 2003 ACM.},
  Affiliation              = {LIACC, FEP, Univ. Do Porto, R. do Campo Alegre 823, 4150 Porto, Portugal; Projecto MatemÃƒÂ¡tica Ensino, Departamento de MatemÃƒÂ¡tica, 3810 Aveiro, Portugal; LIACC, Univ. Do Porto, R. do Campo Alegre 823, 4150 Porto, Portugal},
  Author_keywords          = {Data streams; Functional leaves; Incremental decision trees},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Older version of Gama2006. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70350649252&partnerID=40&md5=70ea1bb950dc872a207307443181016b}
}

@Book{Gama2007,
  Title                    = {Data stream processing},
  Author                   = {Gama, J.a and Rodrigues, P.P.b },
  Year                     = {2007},
  Note                     = {cited By (since 1996)17},

  Abstract                 = {The rapid growth in information science and technology in general and the complexity and volume of data in particular have introduced new challenges for the research community.Many sources produce data continuously. Examples include sensor networks, wireless networks, radio frequency identification (RFID), customer click streams, telephone records, multimedia data, scientific data, sets of retail chain transactions etc. These sources are called data streams. A data stream is an ordered sequence of instances that can be read only once or a small number of times using limited computing and storage capabilities. These sources of data are characterized by being open-ended, flowing at high-speed, and generated by non stationary distributions in dynamic environments. What distinguishes current data from earlier one is automatic data feeds. We do not just have people who are entering information into a computer. Instead, we have computers entering data into each other [25]. Nowadays there are applications in which the data are modeled best as transient data streams instead of as persistent tables. Examples of applications include network monitoring, user modeling in web applications, sensor networks in electrical networks, telecommunications data management, prediction in stock markets, monitoring radio frequency identification etc. In these applications it is not feasible to load the arriving data into a traditional data base management system (DBMS) and traditional DBMS are not designed to directly support the continuous queries required by these applications [3]. Carney et al. [6] pointed out the significant differences between data bases that are passive repositories of data and data bases that actually monitor applications and alert humans when abnormal activity is detected. In the former, only the current state of the data is relevant for analysis. Humans initiate queries, usually one-time, predefined queries. In the latter, data come from external sources (e.g., sensors), and require processing historic data. For example, in monitoring activity, queries should run continuously. The answer to a continuous query is produced over time, reflecting the data seen so far. Moreover, if the process is not strictly stationary (as most of real-world applications), the target concept could gradually change over time. For example, the type of abnormal activity (e.g., attacks in TCP/IP networks, frauds in credit card transactions etc.) changes over time. Organizations use decision support systems to identify potential useful patterns in data. Data analysis is complex, interactive, and exploratory over very large volumes of historic data, eventually stored in distributed environments. Traditional pattern discovery process requires online ad-hoc queries, not previously defined, that are successively refined. Nowadays, given the current trends in decision support and data analysis, the computer plays a much more active role, by searching hypotheses, evaluating and suggesting patterns. Due to the exploratory nature of these queries, an exact answer may not be required. A user may prefer a fast approximate answer. Range queries and selectivity estimation (the proportion of tuples that satisfy a query) are two illustrative examples where fast but approximate answers are more useful than slow and exact ones. Sensor networks are distributed environments producing multiple streams of data. We can consider the network as a distributed database we are interested in querying and mining. In this chapter we review the main techniques used for query and mining data streams that are of potential use in sensor networks. In Sect. 3.2 we refer to the data stream models and identify its main research challenges. Section 3.3 presents basic stream models. Section 3.4 present basic stream algorithms for maintaining synopsis over data streams. Section 3.5 concludes the chapter and points out future directions for research. Ã‚Â© 2007 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {LIAAD-INESC Porto L.A., Faculty of Economics, University of Porto, Rua de Ceuta, 118-6, 4050-190 Porto, Portugal; LIAAD-INESC Porto L.A., Faculty of Sciences, University of Porto, Rua de Ceuta, 118-6, 4050-190 Porto, Portugal},
  Document_type            = {Book Chapter},
  Journal                  = {Learning from Data Streams: Processing Techniques in Sensor Networks},
  Owner                    = {Alexander},
  Pages                    = {25-39},
  Qualityassured           = {qualityAssured},
  Review                   = {Chapter from book. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56049091063&partnerID=40&md5=43688a8fa718552f0f6b730ca3737c2c}
}

@Article{Gan2014,
  Title                    = {Detecting and monitoring abrupt emergences and submergences of episodes over data streams },
  Author                   = {Min Gan and Honghua Dai},
  Journal                  = {Information Systems },
  Year                     = {2014},
  Number                   = {0},
  Pages                    = {277 - 289},
  Volume                   = {39},

  Abstract                 = {Existing studies on episode mining mainly concentrate on the discovery of (global) frequent episodes in sequences. However, frequent episodes are not suited for data streams because they do not capture the dynamic nature of the streams. This paper focuses on detecting dynamic changes in frequencies of episodes over time-evolving streams. We propose an efficient method for the online detection of abrupt emerging episodes and abrupt submerging episodes over streams. Experimental results on synthetic data show that the proposed method can effectively detect the defined patterns and meet the strict requirements of stream processing, such as one-pass, real-time update and return of results, plus limited time and space consumption. Experimental results on real data demonstrate that the patterns detected by our method are natural and meaningful. The proposed method has wide applications in stream monitoring and analysis as the discovered patterns indicate dynamic emergences/disappearances of noteworthy events/phenomena hidden in the streams.},
  Doi                      = {http://dx.doi.org/10.1016/j.is.2012.05.009},
  ISSN                     = {0306-4379},
  Keywords                 = {Stream mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Seems like a followup of Gan2012, but not strictly the same. Frequent episodes are not suited for data streams because they do not capture the dynamic nature of the streams This paper focuses on detecting dynamic changes in frequencies of episodes over time-evolving streams. Experimental results on synthetic data show that the proposed method can effectively detect the defined patterns and meet the strict requirements of stream processing Approved 1,2,3,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306437912000762}
}

@Article{Gan2012,
  Title                    = {An efficient one-pass method for discovering bases of recently frequent episodes over online data streams},
  Author                   = {Gan, M. and Dai, H.},
  Journal                  = {International Journal of Innovative Computing, Information and Control},
  Year                     = {2012},
  Note                     = {cited By (since 1996)1},
  Number                   = {7 A},
  Pages                    = {4675-4690},
  Volume                   = {8},

  Abstract                 = {The knowledge embedded in an online data stream is likely to change over time due to the dynamic evolution of the stream. Consequently, infrequent episode mining over an online stream, frequent episodes should be adaptively extracted from recently generated stream segments instead of the whole stream. However, almost all existing frequent episode mining approaches find episodes frequently occurring over the whole sequence. This paper proposes and investigates a new problem: online mining of recently frequent episodes over data streams. In order to meet strict requirements of stream mining such as one-scan, adaptive result update and instant result return, we choose a novel frequency metric and define a highly condensed set called the base of recently frequent episodes. We then introduce a one-pass method for mining bases of recently frequent episodes. Experimental results show that the proposed method is capable of finding bases of recently frequent episodes quickly and adaptively. The proposed method outperforms the previous approaches with the advantages of one-pass, instant result update and return, more condensed resulting sets and less space usage. Ã‚Â© ICIC International 2012.},
  Affiliation              = {School of Information Technology, Deakin University, Burwood, VIC 3125, Australia},
  Author_keywords          = {Data streams; Online mining; Recently frequent episodes},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {One pass method for discovering bases of recently frequent episodes over online data streams. However, almost all existing frequent episode mining approaches find episodes frequently occurring over the whole sequence. Experimental results show that the proposed method is capable of finding bases of recently frequent episodes quickly and adaptively Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84862309146&partnerID=40&md5=0639a0af8a9c7dd5c686ee97e88d1da1}
}

@InProceedings{Gao2010,
  Title                    = {{Research of Algorithm of Mining Frequent Closed Pattern about Distributed Data Stream}},
  Author                   = {Gao, Hong-bin and Xie, Jing-jing},
  Booktitle                = {2010 2nd International Conference on Information Engineering and Computer Science},
  Year                     = {2010},
  Month                    = dec,
  Pages                    = {1--5},
  Publisher                = {IEEE},

  Abstract                 = {Notice of RetractionAfter careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.New algorithm of mining frequent closed pattern about distributed data stream was proposed. The algorithm bases on the three-layer structure model. First, the leaf-layer nodes overlap the collecting item-sets. Second, the middle A-layer nodes expurgate the infrequent items of overlapped items again and again, and then insert them into prefix-sub-tree. Third, the top-layer nodes and the middle-layer ones answer the clients' request online in feedback way. Analysis and experimental results indicate: This algorithm really resolves the heavy workload between layers and has favorable application prospect.},
  Doi                      = {10.1109/ICIECS.2010.5677822},
  ISBN                     = {978-1-4244-7939-9},
  ISSN                     = {2156-7379},
  Keywords                 = {Algorithm design and analysis,Computers,Data mining,Data models,Distributed databases,Finishing,Nickel,data mining,distributed data stream,frequent closed pattern,leaf-layer nodes,middle A-layer nodes,prefix-subtree,three-layer structure model},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being retracted},
  Shorttitle               = {Information Engineering and Computer Science (ICIE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5677822}
}

@Conference{Gao2010b,
  Title                    = {RETRACTED ARTICLE: Research of algorithm of mining frequent closed pattern about distributed data stream},
  Author                   = {Gao, H.-B. and Xie, J.-J.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {New algorithm of mining frequent closed pattern about distributed data stream was proposed. The algorithm bases on the three-layer structure model. First, the leaf-layer nodes overlap the collecting item-sets. Second, the middle A-layer nodes expurgate the infrequent items of overlapped items again and again, and then insert them into prefix-sub-tree. Third, the top-layer nodes and the middle-layer ones answer the clients' request online in feedback way. Analysis and experimental results indicate: This algorithm really resolves the heavy workload between layers and has favorable application prospect. Ã‚Â©2010 IEEE.},
  Affiliation              = {College of Computer, Wuyi University Wyu, Jiangmen, China},
  Art_number               = {5677822},
  Author_keywords          = {Data mining; Distributed data stream; Frequent closed pattern; GCC algorithm; Overlapped item-set},
  Document_type            = {Conference Paper},
  Journal                  = {2nd International Conference on Information Engineering and Computer Science - Proceedings, ICIECS 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Retracted. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79951599075&partnerID=40&md5=5575bf8a7d0845fad573a18529ebb475}
}

@Conference{Gao2010c,
  Title                    = {Research in data stream clustering based on Gaussian Mixture Model Genetic Algorithm},
  Author                   = {Gao, M.-M.a and Chang, T.-H.a and Gao, X.-X.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Pages                    = {3904-3907},

  Abstract                 = {Clustering data streams is one of the important branches in mining data streams. Because of dynamic and massive characteristics of data streams, traditional data mining algorithms could not satisfy the requirement of online analysis and the appropriate value of number of clusters. The focus on data stream technologies is to design one-pass scan data set, and maintain an effective data structure in memory incrementally which is far smaller than the size of whole data set. In the paper proposes a new feature mining method named Gaussian Mixture Model with Genetic Algorithm (GMMGA), based on an extending method of Gaussian mixture model. This method is use a probability density based data stream clustering which requires only the newly arrived data, not the entire historical data. The GMMGA algorithm can determine the number of Gaussian clusters and the parameters of each Gaussian component through random split and merge operation of Genetic Algorithm. In the GMMGA, a function was made to threshold value to clusters to reduce the bad clusters effect on the clustering result. In this algorithm, it can improve the robustness and accuracy of the clustering numbers, also can save memory and run time. Experimental results show that the method is effective and has higher clustering precision compared with conventional STREAM algorithm and CluStream algorithm. Ã‚Â© 2010 IEEE.},
  Affiliation              = {School of Control and Computer Engineering, North China Electric Power University, Beijing, China; China North Vehicle Research Institute, Beijing, China},
  Art_number               = {5691641},
  Author_keywords          = {Data stream clustering; Gaussian Mixture Model Genetic Algorithm; Split and merge},
  Document_type            = {Conference Paper},
  Journal                  = {2nd International Conference on Information Science and Engineering, ICISE2010 - Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gao2010b.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79951982265&partnerID=40&md5=b170b772ec4fed9539f4ebcfca822528}
}

@InProceedings{Gao2010a,
  Title                    = {{Research in data stream clustering based on Gaussian Mixture Model Genetic Algorithm}},
  Author                   = {Gao, Ming-ming and Gao, Xiang-xiang},
  Booktitle                = {The 2nd International Conference on Information Science and Engineering},
  Year                     = {2010},
  Month                    = dec,
  Pages                    = {3904--3907},
  Publisher                = {IEEE},

  Abstract                 = {Clustering data streams is one of the important branches in mining data streams. Because of dynamic and massive characteristics of data streams, traditional data mining algorithms could not satisfy the requirement of online analysis and the appropriate value of number of clusters. The focus on data stream technologies is to design one-pass scan data set, and maintain an effective data structure in memory incrementally which is far smaller than the size of whole data set. In the paper proposes a new feature mining method named Gaussian Mixture Model with Genetic Algorithm (GMMGA), based on an extending method of Gaussian mixture model. This method is use a probability density based data stream clustering which requires only the newly arrived data, not the entire historical data. The GMMGA algorithm can determine the number of Gaussian clusters and the parameters of each Gaussian component through random split and merge operation of Genetic Algorithm. In the GMMGA, a function was made to threshold value to clusters to reduce the bad clusters effect on the clustering result. In this algorithm, it can improve the robustness and accuracy of the clustering numbers, also can save memory and run time. Experimental results show that the method is effective and has higher clustering precision compared with conventional STREAM algorithm and CluStream algorithm.},
  Doi                      = {10.1109/ICISE.2010.5691641},
  ISBN                     = {978-1-4244-7616-9},
  Keywords                 = {Adaptation model,Algorithm design and analysis,Classification algorithms,Clustering algorithms,Data mining,Data stream clustering,Gaussian Mixture Model Genetic Algorithm,Genetics,Training,split and merge},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The focus on data stream technologies is to design one-pass scan data set, and maintain an effective data structure in memory incrementally which is far smaller than the size of whole data set. In the paper proposes a new feature mining method named Gaussian Mixture Model with Genetic Algorithm. Experimental results show that the method is effective and has higher clustering precision compared with conventional STREAM algorithm and CluStream algorithm. Approved 1,2,3,4,6},
  Shorttitle               = {Information Science and Engineering (ICISE), 2010 },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5691641}
}

@InProceedings{Gaoshan2010,
  Title                    = {{A Heuristic Method for Unstructured Pattern Management over Data Streams}},
  Author                   = {Gaoshan, Miao and Hongyan, Li and Tengjiao, Wang},
  Booktitle                = {2010 12th International Asia-Pacific Web Conference},
  Year                     = {2010},
  Month                    = apr,
  Pages                    = {468--471},
  Publisher                = {IEEE},

  Abstract                 = {Pattern management is an important task in data stream mining and has attracted increasing attention recently. Variations of data stream patterns typically imply some fundamental changes of underlying objects and possess significant domain meanings. Many database applications require investigating the history information to get the knowledge about the evolving process of data streams. However, in most circumstances, the data stream patterns are unstructured: limited memory space cannot record all the patterns discovered online, no training sets or predefined models are available, and large numbers of noises bring another non-trivial challenge. This paper presents our research effort in online pattern management over such streams. A novel algorithm is proposed to detect stream changes, organize meaningful patterns and distinguish useful variations from noises. It extracts new trends from unstructured data heuristically, and involves a special parameter to identify whether the current event should be treated as significant. Several experiments are performed and the results prove this new method feasible and efficient.},
  Doi                      = {10.1109/APWeb.2010.77},
  ISBN                     = {978-1-4244-6599-6},
  Keywords                 = {Acoustic noise,Computer science education,Conference management,Consumer electronics,Data engineering,Data mining,Discrete wavelet transforms,Engineering management,Laboratories,Technology management,data mining,data stream,data stream mining,data streams,database applications,heuristic method,heuristic programming,pattern management,unstructured data,unstructured pattern management},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Pattern management is an important task in data stream mining and has attracted increasing attention recently. However, in most circumstances, the data stream patterns are unstructured, limited memory is a problem, no predefined training set and a lot of noise. A novel algorithm is proposed to detect stream changes, organize meaningful patterns and distinguish useful variations from noises.Several experiments are performed and the results prove this new method feasible and efficient. Approved 1,3,4,6},
  Shorttitle               = {Web Conference (APWEB), 2010 12th International As},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5474089}
}

@Conference{Garg2010,
  Title                    = {Multimodal analysis of body sensor network data streams for real-time healthcare},
  Author                   = {Garg, M.K.a and Kim, D.-J.a and Turaga, D.S.b and Prabhakaran, B.a },
  Year                     = {2010},
  Note                     = {cited By (since 1996)7},
  Pages                    = {469-477},

  Abstract                 = {Fundamental advances in low power circuits, wireless communication, physiological sensor design, and multimedia stream processing, have led to the deployment of body sensor networks for the real-time monitoring of individual health in diverse settings. In this paper we will present a summary of the state-of-the-art in the design and development of aggregation, processing, analysis, and retrieval techniques for body sensor network data streams. In particular, we will focus on multi-modal stream analysis techniques, in distributed and resource constrained environments, for effective real-time healthcare applications. We will describe the associated research challenges ranging from designing novel applications and mining algorithms to systems issues of resource-adaptation, reliability etc., and the intersection of these. We will also present practical deployments and emerging applications of body sensor networks both in individual healthcare as well as in applications for large-scale public health tracking of communities. We will conclude with a summary of open challenges in the field. Copyright 2010 ACM.},
  Affiliation              = {Department of Computer Science, University of Texas at Dallas, Richardson, TX, 75080, United States; IBM T. J. Watson Research Center, 19 Skyline Drive, Hawthorne, NY 10532, United States},
  Author_keywords          = {Body Sensor Networks; Multi-modal Analysis; Sensor Networks; Systems and Communications},
  Document_type            = {Conference Paper},
  Journal                  = {MIR 2010 - Proceedings of the 2010 ACM SIGMM International Conference on Multimedia Information Retrieval},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {. In this paper we will present a summary of the state-of-the-art in the design and development of aggregation, processing, analysis, and retrieval techniques for body sensor network data streams. Survey paper. Discarded, put aside.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77952397838&partnerID=40&md5=ffffdd04e553aa0b4b9a6c6cd20ced00}
}

@InProceedings{Garg2010a,
  Title                    = {{Multimodal analysis of body sensor network data streams for real-time healthcare}},
  Author                   = {Garg, Manoj K. and Kim, Duk-Jin and Turaga, Deepak S. and Prabhakaran, Balakrishnan},
  Booktitle                = {Proceedings of the international conference on Multimedia information retrieval - MIR '10},
  Year                     = {2010},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {469},
  Publisher                = {ACM Press},

  Abstract                 = {Fundamental advances in low power circuits, wireless communication, physiological sensor design, and multimedia stream processing, have led to the deployment of body sensor networks for the real-time monitoring of individual health in diverse settings. In this paper we will present a summary of the state-of-the-art in the design and development of aggregation, processing, analysis, and retrieval techniques for body sensor network data streams. In particular, we will focus on multi-modal stream analysis techniques, in distributed and resource constrained environments, for effective real-time healthcare applications. We will describe the associated research challenges ranging from designing novel applications and mining algorithms to systems issues of resource-adaptation, reliability etc., and the intersection of these. We will also present practical deployments and emerging applications of body sensor networks both in individual healthcare as well as in applications for large-scale public health tracking of communities. We will conclude with a summary of open challenges in the field.},
  Doi                      = {10.1145/1743384.1743467},
  ISBN                     = {9781605588155},
  Keywords                 = {body sensor networks,multi-modal analysis,sensor networks,systems and communications},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Garg2010. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1743384.1743467}
}

@Misc{Garnett,
  Title                    = {{LEARNING FROM DATA STREAMS WITH CONCEPT DRIFTLEARNING FROM DATA STREAMS WITH CONCEPT DRIFT}},

  Author                   = {Garnett, Roman},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Increasing access to large, nonstationary datasets and corresponding demands to analyze these data has led to the development of new online algorithms for performing machine learning on data streams. An important feature of many real-world data streams is “concept drift, ” whereby the characteristics of the data can change arbitrarily over time. The presence of concept drift in a data stream renders many classical data mining techniques unsuitable, and therefore new approaches must be developed in their place. In pursuit of this goal, we introduce a number of new algorithms and techniques. First we discuss the dynamic logistic regressor (dlr), a sequential Bayesian approach for performing binary classification on nonstationary data streams. We proceed to show how the dlr method can be extended to cope with missing observations and missing and corrupted labels. Next we introduce Gaussian processes, a Bayesian technique for performing inference about functions. Using this tool, we propose a new sequential algorithm for performing robust time-series prediction in the presence of changepoints and observation faults. We then extend this work to demonstrate how to perform effective active},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The presence of concept drift in a data stream renders many classical data mining techniques unsuitable. We introduce a number of new algorithms and techniques. Dynamic logistic regressor, and a new algorithm using gaussian processes. Experiments show it outperforms previous solutions. Approved 1,2,3,4,5,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.352.8638}
}

@Article{Gedik2014a,
  Title                    = {Generic windowing support for extensible stream processing systems},
  Author                   = {Gedik, B.},
  Journal                  = {Software - Practice and Experience},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {9},
  Pages                    = {1105-1128},
  Volume                   = {44},

  Abstract                 = {Stream processing applications process high volume, continuous feeds from live data sources, employ data-in-motion analytics to analyze these feeds, and produce near real-time insights with low latency. One of the fundamental characteristics of such applications is the on-the-fly nature of the computation, which does not require access to disk resident data. Stream processing applications store the most recent history of streams in memory and use it to perform the necessary modeling and analysis tasks. This recent history is often managed using windows. All data stream management systems provide some form of windowing functionality. Windowing makes it possible to implement streaming versions of the traditionally blocking relational operators, such as streaming aggregations, joins, and sorts, as well as any other analytic operator that requires keeping the most recent tuples as state, such as time series analysis operators and signal processing operators. In this paper, we provide a categorization of different window types and policies employed in stream processing applications and give detailed operational semantics for various window configurations. We describe an extensibility mechanism that makes it possible to integrate windowing support into user-defined operators, enabling consistent syntax and semantics across system-provided and third-party toolkits of streaming operators. We describe the design and implementation of a runtime windowing library that significantly simplifies the construction of window-based operators by decoupling the handling of window policies and operator logic from each other. We present our experience using the windowing library to implement a relational operators toolkit and compare the efficacy of the solution to an earlier implementation that did not employ a common windowing library. Copyright Ã‚Â© 2013 John Wiley & Sons, Ltd.},
  Affiliation              = {Computer Engineering Department, Bilkent University, Ankara 06800, Turkey},
  Author_keywords          = {data stream processing; windowing library; windowing semantics},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {This recent history is often managed using windows.. In this paper, we provide a categorization of different window types and policies employed in stream processing applications. Overview and example system of sliding windowing support. Might be interesting to discuss. Discarded, but put aside.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905572330&partnerID=40&md5=c1655b17300c563e6c73e3be50fd3d42}
}

@Article{Gedik2014,
  Title                    = {{Disk-Based Management of Interaction Graphs}},
  Author                   = {Gedik, Bugra and Bordawekar, Rajesh},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2014},

  Month                    = nov,
  Number                   = {11},
  Pages                    = {2689--2702},
  Volume                   = {26},

  Abstract                 = {In our increasingly connected and instrumented world, live data recording the interactions between people, systems, and the environment is available in various domains, such as telecommunciations and social media. This data often takes the form of a temporally evolving graph, where entities are the vertices and the interactions between them are the edges. An important feature of this graph is that the number of edges it has grows continuously, as new interactions take place. We call such graphs interaction graphs. In this paper we study the problem of storing interaction graphs such that temporal queries on them can be answered efficiently. Since interaction graphs are append-only and edges are added continuously, traditional graph layout and storage algorithms that are batch based cannot be applied directly. We present the design and implementation of a system that caches recent interactions in memory, while quickly placing the expired interactions to disk blocks such that those edges that are likely to be accessed together are placed together. We develop live block formation algorithms that are fast, yet can take advantage of temporal and spatial locality among the edges to optimize the storage layout with the goal of improving query performance. We evaluate the system on synthetic as well as real-world interaction graphs, and show that our block formation algorithms are effective for answering temporal neighborhood queries on the graph. Such queries form a foundation for building more complex online and offline temporal analytics on interaction graphs.},
  Doi                      = {10.1109/TKDE.2013.2297930},
  ISSN                     = {1041-4347},
  Keywords                 = {Algorithm design and analysis,Buffer storage,Communities,Indexes,Interaction graphs,Layout,Measurement,Twitter,disk layout,storage and querying},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Live data recording the interactions between people, systems, and the environment is available in various domains, such as telecommunciations and social media, and often takes the form of a temporally evolving graph, where entities are the vertices and the interactions between them are the edges. In this paper we study the problem of storing interaction graphs such that temporal queries on them can be answered efficiently. Graph querying, not ML. Discarded.},
  Shorttitle               = {Knowledge and Data Engineering, IEEE Transactions },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6702469}
}

@Conference{Geisler2010,
  Title                    = {A data stream-based evaluation framework for traffic information systems},
  Author                   = {Geisler, S.a and Quix, C.a and Schiffer, S.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)4},
  Pages                    = {11-18},

  Abstract                 = {Traffic information systems based on mobile, in-car sensor technology are a challenge for data management systems as a huge amount of data has to be processed in real-time. Data mining methods must be adapted to cope with these challenges in handling streaming data. Although several data stream mining methods have been proposed, an evaluation of such methods in the context of traffic applications is yet missing. In this paper, we present an evaluation framework for data stream mining for traffic applications. We apply a traffic simulation software to emulate the generation of traffic data by mobile probes. The framework is evaluated in a first case study, namely queue-end detection. We show first results of the evaluation of a data stream mining method, varying multiple parameters for the traffic simulation. The goal of our work is to identify parameter settings for which the data stream mining methods produce useful results for the traffic application at hand. Ã‚Â© 2010 ACM.},
  Affiliation              = {Information Systems, RWTH Aachen University, Aachen, Germany; Knowledge-based Systems Group, RWTH Aachen University, Aachen, Germany},
  Art_number               = {1878505},
  Author_keywords          = {data mining; data streams; traffic information systems},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGSPATIAL International Workshop on GeoStreaming, IWGS 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Geisler2010a. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78751662359&partnerID=40&md5=688674f3d7952c298fd16bfd33c2e5a0}
}

@InProceedings{Geisler2010a,
  Title                    = {{A data stream-based evaluation framework for traffic information systems}},
  Author                   = {Geisler, Sandra and Quix, Christoph and Schiffer, Stefan},
  Booktitle                = {Proceedings of the ACM SIGSPATIAL International Workshop on GeoStreaming - GIS '10},
  Year                     = {2010},

  Address                  = {New York, New York, USA},
  Month                    = nov,
  Pages                    = {11--18},
  Publisher                = {ACM Press},

  Abstract                 = {Traffic information systems based on mobile, in-car sensor technology are a challenge for data management systems as a huge amount of data has to be processed in real-time. Data mining methods must be adapted to cope with these challenges in handling streaming data. Although several data stream mining methods have been proposed, an evaluation of such methods in the context of traffic applications is yet missing. In this paper, we present an evaluation framework for data stream mining for traffic applications. We apply a traffic simulation software to emulate the generation of traffic data by mobile probes. The framework is evaluated in a first case study, namely queue-end detection. We show first results of the evaluation of a data stream mining method, varying multiple parameters for the traffic simulation. The goal of our work is to identify parameter settings for which the data stream mining methods produce useful results for the traffic application at hand.},
  Doi                      = {10.1145/1878500.1878505},
  ISBN                     = {9781450304313},
  Keywords                 = {data mining,data streams,traffic information systems},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Older version of Geisler2012. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1878500.1878505}
}

@Article{Geisler2012,
  Title                    = {An evaluation framework for traffic information systems based on data streams },
  Author                   = {Sandra Geisler and Christoph Quix and Stefan Schiffer and Matthias Jarke},
  Journal                  = {Transportation Research Part C: Emerging Technologies },
  Year                     = {2012},
  Note                     = {Data Management in Vehicular Networks },
  Number                   = {0},
  Pages                    = {29 - 55},
  Volume                   = {23},

  Abstract                 = {Traffic information systems have to process and analyze huge amounts of data in real-time to effectively provide traffic information to road users. Progress in mobile communication technology with higher bandwidths and lower latencies enables the use of data provided by in-car sensors. Data stream management systems have been proposed to address the challenges of such applications which have to process a continuous data flow from various data sources in real-time. Data mining methods, adapted to data streams, can be used to analyze the data and to identify interesting patterns such as congestion or road hazards. Although several data stream mining methods have been proposed, an evaluation of such methods in the context of traffic applications is yet missing. In this paper, we present an evaluation framework for traffic information systems based on data streams. We apply a traffic simulation software to emulate the generation of traffic data by mobile probes. The framework is applied in two case studies, namely queue-end detection and traffic state estimation. The results show which parameters of the traffic information system significantly impact the accuracy of the predicted traffic information. This provides important findings for the design and implementation of traffic information systems using data from mobile probes.},
  Doi                      = {http://dx.doi.org/10.1016/j.trc.2011.08.003},
  ISSN                     = {0968-090X},
  Keywords                 = {Data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Traffic information systems based on mobile, in-car sensor technology is a challenge because processing must be real time, and mining methods must be adapted. An evaluation of mining methods in this context is missing. They evaluate different mining algorithms in the context of queue-end detection and traffic state estimation. Not novel algorithm, but novel problem application. Approved 1,2,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0968090X11001136}
}

@InProceedings{GeneralChair-Song2007,
  Title                    = {{Proceedings of the ACM tenth international workshop on Data warehousing and OLAP}},
  Author                   = {{General Chair-Song}, Il-Yeol and {Program Chair-Pedersen}, Torben Bach},
  Booktitle                = {Proceedings of the ACM tenth international workshop on Data warehousing and OLAP},
  Year                     = {2007},
  Month                    = nov,
  Publisher                = {ACM},

  Abstract                 = {It is our great pleasure to welcome you at the 10th ACM International Workshop on Data Warehousing and OLAP -- DOLAP'07. Continuing the tradition of previous successful DOLAP workshops, the DOLAP 2007 workshop provides an international forum where both researchers and practitioners in the field of Data Warehousing and OLAP can share their findings in theoretical foundations, current methodologies, and practical experiences. The mission of DOLAP is to explore novel research directions and emerging application domains in the areas of data warehousing and OLAP. Although, research in data warehousing and OLAP has produced important technologies for the design, management and use of information systems for decision support, there are still problems and research opportunities in the area. Much of the interest and success in this area can be attributed to the need for software and tools to improve data management and analysis given the large amounts of information that are being accumulated in corporate as well as scientific databases. Nevertheless, the high maturity of these technologies as well as new data needs or applications not only demand more capacity or storing necessities, but also new methods, models, techniques or architectures to satisfy these new needs. Some of the hot topics in data warehouse research include distributed data warehouses, web warehouses, data streams, realtime DWs, GIS/location-based services, and biomedical data. Moreover, there are other aspects developed in other software areas such as security/privacy or quality, which still remain unexplored by current design methods or technologies for data warehouses. The call for papers attracted 28 submissions from Asia, Canada, Europe, and the United States. The program committee accepted 12 papers that can be thematically grouped into data warehouse design, physical data organization, data warehouse processing, and spatio-temporal data warehouses and data mining. The papers in the area of data warehouse design presents novel methods for (semi-)automatic design of DWs and for estimating the size of materialized views. The papers on physical data organization provide new insights into MOLAP storage, probabilistic data management, and bitmap indexing. The papers on data warehouse processing address ETL workflows, real-time DW environments, and the efficient computation of materialized view subsets. Finally, the papers on spatio-temporal data warehouses and data mining expand into new territory by presenting a novel multidimensional model for dynamic spatio-temporal data, a GIS-OLAP system implementation, and a method for discovering unexpected multidimensional sequential rules. Finally, since DOLAP is the premier venue for data warehouse and OLAP research, the program includes a research challenges vision, in the form of a panel with research challenge proposals by four researchers and practitioners.},
  ISBN                     = {978-1-59593-827-5},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Just a proceedings document. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1317331}
}

@Conference{Georgiadis2013,
  Title                    = {Continuous outlier detection in data streams: An extensible framework and state-of-the-art algorithms},
  Author                   = {Georgiadis, D. and Kontaki, M. and Gounaris, A. and Papadopoulos, A. and Tsichlas, K. and Manolopoulos, Y.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Pages                    = {1061-1064},

  Abstract                 = {Anomaly detection is an important data mining task, aiming at the discovery of elements that show significant diversion from the expected behavior; such elements are termed as outliers. One of the most widely employed criteria for determining whether an element is an outlier is based on the number of neighboring elements within a fixed distance (R), against a fixed threshold (k). Such outliers are referred to as distance-based outliers and are the focus of this work. In this demo, we show both an extendible framework for outlier detection algorithms and specific outlier detection algorithms for the demanding case where outlier detection is continuously performed over a data stream. More specifically: i) first we demonstrate a novel flavor of an open-source publicly available tool for Massive Online Analysis (MOA) that is endowed with capabilities to encapsulate algorithms that continuously detect outliers and ii) second, we present four online outlier detection algorithms. Two of these algorithms have been designed by the authors of this demo, with a view to improving on key aspects related to outlier mining, such as running time, flexibility and space requirements. Copyright Ã‚Â© 2013 ACM.},
  Affiliation              = {Aristotle University, Thessaloniki, Greece},
  Author_keywords          = {Continuous processing; Data streams; Metric space; Outlier detection},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Georgiadis2013a. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880542160&partnerID=40&md5=65361676053c0277754c8593b31d3196}
}

@InProceedings{Georgiadis2013a,
  Title                    = {{Continuous outlier detection in data streams}},
  Author                   = {Georgiadis, Dimitrios and Kontaki, Maria and Gounaris, Anastasios and Papadopoulos, Apostolos N. and Tsichlas, Kostas and Manolopoulos, Yannis},
  Booktitle                = {Proceedings of the 2013 international conference on Management of data - SIGMOD '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = jun,
  Pages                    = {1061},
  Publisher                = {ACM Press},

  Abstract                 = {Anomaly detection is an important data mining task, aiming at the discovery of elements that show significant diversion from the expected behavior; such elements are termed as outliers. One of the most widely employed criteria for determining whether an element is an outlier is based on the number of neighboring elements within a fixed distance (R), against a fixed threshold (k). Such outliers are referred to as distance-based outliers and are the focus of this work. In this demo, we show both an extendible framework for outlier detection algorithms and specific outlier detection algorithms for the demanding case where outlier detection is continuously performed over a data stream. More specifically: i) first we demonstrate a novel flavor of an open-source publicly available tool for Massive Online Analysis (MOA) that is endowed with capabilities to encapsulate algorithms that continuously detect outliers and ii) second, we present four online outlier detection algorithms. Two of these algorithms have been designed by the authors of this demo, with a view to improving on key aspects related to outlier mining, such as running time, flexibility and space requirements.},
  Doi                      = {10.1145/2463676.2463691},
  ISBN                     = {9781450320375},
  Keywords                 = {continuous processing,data streams,metric space,outlier detection},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Anomaly detection. . One of the most widely employed criteria for determining whether an element is an outlier uses neighboring distance. Adapt some software, and test 4 algorhtms, two of these algorithms have been designed by the authors. Approved 1,2,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2463676.2463691}
}

@Misc{Georgiadis,
  Title                    = {{Continuous Outlier Detection in Data Streams: An Extensible Framework and State-Of-The-Art Algorithms}},

  Author                   = {Georgiadis, Dimitrios and Papadopoulos, Apostolos and Kontaki, Maria and Tsichlas, Kostas and Gounaris, Anastasios and Manolopoulos, Yannis},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Georgiadis2013a. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.299.8458}
}

@Conference{Gillick2010a,
  Title                    = {Clutter-adaptive visualization for mobile data mining},
  Author                   = {Gillick, B.a and AlTaiar, H.a and Krishnaswamy, S.a and Liono, J.a and Nicoloudis, N.a and Sinha, A.a and Zaslavsky, A.a and Gaber, M.M.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)3},
  Pages                    = {1381-1384},

  Abstract                 = {There is an emerging focus on real-time data stream analysis on mobile devices. While many mobile data stream mining algorithms have been developed in recent times, generic and scalable visualization techniques have not been presented. This paper presents the demonstration of our innovative clutter-adaptive cluster visualization technique for mobile devices. We have fully implemented this technique on the Google Android platform and provide demonstrations for different datasets: location (both real and synthetic), and stock-market (real). Ã‚Â© 2010 IEEE.},
  Affiliation              = {Monash University, Melbourne, Australia; School of Computing, University of Portsmouth, Portsmouth, United Kingdom},
  Art_number               = {5693458},
  Author_keywords          = {Mobile data mining; Visualization},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents the demonstration of our innovative clutter-adaptive cluster visualization technique for mobile devices Approved, doubt about machine learning 1,2},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79951733730&partnerID=40&md5=02534072adc4ae96357ff8476225d766}
}

@InProceedings{Gillick2010,
  Title                    = {{Clutter-Adaptive Visualization for Mobile Data Mining}},
  Author                   = {Gillick, Brett and AlTaiar, Hasnain and Krishnaswamy, Shonali and Liono, Jonathan and Nicoloudis, Nicholas and Sinha, Abhijat and Zaslavsky, Arkady and Gaber, Mohamed Medhat},
  Booktitle                = {2010 IEEE International Conference on Data Mining Workshops},
  Year                     = {2010},
  Month                    = dec,
  Pages                    = {1381--1384},
  Publisher                = {IEEE},

  Abstract                 = {There is an emerging focus on real-time data stream analysis on mobile devices. While many mobile data stream mining algorithms have been developed in recent times, generic and scalable visualization techniques have not been presented. This paper presents the demonstration of our innovative clutter-adaptive cluster visualization technique for mobile devices. We have fully implemented this technique on the Google Android platform and provide demonstrations for different datasets: location (both real and synthetic), and stock-market (real).},
  Doi                      = {10.1109/ICDMW.2010.134},
  ISBN                     = {978-1-4244-9244-2},
  Keywords                 = {Google Android platform,Mobile Data Mining,Visualization,clutter-adaptive visualization,data analysis,data mining,data visualisation,generic visualization techniques,innovative clutter-adaptive cluster visualization ,mobile computing,mobile data mining,mobile data stream mining algorithms,mobile devices,real-time data stream analysis,real-time systems,scalable visualization techniques},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gillick2010a. Discarded.},
  Shorttitle               = {Data Mining Workshops (ICDMW), 2010 IEEE Internati},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5693458}
}

@Conference{Gillick2006,
  Title                    = {Visualisation of fuzzy classification of data elements in ubiquitous data stream mining},
  Author                   = {Gillick, B. and Krishnaswamy, S. and Gaber, M.M. and Zaslavsky, A.},
  Year                     = {2006},
  Note                     = {cited By (since 1996)4},
  Pages                    = {29-38},

  Abstract                 = {Ubiquitous data mining (UDM) allows data mining operations to be performed on continuous data streams using resource limited devices. Visualisation is an essential tool to assist users in understanding and interpreting data mining results and to aide the user in directing further mining operations. However, there are currently no on-line real-time visualisation tools to complement the UDM algorithms. In this paper we investigate the use of visualisation techniques, within an on-line real-time visualisation framework, in order to enhance UDM result interpretation on handheld devices. We demonstrate a proof of concept implementation for visualising degree of membership of data elements to clusters produced using fuzzy logic algorithms.},
  Affiliation              = {Faculty of Information Technology, Monash University, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 3rd International Workshop on Ubiquitous Computing, IWUC 2006 - In Conjunction with ICEIS 2006},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Data mining visualization on mobiel devices. There are currently no on-line real-time visualisation tools to complement the algorithms that allow mining on continous streams using resource limited devices. In this paper we investigate the use of visualisation techniques, within an on-line real-time visualisation framework, in order to enhance UDM result interpretation on handheld device. Visualization, not really dealing with a particular problem. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77957918835&partnerID=40&md5=3e0860673a2363805244c6113b14d10b}
}

@Misc{Golab,
  Title                    = {{Consistency in a Stream Warehouse}},

  Author                   = {Golab, Lukasz and Johnson, Theodore},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A stream warehouse is a Data Stream Management System (DSMS) that stores a very long history, e.g. years or decades; or equivalently a data warehouse that is continuously loaded. A stream warehouse enables queries that seamlessly range from realtime alerting and diagnostics to long-term data mining. However, continuously loading data from many different and uncontrolled sources into a real-time stream warehouse introduces a new consistency problem: users want results in as timely a fashion as possible, but “stable ” results often require lengthy synchronization delays. In this paper we develop a theory of temporal consistency for stream warehouses that allows for multiple consistency levels. We show how to restrict query answers to a given consistency level and we show how warehouse maintenance can be optimized using knowledge of the consistency levels required by materialized views.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Consistency is problematic when users want stable results from stream warehouse - but stability often require lengthy sync delay. In this paper we develop a theory of temporal consistency for stream warehouses that allows for multiple consistency levels. Data consistency, no ML.. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.229.2514}
}

@Conference{Golab2011,
  Title                    = {Consistency in a stream warehouse},
  Author                   = {Golab, L. and Johnson, T.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)10},
  Pages                    = {114-122},

  Abstract                 = {A stream warehouse is a Data Stream Management System (DSMS) that stores a very long history, e.g. years or decades; or equivalently a data warehouse that is continuously loaded. A stream warehouse enables queries that seamlessly range from realtime alerting and diagnostics to long-term data mining. However, continuously loading data from many different and uncontrolled sources into a real-time stream warehouse introduces a new consistency problem: users want results in as timely a fashion as possible, but "stable" results often require lengthy synchronization delays. In this paper we develop a theory of temporal consistency for stream warehouses that allows for multiple consistency levels. We show how to restrict query answers to a given consistency level and we show how warehouse maintenance can be optimized using knowledge of the consistency levels required by materialized views.},
  Affiliation              = {AT and T Labs - Research, 180 Park Avenue, Florham Park, NJ 07932, United States},
  Document_type            = {Conference Paper},
  Journal                  = {CIDR 2011 - 5th Biennial Conference on Innovative Data Systems Research, Conference Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Golab. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053547427&partnerID=40&md5=7bfba7d38a1ec2d1c8db5095b8feac65}
}

@Article{Gondal2013,
  Title                    = {Regularly frequent patterns mining from sensor data stream},
  Author                   = {Gondal, I. and Kamruzzaman, J.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 2},
  Pages                    = {417-424},
  Volume                   = {8227 LNCS},

  Abstract                 = {Mining interesting and useful knowledge from the huge amount of data gathered in wireless sensor networks is a challenging task. Works reported in literature use support metric-based sensor association rule which employs the occurrence frequency of patterns as criteria. Such criteria may not be appropriate for finding significant patterns. Moreover, temporal regularity in occurrence behavior should be considered as another important measure for assessing the importance of patterns in WSNs. Frequent sensor patterns that occur after regular intervals is called regularly frequent sensor patterns. Even though mining regularly frequent sensor patterns from sensor data stream is extremely important in many real-time applications, no such algorithm has been proposed yet. In this paper, we propose a novel tree structure called Regularly Frequent Sensor Pattern-tree (RSP-tree) and an efficient mining approach for finding regularly frequent sensor patterns from WSNs. Extensive performance analyses show that our technique is time and memory efficient in finding regularly frequent sensor patterns. Ã‚Â© Springer-Verlag 2013.},
  Affiliation              = {Faculty of Information Technology, Monash University, Melbourne, VIC, Australia},
  Author_keywords          = {Data mining; Frequent pattern; Knowledge discovery; Regularly frequent sensor pattern; Wireless sensor networks},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Wireless sensor networks mining. Works reported in literature use support metric-based sensor association rule which employs the occurrence frequency of patterns as criteria. Even though mining regularly frequent sensor patterns from sensor data stream is extremely important in many real-time applications, no such algorithm has been proposed yet. Propose Regularly Frequent Sensor Pattern-tree (RSP-tree) and algorhtm for finding regularly frequent patterns. Extensive performance analyses show that our technique is time and memory efficient in finding regularly frequent sensor patterns. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893377822&partnerID=40&md5=585abf2cfceebf730830e2d76855a465}
}

@InProceedings{Greensmith2006,
  Title                    = {{Dendritic Cells for Anomaly Detection}},
  Author                   = {Greensmith, J. and Twycross, J. and Aickelin, U.},
  Booktitle                = {2006 IEEE International Conference on Evolutionary Computation},
  Year                     = {2006},
  Pages                    = {664--671},
  Publisher                = {IEEE},

  Abstract                 = {Artificial immune systems, more specifically the negative selection algorithm, have previously been applied to intrusion detection. The aim of this research is to develop an intrusion detection system based on a novel concept in immunology, the Danger Theory. Dendritic Cells (DCs) are antigen presenting cells and key to the activation of the human immune system. DCs perform the vital role of combining signals from the host tissue and correlate these signals with proteins known as antigens. In algorithmic terms, individual DCs perform multi-sensor data fusion based on time-windows. The whole population of DCs asynchronously correlates the fused signals with a secondary data stream. The behaviour of human DCs is abstracted to form the DC Algorithm (DCA), which is implemented using an immune inspired framework, libtissue. This system is used to detect context switching for a basic machine learning dataset and to detect outgoing portscans in real-time. Experimental results show a significant difference between an outgoing portscan and normal traffic.},
  Doi                      = {10.1109/CEC.2006.1688374},
  ISBN                     = {0-7803-9487-9},
  Keywords                 = {Application software,Artificial immune systems,Context awareness,Detectors,Distributed control,Humans,Immune system,Intrusion detection,Machine learning,Machine learning algorithms,anomaly detection,artificial immune systems,basic machine learning dataset,context switching,dendritic cells,intrusion detection,negative selection algorithm,outgoing portscans,security of data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Bio inspired Instrusion detection. In algorithmic terms, individual DCs perform multi-sensor data fusion based on time-windows. This system is used to detect context switching for a basic machine learning dataset and to detect outgoing portscans in real-time. Experimental results show a significant difference between an outgoing portscan and normal traffic. Appears to be using ML, in particlar for data fusion based on windows. Approved 1,3,4,6},
  Shorttitle               = {Evolutionary Computation, 2006. CEC 2006. IEEE Con},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1688374}
}

@Conference{Greensmith2006a,
  Title                    = {Dendritic cells for anomaly detection},
  Author                   = {Greensmith, J. and Twycross, J. and Aickelin, U.},
  Year                     = {2006},
  Note                     = {cited By (since 1996)42},
  Pages                    = {664-671},

  Abstract                 = {Artificial immune systems, more specifically the negative selection algorithm, have previously been applied to intrusion detection. The aim of this research is to develop an intrusion detection system based on a novel concept in immunology, the Danger Theory. Dendritic Cells (DCs) are antigen presenting cells and key to the activation of the human immune system. DCs perform the vital role of combining signals from the host tissue and correlate these signals with proteins known as antigens. In algorithmic terms, individual DCs perform multi-sensor data fusion based on time-windows. The whole population of DCs asynchronously correlates the fused signals with a secondary data stream. The behaviour of human DCs is abstracted to form the DC Algorithm (DCA), which is implemented using an immune inspired framework, libtissue. This system is used to detect context switching for a basic machine learning dataset and to detect outgoing portscans in real-time. Experimental results show a significant difference between an outgoing portscan and normal traffic. Ã‚Â© 2006 IEEE.},
  Affiliation              = {School of Computer Science, University of Nottingham, NG8 1BB, United Kingdom},
  Art_number               = {1688374},
  Document_type            = {Conference Paper},
  Journal                  = {2006 IEEE Congress on Evolutionary Computation, CEC 2006},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Greensmith2006. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34547278626&partnerID=40&md5=8c0e400f5ea0c19209c2949a39758479}
}

@Conference{Gu2008a,
  Title                    = {Toward predictive failure management for distributed stream processing systems},
  Author                   = {Gu, X.a and Papadimitriou, S.b and Yu, P.S.c and Chang, S.-P.b },
  Year                     = {2008},
  Note                     = {cited By (since 1996)6},
  Pages                    = {825-832},

  Abstract                 = {Distributed stream processing systems (DSPSs) have many important applications such as sensor data analysis, network security, and business intelligence. Failure management is essential for DSPSs that often require highlyavailable system operations. In this paper, we explore a new predictive failure management approach that employs online failure prediction to achieve more efficient failure management than previous reactive or proactive failure management approaches. We employ light-weight streambased classification methods to perform online failure forecast. Based on the prediction results, the system can take differentiated failure preventions on abnormal components only. Our failure prediction model is tunable, which can achieve a desired tradeoff between failure penalty reduction and prevention cost based on a user-defined reward function. To achieve low-overhead online learning, we propose adaptive data stream sampling schemes to adaptively adjust measurement sampling rates based on the states of monitored components, and maintain a limited size of historical training data using reservoir sampling. We have implemented an initial prototype of the predictive failure management framework within the IBM System S distributed stream processing system. Experiment results show that our system can achieve more efficient failure management than conventional reactive and proactive approaches, while imposing low overhead to the DSPS. Ã‚Â© 2008 IEEE.},
  Affiliation              = {North Carolina State Univ.; IBM Research; U. of Illinois, Chicago, United States},
  Art_number               = {4595959},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - The 28th International Conference on Distributed Computing Systems, ICDCS 2008},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gu2008. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-51849153220&partnerID=40&md5=b280f94b798662a2dfc9173ac61496bd}
}

@InProceedings{Gu2008,
  Title                    = {{Toward Predictive Failure Management for Distributed Stream Processing Systems}},
  Author                   = {Gu, Xiaohui and Papadimitriou, Spiros and Yu, Philip S. and Chang, Shu-Ping},
  Booktitle                = {2008 The 28th International Conference on Distributed Computing Systems},
  Year                     = {2008},
  Month                    = jun,
  Pages                    = {825--832},
  Publisher                = {IEEE},

  Abstract                 = {Distributed stream processing systems (DSPSs) have many important applications such as sensor data analysis, network security, and business intelligence. Failure management is essential for DSPSs that often require highly-available system operations. In this paper, we explore a new predictive failure management approach that employs online failure prediction to achieve more efficient failure management than previous reactive or proactive failure management approaches. We employ light-weight stream-based classification methods to perform online failure forecast. Based on the prediction results, the system can take differentiated failure preventions on abnormal components only. Our failure prediction model is tunable, which can achieve a desired tradeoff between failure penalty reduction and prevention cost based on a user-defined reward function. To achieve low-overhead online learning, we propose adaptive data stream sampling schemes to adaptively adjust measurement sampling rates based on the states of monitored components, and maintain a limited size of historical training data using reservoir sampling. We have implemented an initial prototype of the predictive failure management framework within the IBM System S distributed stream processing system. Experiment results show that our system can achieve more efficient failure management than conventional reactive and proactive approaches, while imposing low overhead to the DSPS.},
  Doi                      = {10.1109/ICDCS.2008.34},
  ISSN                     = {1063-6927},
  Keywords                 = {Condition monitoring,Cost function,Data Stream Processing,Data analysis,Data security,Failure Prediction,Fault Tolerance,IBM System S distributed stream processing systems,Intelligent networks,Intelligent sensors,Predictive models,Sampling methods,Sensor systems and applications,Size measurement,System Mining,adaptive data stream sampling schemes,business intelligence,continuous query processing,distributed processing,failure penalty prevention,failure penalty reduction,fault tolerant computing,light-weight stream-based classification methods,measurement sampling rates,network security,online failure prediction,predictive failure management,query processing,reservoir sampling,sampling methods,sensor data analysis},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Fail management for distributed stream processing systems. We explore a new predictive failure management approach that employs online failure prediction to achieve more efficient failure management than previous approaches. We employ light-weight stream-based classification methods to perform online failure forecast. Experiment results show that our system can achieve more efficient failure management than conventional approaches. Approved. 1,2,3,4,5,6},
  Shorttitle               = {Distributed Computing Systems, 2008. ICDCS '08. Th},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4595959}
}

@InProceedings{Gu2009,
  Title                    = {{Online Anomaly Prediction for Robust Cluster Systems}},
  Author                   = {Gu, Xiaohui and Wang, Haixun},
  Booktitle                = {2009 IEEE 25th International Conference on Data Engineering},
  Year                     = {2009},
  Month                    = mar,
  Pages                    = {1000--1011},
  Publisher                = {IEEE},

  Abstract                 = {In this paper, we present a stream-based mining algorithm for online anomaly prediction. Many real-world applications such as data stream analysis requires continuous cluster operation. Unfortunately, today's large-scale cluster systems are still vulnerable to various software and hardware problems. System administrators are often overwhelmed by the tasks of correcting various system anomalies such as processing bottlenecks (i.e., full stream buffers), resource hot spots, and service level objective (SLO) violations. Our anomaly prediction scheme raises early alerts for impending system anomalies and suggests possible anomaly causes. Specifically, we employ Bayesian classification methods to capture different anomaly symptoms and infer anomaly causes. Markov models are introduced to capture the changing patterns of different measurement metrics. More importantly, our scheme combines Markov models and Bayesian classification methods to predict when a system anomaly will appear in the foreseeable future and what are the possible anomaly causes. To the best of our knowledge, our work provides the first stream-based mining algorithm for predicting system anomalies. We have implemented our approach within the IBM System S distributed stream processing cluster, and conducted case study experiments using fully implemented distributed data analysis applications processing real application workloads. Our experiments show that our approach efficiently predicts and diagnoses several bottleneck anomalies with high accuracy while imposing low overhead to the cluster system.},
  Doi                      = {10.1109/ICDE.2009.128},
  ISBN                     = {978-1-4244-3422-0},
  ISSN                     = {1084-4627},
  Keywords                 = {Application software,Bayes methods,Bayesian classification methods,Bayesian methods,Clustering algorithms,Continuous time systems,Data analysis,Data engineering,Hardware,Large-scale systems,Markov models,Markov processes,Predictive models,Robustness,data analysis,data stream analysis,distributed processing,online anomaly prediction,pattern classification,resource hot spots,robust cluster systems,security of data,service level objective violations,stream-based mining algorithm,the IBM System S distributed stream processing clu},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Very similar to Gu2008, but not exactly. Included just in case. We present a stream-based mining algorithm for online anomaly prediction. To the best of our knowledge, our work provides the first stream-based mining algorithm for predicting system anomalies. Our experiments show that our approach efficiently predicts and diagnoses several bottleneck anomalies with high accuracy while imposing low overhead to the cluster system. Approved 1,2,3,4,5,6},
  Shorttitle               = {Data Engineering, 2009. ICDE '09. IEEE 25th Intern},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4812472}
}

@Conference{Gu2009a,
  Title                    = {Online anomaly prediction for robust cluster systems},
  Author                   = {Gu, X.a and Wang, H.b },
  Year                     = {2009},
  Note                     = {cited By (since 1996)9},
  Pages                    = {1000-1011},

  Abstract                 = {In this paper, we present a stream-based mining algorithm for online anomaly prediction. Many real-world applications such as data stream analysis requires continuous cluster operation. Unfortunately, today 's large-scale cluster systems are still vulnerable to various software and hardware problems. System administrators are often overwhelmed by the tasks of correcting various system anomalies such as processing bottlenecks (i.e., full stream buffers), resource hot spots, and service level objective (SLO) violations. Our anomaly prediction scheme raises early alerts for impending system anomalies and suggests possible anomaly causes. Specifically, we employ Bayesian classification methods to capture different anomaly symptoms and infer anomaly causes. Markov models are introduced to capture the changing patterns of different measurement metrics. More importantly, our scheme combines Markov models and Bayesian classification methods to predict when a system anomaly will appear in the foreseeable future and what are the possible anomaly causes. To the best of our knowledge, our work provides the first stream-based mining algorithm for predicting system anomalies. We have implemented our approach within the IBM System S distributed stream processing cluster, and conducted case study experiments using fully implemented distributed data analysis applications processing real application workloads. Our experiments show that our approach efficiently predicts and diagnoses several bottleneck anomalies with high accuracy while imposing low overhead to the cluster system. Ã‚Â© 2009 IEEE.},
  Affiliation              = {North Carolina State University, Raleigh, NC 27695, United States; IBM T. J. Watson Research Center, Hawthorne, NY 10532, United States},
  Art_number               = {4812472},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gu2009. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-67649637304&partnerID=40&md5=c4a07b87b74515cf76828e2333cd2eeb}
}

@Article{Gu2009b,
  Title                    = {{Online Anomaly Prediction for Robust Cluster Systems}},
  Author                   = {Gu, Xiaohui and Wang, Haixun},
  Journal                  = {IN PROC. OF ICDE},
  Year                     = {2009},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In this paper, we present a stream-based mining algorithm for online anomaly prediction. Many real-world applications such as data stream analysis requires continuous cluster operation. Unfortunately, today’s large-scale cluster systems are still vulnerable to various software and hardware problems. System administrators are often overwhelmed by the tasks of correcting various system anomalies such as processing bottlenecks (i.e., full stream buffers), resource hot spots, and service level objective (SLO) violations. Our anomaly prediction scheme raises early alerts for impending system anomalies and suggests possible anomaly causes. Specifically, we employ Bayesian classification methods to capture different anomaly symptoms and infer anomaly causes. Markov models are introduced to capture the changing patterns of different measurement metrics. More importantly, our scheme combines Markov models and Bayesian classification methods to predict when a system anomaly will appear in the foreseeable future and what are the possible anomaly causes. To the best of our knowledge, our work provides the first stream-based mining algorithm for predicting system anomalies. We have implemented our approach within the IBM System S distributed stream processing cluster, and conducted case study experiments using fully implemented distributed data analysis applications processing real application workloads. Our experiments show that our approach efficiently predicts and diagnoses several bottleneck anomalies with high accuracy while imposing low overhead to the cluster system.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Gu2009. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.403.9022}
}

@InProceedings{GLTC2007,
  Title                    = {{A single pass algorithm of finding frequent vibrated items over online data streams}},
  Author                   = {{Guanling Lee} and {Qiao-Tzu Chen}},
  Booktitle                = {2007 2nd International Conference on Digital Information Management},
  Year                     = {2007},
  Pages                    = {206--211},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Data streams are data items generated unbounded and continuously. To detect the vibration of data item s quantity, a single pass algorithm is proposed for mining vibrated items over online data streams in this paper. The change of data item can be reported at once by measuring its vibrated slope. Not only the change of data item will be detected, the period in which the data item is frequent vibrated is also reported. Moreover, a set of simulations is performed to show the benefit of our approach.},
  Doi                      = {10.1109/ICDIM.2007.4444224},
  ISBN                     = {978-1-4244-1475-8},
  Keywords                 = {Change detection algorithms,Computer science,Counting circuits,Data engineering,Data mining,Frequency conversion,Frequency estimation,Marketing and sales,Monitoring,Vibration measurement,data mining,frequent vibrated items,online data streams,single pass algorithm,vibrated items mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Mining vibrated items over online data streams - items which frequency vibrate. Moreover, a set of simulations is performed to show the benefit of our approach. Approved 3},
  Shorttitle               = {Digital Information Management, 2007. ICDIM '07. 2},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4444224}
}

@Misc{Guha2005,
  Title                    = {{Data Visualization and Mining using the GPU}},

  Author                   = {Guha, Sudipto and Krishnan, Shankar and Venkatasubramanian, Suresh},
  Year                     = {2005},

  __markedentry            = {[Alexander:]},
  Abstract                 = {An exciting development in the computing industry has been the emergence of graphics processing units (the GPU) as a fast general purpose co-processor. Initially designed for gaming applications, todays GPUs demonstrate impressive computing power and high levels of parallelism and are now being used for a variety of applications far removed from traditional graphics rendering settings. Perhaps the most powerful use of the GPU has been in visualization, which couples the raw computing power of the GPU with its extensive capabilities for rendering scenes. The GPU provides the required computing power and real-time interactive rendering capabilities and there are now GPU-assisted algorithms for many fundamental problems in data visualization and analysis, including such basic primitives as matrix operations, FFTs, wavelet transforms, clustering and mining data streams. This is an exciting and fast developing area, and the tools and technique are now mature enough that researchers with no experience in using the GPU can use it to develop new data mining tools. The purpose of this tutorial is to introduce the KDD audience to the GPU and the programming model it represents, describe the ways in which one can program the GPU, and demonstrate a set of data mining primitives that have been implemented effectively on the GPU.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Perhaps the most powerful use of the GPU has been in visualization. There are now GPU-assisted algorithms for many fundamental problems in data visualization and analysis, including such basic primitives as matrix operations, FFTs, wavelet transforms, clustering and mining data streams.The purpose of this tutorial is to introduce the KDD audience to the GPU and the programming model it represent. No novelty, no ML. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.95.1701}
}

@InProceedings{Guo2011b,
  Title                    = {{Mining frequent patterns across multiple data streams}},
  Author                   = {Guo, Jing and Zhang, Peng and Tan, Jianlong and Guo, Li},
  Booktitle                = {Proceedings of the 20th ACM international conference on Information and knowledge management - CIKM '11},
  Year                     = {2011},

  Address                  = {New York, New York, USA},
  Month                    = oct,
  Pages                    = {2325},
  Publisher                = {ACM Press},

  Abstract                 = {Mining frequent patterns from data streams has drawn increasing attention in recent years. However, previous mining algorithms were all focused on a single data stream. In many emerging applications, it is of critical importance to combine multiple data streams for analysis. For example, in real-time news topic analysis, it is necessary to combine multiple news report streams from dierent media sources to discover collaborative frequent patterns which are reported frequently in all media, and comparative frequent patterns which are reported more frequently in a media than others. To address this problem, we propose a novel frequent pattern mining algorithm Hybrid-Streaming, H-Stream for short. H-Stream builds a new Hybrid-Frequent tree to maintain historical frequent and potential frequent itemsets from all data streams, and incrementally updates these itemsets for efficient collaborative and comparative pattern mining. Theoretical and empirical studies demonstrate the utility of the proposed method.},
  Doi                      = {10.1145/2063576.2063957},
  ISBN                     = {9781450307178},
  Keywords                 = {data stream mining,frequent pattern mining,multiple data streams},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {However, previous mining algorithms were all focused on a single data stream. We propose a novel frequent pattern mining algorithm Hybrid-Streaming. H-Stream builds a new Hybrid-Frequent tree to maintain historical frequent and potential frequent itemsets from all data streams, and incrementally updates these itemsets for efficient collaborative and comparative pattern mining. Theoretical and empirical studies demonstrate the utility of the proposed method. Approved 1,2,3,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2063576.2063957}
}

@Conference{Guo2011a,
  Title                    = {Mining frequent patterns across multiple data streams},
  Author                   = {Guo, J.a b and Zhang, P.a and Tan, J.a and Guo, L.a },
  Year                     = {2011},
  Note                     = {cited By (since 1996)2},
  Pages                    = {2325-2328},

  Abstract                 = {Mining frequent patterns from data streams has drawn increasing attention in recent years. However, previous mining algorithms were all focused on a single data stream. In many emerging applications, it is of critical importance to combine multiple data streams for analysis. For example, in real-time news topic analysis, it is necessary to combine multiple news report streams from dierent media sources to discover collaborative frequent patterns which are reported frequently in all media, and comparative frequent patterns which are reported more frequently in a media than others. To address this problem, we propose a novel frequent pattern mining algorithm Hybrid-Streaming, H-Stream for short. H-Stream builds a new Hybrid-Frequent tree to maintain historical frequent and potential frequent itemsets from all data streams, and incrementally updates these itemsets for efficient collaborative and comparative pattern mining. Theoretical and empirical studies demonstrate the utility of the proposed method. Ã‚Â© 2011 ACM.},
  Affiliation              = {Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Beijing University of Posts and Telecommunications, Beijing, 100876, China},
  Author_keywords          = {data stream mining; frequent pattern mining; multiple data streams},
  Document_type            = {Conference Paper},
  Journal                  = {International Conference on Information and Knowledge Management, Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Guo2011b. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-83055161487&partnerID=40&md5=2d2dcc653940b3ac163d012774452569}
}

@Article{Guo2011,
  Title                    = {Approximate mining of global closed frequent itemsets over data streams },
  Author                   = {Lichao Guo and Hongye Su and Yu Qu},
  Journal                  = {Journal of the Franklin Institute },
  Year                     = {2011},
  Number                   = {6},
  Pages                    = {1052 - 1081},
  Volume                   = {348},

  Abstract                 = {This paper focuses on how to efficiently find the global Approximate Closed Frequent Itemsets (ACFIs) over streams. To achieve this purpose over a multiple, continuous, rapid and time-varying data stream, a fast, incremental, real-time and little-memory-cost algorithm should be regarded. Based on the max-frequency window model, a Max-Frequency Pattern Tree (MFP-Tree) structure is established to maintain summary information over the global stream. Subsequently, a novel algorithm Generating Global Approximate Closed Frequent Itemsets on Max-Frequency Window model (GGACFI-MFW) is proposed to update the MFP-Tree with high efficiency. The case studies show the efficiency and effectiveness of the proposed approach.},
  Doi                      = {http://dx.doi.org/10.1016/j.jfranklin.2011.04.006},
  ISSN                     = {0016-0032},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Finding global Approximate Closed Frequent Itemsets in streams. Max-Frequency Pattern Tree (MFP-Tree) structure is established to maintain summary information over the global stream. (GGACFI-MFW) is proposed to update the MFP-Tree with high efficiency. The case studies show the efficiency and effectiveness of the proposed approach. Approved 1,3,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S001600321100086X}
}

@InProceedings{Guo2009,
  Title                    = {{A New Algorithm for Mining Global Frequent Itemsets in a Stream}},
  Author                   = {Guo, Lichao and Su, Hongye and Qu, Yu},
  Booktitle                = {2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery},
  Year                     = {2009},
  Pages                    = {232--238},
  Publisher                = {IEEE},
  Volume                   = {5},

  Abstract                 = {To find global frequent itemsets in a multiple, continuous, rapid and time-varying data stream, a fast, incremental, real-time, and little-memory-cost algorithm should be used. Based on the max-frequency window model, a BHS summary structure and a novel algorithm called GGFI-MFW are proposed. It merely updates the summaries for subsets of the data new arrived and could directly generate the max-frequency for a given item set without scanning the whole summary. Experiment results indicate that the proposed algorithm could efficiently find global frequent itemsets over a data stream with a small memory and perform overwhelming superiority for a large number of distinct items.},
  Doi                      = {10.1109/FSKD.2009.265},
  ISBN                     = {978-0-7695-3735-1},
  Keywords                 = {BHS summary structure,Data mining,Frequency measurement,Frequency shift keying,Fuzzy systems,GGFI-MFW,Ice,Industrial control,Itemsets,Marketing and sales,Research and development,data mining,little-memory-cost algorithm,max-frequency window model,mining global frequent itemsets,time-varying data stream},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {a BHS summary structure and a novel algorithm called GGFI-MFW are proposed. Experiment results indicate that the algorithm could efficiently find global frequent itemsets over a data stream with a small memory and perform overwhelming superiority for a large number of distinct items. Very short abstract, does not place itself in research field nor context. 1,3,4,6},
  Shorttitle               = {Fuzzy Systems and Knowledge Discovery, 2009. FSKD },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5360625}
}

@Article{Gupta2010,
  Title                    = {Mining closed itemsets in data stream using formal concept analysis},
  Author                   = {Gupta, A. and Bhatnagar, V. and Kumar, N.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2010},
  Note                     = {cited By (since 1996)5},
  Pages                    = {285-296},
  Volume                   = {6263 LNCS},

  Abstract                 = {Mining of frequent closed itemsets has been shown to be more efficient than mining frequent itemsets for generating non-redundant association rules. The task is challenging in data stream environment because of the unbounded nature and no-second-look characteristics. In this paper, we propose an algorithm, CLICI, for mining all recent closed itemsets in landmark window model of online data stream. The algorithm consists of an online component, which processes the transactions arriving in the stream without candidate generation and updates the synopsis appropriately. The offline component is invoked on demand to mine all frequent closed itemsets. User can explore and experiment by specifying the support threshold dynamically. The synopsis, CILattice, stores all recent closed itemsets in the stream. It is based on Concept Lattice - a core structure of Formal Concept Analysis (FCA). Closed itemsets stored in the form of lattice facilitate generation of non-redundant association rules and is the main motivation behind using lattice based synopsis. Experimental evaluation using synthetic and real life datasets demonstrates the scalablility of the algorithm. Ã‚Â© 2010 Springer-Verlag.},
  Affiliation              = {Department of Computer Science, University of Delhi, India},
  Author_keywords          = {Closed Itemsets; Data Stream; Landmark Window Model Formal Concept Analysis},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We propose an algorithm, CLICI, for mining all recent closed itemsets in landmark window model of online data stream. The algorithm consists of an online component, which processes the transactions arriving in the stream without candidate generation and updates the synopsis appropriately. The offline component is invoked on demand to mine all frequent closed itemsets. User specified threshold. Based on Concept Lattice. Experimental evaluation using synthetic and real life datasets demonstrates the scalablility of the algorithm. Approved 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78049354493&partnerID=40&md5=d4a1bfc17845a7bb1cc512754fd67d1d}
}

@Article{Gupta2012,
  Title                    = {Mining of multiobjective non-redundant association rules in data streams},
  Author                   = {Gupta, A. and Kumar, N. and Bhatnagar, V.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2012},
  Note                     = {cited By (since 1996)1},
  Number                   = {PART 2},
  Pages                    = {73-81},
  Volume                   = {7268 LNAI},

  Abstract                 = {Non-redundant association rule mining requires generation of both closed itemsets and their minimal generators. However, only a few researchers have addressed both the issues for data streams. Further, association rule mining is now considered as multiobjective problem where multiple measures like correlation coefficient, recall, comprehensibility, lift etc can be used for evaluating a rule. Discovery of multiobjective association rules in data streams has not been paid much attention. In this paper, we have proposed a 3-step algorithm for generation of multiobjective non-redundant association rules in data streams. In the first step, an online procedure generates closed itemsets incrementally using state of the art CLICI algorithm and stores the results in a lattice based synopsis. An offline component invokes the proposed genMG and genMAR procedures whenever required. Without generating candidates, genMG computes minimal generators of all closed itemsets stored in the synopsis. Next, genMAR generates multiobjective association rules using non-dominating sorting based on user specified interestingness measures that are computed using the synopsis. Experimental evaluation using synthetic and real life datasets demonstrates the efficiency and scalability of the proposed algorithm. Ã‚Â© 2012 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {Department of Computer Science, University of Delhi, India},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Non-redundant association rule mining requires generation of both closed itemsets and their minimal generators, but only a few researchers have addressed both issues for streams. Association rule mining is now also considered a multiobjective problem, which has not been given much attention. Propose a 3-step algorithm for generation of multiobjective non-redundant association rules mining from streams. Experimental evaluation using synthetic and real life datasets demonstrates the efficiency and scalability of the proposed algorithm. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861048846&partnerID=40&md5=621a10456394af78c05abf57526e1571}
}

@InProceedings{Gupta2009,
  Title                    = {{CHAOS: A Data Stream Analysis Architecture for Enterprise Applications}},
  Author                   = {Gupta, Chetan and Wang, Song and Ari, Ismail and Hao, Ming and Dayal, Umeshwar and Mehta, Abhay and Marwah, Manish and Sharma, Ratnesh},
  Booktitle                = {2009 IEEE Conference on Commerce and Enterprise Computing},
  Year                     = {2009},
  Month                    = jul,
  Pages                    = {33--40},
  Publisher                = {IEEE},

  Abstract                 = {In this paper, we describe the design of our architecture for continuous, heterogeneous analysis over streams, aka CHAOS that combines stream processing, approximation techniques, mining, complex event processing and visualization. CHAOS, with the novel concept of computational stream analysis Cube, provides an effective, scalable platform for near real time processing of business and enterprise streams. We describe our approach with a real data center temperature analysis application.},
  Doi                      = {10.1109/CEC.2009.74},
  ISBN                     = {978-0-7695-3755-9},
  Keywords                 = {Business,CHAOS,Chaos,Computer architecture,Cube,Data Center,Data analysis,Data visualization,Ecosystems,Engines,Information analysis,Information management,Performance analysis,Stream Analysis Architecture,business data processing,complex event processing,computational stream analysis,continuous heterogeneous analysis-over-streams,data analysis,data center temperature analysis,data stream analysis architecture,enterprise applications},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {CHAOS, with the novel concept of computational stream analysis Cube, provides an effective, scalable platform for near real time processing of business and enterprise streams. No ML. Discarded.},
  Shorttitle               = {Commerce and Enterprise Computing, 2009. CEC '09. },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5210817}
}

@Article{Gupta2012a,
  Title                    = {Cloud computing and big data analytics: What is new from databases perspective?},
  Author                   = {Gupta, R. and Gupta, H. and Mohania, M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {42-61},
  Volume                   = {7678 LNCS},

  Abstract                 = {Many industries, such as telecom, health care, retail, pharmaceutical, financial services, etc., generate large amounts of data. Gaining critical business insights by querying and analyzing such massive amounts of data is becoming the need of the hour. The warehouses and solutions built around them are unable to provide reasonable response times in handling expanding data volumes. One can either perform analytics on big volume once in days or one can perform transactions on small amounts of data in seconds. With the new requirements, one needs to ensure the real-time or near real-time response for huge amount of data. In this paper we outline challenges in analyzing big data for both data at rest as well as data in motion. For big data at rest we describe two kinds of systems: (1) NoSQL systems for interactive data serving environments; and (2) systems for large scale analytics based on MapReduce paradigm, such as Hadoop, The NoSQL systems are designed to have a simpler key-value based data model having in-built sharding, hence, these work seamlessly in a distributed cloud based environment. In contrast, one can use Hadoop based systems to run long running decision support and analytical queries consuming and possible producing bulk data. For processing data in motion, we present use-cases and illustrative algorithms of data stream management system (DSMS). We also illustrate applications which can use these two kinds of systems to quickly process massive amount of data. Ã‚Â© Springer-Verlag 2012.},
  Affiliation              = {IBM Research, India},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Big data: The warehouses and solutions built around them are unable to provide reasonable response times in handling expanding data volumes, but we need it. In this paper we outline challenges in analyzing big data for both data at rest as well as data in motion. Overview of infrastructure. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84871552513&partnerID=40&md5=aa76faa11534cb87dbd42569caf27b46}
}

@Conference{Haghighat2013,
  Title                    = {Using big data and smart field technology for detecting leakage in a CO2 storage project},
  Author                   = {Haghighat, S.A. and Mohaghegh, S.D. and Gholami, V. and Shahkarami, A. and Moreno, D.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {815-821},
  Volume                   = {1},

  Abstract                 = {Smart Fields are distinguished with two characteristics: Big Data and Real-Time access. A small smart field with only ten wells can generate more than a billion data points every year. This data is streamed in real-time while being stored in data historians. The challenge for operating a smart field is to be able to process this massive amount of information in ways that can be useful in reservoir management and relevant operations. In this paper we introduce a technology for processing and utilization of data generated in a smart field. The project is a CO2 storage demonstration at Citronelle Dome, Alabama and the objective is to use smart field technology to build a real-time, long-term, CO2 Intelligent Leakage Detection System (ILDS). The main concern for geologic CO2 sequestration is the capability of the underground carbon dioxide storage to confine and sustain the injected CO2 for very long time. If a leakage from a geological sink occurs, it is crucial to find the approximate location and amount of the leak in order to take on proper remediation activity. To help accommodate CO 2 leak detection, two PDGs (Permanent Down-hole Gauges) have been installed in the observation well. A reservoir simulation model for CO 2 sequestration at Citronelle Dome was developed. Multiple scenarios of CO2 leakage are modeled and high frequency pressure data from the PDGs in the observation well are collected. The complexity of the pressure signal behavior and the reservoir model makes the use of inverse solution of analytical models impractical. Therefore an alternate solution is developed for the ILDS, based on Machine Learning. High Frequency Data Streams are processed in real-time, summarized (by Descriptive Statistics) and transformed into a format appropriate for pattern recognition technology. Successful detection of location and amount of CO2 leaking from the reservoir using the real-time data streams demonstrates the power of pattern recognition and machine learning as a reservoir and operational management tool for smart fields. Copyright 2013, Society of Petroleum Engineers.},
  Affiliation              = {West Virginia University, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - SPE Annual Technical Conference and Exhibition},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Detecting leakage in CO2 storage. Multiple scenarios of CO2 leakage are modeled and high frequency pressure data from the PDGs in the observation well are collected. The complexity of the pressure signal behavior and the reservoir model makes the use of inverse solution of analytical models impractical. An alternate solution is developed for the ILDS, based on Machine Learning. Successful detection of location and amount of CO2 leaking from the reservoir using the real-time data streams demonstrates the power of pattern recognition and machine learning. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84894200920&partnerID=40&md5=12a3440df69dc3783eaeb923687b934e}
}

@Article{Haghighi2010,
  Title                    = {Situation-aware adaptive visualization for sensory data stream mining},
  Author                   = {Haghighi, P.D. and Gillick, B. and Krishnaswamy, S. and Gaber, M.M. and Zaslavsky, A.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2010},
  Note                     = {cited By (since 1996)1},
  Pages                    = {43-58},
  Volume                   = {5840 LNCS},

  Abstract                 = {With the emergence of ubiquitous data mining and recent advances in mobile communications, there is a need for visualization techniques to enhance the user-interactions, real-time decision making and comprehension of the results of mining algorithms. In this paper we propose a novel architecture for situation-aware adaptive visualization that applies intelligent visualization techniques to data stream mining of sensory data. The proposed architecture incorporates fuzzy logic principles for modeling and reasoning about context/situations and performs gradual adaptation of data mining and visualization parameters according to the occurring situations. A prototype of the architecture is implemented and described in the paper through a real-world scenario in the area of healthcare monitoring. Ã‚Â© 2010 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {Centre for Distributed Systems and Software Engineering, Monash University, Caulfield Campus, 900 Dandenong Rd, Caulfield East, VIC 3145, Australia},
  Author_keywords          = {Context-aware; Data Stream Mining; Fuzzy logic; Visualization},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Haghighi. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77957889701&partnerID=40&md5=644f507033f43491b3596a7c4f27c071}
}

@Article{Haghighi2013,
  Title                    = {Open Mobile Miner: A Toolkit for Building Situation-Aware Data Mining Applications},
  Author                   = {Haghighi, P.D.a and Krishnaswamy, S.a and Zaslavsky, A.b and Gaber, M.M.c and Sinha, A.a and Gillick, B.a },
  Journal                  = {Journal of Organizational Computing and Electronic Commerce},
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Number                   = {3},
  Pages                    = {224-248},
  Volume                   = {23},

  Abstract                 = {In organizational computing and information systems, data mining techniques have been widely used for analyzing customer behavior and discovering hidden patterns. Mobile Data Mining is the process of intelligently analyzing continuous data streams on mobile devices. The use of mobile data mining for real-time business intelligence applications can be greatly advantageous. Past research has shown that resource-aware adaptation of data stream mining can significantly improve the continuity of data mining operations in mobile environments. The key underlying premise is that by varying the accuracy of the analysis process in accordance with changing available resource levels, the longevity and continuity of mobile data mining applications is ensured. In this article we qualitatively extend the notion of resource-aware adaptation of mobile data mining to holistically enable situation-awareness feature for user applications. We then present a novel generic toolkit that enables building situation and resource-aware mobile data mining applications and describe along with underlying theoretical foundations of resource and situation criticality, awareness and adaptation, which are entirely transparent and hidden from the user. The Open Mobile Miner (OMM) toolkit builds on our research for performing adaptive analysis of data streams on mobile/embedded devices. Finally, we describe a mobile health monitoring application as a case study and discuss the results of our conducted experimental evaluation which demonstrate the adaptation transparency and easy use of OMM for building mobile data mining applications such as stock market monitoring and real estate data analysis. Ã‚Â© 2013 Copyright Taylor & Francis Group, LLC.},
  Affiliation              = {Faculty of Information Technology, Monash University, Melbourne, Australia; CSIRO, Canberra, Australia; School of Computing, University of Portsmouth, Hampshire, United Kingdom},
  Author_keywords          = {adaptation model; context awareness; data stream mining; e-commerce applications; mobile computing; ubiquitous computing},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Past research has shown that resource-aware adaptation of data stream mining can significantly improve the continuity of data mining operations in mobile environments. In this article we qualitatively extend the notion of resource-aware adaptation of mobile data mining to holistically enable situation-awareness for user applications. Finally, we describe a mobile health monitoring application as a case study and discuss the results of our conducted experimental evaluation which demonstrate the adaptation transparency and easy use of Open Mobile Miner. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880645305&partnerID=40&md5=f3d7effcd383324f726bf905830754f7}
}

@InProceedings{Haghighi2009,
  Title                    = {{Mobile Data Mining for Intelligent Healthcare Support}},
  Author                   = {Haghighi, P.D. and Zaslavsky, A. and Krishnaswamy, S. and Gaber, M.M.},
  Booktitle                = {2009 42nd Hawaii International Conference on System Sciences},
  Year                     = {2009},
  Pages                    = {1--10},
  Publisher                = {IEEE},

  Abstract                 = {The growth in numbers and capacity of mobile devices such as mobile phones coupled with widespread availability of inexpensive range of biosensors presents an unprecedented opportunity for mobile healthcare applications. In this paper we propose a novel approach for situation-aware adaptive processing (SAAP) of data streams for smart and real-time analysis of data. The implementation and evaluation of the framework for a health monitoring application is described.},
  Doi                      = {10.1109/HICSS.2009.309},
  ISBN                     = {978-0-7695-3450-3},
  ISSN                     = {1530-1605},
  Keywords                 = {Biosensors,Context modeling,Data analysis,Data mining,Fluctuations,Fuzzy logic,Medical services,Mobile handsets,Patient monitoring,Performance analysis,biosensors,data mining,health care,health monitoring application,intelligent healthcare support,medical administrative data processing,mobile computing,mobile data mining,mobile devices,mobile handsets,mobile healthcare applications,mobile phones,situation-aware adaptive processing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mobile healthcare applications exploiting inexpensive biosensors and mobile devices. The implementation and evaluation of the framework for a health monitoring application is described. Bibtex key Haghighi applied to healthcare. Approved. 1,6},
  Shorttitle               = {System Sciences, 2009. HICSS '09. 42nd Hawaii Inte},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4755589}
}

@Article{Haghighi2009a,
  Title                    = {Context-aware adaptive data stream mining},
  Author                   = {Haghighi, P.D.a c and Zaslavsky, A.a and Krishnaswamya, S.a and Gabera, M.M.a and Lokeb, S.b },
  Journal                  = {Intelligent Data Analysis},
  Year                     = {2009},
  Note                     = {cited By (since 1996)6},
  Number                   = {3},
  Pages                    = {423-434},
  Volume                   = {13},

  Abstract                 = {In resource-constrained devices, adaptation of data stream processing to variations of data rates and availability of resources is crucial for consistency and continuity of running applications. However, to enhance and maximize the benefits of adaptation, there is a need to go beyond mere computational and device capabilities to encompass the full spectrum of context-awareness. This paper presents a general approach for context-aware adaptive mining of data streams that aims to dynamically and autonomously adjust data stream mining parameters according to changes in context and situations. We perform intelligent and real-time analysis of data streams generated from sensors that is under-pinned using context-aware adaptation. A prototype of the proposed architecture is implemented and evaluated in the paper through a real-world scenario in the area of healthcare monitoring. Ã‚Â© 2009 IOS Press. All rights reserved.},
  Affiliation              = {Center for Distributed Systems and Software Engineering, Monash University, Melbourne, VIC, Australia; Department of Computer Science and Computer Engineering, La Trobe University, Bundoora, VIC, Australia; Faculty of Information Technology, Monash University, 900 Dandenong Rd., Caulfield East, VIC 3145, Australia},
  Author_keywords          = {Context; Data mining; Fuzzy logic},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Haghighi. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-66949158742&partnerID=40&md5=743880a7a7eddc54a437f5ee6d8cd364}
}

@Misc{Haghighi,
  Title                    = {{Situation-Aware Adaptive Processing (SAAP) of Data Streams}},

  Author                   = {Haghighi, Pari Delir and Gaber, Mohamed Medhat and Krishnaswamy, Shonali and Zaslavsky, Arkady},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The growth and proliferation of technologies in the field of sensor networking and mobile computing have led to the emergence of diverse applications that process and analyze sensory data on mobile devices such as a smart phone. However, the real power to make a significant impact on the area of developing these applications rests not merely on deploying the technologies but on the ability to perform real-time, intelligent analysis of the data streams that are generated by the various sensors. In this chapter, we present a novel approach for Situation-Aware Adaptive Processing (SAAP) of data streams for pervasive computing environments. This approach uses fuzzy logic principles for modeling and reasoning about uncertain situations and performs gradual adaptation of parameters of data stream mining algorithms in real-time according to availability of resources and the occurring situations.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Situation-Aware Adaptive Processing of data streams. This approach uses fuzzy logic principles for modeling and reasoning about uncertain situations and performs gradual adaptation of parameters of data stream mining algorithms in real-time according to availability of resources and the occurring situations. Approved. 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.205.3598}
}

@InProceedings{Halkidi2011,
  Title                    = {{Online Clustering of Distributed Streaming Data Using Belief Propagation Techniques}},
  Author                   = {Halkidi, Maria and Koutsopoulos, Iordanis},
  Booktitle                = {2011 IEEE 12th International Conference on Mobile Data Management},
  Year                     = {2011},
  Month                    = jun,
  Pages                    = {216--225},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Extraction of patterns out of streaming data that are generated from geographically dispersed devices is a major challenge in data mining. The sequential, distributed fashion in which data become available to the decision maker, together with the fact that the decision maker needs to rely only on recently received data due to storage and communication constraints, render the objective of keeping track of data evolution a nontrivial one. We consider a set of distributed nodes that communicate directly with a central location. We address the problem of clustering distributed streaming data through a two-level clustering approach. We adopt belief propagation techniques to perform stream clustering at both levels. At the node level, a batch of data arrives at each time slot, and the goal is to maintain a set of salient data (local exemplars) at each time slot, which best represents the data received up to that slot. At each epoch, the local exemplars from distributed nodes are sent to the central location, which in turn performs a second-level clustering on them to derive a data synopsis global for the whole system. The local exemplars that emerge from the second level clustering procedure are fed back to the nodes with appropriately modified weights which reflect their importance in global clustering. As demonstrated by our experiments, the two-level belief propagation-based clustering approach together with the feedback is ideal for handling data from different nodes, as it has the same performance in terms of clustering quality with the case where the clustering is performed on the raw data sent from nodes to the central location.},
  Doi                      = {10.1109/MDM.2011.63},
  ISBN                     = {978-1-4577-0581-6},
  Keywords                 = {Belief propagation,Clustering algorithms,Data mining,Data models,Distributed databases,Heuristic algorithms,Message passing,belief maintenance,belief propagation techniques,clustering quality,communication constraints,data evolution,data handling,data mining,data synopsis global,decision maker,decision making,distributed nodes,distributed streaming data,geographically dispersed devices,global clustering,local exemplars,online clustering,pattern clustering,pattern extraction,salient data,second level clustering procedure,second-level clustering,storage constraints,storage management,stream clustering,two-level belief propagation-based clustering appr,two-level clustering approach},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Online Clustering of Distributed Streaming Data Using Belief Propagation Techniques. We consider a set of distributed nodes that communicate directly with a central location. Two-level clustering approach. At each epoch, the local exemplars from distributed nodes are sent to the central location, which clusters again. As demonstrated by our experiments, the two-level belief propagation-based clustering approach together with the feedback is ideal for handling data from different nodes, as it has the same performance in terms of clustering quality with raw data sent to central location. Approved 1,3,4,6},
  Shorttitle               = {Mobile Data Management (MDM), 2011 12th IEEE Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6068441}
}

@Misc{Han2005,
  Title                    = {{DOI: 10.1007/s10619-005-3296-1 Stream Cube: An Architecture for Multi-Dimensional Analysis of Data Streams}},

  Author                   = {Han, Jiawei and Chen, Yixin and Dong, Guozhu and Pei, Jian and Wah, Benjamin W. and Wang, Jianyong and Cai, Y. Dora and Elmagarmid, Ahmed},
  Year                     = {2005},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Real-time surveillance systems, telecommunication systems, and other dynamic environments often generate tremendous (potentially infinite) volume of stream data: the volume is too huge to be scanned multiple times. Much of such data resides at rather low level of abstraction, whereas most analysts are interested in relatively high-level dynamic changes (such as trends and outliers). To discover such high-level characteristics, one may need to perform on-line multi-level, multi-dimensional analytical processing of stream data. In this paper, we propose an architecture, called stream cube, to facilitate on-line, multi-dimensional, multi-level analysis of stream data. For fast online multi-dimensional analysis of stream data, three important techniques are proposed for efficient and effective computation of stream cubes. First, a tilted time frame model is proposed as a multi-resolution model to register time-related data: the more recent data are registered at finer resolution, whereas the more distant data are registered at coarser resolution. This design reduces the overall storage of time-related data and adapts nicely to the data analysis tasks commonly encountered in practice. Second, instead of materializing cuboids at all levels, we propose to maintain a small number of critical layers. Flexible analysis can be efficiently performed based on the concept of observation layer and minimal interesting layer. Third, an efficient stream data cubing algorithm is developed which computes only the layers (cuboids) along a popular path and leaves the other cuboids for query-driven, on-line computation. Based on this design methodology, stream data cube can be constructed and},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Real-time surveillance systems, telecommunication systems, and other dynamic environments often generate tremendous (potentially infinite) volume of stream data. We propose an architecture, called stream cube, to facilitate on-line, multi-dimensional, multi-level analysis of stream data. The impact of the design and implementation of stream data cube in the context of stream data mining is also discussed in the paper Not strictly ML, but not clear if they are testing with an ML case. Approved 1,3,4},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.205.2394}
}

@Misc{Han,
  Title                    = {{Chapter 1 Research Challenges for Data Mining in Science and Engineering}},

  Author                   = {Han, Jiawei and Gao, Jing},

  __markedentry            = {[Alexander:]},
  Abstract                 = {With the rapid development of computer and information technology in the last several decades, an enormous amount of data in science and engineering has been and will continuously be generated in massive scale, either being stored in gigantic storage devices or flowing into and out of the system in the form of data streams. Moreover, such data has been made widely available, e.g., via the Internet. Such tremendous amount of data, in the order of tera- to peta-bytes, has fundamentally changed science and engineering, transforming many disciplines from data-poor to increasingly data-rich, and calling for new, data-intensive methods to conduct research in science and engineering. In this paper, we discuss the research challenges in science and engineering, from the data mining perspective, with a focus on the following issues: (1) information network analysis, (2) discovery, usage, and understanding of patterns and knowledge, (3) stream data mining, (4) mining moving object data, RFID data, and data from sensor networks, (5) spatiotemporal and multimedia data mining, (6) mining text, Web, and other unstructured data, (7) data cube-oriented multidimensional online analytical mining, (8) visual data mining, and (9) data mining by integration of sophisticated scientific and engineering domain knowledge.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Chapter from book. Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.212.7531}
}

@InProceedings{Han2011,
  Title                    = {{Hybrid Cube: An Architecture for Analysis of Network Security Events Data Stream}},
  Author                   = {Han, Yu and Niu, Wei and Zhu, Junmao},
  Booktitle                = {2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control},
  Year                     = {2011},
  Month                    = oct,
  Pages                    = {310--313},
  Publisher                = {IEEE},

  Abstract                 = {Managing the network security events data stream, which is very large and real-time, and mining useful information from the data stream to analyse and forecast security situation, are very difficult. In this paper, we present an architecture, hybrid data stream cube, and its incremental updating algorithm. Experimental results proved that this architecture could facilitate on-line, multi-dimension, multi-level analysis of network security events data stream and shorten the response time.},
  Doi                      = {10.1109/IMCCC.2011.84},
  ISBN                     = {978-0-7695-4519-6},
  Keywords                 = {Algorithm design and analysis,Computer architecture,Distributed databases,Real time systems,Security,Software,Time factors,computer network management,computer network security,cube,data mining,data stream,hybrid data stream cube,incremental updating algorithm,multi-level analysis,network management,network security,network security events},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Looks like it might possibly be a newer version of Han2005, but not clear. Managing the network security events data stream, which is very large and real-time, and mining are very difficult. In this paper, we present an architecture, hybrid data stream cube, and its incremental updating algorithm. Experimental results proved that this architecture could facilitate on-line, multi-dimension, multi-level analysis of network security events data stream and shorten the response time. Approved 1,3,4,6},
  Shorttitle               = {Instrumentation, Measurement, Computer, Communicat},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6154062}
}

@Conference{Han2011a,
  Title                    = {Hybrid cube: An architecture for analysis of network security events data stream},
  Author                   = {Han, Y. and Niu, W. and Zhu, J.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {310-313},

  Abstract                 = {Managing the network security events data stream, which is very large and real-time, and mining useful information from the data stream to analyse and forecast security situation, are very difficult. In this paper, we present an architecture, hybrid data stream cube, and its incremental updating algorithm. Experimental results proved that this architecture could facilitate on-line, multi-dimension, multi-level analysis of network security events data stream and shorten the response time. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Institute of Northern Electronic Equipment, Beijing, China},
  Art_number               = {6154062},
  Author_keywords          = {cube; data stream; network security},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2011 International Conference on Instrumentation, Measurement, Computer, Communication and Control, IMCCC 2011},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Han2011. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84860644632&partnerID=40&md5=efa0f7f1ec009ef81e13219a2fdd5300}
}

@Misc{Hang,
  Title                    = {{Real-time Business Intelligence System Architecture with Stream Mining}},

  Author                   = {Hang, Yang and Fong, Simon},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Business Intelligence (BI) capitalized on datamining and analytics techniques for discovering trends and reacting to events with quick decisions. We argued that a new breed of data-mining, namely stream-mining where continuous data streams arrive into the system and get mined very quickly, stimulates the design of a new real-time BI architecture. In the past, stream-mining (especially in algorithmic level) and digital information system architectures have been studied separately. We attempted in this paper to present a unified view on the real-time BI system architecture powered by stream-mining. Some typical applications in which our architecture can support are described},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In the past, stream-mining (especially in algorithmic level) and digital information system architectures have been studied separately. We attempted in this paper to present a unified view on the real-time BI system architecture powered by stream-mining. Some typical applications in which our architecture can support are described. Appears to be using ML, appears to be novel. Not clear, but goes through. Approved 1,2},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.331.9834}
}

@InProceedings{Hang2010,
  Title                    = {{Investigating the Impact of Bursty Traffic on Hoeffding Tree Algorithm in Stream Mining over Internet}},
  Author                   = {Hang, Yang and Fong, Simon},
  Booktitle                = {2010 2nd International Conference on Evolving Internet},
  Year                     = {2010},
  Month                    = sep,
  Pages                    = {147--152},
  Publisher                = {IEEE},

  Abstract                 = {Steam data are continuous and ubiquitous in nature which can be found in many Web applications operating on Internet. Some instances of stream data are web logs, online users' click-streams, online media streaming and Web transaction records. Stream Mining was proposed as a relatively new data analytic solution for handling such streams. It has been widely acclaimed of its usefulness in real-time decision-support applications, for example web recommenders. Hoeffding Tree Algorithm (HTA) is one of the popular choices for implementing Very-Fast-Decision-Tree in stream mining. The theoretical aspects have been studied extensively by researchers. However, the data streams that fed into HTA are usually assumed at a constant rate in the literature. HTA has yet been tested under bursty traffic such as Internet environment. This paper sheds some light into the impact of bursty traffic on the performance of HTA in stream mining.},
  Doi                      = {10.1109/INTERNET.2010.33},
  ISBN                     = {978-1-4244-8150-7},
  ISSN                     = {2156-7190},
  Keywords                 = {Bursty stream,Hoeffding tree algorithm,Internet,Web recommenders,Web transaction records,bursty traffic,data mining,decision support applications,decision support systems,decision trees,real-time application,recommender systems,stream data,stream mining,very fast decision tree},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Seemingly older version of Hang2010d. Discarded.},
  Shorttitle               = {Evolving Internet (INTERNET), 2010 Second Internat},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5616422}
}

@InProceedings{Hang2010a,
  Title                    = {{Real-time business intelligence system architecture with stream mining}},
  Author                   = {Hang, Yang and Fong, Simon},
  Booktitle                = {2010 Fifth International Conference on Digital Information Management (ICDIM)},
  Year                     = {2010},
  Month                    = jul,
  Pages                    = {29--34},
  Publisher                = {IEEE},

  Abstract                 = {Business Intelligence (BI) capitalized on data-mining and analytics techniques for discovering trends and reacting to events with quick decisions. We argued that a new breed of data-mining, namely stream-mining where continuous data streams arrive into the system and get mined very quickly, stimulates the design of a new real-time BI architecture. In the past, stream-mining (especially in algorithmic level) and digital information system architectures have been studied separately. We attempted in this paper to present a unified view on the real-time BI system architecture powered by stream-mining. Some typical applications in which our architecture can support are described.},
  Doi                      = {10.1109/ICDIM.2010.5664637},
  ISBN                     = {978-1-4244-7572-8},
  Keywords                 = {Artificial intelligence,Bismuth,Business,Computer architecture,Conferences,Data mining,Real time systems,business intelligence,competitive intelligence,data analysis,data analytics,data mining,digital information system architectures,information systems,stream mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Hang. Discarded.},
  Shorttitle               = {Digital Information Management (ICDIM), 2010 Fifth},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5664637}
}

@Conference{Hang2010b,
  Title                    = {Investigating the impact of bursty traffic on Hoeffding Tree Algorithm in stream mining over internet},
  Author                   = {Hang, Y. and Fong, S.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)2},
  Pages                    = {147-152},

  Abstract                 = {Stream data are continuous and ubiquitous in nature which can be found in many Web applications operating on Internet. Some instances of stream data are web logs, online users' click-streams, online media streaming and Web transaction records. Stream Mining was proposed as a relatively new data analytic solution for handling such streams. It has been widely acclaimed of its usefulness in real-time decision-support applications, for example web recommenders. Hoeffding Tree Algorithm (HTA) is one of the popular choices for implementing Very Fast Decision Tree (VFDT) in stream mining. The theoretical aspects have been studied extensively by researchers. However, the data streams that fed into HTA are usually assumed at a constant rate in the literature. HTA has yet been tested under bursty traffic such as Internet environment. This paper sheds some light into the impact of bursty traffic on the performance of HTA in stream mining. Ã‚Â© 2010 IEEE.},
  Affiliation              = {Faculty of Science and Technology, University of Macau, Macau, China},
  Art_number               = {5616422},
  Author_keywords          = {Bursty stream; Hoeffding tree algorithm; Real-time application; Stream mining},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2nd International Conference on Evolving Internet, Internet 2010, 1st International Conference on Access Networks, Services and Technologies, Access 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Hang. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78649831325&partnerID=40&md5=5e3dc1b33898b77e545abf4402ee63a0}
}

@Conference{Hang2010c,
  Title                    = {Real-time business intelligence system architecture with stream mining},
  Author                   = {Hang, Y. and Fong, S.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)2},
  Pages                    = {29-34},

  Abstract                 = {Business Intelligence (BI) capitalized on datamining and analytics techniques for discovering trends and reacting to events with quick decisions. We argued that a new breed of data-mining, namely stream-mining where continuous data streams arrive into the system and get mined very quickly, stimulates the design of a new real-time BI architecture. In the past, stream-mining (especially in algorithmic level) and digital information system architectures have been studied separately. We attempted in this paper to present a unified view on the real-time BI system architecture powered by stream-mining. Some typical applications in which our architecture can support are described. Ã‚Â©2010 IEEE.},
  Affiliation              = {Department of Computer and Information Science, University of Macau, Macau},
  Art_number               = {5664637},
  Document_type            = {Conference Paper},
  Journal                  = {2010 5th International Conference on Digital Information Management, ICDIM 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Hang. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650927623&partnerID=40&md5=0f40201c5b700df23a8f308de1d7e6db}
}

@Conference{Hang2010d,
  Title                    = {Stream mining over fluctuating network traffic at variable data rates},
  Author                   = {Hang, Y. and Fong, S.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Pages                    = {436-441},

  Abstract                 = {Data stream mining algorithm, such as the popular classifier implemented by Hoeffding tree algorithm (HTA) is acclaimed to be able to handle high speed data streams that potentially amounts to infinity. It emerges as a hot research area recently on applying HTA in different applications that require real-time responses and fast decision making. In particular, we discovered the effect of Internet traffic on Hoeffding bound (HB) which is one of the key performance indicators in HTA stream mining is related to fluctuation. The error of HB oscillates with the fluctuation of data rate in realtime data stream which causes frequent HTA tree reconstruction, and in turn that has an adverse effect on the overall prediction accuracy. From the experiment in this paper, we observe that the HB is related to HTA's accuracy. And data streams extracted from Internet traffic exhibit fluctuations of highly variable data rates, they influence significantly on HB value. A simple and effective mechanism without the need of arbitrating or intervening with the traffic data rates is proposed in this paper for smoothing the HB fluctuation. From our simulation, the results show that the HB fluctuation is smoothed, and the accuracy in HTA is stabilized. It is believed that the proposed technique can subside the problem of stream mining in network environment where traffic is fluctuating.},
  Affiliation              = {Faculty of Science and Technology, University of Macau, Macau},
  Art_number               = {5713490},
  Author_keywords          = {Component; Hoeffding tree algorithm; Internet traffic; Real time application; Real time constraint; Stream mining},
  Document_type            = {Conference Paper},
  Journal                  = {Proc. - 6th Intl. Conference on Advanced Information Management and Service, IMS2010, with ICMIA2010 - 2nd International Conference on Data Mining and Intelligent Information Technology Applications},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Later version of the other Hang papers in 2010, it seems. Hoeffding Tree Algorithm (HTA) is one of the popular choices for implementing Very-Fast-Decision-Tree in stream mining, and has been studied extensively. However, the data streams that fed into HTA are usually assumed at a constant rate in the literature. This paper sheds some light into the impact of bursty traffic on the performance of HTA in stream mining. From our simulation, the results show that the HB fluctuation is smoothed, and the accuracy in HTA is stabilized. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79952791887&partnerID=40&md5=666faaf93837f2bbf8edde4a8ec95248}
}

@Conference{Hang2010e,
  Title                    = {An experimental comparison of decision trees in traditional data mining and data stream mining},
  Author                   = {Hang, Y. and Fong, S.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)1},
  Pages                    = {442-447},

  Abstract                 = {Data Stream mining (DSM) is claimed to be the successor of traditional data mining where it is capable of mining continuous incoming data streams in real-time with an acceptable performance. Nowadays many computer applications evolved to online and on-demand basis, fresh data are feeding in at high speeds. Not only a decision response needs to be made rapidly, the trained decision tree models would have to be updated recurrently as frequent as the latest data arrive. By the nature of traditional data mining, training datasets are assumed structured and static, and the decision tree models are either refreshed in batches or never. That is, the full dataset will be completely scanned (sometimes in multiple repetitions), induction of rules by Greedy algorithm that proceeds in manner of divide-and-conquer in the case of constructing a C4.5 decision tree. DSM on the other hand progressively builds and renews the decision tree model at a time when a new pass of data come by. In this paper, we evaluated the performance of a popular decision tree in DSM, which is known as Hoeffding Tree vis-ÃƒÂ -vis that of C4.5. A good mix of types of datasets was used in the experiments for investigating the apparent differences between the decision trees. An open-source DSM simulator was programmed in JAVA for the experiments.},
  Affiliation              = {Faculty of Science and Technology, University of Macau, Macau},
  Art_number               = {5713491},
  Author_keywords          = {Data stream mining; Decision tree; Hoeffding tree algorithm; JAVA simulator; Noise data},
  Document_type            = {Conference Paper},
  Journal                  = {Proc. - 6th Intl. Conference on Advanced Information Management and Service, IMS2010, with ICMIA2010 - 2nd International Conference on Data Mining and Intelligent Information Technology Applications},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {By the nature of traditional data mining, training datasets are assumed structured and static, and the decision tree models are either refreshed in batches or never. In this paper, we evaluated the performance of a popular decision tree in data stream mining, which is known as Hoeffding Tree vis-à-vis that of C4.5. Evaluation only of different algorithms. Discarded, put aside.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79952795279&partnerID=40&md5=75001d142c2e5e89191804e48ba4a3d4}
}

@Article{Hao2014,
  Title                    = {IMSPMIS-Stream: incremental mining of top-k short sequential pattern over multiple item set streams},
  Author                   = {Hao, X.a b and Han, G.a b and Chen, Y.a b and Wang, P.a b and Ren, J.a b },
  Journal                  = {Journal of Computational Information Systems},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {6},
  Pages                    = {2305-2312},
  Volume                   = {10},

  Abstract                 = {Many previous algorithms in data streams are about single stream, which can only process single items. The algorithms about data streams are always extended by sequential pattern algorithms about static database, they can't satisfy the requirement of scanning streams only once and online mining. Moreover, top-k short sequential pattern hasn't been studied yet. Therefore, IMSPMIS-Stream algorithm is proposed to mine online multiple streams with the single scan by the incremental method in this paper. The streams are continuous transactions, which is also called item set streams. Several streams are mined interactively based on sliding windows at the same time. An approach to count the support of every sub item set is designed to get the support during one scan. The short sequential pattern is deffned, whose item sets are shorter than all the item sets with the same occurring time. When the arrival transactions reach to the capacity of the window, sequential patterns will be output by combining top-k short item sets. The experiments show that the IMSPMIS-Stream algorithm overcomes the memory limitation and its execution time is reduced compared with some previous algorithms under the same conditions. Copyright Ã‚Â© 2014 Binary Information Press.},
  Affiliation              = {College of Information Science and Engineering, Yanshan University, Qinhuangdao 066004, China; The Key Laboratory for Computer Virtual Technology and System Integration of Hebei Province, Qinhuangdao 066004, China},
  Author_keywords          = {Item set streams; Multiple streams; One scan; Sequential pattern; Sliding windows},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {IMSPMIS-Stream algorithm is proposed to mine online multiple streams with the single scan by the incremental method in this paper. Several streams are mined interactively based on sliding windows at the same time. Experiments show that the algorithm overcomes the memory limitation and its execution time is reduced compared with some previous algorithms under the same conditions. Good abstract, easy to follow. Compares runtime to other algorithms, but don't know which. Outcome is patterns, but not sure what this algorithm learns or the accuracy of the learning 1,2,3,(5?),6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84900494870&partnerID=40&md5=9330545e7de780abe52d8d0b04ec5d5e}
}

@InProceedings{Harris2005,
  Title                    = {{AQS-20 Through-the-Sensor (TTS) Performance Assessment}},
  Author                   = {Harris, M. and Avera, W. and Steed, C. and Sample, J. and Bibee, L.D. and Morgerson, D. and Hammack, J. and Null, M.},
  Booktitle                = {Proceedings of OCEANS 2005 MTS/IEEE},
  Year                     = {2005},
  Pages                    = {1--6},
  Publisher                = {IEEE},

  Abstract                 = {Performance of existing and planned mine hunting sensors is dependent on the environment. When the sea floor is a flat smooth hard sandy surface with no mine like clutter on it, then sensor performance is outstanding and acoustic mine hunting is relatively easy. Introduce clutter, a rough seafloor and a soft muddy bottom, sensor performance is seriously degraded making mine hunting operations extremely difficult to impossible. One must know the environment to know sensor performance. Historical environmental data is important but not sufficient. In spite of painstaking efforts to collect, process and disseminate data, historical information is often missing, outdated or in error. To know sensor performance, near realtime environmental data must be collected to verify, supplement and refresh historical holdings. This paper describes the results of two near real-time end-to-end Through-the-Sensor (TTS) demonstrations conducted in FY05 using AQS-20 data. Critical environmental parameters were extracted from the raw tactical data stream using a TTS approach. Data collected by the AQS-20 was processed for bathymetry, sediment type and \% burial. Supplemental data was fused with historical information on scene and used to calculate doctrinal bottom type in NAVOCEANO's Bottom Mapping Workstation. The information was passed to MEDAL where track spacing and hunt times were calculated. NAVOCEANO, in a fast reach back mode using TEDServices, examined the data, added value, and returned it. The impact to the mine warfare community is a true sense of sensor performance.},
  Doi                      = {10.1109/OCEANS.2005.1639807},
  ISBN                     = {0-933957-34-3},
  Keywords                 = {AQS-20,Acoustic sensors,Bottom Mapping Workstation,Data mining,Degradation,Layout,MEDAL,NAVOCEANO,Rough surfaces,Sea floor,Sea surface,Sediments,Speech synthesis,Surface roughness,TEDServices,Through-the-Sensor performance assessment,acoustic mine hunting,bathymetry,burial percent,buried object detection,military systems,mine hunting sensors,mine warfare,sea floor topography,sediment type,sediments,track spacing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mine hunting from sea floor. One must know the environment to know sensor performance. This paper describes the results of two near real-time end-to-end Through-the-Sensor (TTS) demonstrations conducted in FY05 using AQS-20 data. Appears to be using ML to get true sensor readings, but not quite sure. Approved 1},
  Shorttitle               = {OCEANS, 2005. Proceedings of MTS/IEEE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1639807}
}

@InProceedings{Hart2007,
  Title                    = {{Visual Tools for Analysing Evolution, Emergence, and Error in Data Streams}},
  Author                   = {Hart, Sol and Yearwood, John and Bagirov, Adil M.},
  Booktitle                = {6th IEEE/ACIS International Conference on Computer and Information Science (ICIS 2007)},
  Year                     = {2007},
  Pages                    = {987--992},
  Publisher                = {IEEE},

  Abstract                 = {The relatively new field of stream mining has necessitated the development of robust drift-aware algorithms that provide accurate, real time, data handling capabilities. Tools are needed to assess and diagnose important trends and investigate drift evolution parameters. In this paper, we present two new and novel visualisation techniques, Pixie and Luna graphs, which incorporate salient group statistics coupled with intuitive visual representations of multidimensional groupings over time. Through the novel representations presented here, spatial interactions between temporal divisions can be diagnosed and overall distribution patterns identified. It provides a means of evaluating in non-constrained capacity, commonly constrained evolutionary problems.},
  Doi                      = {10.1109/ICIS.2007.194},
  ISBN                     = {0-7695-2841-4},
  Keywords                 = {Algorithm design and analysis,Australia,Computer displays,Computer errors,Data handling,Data mining,Information analysis,Information technology,Luna graph,Machine learning,Pixie graph,Robustness,constrained evolutionary problems,data handling,data mining,data streams,data visualisation,drift-aware algorithms,evolutionary computation,graph theory,group theory,multidimensional groupings,salient group statistics,spatial interactions,statistical analysis,stream mining,visual representations,visual tools,visualisation techniques},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {The relatively new field of stream mining has necessitated the development of robust drift-aware algorithms that provide accurate, real time, data handling capabilities. In this paper, we present two new and novel visualisation techniques. It provides a means of evaluating in non-constrained capacity, commonly constrained evolutionary problems. Incorporate salient group statistics. Unsure. I would say Discarded.},
  Shorttitle               = {Computer and Information Science, 2007. ICIS 2007.},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4276512}
}

@Article{Hassani2013,
  Title                    = {Subspace MOA: Subspace stream clustering evaluation using the MOA framework},
  Author                   = {Hassani, M. and Kim, Y. and Seidl, T.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2013},
  Note                     = {cited By (since 1996)2},
  Number                   = {PART 2},
  Pages                    = {446-449},
  Volume                   = {7826 LNCS},

  Abstract                 = {Most available static data are becoming more and more high-dimensional. Therefore, subspace clustering, which aims at finding clusters not only within the full dimension but also within subgroups of dimensions, has gained a significant importance. Recently, OpenSubspace framework was proposed to evaluate and explorate subspace clustering algorithms in WEKA with a rich body of most state of the art subspace clustering algorithms and measures. Parallel to it, MOA (Massive Online Analysis) framework was developed also above WEKA to provide algorithms and evaluation methods for mining tasks on evolving data streams over the full space only. Similar to static data, most streaming data sources are becoming high-dimensional, and tracking their evolving clusters is also becoming important and challenging. In this demonstrator, we present, to the best of our knowledge, the first subspace clustering evaluation framework over data streams called Subspace MOA. Our demonstrator follows the online-offline model which is used in most data stream clustering algorithms. In the online phase, users have the possibility to select one of three most famous summarization techniques to form the microclusters. In the offline phase, one of five subspace clustering algorithms can be selected. The framework is supported with a subspace stream generator, a visualization interface to present the evolving clusters over different subspaces, and various subspace clustering evaluation measures. Ã‚Â© Springer-Verlag 2013.},
  Affiliation              = {Data Management and Data Exploration Group, RWTH Aachen University, Germany},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Static data are becoming more and more high-dimensional. Subspace-clustering is useful to cluster in subgroups. They describe some other frameworks then: In this demonstrator, we present, to the best of our knowledge, the first subspace clustering evaluation framework over data streams called Subspace MOA. Our demonstrator follows the online-offline model which is used in most data stream clustering algorithms. State of the art since it is the first one to do it. Approved 1,2,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84892843718&partnerID=40&md5=7bc65bbf7ce32149cc98788175d13a63}
}

@Article{Hassani2012,
  Title                    = {Density-based projected clustering of data streams},
  Author                   = {Hassani, M.a and Spaus, P.a and Gaber, M.M.b and Seidl, T.a },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2012},
  Note                     = {cited By (since 1996)2},
  Pages                    = {311-324},
  Volume                   = {7520 LNAI},

  Abstract                 = {In this paper, we have proposed, developed and experimentally validated our novel subspace data stream clustering, termed PreDeConStream. The technique is based on the two phase mode of mining streaming data, in which the first phase represents the process of the online maintenance of a data structure, that is then passed to an offline phase of generating the final clustering model. The technique works on incrementally updating the output of the online phase stored in a micro-cluster structure, taking into consideration those micro-clusters that are fading out over time, speeding up the process of assigning new data points to existing clusters. A density based projected clustering model in developing PreDeConStream was used. With many important applications that can benefit from such technique, we have proved experimentally the superiority of the proposed methods over state-of-the-art techniques. Ã‚Â© 2012 Springer-Verlag.},
  Affiliation              = {Data Management and Data Exploration Group, RWTH Aachen University, Germany; School of Computing, University of Portsmouth, United Kingdom},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We developed and experimentally validated our novel subspace data stream clustering, termed PreDeConStream. Two phase mining of stream. With many important applications that can benefit from such technique, we have proved experimentally the superiority of the proposed methods over state-of-the-art techniques. Approved 1,2,3,4,5,6

Retrieved from Springer.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867617125&partnerID=40&md5=0265d03752fcae29b3d63e98f8a1f4b5}
}

@InProceedings{Hawkins2013,
  Title                    = {{Online learning from streaming data}},
  Author                   = {Hawkins, Jeff},
  Booktitle                = {Proceedings of the 22nd ACM international conference on Conference on information \& knowledge management - CIKM '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = oct,
  Pages                    = {1915--1916},
  Publisher                = {ACM Press},

  Abstract                 = {High velocity machine-generated data is growing rapidly. To act on this data in real time requires models that learn continuously and discover the temporal patterns in noisy data streams. The brain is also an online learning system that builds models from streaming data. In this talk I will describe recent advances in brain theory and how we have applied those advances to machine-generated streaming data. At the heart of our work are new insights into how layers of cells in the neocortex infer and make predictions from fast changing sensory data. This theory, called the Cortical Learning Algorithm, has been tested extensively. We have embedded these learning algorithms into a product called Grok which is being applied to numerous problems such as energy load forecasting and anomaly detection. I will give an introduction to the Cortical Learning Algorithm including how it uses sparse distributed representations and then show how Grok makes predictions and detects anomalies in streaming data. The Cortical Learning Algorithm is now an open source project (www.numenta.org) and I will give a brief introduction to the project.},
  Doi                      = {10.1145/2505515.2514695},
  ISBN                     = {9781450322638},
  Keywords                 = {brain theory,grok,numenta,online learning,streaming data},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {Overview of a talk. At the heart of our work are new insights into how layers of cells in the neocortex infer and make predictions from fast changing sensory data. Interesting, but not a contribution. Discarded, put aside.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2505515.2514695}
}

@Article{Hawwash2010,
  Title                    = {Mining and tracking evolving web user trends from large web server logs},
  Author                   = {Hawwash, B. and Nasraoui, O.},
  Journal                  = {Statistical Analysis and Data Mining},
  Year                     = {2010},
  Note                     = {cited By (since 1996)1},
  Number                   = {2},
  Pages                    = {106-125},
  Volume                   = {3},

  Abstract                 = {Recently, online organizations became interested in tracking users' behavior on their websites to better understand and satisfy their needs. In response to this need, web usage mining tools were developed to help them use web logs to discover usage patterns or profiles. However, since website usage logs are being continuously generated, in some cases, amounting to a dynamic data stream, most existing tools are still not able to handle their changing nature or growing size. This paper proposes a scalable framework that is capable of tracking the changing nature of user behavior on a website, and represent it in a set of evolving usage profiles. These profiles can offer the best usage representation of user activity at any given time, and they can be used as an input to higher-level applications such as a web recommendation system. Our specific aim is to make the hierarchical unsupervised niche clustering (HUNC) algorithm more scalable, and to add integrated profile tracking and cluster-based validation to it. Our experiments on real web log data confirm the validity of our approach for large data sets that previously could not be handled in one shot. Ã‚Â© 2010 Wiley Periodicals, Inc.},
  Affiliation              = {Knowledge Discovery and Web Mining Laboratory, Department of Computer Engineering and Computer Science, University of Louisville, Louisville, KY 40292, United States},
  Author_keywords          = {Clustering; Concept drifts; Data streams; Evolution; Personalization; User profiles; Web analytics; Web usage mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Tracking users' behavior on their websites to better understand and satisfy their needs. This paper proposes a scalable framework that is capable of tracking the changing nature of user behavior on a website, and represent it in a set of evolving usage profiles. Our specific aim is to make the hierarchical unsupervised niche clustering (HUNC) algorithm more scalable, and to add integrated profile tracking and cluster-based validation to it. Our experiments on real web log data confirm the validity of our approach for large data sets that previously could not be handled in one shot. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77952225633&partnerID=40&md5=2a004583788bd87b3e485158206364a8}
}

@Article{Hayes2013,
  Title                    = {{A real-time stream storage and analysis platform for underwater acoustic monitoring}},
  Author                   = {Hayes, J. P. and Kolar, H. R. and Akhriev, A. and Barry, M. G. and Purcell, M. E. and McKeown, E. P.},
  Journal                  = {IBM Journal of Research and Development},
  Year                     = {2013},

  Month                    = may,
  Number                   = {3},
  Pages                    = {15:1--15:10},
  Volume                   = {57},

  Abstract                 = {We describe a distributed, real-time system for the collection and analysis of underwater acoustic data. The system uses a number of preprocessing steps to classify and detect acoustic events and to identify and compensate for gaps in the data stream. Different event-detection techniques are applied in a distributed manner on the incoming data stream from each sensor to aid in the indexing and storage of the data. Other event-detection techniques process multiple simultaneous streams to identify and classify events of interest. Building upon the deployed system, a stream analytical platform provides data handling, preprocessing, and analytics in real time. These analytics identify and classify anthropogenic, environmental, and animal noise (a significant amount of which occurs outside the audible range of human hearing) and ascertain the direction of the noise source.},
  Doi                      = {10.1147/JRD.2013.2245973},
  ISSN                     = {0018-8646},
  Keywords                 = {Acoustics,Base stations,Monitoring,Noise measurement,Real-time systems,Sonar equipment,Underwater acoustics},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We describe a distributed, real-time system for the collection and analysis of underwater acoustic data. Has to handle gaps in stream. Building upon the deployed system, a stream analytical platform provides data handling, preprocessing, and analytics in real time. Approved 1,6},
  Shorttitle               = {IBM Journal of Research and Development},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6517318}
}

@Misc{Hazan,
  Title                    = {{Electronic Colloquium on Computational Complexity, Report No. 88 (2007) Adaptive Algorithms for Online Decision Problems}},

  Author                   = {Hazan, Elad and Seshadhri, C.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We study the notion of learning in an oblivious changing environment. Existing online learning algorithms which minimize regret are shown to converge to the average of all locally optimal solutions. We propose a new performance metric, strengthening the standard metric of regret, to capture convergence to locally optimal solutions, and propose efficient algorithms which provably converge at the optimal rate. One application is the portfolio management problem, for which we show that all previous algorithms behave suboptimally under dynamic market conditions. Another application is online routing, for which our adaptive algorithm exploits local congestion patterns and runs in near-linear time. We also give an algorithm for the tree update problem that is statically optimal for every sufficiently long contiguous subsequence of accesses. Our algorithm combines techniques from data streaming algorithms, composition of learning algorithms, and a twist on the standard experts framework.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Existing online learning algorithms which minimize regret are shown to converge to the average of all locally optimal solutions. We propose a new performance metric, strengthening the standard metric of regret. Applicable to online portfolio management or online routing. Our algorithm combines techniques from data streaming algorithms, composition of learning algorithms, and a twist on the standard experts framework Approved 1,2,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.1697}
}

@Misc{He,
  Title                    = {{A Single-pass Online Data Mining Algorithm Combined with Control Theory with Limited Memory in Dynamic Data Streams}},

  Author                   = {He, Yanxiang and Xiong, Naixue and D\'{e}fago, Xavier and Yang, Yan and He, Jing},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper addresses a fundamental problem that arises in data streaming scenarios, namely, today’s data mining is ill-equipped to handle data streams effectively, and pays little attention to the network stability and the fast response [36]. To the question, we present a control-theoretic explicit rate (ER) online data mining control algorithm (ODMCA) to regulate the sending rate of mined data, which accounts for the main memory occupancies of terminal nodes. The proposed method uses a distributed proportional integrative plus derivative controller combined with data-mining, where the control parameters can be designed to ensure the stability of the control loop in terms of sending rate of mined data. We further analyze the theoretical aspects of the proposed algorithm, and simulation results show the efficiency of our scheme in terms of high main memory occupancy, fast response of the main memory occupancy as well as of the controlled sending rates.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Today’s data mining is ill-equipped to handle data streams effectively, and pays little attention to the network stability and the fast response. We present a control-theoretic explicit rate (ER) online data mining control algorithm (ODMCA) to regulate the sending rate of mined data. We further analyze the theoretical aspects of the proposed algorithm, and simulation results show the efficiency of our scheme in terms of high main memory occupancy, fast response of the main memory occupancy as well as of the controlled sending rate. Approved 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.161.8080}
}

@Article{He2005,
  Title                    = {A single-pass online data mining algorithm combined with control theory with limited memory in dynamic data streams},
  Author                   = {He, Y.a and Xiong, N.a b and DÃƒÂ©fago, X.b c and Yang, Y.d and He, J.e },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1119-1130},
  Volume                   = {3795 LNCS},

  Abstract                 = {This paper addresses a fundamental problem that arises in data streaming scenarios, namely, today's data mining is ill-equipped to handle data streams effectively, and pays little attention to the network stability and the fast response [36]. To the question, we present a control-theoretic explicit rate (ER) online data mining control algorithm (ODMCA) to regulate the sending rate of mined data, which accounts for the main memory occupancies of terminal nodes. The proposed method uses a distributed proportional integrative plus derivative controller combined with data-mining, where the control parameters can be designed to ensure the stability of the control loop in terms of sending rate of mined data. We further analyze the theoretical aspects of the proposed algorithm, and simulation results show the efficiency of our scheme in terms of high main memory occupancy, fast response of the main memory occupancy as well as of the controlled sending rates. Ã‚Â© Springer-Verlag Berlin Heidelberg 2005.},
  Affiliation              = {State Key Lab. of Software Engineering, Computer School, Wuhan University, China; School of Information Science, Japan Advanced Institute of Science and Technology (JAIST), Japan; PRESTO, Japan Science and Technology Agency (JST), Japan; Computer School, Wuhan University of Science and Technology, China; Department of Computer Science, Utah State University, Logan, UT 84322-4205, United States},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of He. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33646851275&partnerID=40&md5=2c9329c85ad76c3099e9fc4ec09c1954}
}

@Conference{HeiermanIII2003,
  Title                    = {Improving home automation by discovering regularly occurring device usage patterns},
  Author                   = {Heierman III, E.O. and Cook, D.J.},
  Year                     = {2003},
  Note                     = {cited By (since 1996)28},
  Pages                    = {537-540},

  Abstract                 = {The data stream captured by recording inhabitant-device interactions in an environment can be mined to discover significant patterns, which an intelligent agent could use to automate device interactions. However, this knowledge discovery problem is complicated by several challenges, such as excessive noise in the data, data that does not naturally exist as transactions, a need to operate in real time, and a domain where frequency may not be the best discriminator. In this paper, we propose a novel data mining technique that addresses these challenges and discovers regularly-occurring interactions with a smart home. We also discuss a case study that shows the data mining technique can improve the accuracy of two prediction algorithms, thus demonstrating multiple uses for a home automation system. Finally, we present an analysis of the algorithm and results obtained using inhabitant interactions. Ã‚Â© 2003 IEEE.},
  Affiliation              = {Department of Computer Science and Engineering, University of Texas, Arlington, TX, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Heierman2003. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78149322566&partnerID=40&md5=d23a4ef3667bbb4b32b6a2f22bc420e6}
}

@InProceedings{Heierman2003,
  Title                    = {{Improving home automation by discovering regularly occurring device usage patterns}},
  Author                   = {Heierman, E.O. and Cook, D.J.},
  Booktitle                = {Third IEEE International Conference on Data Mining},
  Year                     = {2003},
  Pages                    = {537--540},
  Publisher                = {IEEE Comput. Soc},

  Abstract                 = {The data stream captured by recording inhabitant-device interactions in an environment can be mined to discover significant patterns, which an intelligent agent could use to automate device interactions. However, this knowledge discovery problem is complicated by several challenges, such as excessive noise in the data, data that does not naturally exist as transactions, a need to operate in real time, and a domain where frequency may not be the best discriminator. We propose a novel data mining technique that addresses these challenges and discovers regularly-occurring interactions with a smart home. We also discuss a case study that shows the data mining technique can improve the accuracy of two prediction algorithms, thus demonstrating multiple uses for a home automation system. Finally, we present an analysis of the algorithm and results obtained using inhabitant interactions.},
  Doi                      = {10.1109/ICDM.2003.1250971},
  ISBN                     = {0-7695-1978-4},
  Keywords                 = {Data mining,Displays,Home appliances,Home automation,Intelligent agent,Intelligent sensors,Neural networks,Prediction algorithms,Sensor arrays,Smart homes,cooperative systems,data mining,data mining technique,data stream,home automation,home automation system,inhabitant-device interaction,intelligent agent,knowledge discovery,pattern discovery,prediction algorithm},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Improving home automation by discovering regularly occurring device usage patterns. Complicate by excessive noise in the data, data that does not naturally exist as transactions, a need to operate in real time, and a domain where frequency may not be the best discriminator. Propose a data mining technique to address this. Finally, we present an analysis of the algorithm and results obtained using inhabitant interactions. Approved 1,6},
  Shorttitle               = {Data Mining, 2003. ICDM 2003. Third IEEE Internati},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1250971}
}

@Article{Heierman2004,
  Title                    = {{Mining temporal sequences to discover interesting patterns}},
  Author                   = {Heierman, Edwin O. and Youngblood, G. Michael and Cook, Diane J.},
  Journal                  = {IN: PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {When mining temporal sequences, knowledge discovery techniques can be applied that discover interesting patterns of interactions. Existing approaches use frequency, and sometimes length, as measurements for interestingness. Because these are temporal sequences, additional characteristics, such as periodicity, may also be interesting. We propose that information theoretic principles can be used to evaluate interesting characteristics of time-ordered input sequences. In this paper, we present a novel data mining technique based on the Minimum Description Length principle that discovers interesting features in a time-ordered sequence. We discuss features of our real-time mining approach, show applications of the knowledge mined by the approach, and present a technique to bootstrap a decision maker from the mined patterns.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Existing approaches use frequency, and sometimes length, as measurements for interestingness. Because these are temporal sequences, additional characteristics, such as periodicity, may also be interesting. We propose that information theoretic principles can be used to evaluate interesting characteristics. We present a novel data mining technique based on the Minimum Description Length principle that discovers interesting features in a time-ordered sequence. Approved 1,2,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.63.9615}
}

@Article{Hemalatha2013,
  Title                    = {Frequent Bit Pattern Mining Over Tri-axial Accelerometer Data Streams for Recognizing Human Activities and Detecting Fall },
  Author                   = {C.Sweetlin Hemalatha and V. Vaidehi},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {The 4th International Conference on Ambient Systems, Networks and Technologies (ANT 2013), the 3rd International Conference on Sustainable Energy Information Technology (SEIT-2013) },
  Number                   = {0},
  Pages                    = {56 - 63},
  Volume                   = {19},

  Abstract                 = {Abstract Human fall causes injuries and may even lead to death in the case of older age. Due to increasing elderly population every year to the total population and the health problems and risks caused by fall especially among the age group of 60 and above, detecting fall at the earliest is essential in order to avoid human loss. Basically, fall detection is considered as a classification problem which requires developing a classifier model that recognizes and classifies normal human activities and abnormal activity like fall. Most of the existing fall detection methods are based on classifiers constructed using traditional methods such as decision trees, Bayesian Networks, Support Vector Machine etc. These classifiers may miss to cover certain hidden and interesting patterns in the data and thus suffer high false positives rates. This paper presents a novel algorithm called Frequent Bit Pattern based Associative Classification (FBPAC) that maps the tri-axial accelerometer data streams to bit patterns and mines the frequent bit pattern occurring for normal activities like sitting/standing, lying and walking within a time-sensitive sliding window. Unlike normal activities, fall have significant peak acceleration and it is detected by setting most significant bit of bit pattern and thus clearly distinguishes fall from lying activity, thereby reducing false positive rates. Empirical studies are conducted by collecting real time tri-axial accelerometer data from a wearable and unobtrusive sensing device. Experimental results show that within a time-sensitive sliding window of 10&#xa0;seconds, the proposed algorithm achieves up to 92% overall accuracy.},
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.06.013},
  ISSN                     = {1877-0509},
  Keywords                 = {Data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Detecting human activity and people falling. Mining sensors and checking acitivty. Most of the existing fall detection methods are based on classifiers constructed using traditional methods such as decision trees, Bayesian Networks, Support Vector Machine etc and have high false positive rate. Their approach is better. Experimental results show that within a time-sensitive sliding window of 10 seconds, the proposed algorithm achieves up to 92% overall accuracy. Approved 1,2,3,4,5,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050913006212}
}

@Article{Hemalatha2014,
  Title                    = {Minimal Infrequent Pattern based approach for mining outliers in data streams },
  Author                   = {C. Sweetlin Hemalatha and V. Vaidehi and R. Lakshmi},
  Journal                  = {Expert Systems with Applications },
  Year                     = {2014},
  Number                   = {0},
  Pages                    = { - },

  Abstract                 = {Abstract Outlier detection is an important task in data mining which aims at detecting patterns that are unusual in a dataset. Though several techniques are proved to be useful in solving some outlier detection problems, there are certain issues yet to be resolved. Most of the existing methods compute distance of points in full dimensional space to detect outliers. But in high dimensional space, the concept of proximity may not be qualitatively meaningful due to the curse of dimensionality and incurs high computational cost. Moreover, the existing methods focus on discovering outliers but do not provide the interpretability of different subspaces that cause the abnormality. Frequent pattern mining based approaches resolve the aforementioned issues. Recently, infrequent pattern mining has attracted the attention of data mining research community which aims at discovering rare associations. and researches in this area motivated to propose a new method to detect outliers in data streams. Infrequent patterns are more interesting than frequent patterns in some domains such as fraudulent credit transactions, anomaly detection etc. In such applications, mining infrequent patterns facilitates detecting outliers. Minimal infrequent patterns are generators of family of infrequent patterns. In this paper, a novel method is presented to detect outliers by mining minimal infrequent patterns from data streams. Three measures namely Transaction Weighting Factor (TWF), Minimal Infrequent Deviation Factor (MIPDF) and Minimal Infrequent Pattern based Outlier Factor (MIFPOF) are defined. An algorithm called Minimal Infrequent Pattern based Outlier Detection (MIFPOD) method is proposed for detecting outliers in data streams based on mined minimal infrequent patterns. The effectiveness of the proposed method is demonstrated on synthetic dataset obtained from vital dataset collected from body sensors and a publicly available real dataset. The experimental results have shown that the proposed method outperforms the existing methods in detecting outliers.},
  Doi                      = {http://dx.doi.org/10.1016/j.eswa.2014.09.053},
  ISSN                     = {0957-4174},
  Keywords                 = {Minimal infrequent pattern},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Outlier detection. In high dimensional space, the concept of proximity may not be qualitatively meaningful. Recently, infrequent pattern mining has attracted the attention of data mining research community which aims at discovering rare associations. Infrequent patterns are more interesting than frequent patterns in some domains such as fraudulent credit transactions, anomaly detection, etc. The effectiveness of the proposed method is demonstrated on synthetic dataset obtained from vital dataset collected from body sensors and a publicly available real dataset. The experimental results have shown that the proposed method outperforms the existing methods in detecting outliers. Approved 1,2,3,4,5,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0957417414006149}
}

@Misc{Hicks,
  Title                    = {{ohmage: An Open Mobile System for Activity and Experience Sampling}},

  Author                   = {Hicks, John and Ramanathan, Nithya and Falaki, Hossein and Longstaff, Brent and Parameswaran, Kannan and Monibi, Mohamad and Kim, Donnie H. and Selsky, Joshua and Jenkins, John and Tangmunarunkit, Hongsuda and Estrin, Deborah},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Advances in technology and infrastructure have positioned mobile phones as a convenient platform for real-time assessment of an individuals health and behavior, while offering unprecedented accessibility and affordability to both the producers and the consumers of the data. In this paper we address several of the key challenges that arise in leveraging smartphones for health: designing the complex set of building blocks required for an end-to-end system, motivating participants to sustain engagement in long-lived data collection, and interpreting both the data and the quality of the data collected. We present ohmage, a mobile to web platform that records, analyzes, and visualizes data from both prompted experience samples entered by the user, as well as continuous streams of data passively collected from sensors onboard the mobile device. In order to address the system design and participation motivation challenges, we have incorporated feedback from hundreds of behavioral and technology researchers, focus group participants, and end-users of the system in an iterative design process. ohmage additionally includes rich system and user analytics to instrument the act of participation itself and ultimately to contextualize and better understand the factors affecting the quality of collected data over time. We evaluate the usability and feasibility of},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {ohmage: An Open Mobile System for Activity and Experience Sampling. In this paper we address several of the key challenges that arise in leveraging smartphones for health. hmage additionally includes rich system and user analytics to instrument the act of participation itself and ultimately to contextualize and better understand the factors affecting the quality of collected data over time. We evaluate the usability and feasibility of ohmage using data from 3 studies with a variety of populations including young moms and recent breast cancer survivors. More than 85% of the diverse set of participants who responded to exit surveys claim they would use ohmage for further personal behavior discovery. Not really clear if using ML, but seemingly so. Approved 1,3,4},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.230.7068}
}

@Article{Hill2013,
  Title                    = {Automated Bayesian quality control of streaming rain gauge data },
  Author                   = {David J. Hill},
  Journal                  = {Environmental Modelling \& Software },
  Year                     = {2013},
  Number                   = {0},
  Pages                    = {289 - 301},
  Volume                   = {40},

  Abstract                 = {Radar-rainfall data are being used in an increasing number of real-time applications because of their wide spatial and temporal coverage. Because of uncertainties in radar measurements and the relationship between radar measurements and rainfall on the ground, radar-rainfall data are often combined with rain gauge data to improve their accuracy. However, while rain gauges can provide accurate estimates of rainfall, their data are sometimes corrupted with errors caused by the environment in which the gauges are deployed. This study develops a real-time method for identifying measurement errors in rain gauge data streams. This method employs a dynamic Bayesian network (DBN) model of the rain gauge data stream to sequentially forecast the next rain gauge measurement from both the rain gauge and weather radar data streams and a decision rule-based classifier to identify data errors. Because of the uncertainty in the relationship between the radar and rainfall measurements, this method uses a statistical learning method (expectation maximization) to determine the best parameters for this relationship, given an adaptively sized moving window of previous measurements. The performance of the error detector developed in this study is demonstrated using a precipitation sensor network composed of five telemetered tipping bucket rain gauges and a WSR-88D weather radar. Through an analysis using synthetic errors, the false alarm rate and false negative rate were calculated to be 0.90% and 1.5%, respectively.},
  Doi                      = {http://dx.doi.org/10.1016/j.envsoft.2012.10.006},
  ISSN                     = {1364-8152},
  Keywords                 = {Bayesian modeling},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This study develops a real-time method for identifying measurement errors in rain gauge data streams. Uses Dynamic Bayesian Networks. Through an analysis using synthetic errors, the false alarm rate and false negative rate were calculated to be 0.90% and 1.5%, respectively. Approved 1,3,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1364815212002538}
}

@Article{Hill2007,
  Title                    = {{Real-time bayesian anomaly detection for environmental sensor data}},
  Author                   = {Hill, David J. and Minsker, Barbara S. and Amir, Eyal},
  Journal                  = {IN 32ND CONFERENCE OF IAHR, THE INTERNATIONAL ASSOCIATION OF HYDRAULIC ENGINEERING \& RESEARCH},
  Year                     = {2007},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Real-time bayesian anomaly detection for environmental sensor data. This study investigates these methods’ abilities, using both coupled and uncoupled detection, to perform QA/QC on two windspeed data streams from Corpus Christi, Texas; The results indicate that a coupled DBN anomaly detector performs well at identifying erroneous data in these data streams. Approved 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.329.8262}
}

@Misc{Hinneburg,
  Title                    = {{Analyzing Data Streams by Online DFT}},

  Author                   = {Hinneburg, Er and Habich, Dirk and Karnstedt, Marcel},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {We present a new mining tool called Online DFT, which is particularly powerful for estimating the spectrum of a data stream. Almost no information in the abstract. Unique features of our new method include its low update complexity with high-accuracy estimations for very long periods. It is not related to any particular problem or any algorithm Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.102.2808}
}

@Article{HJWSL2009,
  Title                    = {{estMax: Tracing Maximal Frequent Item Sets Instantly over Online Transactional Data Streams}},
  Author                   = {{Ho Jin Woo} and {Won Suk Lee}},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2009},

  Month                    = oct,
  Number                   = {10},
  Pages                    = {1418--1431},
  Volume                   = {21},

  Abstract                 = {Frequent item set mining is one of the most challenging issues for descriptive data mining. In general, its resulting set tends to produce a large number of frequent item sets. To represent them in a more compact notation, closed or maximal frequent item sets are often used but finding such item sets over online transactional data streams is not easy due to the requirements of a data stream. For this purpose, this paper proposes a method of tracing the set of MFIs instantly over an online data stream. The method, namely estMax, maintains the set of frequent item sets by a prefix tree and extracts all MFIs without any additional superset/subset checking mechanism. Upon processing a new transaction, those frequent item sets that are matched maximally by the transaction are newly marked in their corresponding nodes of the prefix tree as candidates for MFIs. At the same time, if any subset of a newly marked item set has been already marked as a candidate MFI by a previous transaction, it is cleared as well. By employing this additional step, it is possible to extract the set of MFIs at any moment. The performance of the estMax method is comparatively analyzed by a series of experiments to identify its various characteristics.},
  Doi                      = {10.1109/TKDE.2008.233},
  ISSN                     = {1041-4347},
  Keywords                 = {Data mining,Mining methods and algorithms,data mining,descriptive data mining,estMax method,frequent item set mining,maximal frequent item sets,online transactional data stream,superset-subset checking mechanism,transaction processing,transactional data streams.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Woo2009. Discarded.},
  Shorttitle               = {Knowledge and Data Engineering, IEEE Transactions },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4711051}
}

@Misc{Ho,
  Title                    = {{Learning from data streams via online transduction}},

  Author                   = {Ho, Shen-Shyang and et Al.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A practical issue in the existing transduction methods is expensive and inefficient computation compared to induction methods. This has hindered the use of transduction methods in temporal and real-time data mining. In this paper, we introduce a fast incremental transductive confidence machine (TCM) based on adiabatic incremental support vector machine (SVM) such that critical information from current transduction trial is stored for later use. The algorithm is empirically shown to be computationally efficient and its performance is consistent with standard TCM implementation. Besides being a classifier, TCM provides additional useful statistical information about the data that it processed. These information can be useful for temporal and real-time data mining. We demonstrate the feasibility and usefulness of using such statistical information for stream-based active learning.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Existing transduction methods is expensive and inefficient computation compared to induction methods. Introduce a fast incremental transductive confidence machine based on adiabatic incremental SVM. Feasibility is demonstrated. Approved 1,2,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.480}
}

@Conference{Ho2008,
  Title                    = {Automated cyclone discovery and tracking using knowledge sharing in multiple heterogeneous satellite data},
  Author                   = {Ho, S.-S. and Talukder, A.},
  Year                     = {2008},
  Note                     = {cited By (since 1996)4},
  Pages                    = {928-936},

  Abstract                 = {Current techniques for cyclone detection and tracking employ NCEP (National Centers for Environmental Prediction) models from in-situ measurements. This solution does not provide true global coverage, unlike remote satellite observations. However it is impractical to use a single Earth orbiting satellite to detect and track events such as cyclones in a continuous manner due to limited spatial and temporal coverage. One solution to alleviate such persistent problems is to utilize heterogeneous sensor data from multiple orbiting satellites. However, this solution requires overcoming other new challenges such as varying spatial and temporal resolution between satellite sensor data, the need to establish correspondence between features from different satellite sensors, and the lack of definitive indicators for cyclone events in some sensor data. We describe an automated cyclone discovery and tracking approach using heterogeneous near real-time sensor data from multiple satellites. This approach addresses the unique challenges associated with knowledge discovery and mining from heterogeneous satellite data streams. We consider two remote sensor measurements in our current implementation, namely: QuikSCAT wind satellite measurements, and merged precipitation data from TRMM and other satellites. More satellites will be incorporated in the near future and our solution is sufficiently powerful that it generalizes to multiple sensor measurement modalities. Our approach consists of three main components: (i) feature extraction from each sensor measurement, (ii) an ensemble classifier for cyclone discovery, and (iii) knowledge sharing between the different remote sensor measurements based on a linear Kalman filter for predictive cyclone tracking. Experimental results on historical hurricane datasets demonstrate the superior performance of our approach compared to previous work. Ã‚Â© 2008 ACM.},
  Affiliation              = {Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Ave 300-123, Pasadena, CA 91109, United States},
  Author_keywords          = {Ensemble classifier; Event detection and prediction; Event tracking; Heterogeneous data mining; Knowledge transfer; Mining massive data stream; Multi-sensor data fusion; Real-time data mining},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Cyclone detection and tracking is currently using measurements from the local area, which is not truly global tracking. We describe an automated cyclone discovery and tracking approach using heterogeneous near real-time sensor data from multiple satellites. Ensemble classifier. Experimental results on historical hurricane datasets demonstrate the superior performance of our approach compared to previous work. Approved 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-65449147556&partnerID=40&md5=ce676c5ec881285a990ac5be58aa79f0}
}

@InProceedings{Ho2008a,
  Title                    = {{Automated cyclone discovery and tracking using knowledge sharing in multiple heterogeneous satellite data}},
  Author                   = {Ho, Shen-Shyang and Talukder, Ashit},
  Booktitle                = {Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD 08},
  Year                     = {2008},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {928},
  Publisher                = {ACM Press},

  Abstract                 = {Current techniques for cyclone detection and tracking employ NCEP (National Centers for Environmental Prediction) models from in-situ measurements. This solution does not provide true global coverage, unlike remote satellite observations. However it is impractical to use a single Earth orbiting satellite to detect and track events such as cyclones in a continuous manner due to limited spatial and temporal coverage. One solution to alleviate such persistent problems is to utilize heterogeneous sensor data from multiple orbiting satellites. However, this solution requires overcoming other new challenges such as varying spatial and temporal resolution between satellite sensor data, the need to establish correspondence between features from different satellite sensors, and the lack of definitive indicators for cyclone events in some sensor data. We describe an automated cyclone discovery and tracking approach using heterogeneous near real-time sensor data from multiple satellites. This approach addresses the unique challenges associated with knowledge discovery and mining from heterogeneous satellite data streams. We consider two remote sensor measurements in our current implementation, namely: QuikSCAT wind satellite measurements, and merged precipitation data from TRMM and other satellites. More satellites will be incorporated in the near future and our solution is sufficiently powerful that it generalizes to multiple sensor measurement modalities. Our approach consists of three main components: (i) feature extraction from each sensor measurement, (ii) an ensemble classifier for cyclone discovery, and (iii) knowledge sharing between the different remote sensor measurements based on a linear Kalman filter for predictive cyclone tracking. Experimental results on historical hurricane datasets demonstrate the superior performance of our approach compared to previous work.},
  Doi                      = {10.1145/1401890.1402001},
  ISBN                     = {9781605581934},
  Keywords                 = {ensemble classifier,event detection and prediction,event tracking,heterogeneous data mining,knowledge transfer,mining massive data stream,multi-sensor data fusion,real-time data mining},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ho2008. Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1401890.1402001}
}

@Article{Hofgesang2009,
  Title                    = {Online mining of web usage data: An overview},
  Author                   = {Hofgesang, P.I.},
  Journal                  = {Studies in Computational Intelligence},
  Year                     = {2009},
  Note                     = {cited By (since 1996)2},
  Pages                    = {1-23},
  Volume                   = {172},

  Abstract                 = {In recent years, web usage mining techniques have helped online service providers to enhance their services, and restructure and redesign their websites in line with the insights gained. The application of these techniques is essential in building intelligent, personalised online services. More recently, it has been recognised that the shift from traditional to online services -and so the growing numbers of online customers and the increasing traffic generated by them -brings new challenges to the field. Highly demanding real-world E-commerce and E-services applications, where the rapid, and possibly changing, large volume data streams do not allow offline processing, motivate the development of new, highly efficient real-time web usage mining techniques. This chapter provides an introduction to online web usage mining and presents an overview of the latest developments. In addition, it outlines the major, and yet mostly unsolved, challenges in the field. Ã‚Â© 2009 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {Department of Computer Science, VU University Amsterdam, De Boelelaan 1081A, 1081 HV Amsterdam, Netherlands},
  Author_keywords          = {Data stream mining; Incremental algorithms; Online web usage mining; Survey},
  Document_type            = {Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {E-commerce and e-services, where rapid high volume data is a problem require new efficient real time mining. This paper reviews recent developments and state of online web mining. Discarded, but put aside.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57749180194&partnerID=40&md5=d76eed83ff7f0f1c1885f8a7b82366b2}
}

@Article{Hofleitner2012,
  Title                    = {Arterial travel time forecast with streaming data: A hybrid approach of flow modeling and machine learning },
  Author                   = {Aude Hofleitner and Ryan Herring and Alexandre Bayen},
  Journal                  = {Transportation Research Part B: Methodological },
  Year                     = {2012},
  Number                   = {9},
  Pages                    = {1097 - 1122},
  Volume                   = {46},

  Abstract                 = {This article presents a hybrid modeling framework for estimating and predicting arterial traffic conditions using streaming \{GPS\} probe data. The model is based on a well-established theory of traffic flow through signalized intersections and is combined with a machine learning framework to both learn static parameters of the roadways (such as free flow velocity or traffic signal parameters) as well as to estimate and predict travel times through the arterial network. The machine learning component of the approach uses the significant amount of historical data collected by the Mobile Millennium system since March 2009 with over 500 probe vehicles reporting their position once per minute in San Francisco, CA. The hybrid model provides a distinct advantage over pure statistical or pure traffic theory models in that it is robust to noisy data (due to the large volumes of historical data) and it produces forecasts using traffic flow theory principles consistent with the physics of traffic. Validation of the model is performed in two different ways. First, a large scale test of the model is performed by splitting the data source into two sets, using the first to produce the estimates and the second to validate them. Second, an alternate validation approach is presented. It consists of a 3-day experiment in which \{GPS\} data was collected once per second from 20 drivers on four routes through San Francisco, allowing for precise calculation of actual travel times. The model is run by down-sampling the data and validated using the travel times from these 20 drivers. The results indicate that this approach is a significant step forward in estimating traffic states throughout the arterial network using a relatively small amount of real-time data. The estimates from our model are compared to those given by a data-driven baseline algorithm, for which we achieve a 16% improvement in terms of the root mean squared error of travel time estimates. The primary reason for success is the reliance on a flow model of traffic, which ensures that estimates are consistent with the physics of traffic.},
  Doi                      = {http://dx.doi.org/10.1016/j.trb.2012.03.006},
  ISSN                     = {0191-2615},
  Keywords                 = {Arterial traffic},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Estimating and predicting traffic conditions. Hybrid model of traffic theory and machine learning. First, a large scale test of the model is performed by splitting the data source into two sets, using the first to produce the estimates and the second to validate them. he estimates from our model are compared to those given by a data-driven baseline algorithm, for which we achieve a 16% improvement in terms of the root mean squared error of travel time estimates. Approved 1,2,3,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0191261512000513}
}

@Article{Horovitz2005,
  Title                    = {Making sense of ubiquitous data streams - A fuzzy logic approach},
  Author                   = {Horovitz, O. and Gaber, M.M. and Krishnaswamy, S.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2005},
  Note                     = {cited By (since 1996)2},
  Pages                    = {922-928},
  Volume                   = {3682 LNAI},

  Abstract                 = {There is currently a growing new focus in data mining - Ubiquitous Data Mining (UDM). UDM is the process of mining data streams in a ubiquitous environment, on resource constrained devices [KPP02]. UDM is widely applied in facilitating real-time decision making in mobile and highly dynamic environments/applications, such as road safety and mobile stock portfolio monitoring. A significant challenge in these contexts is the interpretation and analysis of results produced through unsupervised techniques (which are invaluable since little is known about the streamed data). We propose a novel fuzzy approach that leverages the significant benefits of UDM clustering and supplements the interpretation and use of these results through using expert/background knowledge. Ã‚Â© Springer-Verlag Berlin Heidelberg 2005.},
  Affiliation              = {School of Computer Science and Software Engineering, Monash University, Australia},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Older version of Horovitz2007. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33745318456&partnerID=40&md5=1d4deb9cb169916a529376c59627994b}
}

@Article{Horovitz2007,
  Title                    = {A fuzzy approach for interpretation of ubiquitous data stream clustering and its application in road safety},
  Author                   = {Horovitz, O. and Krishnaswamy, S. and Gaber, M.M.},
  Journal                  = {Intelligent Data Analysis},
  Year                     = {2007},
  Note                     = {cited By (since 1996)9},
  Number                   = {1},
  Pages                    = {89-108},
  Volume                   = {11},

  Abstract                 = {Ubiquitous Data Mining is the process of analysing data emanating from distributed and heterogeneous sources in the form of a continuous stream with mobile and/or embedded devices. Unsupervised learning is clearly beneficial for initial understanding of data streams, and consequently various clustering algorithms have been developed and applied in UDM systems for the purpose of mining data streams. However, unsupervised data mining techniques require human intervention for further understanding and analysis of the clustering results. This becomes an issue as UDM applications aim to support mobile and highly dynamic users/applications and there is a need for real-time decision making and interpretation of results. In this paper we present an approach to automate the annotation of results obtained from ubiquitous data stream clustering to facilitate interpreting and use of the results to enable real-time, mobile decision making. Ã‚Â© 2007 - IOS Press and the authors. All rights reserved.},
  Affiliation              = {Caulfield School of Information Technology, Monash University, VIC, Australia},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Ubiquitous Data Mining - mining on resource constrained devices. Interpretation and analysis of results from unsupervised results is a big challenge. In this paper we present an approach to automate the annotation of results obtained from ubiquitous data stream clustering to facilitate interpreting and use of the results to enable real-time, mobile decision making. Approved 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-41849138277&partnerID=40&md5=e7999550bf2d8d66fcda2244481ae308}
}

@Misc{Hossain,
  Title                    = {{Bayesian Classification on Spatial Data Streams Using P-Treesâ€™, CS-NDSU}},

  Author                   = {Hossain, Mohammad and Perera, Amal Shehan and Perrizo, William},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Classification of spatial data can be difficult with existing methods due to the large numbers and sizes of spatial data sets. The task becomes even more difficult when we consider continuous spatial data streams. Data streams require a classifier that can be built and rebuilt repeatedly in near real time. This paper presents an approach to deal with this challenge. Our approach uses the Peano Count Tree (P-tree), which provides a lossless, compressed and data-mining-ready representation (data structure) for spatial data. This data structure can be applied in many classification techniques. In this paper we focus on Bayesian classification. A Bayesian classifier is a statistical classifier, which uses the Bayes theorem to predict class membership as a conditional probability that a given data sample falls into a particular class. In this paper we demonstrate how P-trees can improve the classification of spatial data when using a Bayesian classifier. We also introduce the use of information gain calculations with Bayesian classification to improve its accuracy. The use of a P-tree based Bayesian classifier can not only make classification more effective on spatial data, but also can reduce the build time of the classifier considerably. This improvement in build time makes it feasible for use with streaming data.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Bayesian Classification on Spatial Data Streams Using P-Trees. n this paper we demonstrate how P-trees can improve the classification of spatial data when using a Bayesian classifier. Approved 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.126.9602}
}

@InProceedings{HFLHHSC2008,
  Title                    = {{Efficiently mining frequent patterns in recent music query streams}},
  Author                   = {{Hua-Fu Li} and {Ming-Ho Hsiao} and {Hsuan-Sheng Chen}},
  Booktitle                = {2008 IEEE International Conference on Multimedia and Expo},
  Year                     = {2008},
  Month                    = jun,
  Pages                    = {1269--1272},
  Publisher                = {IEEE},

  Abstract                 = {Mining frequent melody structures from music data is one of the most important issues in multimedia data mining. In this paper, we proposed an efficient online algorithm, called BVMDS (bit-vector based mining of data streams), to mine all frequent temporal patterns over sliding windows of music melody sequence streams. An effective bit-sequence representation is used in BVMDS to reduce the time and memory needed to slide the windows. An effective list structure is used to overcome the performance bottleneck of previous work, FTP-stream. Experiments show that the BVMDS algorithm outperforms FTP-stream algorithm, and just scans the streaming data once.},
  Doi                      = {10.1109/ICME.2008.4607673},
  ISBN                     = {978-1-4244-2570-9},
  Keywords                 = {Buffer storage,Computer science,Data mining,Data structures,Measurement,Monitoring,Multiple signal classification,Streaming media,Telecommunication network management,Telecommunication traffic,bit-sequence representation,bit-vector based mining,data mining,data streams,melody structures,mining frequent patterns,multimedia data mining,multimedia systems,music,music data,music query streams,query processing,sliding windows},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining frequent melodies from music. In this paper, we proposed an efficient online algorithm, called BVMDS. An effective list structure is used to overcome the performance bottleneck of previous work, FTP-stream, which is outperformed in performed experiments. Approved 1,2,3,4,6},
  Shorttitle               = {Multimedia and Expo, 2008 IEEE International Confe},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4607673}
}

@InProceedings{HFLYL2004,
  Title                    = {{Single-pass algorithms for mining frequency change patterns with limited space in evolving append-only and dynamic transaction data streams}},
  Author                   = {{Hua-Fu Li} and {Suh-Yin Lee}},
  Booktitle                = {IEEE International Conference on e-Technology, e-Commerce and e-Service, 2004. EEE '04. 2004},
  Year                     = {2004},
  Pages                    = {215--222},
  Publisher                = {IEEE},

  Abstract                 = {We propose an online single-pass algorithm MFC-append (mining frequency change patterns in append-only data streams) for online mining frequent frequency change items in continuous append-only data streams. An online space-efficient data structure called Change-Sketch is developed for providing fast response time to compute dynamic frequency changes between data streams. A modified approach MFC-dynamic (mining frequency change patterns in dynamic data streams) is also presented to mine frequency changes in dynamic data streams. The theoretic analyses show that our algorithms meet the major performance requirements of single-pass, bounded storage, and real time for streaming data mining.},
  Doi                      = {10.1109/EEE.2004.1287312},
  ISBN                     = {0-7695-2073-1},
  Keywords                 = {Algorithm design and analysis,Change-Sketch data structure,Computer science,Data engineering,Data mining,Data structures,Decision trees,Delay,Frequency,Monitoring,Performance analysis,append-only data stream,computational complexity,data mining,data stream model,data structures,deterministic algorithms,dynamic transaction data streams,frequency change pattern mining,online single-pass algorithm,transaction processing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Mining frequent frequency change items. The theoretic analyses show that our algorithms meet the major performance requirements of single-pass, bounded storage, and real time for streaming data mining. Approved 1,6},
  Shorttitle               = {e-Technology, e-Commerce and e-Service, 2004. EEE },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1287312}
}

@InProceedings{HFLYLKS2005,
  Title                    = {{DSM-TKP: Mining Top-K Path Traversal Patterns over Web Click-Streams}},
  Author                   = {{Hua-Fu Li} and {Suh-Yin Lee} and {Man-Kwan Shan}},
  Booktitle                = {The 2005 IEEE/WIC/ACM International Conference on Web Intelligence (WI'05)},
  Year                     = {2005},
  Pages                    = {326--329},
  Publisher                = {IEEE},

  Abstract                 = {Online, single-pass mining Web click streams poses some interesting computational issues, such as unbounded length of streaming data, possibly very fast arrival rate and just one scan over previously arrived click-sequencer In this paper, we propose a new, single-pass algorithm, called DSM-TKP (data stream mining for top-k path traversal patterns), for mining top-k path traversal patterns, where k is the desired number of path traversal patterns to be mined. An effective summary data structure called TKP-forest (top-k path forest) is used to maintain the essential information about the top-k path traversal patterns of the click-stream so far. Experimental studies show that DSM-TKP algorithm uses stable memory usage and makes only one pass over the streaming data.},
  Doi                      = {10.1109/WI.2005.56},
  ISBN                     = {0-7695-2415-X},
  Keywords                 = {Computer science,Data engineering,Data mining,Data models,Data structures,Databases,Internet,Itemsets,Measurement,Monitoring,Telecommunication traffic,Web click-stream,data mining,data stream mining,data structures,memory usage,single-pass algorithm,summary data structure,top-k path forest,top-k path traversal pattern,tree searching},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2005b},
  Shorttitle               = {Web Intelligence, 2005. Proceedings. The 2005 IEEE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1517866}
}

@InProceedings{HFLYLKS2005a,
  Title                    = {{Online Mining (Recently) Maximal Frequent Itemsets over Data Streams}},
  Author                   = {{Hua-Fu Li} and {Suh-Yin Lee} and {Man-Kwan Shan}},
  Booktitle                = {15th International Workshop on Research Issues in Data Engineering: Stream Data Mining and Applications (RIDE-SDMA'05)},
  Year                     = {2005},
  Pages                    = {11--18},
  Publisher                = {IEEE},

  Abstract                 = {A data stream is a massive, open-ended sequence of data elements continuously generated at a rapid rate. Mining data streams is more difficult than mining static databases because the huge, high-speed and continuous characteristics of streaming data. In this paper, we propose a new one-pass algorithm called DSM-MFI (stands for Data Stream Mining for Maximal Frequent Itemsets), which mines the set of all maximal frequent itemsets in landmark windows over data streams. A new summary data structure called summary frequent itemset forest (abbreviated as SFI-forest) is developed for incremental maintaining the essential information about maximal frequent itemsets embedded in the stream so far. Theoretical analysis and experimental studies show that the proposed algorithm is efficient and scalable for mining the set of all maximal frequent itemsets over the entire history of the data streams.},
  Doi                      = {10.1109/RIDE.2005.13},
  ISBN                     = {0-7695-2390-0},
  ISSN                     = {1097-8585},
  Keywords                 = {Algorithm design and analysis,Computer science,DSM-MFI,Data Stream Mining for Maximal Frequent Itemsets,Data engineering,Data mining,Data models,Data structures,History,Itemsets,Measurement,SFI-forest,Transaction databases,data mining,data streams,data structures,landmark windows,one-pass algorithm,online mining,static databases,summary data structure},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Data Stream Mining for Maximal Frequent Itemsets. New summary structure for itemset forest. Theoretical analysis and experimental studies show that the proposed algorithm is efficient and scalable for mining the set of all maximal frequent itemsets over the entire history of the data streams. Approved 1,3,4,6},
  Shorttitle               = {Research Issues in Data Engineering: Stream Data M},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1498226}
}

@InProceedings{HFLYLKS2004,
  Title                    = {{Mining frequent closed structures in streaming melody sequences}},
  Author                   = {{Hua-Fu Li} and {Suh-Yin Lee} and {Man-Kwan Shan}},
  Booktitle                = {2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)},
  Year                     = {2004},
  Pages                    = {2031--2034},
  Publisher                = {IEEE},
  Volume                   = {3},

  Abstract                 = {We study the problem of mining frequent closed structures in a continuous, infinite-sized, and fast changing music melody stream. By modeling a music melody as a sequence of chord-sets, we propose an efficient algorithm FCS-stream (frequent closed structures of streaming melody sequences) for incremental mining of frequent closed structures in one scan of the continuous stream of chord-set sequences. An extended prefix-tree structure called TCS-tree (temporal closed structure tree) is developed for storing compact, essential information about the frequent closed structures of the stream. Results from our theoretical analysis and experimental studies with synthetic data show that the FCS-stream algorithm satisfies the main performance requirements, namely, single-pass, bounded memory, and real-time, for data stream mining.},
  Doi                      = {10.1109/ICME.2004.1394663},
  ISBN                     = {0-7803-8603-5},
  Keywords                 = {Algorithm design and analysis,Buffer storage,Computer science,Data mining,Data models,FCS-stream,Operating systems,Performance analysis,Query processing,Terminology,Transaction databases,audio signal processing,chord-set sequences,continuous infinite-sized melody stream,data mining,data stream mining,fast changing music melody stream,frequent closed structure mining,incremental mining,information analysis,music,prefix-tree structure,query processing,streaming melody sequences,temporal closed structure tree,trees (mathematics)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {More recent contribution from the same project as HFLHHSC2008, but seems complimentary. The problem of mining frequent closed structures in a continuous, infinite-sized, and fast changing music melody stream. Results from our theoretical analysis and experimental studies with synthetic data show that the FCS-stream algorithm satisfies the main performance requirements, namely, single-pass, bounded memory, and real-time, for data stream mining. Approved 1,3,4,6},
  Shorttitle               = {Multimedia and Expo, 2004. ICME '04. 2004 IEEE Int},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1394663}
}

@Article{Huang2014,
  Title                    = {Online mining abnormal period patterns from multiple medical sensor data streams},
  Author                   = {Huang, G.a and Zhang, Y.a and Cao, J.b and Steyn, M.a c and Taraporewalla, K.c },
  Journal                  = {World Wide Web},
  Year                     = {2014},
  Note                     = {cited By (since 1996)1},
  Number                   = {4},
  Pages                    = {569-587},
  Volume                   = {17},

  Abstract                 = {With the advanced technology of medical devices and sensors, an abundance of medical data streams are available. However, data analysis techniques are very limited, especially for processing massive multiple physiological streams that may only be understood by medical experts. The state-of-the-art techniques only allow multiple medical devices to independently monitor different physiological parameters for the patient's status, thus they signal too many false alarms, creating unnecessary noise, especially in the Intensive Care Unit (ICU). An effective solution which has been recently studied is to integrate information from multiple physiologic parameters to reduce alarms. But it is a challenge to detect abnormalities from high frequently changed physiological streams data, since abnormalities occur gradually due to the complex situation of patients. An analysis of ICU physiological data streams shows that many vital physiological parameters are changed periodically (such as heart rate, arterial pressure, and respiratory impedance) and thus abnormalities are generally abnormal period patterns. In this paper, we develop a Mining Abnormal Period Patterns from Multiple Physiological Streams (MAPPMPS) method to detect and rank abnormalities in medical sensor streams. The efficiency and effectiveness of the MAPPMPS method is demonstrated by a real-world massive database of multiple physiological streams sampled in ICU, comprising 250 patients' streams (each stream involving over 1.3 million data points) with a total size of 28 GB data. Ã‚Â© 2013 Springer Science+Business Media New York.},
  Affiliation              = {Center for Applied Informatics, Victoria University, Melbourne, Australia; Nanjing University of Finance and Economics, Nanjing, China; Royal Brisbane and Women's Hospital, Herston, Australia},
  Author_keywords          = {Abnormal period patterns; Data mining; Medical sensor data streams; Multiple data streams},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Abonrmal periods in medicine. The state-of-the-art techniques only allow multiple medical devices to independently monitor different physiological parameters for the patient's status, thus they signal too many false alarms. Medicinal singals change periodically often. Develop Mining Abnormal Period Patterns from Multiple Physiological Streams (MAPPMPS) method to detect and rank abnormalities in medical sensor streams. Is demonstrated by a real-world massive database of multiple physiological streams sampled in ICU. Approved 1,2,3,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84902362543&partnerID=40&md5=84a29f0a81d1ac968457a44ceb464d59}
}

@Article{Huang2011,
  Title                    = {A semi-supervised boosting algorithm for mining time-changing data streams},
  Author                   = {Huang, S. and Sha, A. and Ma, S.},
  Journal                  = {Journal of Information and Computational Science},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Number                   = {13},
  Pages                    = {2807-2814},
  Volume                   = {8},

  Abstract                 = {Mining time-changing data streams is of great interest due to its many applications. The fundamental challenges are how to detect the change online and gather sufficient labeled training data to adjust the obsolete classifier. Most current solutions mainly assume the labeled data is available, which is usually violated in real word applications. This paper proposes a semi-supervised boosting algorithm to address these issues. In detail, a method without need for labeled data is used to monitor the change. Upon concept-drift is detected, an information regularization based semi-supervised boosting algorithm is utilized to adjust the outdated model. Thus our solution can detect the change and adapt to it without need extra labeling efforts. Experimental results from both synthetic and real-world data show the advantages of our solution. 1548-7741/Copyright Ã‚Â© 2011 Binary Information Press.},
  Affiliation              = {School of Computer Science and Engineering, Jiangsu University of Science and Technology, Zhenjiang 212003, China},
  Author_keywords          = {Concept-drift; Mining time-changing data streams; Mutual information regularization; Semi-supervised boosting},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Semi-supervised boosting algorithm for mining from drifting streams. Upon concept-drift is detected, an information regularization based semi-supervised boosting algorithm is utilized to adjust the outdated model, without requiring new labeling. Experimental results from both synthetic and real-world data show the advantages of our solution. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-83255170663&partnerID=40&md5=dc48acd467f9f8380dbe335734803c90}
}

@Article{Huang2009,
  Title                    = {History guided low-cost change detection in streams},
  Author                   = {Huang, W. and Omiecinski, E. and Mark, L. and Nguyen, M.Q.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {75-86},
  Volume                   = {5691 LNCS},

  Abstract                 = {Change detection in continuous data streams is very useful in today's computing environment. However, high computation overhead prevents many data mining algorithms from being used for online monitoring. We propose a history-guided low-cost change detection method based on the "s-monitor" approach. The "s-monitor" approach monitors the stream with simple models ("s-monitors") which can reflect changes of complicated models. By interleaving frequent s-monitor checks and infrequent complicated model checks, we can keep a close eye on the stream without heavy computation overhead. The selection of s-monitors is critical for successful change detection. History can often provide insights to select appropriate s-monitors and monitor the streams. We demonstrate this method using subspace cluster monitoring for log data and frequent item set monitoring for retail data. Our experiments show that this approach can catch more changes in a more timely manner with lower cost than traditional approaches. The same approach can be applied to different models in various applications, such as monitoring live weather data, stock market fluctuations and network traffic streams. Ã‚Â© 2009 Springer Berlin Heidelberg.},
  Affiliation              = {College of Computing, Georgia Institute of Technology, Atlanta, United States},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Change detection in streams. High computation overhead prevents many data mining algorithms from being used for online monitoring, so they present a low cost approach. Our experiments on both synthetic and real world data show that this approach can catch more changes in a more timely manner with lower cost. Approved 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70349323157&partnerID=40&md5=771eca22765097c34d52d0f3a78c4e6b}
}

@Conference{Huang2005,
  Title                    = {S-monitors: Low-cost change detection in data streams},
  Author                   = {Huang, W.a and Omiecinski, E.a and Mark, L.a and Zhao, W.b },
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Pages                    = {85-100},

  Abstract                 = {Change detection in continuous data streams is very useful in today's computing environment. However, high computation overhead prevents many data mining algorithms from being used for online monitoring. We formalize the change detection problem and propose several metrics to evaluate change detection algorithms. We then present a novel low-cost approach to detect changes of models in streams and demonstrate the advantages of this approach using subspace cluster monitoring as an example. Our experiments on both synthetic and real world data show that this approach can catch more changes in a more timely manner with lower cost. The same approach can be applied to different models in various applications, such as monitoring live weather/environmental data, stock market fluctuations and network traffic streams. Ã‚Â© 2013.},
  Affiliation              = {College of Computing, Georgia Institute of Technology, Atlanta GA, United States; School of Computer and Information Science, University of South Australia, Australia},
  Author_keywords          = {Change detection; Low-cost; S-monitor; Stream},
  Document_type            = {Conference Paper},
  Journal                  = {AusDM 2005 Proc. - 4th Australasian Data Mining Conf. - Collocated with the 18th Australian Joint Conf. on Artificial Intelligence, AI 2005 and the 2nd Australian Conf. on Artifical Life, ACAL 2005},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Older version of Huang2009.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84884318785&partnerID=40&md5=09ca38e6309cb4b84da29a9f90c835a0}
}

@InProceedings{Huijun2012,
  Title                    = {{A New Evolving Data Streams System with Data Fusion}},
  Author                   = {Huijun, Yu and Zhigang, Wang and Xiaoyan, Liu},
  Booktitle                = {2012 International Conference on Industrial Control and Electronics Engineering},
  Year                     = {2012},
  Month                    = aug,
  Pages                    = {1743--1746},
  Publisher                = {IEEE},

  Abstract                 = {Cluster analysis is an important data mining issue, where objects under investigation are grouped into subsets of the original set of objects. In recent several years, a few clustering algorithms have been developed for the data stream problem. However these algorithms lack of extensibility or efficiency. In this paper we propose a new evolving data streams system with data fusion. We discuss a fundamentally different philosophy for data stream clustering which is guided by application centered requirements. The system is highly suitable for real-time implementation and is demonstrated through a series of experiments. The experiments over a number of real and synthetic data sets illustrate the effectiveness and efficiency.},
  Doi                      = {10.1109/ICICEE.2012.461},
  ISBN                     = {978-1-4673-1450-3},
  Keywords                 = {Algorithm design and analysis,Cluster,Clustering algorithms,Data mining,Data stream,Real-time systems,Robustness,Streaming media,Time series analysis,cluster analysis,clustering algorithms,data fusion,data mining,data streams system,evolving algorithm,fusion,pattern clustering,sensor fusion,synthetic data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In recent several years, a few clustering algorithms have been developed for the data stream problem, but they lack extensibility or efficiency. A new philosphy for clsutering which is application centered. The experiments over a number of real and synthetic data sets illustrate the effectiveness and efficiency. Approved 1,2,3,4,6},
  Shorttitle               = {Industrial Control and Electronics Engineering (IC},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6322751}
}

@Article{Hunter2007,
  Title                    = {Feature extraction from sensor data streams for real-time human behaviour recognition},
  Author                   = {Hunter, J. and Colley, M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)1},
  Pages                    = {115-126},
  Volume                   = {4702 LNAI},

  Abstract                 = {In this paper we illustrate the potential of motion behaviour analysis in assessing the wellbeing of unsupervised, vulnerable individuals. By learning the routine motion behaviour of the subject (i.e. places visited, routes taken between places) we show it is possible to detect unusual behaviours while they are happening. This requires the processing of continuous sensor data streams, and real-time recognition of the subject's behaviour. To address privacy concerns, analysis will be performed locally to the subject on a small computing device. Current data mining techniques were not developed for restricted computing environments, nor for the demands of real-time behaviour recognition. In this paper we present a novel, online technique for discretizing a sensor data stream that supports both unsupervised learning of human motion behaviours and real-time recognition. We performed experiments using GPS data and compared the results of Dynamic Time Warping. Ã‚Â© Springer-Verlag Berlin Heidelberg 2007.},
  Affiliation              = {Department of Computer Science, University of Essex, Wivenhoe Park, Colchester CO4 3SQ, United Kingdom},
  Author_keywords          = {Real-time behaviour recognition; Sensor data stream discretization; Unsupervised learning},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Real-time human behavior recognition, to detect unusual behaviors. For privacy, analysis is performed on a small computing device local to the subject. In this paper we present a novel, online technique for discretizing a sensor data stream that supports both unsupervised learning of human motion behaviours and real-time recognition. Performed experiments and compared it to Dynamic Time Warping. Approved 1,2,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38049129643&partnerID=40&md5=9b9525f80dd69f034116251def946e85}
}

@Misc{Hyuk,
  Title                    = {{Finding Recent Frequent Itemsets Adaptively over Online Data Streams}},

  Author                   = {Hyuk, Joong and Won, Chang and Lee, Suk},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A data stream is a massive unbounded sequence of data elements continuously generated at a rapid rate. Consequently, the knowledge embedded in a data stream is more likely to be changed as time goes by. Identifying the recent change of a data stream, specially for an online data stream, can provide valuable information for the analysis of the data stream. In addition, monitoring the continuous variation of a data stream enables to find the gradual change of embedded knowledge. However, most of mining algorithms over a data stream do not differentiate the information of recently generated transactions from the obsolete information of old transactions which may be no longer useful or possibly invalid at present. This paper proposes a data mining method for finding recent frequent itemsets adaptively over an online data stream. The effect of old transactions on the mining result of the data steam is diminished by decaying the old occurrences of each itemset as time goes by. Furthermore, several optimization techniques are devised to minimize processing time as well as main memory usage. Finally, the proposed method is analyzed by a series of experiments.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Finding recent frequent itemsets. Most mining algorithms do not differentiate between obselete information from relevant info. Their approach diminishes old occurences. Analyzed by a series of experiments. Approved 1,2,3,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.132.1264}
}

@InProceedings{Ikonomovska2011,
  Title                    = {{Adaptive Windowing for Online Learning from Multiple Inter-related Data Streams}},
  Author                   = {Ikonomovska, Elena and Driessens, Kurt and Dzeroski, Saso and Gama, Joao},
  Booktitle                = {2011 IEEE 11th International Conference on Data Mining Workshops},
  Year                     = {2011},
  Month                    = dec,
  Pages                    = {697--704},
  Publisher                = {IEEE},

  Abstract                 = {Relational reinforcement learning is a promising branch of reinforcement learning research that deals with structured environments. In these environments, states and actions are differentiated by the presence of certain types of objects and the relations between them and the objects that are involved in the actions. This makes it ultimately suited for tasks that require the manipulation of multiple, interacting objects, such as tasks that a future house-holding robot can be expected to perform like cleaning up a dinner table or storing away done dishes. However, the application of relational reinforcement learning to robotics has been hindered by assumptions such as discrete and atomic state observations. Typical robotic observation systems work in a streaming setup, where objects are discovered and recognized and their placement within their surroundings is determined in a quasi continuous manner instead of a state based one. The resulting information stream can be compared to a set of multiple inter-related data streams. In this paper, we propose an adaptive windowing strategy for generating a stream of learning examples and enabling relational learning from this kind of data. Our approach is independent from the learning algorithm and is based on a gradient search over the space of parameter values, i.e., window sizes, guided by the estimation of the testing error. The proposed algorithm performs online and is data driven and flexible. To the best of our knowledge, this is the first work addressing this problem. Our ideas are empirically supported by an extensive experimental evaluation in a controlled setup using artificial data.},
  Doi                      = {10.1109/ICDMW.2011.22},
  ISBN                     = {978-1-4673-0005-6},
  Keywords                 = {Data models,Gaussian distribution,Learning,Regression tree analysis,Robots,Testing,Training,adaptive windowing,atomic state observations,control engineering computing,data handling,discrete state observations,future householding robot,information stream,interacting objects,learning (artificial intelligence),multi-relational data mining,multi-relational data streams,multiple interrelated data streams,on-line learning,online learning,quasi continuous manner,relational learning,relational regression trees,relational reinforcement learning,robotic observation systems,service robots},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Relational reinforcement learning. The application of relational reinforcement learning to robotics has been hindered by assumptions such as discrete and atomic state observations. They model it as multiple data streams instead, and learn relation data from it. To the best of our knowledge, this is the first work addressing this problem. Our ideas are empirically supported by an extensive experimental evaluation in a controlled setup using artificial data. Approved 1,2,3,5,6},
  Shorttitle               = {Data Mining Workshops (ICDMW), 2011 IEEE 11th Inte},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6137448}
}

@Conference{Ikonomovska2011a,
  Title                    = {Adaptive windowing for online learning from multiple inter-related data streams},
  Author                   = {Ikonomovska, E.a and Driessensy, K.b and DÃ…Â¾eroski, S.a and Gamaz, J.c },
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Pages                    = {697-704},

  Abstract                 = {Relational reinforcement learning is a promising branch of reinforcement learning research that deals with structured environments. In these environments, states and actions are differentiated by the presence of certain types of objects and the relations between them and the objects that are involved in the actions. This makes it ultimately suited for tasks that require the manipulation of multiple, interacting objects, such as tasks that a future house-holding robot can be expected to perform like cleaning up a dinner table or storing away done dishes. However, the application of relational reinforcement learning to robotics has been hindered by assumptions such as discrete and atomic state observations. Typical robotic observation systems work in a streaming setup, where objects are discovered and recognized and their placement within their surroundings is determined in a quasi continuous manner instead of a state based one. The resulting information stream can be compared to a set of multiple inter-related data streams. In this paper, we propose an adaptive windowing strategy for generating a stream of learning examples and enabling relational learning from this kind of data. Our approach is independent from the learning algorithm and is based on a gradient search over the space of parameter values, i.e., window sizes, guided by the estimation of the testing error. The proposed algorithm performs online and is data driven and flexible. To the best of our knowledge, this is the first work addressing this problem. Our ideas are empirically supported by an extensive experimental evaluation in a controlled setup using artificial data. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Department of Knowledge Technologies, JoÃ…Â¾ef Stefan Institute, Jamova cesta 39, SI-1000 Ljubljana, Slovenia; Department of Knowledge Engineering, Maastricht University, Sint Servaasklooster 39, 6211 TE Maastricht, Netherlands; LIAAD, INESC Porto L.A., Rua de Ceuta, 118, 6o, 4050-190 Porto, Portugal},
  Art_number               = {6137448},
  Author_keywords          = {Multi-relational data mining; Multi-relational data streams; On-line learning; Relational regression trees},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ikonomovska2011. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84857184347&partnerID=40&md5=1f616a9f60ed55457c4ecd26222180ae}
}

@Misc{Ikonomovska,
  Title                    = {{A SURVEY OF STREAM DATA MINING}},

  Author                   = {Ikonomovska, Elena and Loskovska, Suzana and Gjorgjevik, Dejan},

  __markedentry            = {[Alexander:]},
  Abstract                 = {At present a growing number of applications that generate massive streams of data need intelligent data processing and online analysis. Real-time surveillance systems, telecommunication systems, sensor networks and other dynamic environments are such examples. The imminent need for turning such data into useful information and knowledge augments the development of systems, algorithms and frameworks that address streaming challenges. The storage, querying and mining of such data sets are highly computationally challenging tasks. Mining data streams is concerned with extracting knowledge structures represented in models and patterns in non stopping streams of information. In this paper, we present the theoretical foundations of data stream analysis and identify potential directions of future research. Mining data stream techniques are being critically reviewed.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {Survey very related to our paper, stream data mining. Present theoretical foundations and identify potential future research directions. Discarded, but put aside.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.65.8681}
}

@Article{Ikonomovska2011b,
  Title                    = {Learning model trees from evolving data streams},
  Author                   = {Ikonomovska, E.a d and Gama, J.b c and DÃ…Â¾eroski, S.a },
  Journal                  = {Data Mining and Knowledge Discovery},
  Year                     = {2011},
  Note                     = {cited By (since 1996)29},
  Number                   = {1},
  Pages                    = {128-168},
  Volume                   = {23},

  Abstract                 = {The problem of real-time extraction of meaningful patterns from timechanging data streams is of increasing importance for the machine learning and data mining communities. Regression in time-changing data streams is a relatively unexplored topic, despite the apparent applications. This paper proposes an efficient and incremental stream mining algorithm which is able to learn regression and model trees Ã‚Â© 2010 The Author(s).},
  Affiliation              = {JoÃ…Â¾ef Stefan Institute, Jamova cesta 39, 1000 Ljubljana, Slovenia; LIAAD/INESC, University of Porto, Rua de Ceuta, 118-6, 4050-190 Porto, Portugal; Faculty of Economics, University of Porto, Rua Roberto Frias, 4200 Porto, Portugal; Faculty of Electrical Engineering and Information Technologies, Ss. Cyril and Methodius University, Karpos II bb, 1000 Skopje, Macedonia},
  Author_keywords          = {Concept drift; Incremental algorithms; Model trees; Non-stationary data streams; On-line change detection; On-line learning; Regression trees; Stream data mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Regression in time-changing data streams is a relatively unexplored topic, despite the apparent applications. This paper proposes an efficient and incremental stream mining algorithm which is able to learn regression and model trees. Approved 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79960103750&partnerID=40&md5=fa84e719ebe18c5dcdcd81f3ad148106}
}

@Misc{In,
  Title                    = {{Parallel, Incremental and Interactive Mining for}},

  Author                   = {In, Frequent Itemsets and Veloso, Adriano and Meira, Wagner and {De Carvalho}, Marcio Bunte and Parthasarathy, Srinivasan and Zaki, Mohammed},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper deals with new approaches to maintaining frequent itemsets in evolving databases. Our new approaches make use of incremental techniques to provide significant I/O reduction, and parallel techniques to provide computational savings. At the same time, our approaches are able to effectively handle online data updates (deletions/insertions) and interactive response times (approximate/partial results). Some additional highlights of the proposed approaches include extending the validity of the itemsets (generating approximate models of itemsets), and performing selective updates (tracking stable and predictable itemsets). These features allow our approaches to mine evolving data stored in warehouses as well as (potentially) streaming data. Extensive experimental benchmarking on evolving data demonstrates the potential advantages of the proposed approaches. We believe that this work can have high impact in application areas such as electronic commerce, web mining, and network intrusion detection.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Parallel, Incremental and Interactive Mining for frequent itemsets. Extensive experimental benchmarking on evolving data demonstrates the potential advantages of the proposed approaches. They say it can be useful in electronic commerce, web mining, and network intrusion detection.. Approved 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.9.7034}
}

@Article{Ishida2008,
  Title                    = {Detecting current outliers: Continuous outlier detection over time-series data streams},
  Author                   = {Ishida, K. and Kitagawa, H.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2008},
  Note                     = {cited By (since 1996)3},
  Pages                    = {255-268},
  Volume                   = {5181 LNCS},

  Abstract                 = {The development of sensor devices and ubiquitous computing have increased time-series data streams. With data streams, current data arrives continuously and must be monitored. This paper presents outlier detection over data streams by continuous monitoring. Outlier detection is an important data mining issue and discovers outliers, which have features that differ profoundly from other objects or values. Most existing outlier detection techniques, however, deal with static data, which is computationally expensive. Specifically, for outlier detection over data streams, real-time response is very important. Existing techniques for static data, however, are fraught with many meaningless processes over data streams, and the calculation cost is too high. This paper introduces a technique that provides effective outlier detection over data streams using differential processing, and confirms effectiveness. Ã‚Â© 2008 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {Center for Computational Sciences, University of Tsukuba, 1-1-1 Tennodai, Tsukuba, Ibaraki 305-8573, Japan},
  Author_keywords          = {Data stream; DB-Outlier; Outlier detection; Time-series data},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents outlier detection over data streams by continuous monitoring. Most existing outlier detection techniques, however, deal with static data, which is computationally expensive. Real time response is very important. This paper introduces a technique that provides effective outlier detection over data streams using differential processing, and confirms effectiveness. Approved 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-52949130990&partnerID=40&md5=94629e1deee6b30ad7c156af5d7d9ee3}
}

@Misc{Islam2005,
  Title                    = {{Mac layer support for real-time traffic in a sahn}},

  Author                   = {Islam, Muhammad Mahmudul and Pose, Ronald},
  Year                     = {2005},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In multi-hop ad-hoc wireless networks with shared medium and a contention based media access control (MAC) protocol, guaranteed quality of service (QoS) support for realtime traffic (e.g. voice, video, interactive applications etc.) is very challenging. Commercially available contention based MAC protocols, e.g. IEEE 802.11e, do not provide any mechanism to prevent a network from getting overloaded. Hence they fail to provide desired QoS (e.g. throughput, end-to-end delay, delivery ratio) for realtime traffic when the network is loaded beyond certain limits. In our previous work we have explained in details why trivial solutions are inadequate to support deterministic QoS for real-time traffic in multi-hop ad-hoc networks. We have also presented an analytical model to offer a distributed admission control and bandwidth reservation scheme by extending the features of the basic channel access mechanism of IEEE 802.11e and coordinating with the network layer. In this paper we have extended our analytical model to make it more effective than the initial one by considering neighboring nodes in bandwidth calculation. We refer to the improved IEEE 802.11e as SAHN-MAC. The proposed admission control mechanism of SAHN-MAC prevents any new data stream from initiating if the new stream saturates or is about to saturate any part of the network. The bandwidth reservation scheme is necessary for the admission control scheme to work properly. The proposed mechanisms have also been verified and evaluated via various simulations.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Not about ML but about network optimaliztation.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.9309}
}

@Article{Islam2005a,
  Title                    = {{Making SAHN-MAC Independent of Single Frequency Channel and Omnidirectional Antennas}},
  Author                   = {Islam, Muhammad Mahmudul and Pose, Ronald},
  Journal                  = {IN IASTED NCS},
  Year                     = {2005},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Provision for quality of service (QoS) for real-time traffic in multi-hop ad-hoc wireless networks with shared medium and a contention based media access control (MAC) protocol is very challenging. In our previous work we have explained the challenges in detail and provided a solution within the context of suburban ad-hoc networks (SAHN). A SAHN is a multi-hop ad-hoc network that aims to provide suburban area connectivity at broadband speed with a low initial cost and zero service charges. The solution is based on an analytical model that uses the channel access mechanism of IEEE 802.11e. The admission control mechanism of SAHN-MAC prevents any new data stream from initiating if the new stream saturates or is about to saturate any part of the network. The bandwidth reservation scheme is necessary for the admission control scheme to work properly. In this paper we extend our previous work to make SAHN-MAC independent of single frequency channel and omnidirectional antenna. The improvements have been evaluated via simulations.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {ad hoc network admission control using some analytical model. Stops transmission if the new stream saturates or is about to saturate any part of the network. Discarded, not machine learning.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.129.6679}
}

@Misc{Jain,
  Title                    = {{Towards a New Approach for Mining Frequent Itemsets on Data Stream}},

  Author                   = {Jain, Shailendra and Patil, Sonal},

  __markedentry            = {[Alexander:]},
  Abstract                 = {From the advent of association rule mining, it has become one of the most researched areas of data exploration schemes. In recent years, implementing association rule mining methods in extracting rules from a continuous flow of voluminous data, known as Data Stream has generated immense interest due to its emerging applications such as network-traffic analysis, sensor-network data analysis. For such typical kinds of application domains, the facility to process such enormous amount of stream data in a single pass is critical. Nowadays, many organizations generate and utilize vast data streams (Huang, 2002). Employing data mining schemes on such massive data streams can unearth real-time},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They contribute a novel association rule mining algorithm for high speed data streams. Mining frequent itemsets. They say there is a lack of holistic and generic approaches. Approved 1,2,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.300.6748}
}

@InProceedings{Jawad2006,
  Title                    = {{Online Algorithms for Complete Itemset Counts Using Set-to-String Mappings}},
  Author                   = {Jawad, Ahmed and Karim, Asim and Khan, Imdadullah},
  Booktitle                = {2006 IEEE International Multitopic Conference},
  Year                     = {2006},
  Month                    = dec,
  Pages                    = {320--325},
  Publisher                = {IEEE},

  Abstract                 = {We present two algorithms for maintaining the exact counts of all itemsets over a stream of transactions. The count of each subset in a transaction is maintained by mapping it to substrings of the alphabet. This technique allows efficient time processing of the items in a single pass over the data stream. The two algorithms differ in their mapping schemes and data structures. The first algorithm performs prefix-based-scan of each transaction taken as a Boolean string, while the second algorithm improves on the first by exploiting the capability of suffix tree like structure for online enumeration of transaction suffixes. Correctness proofs and theoretic bounds on time and space complexity of these algorithms are presented. The algorithms are implemented and evaluated on several synthetic datasets. The results confirm that these algorithms are well suited to association rule mining over data streams for many practical business applications.},
  Doi                      = {10.1109/INMIC.2006.358185},
  ISBN                     = {1-4244-0794-X},
  Keywords                 = {Algorithm design and analysis,Boolean string,Computer science,Data analysis,Data mining,Data structures,Failure analysis,Frequency,Itemsets,Pattern analysis,Transaction databases,association rule mining,business applications,complete itemset counts,computational complexity,data mining,online algorithms,online enumeration,prefix-based-scan technique,set-to-string mappings,space complexity,suffix tree like structure,synthetic datasets,time complexity,transaction processing,transaction suffixes,tree data structures},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We present two algorithms for maintaining the exact counts of all itemsets over a stream of transactions. The algorithms are implemented and evaluated on several synthetic datasets. The results confirm that these algorithms are well suited to association rule mining over data streams. If frequent is okay, Approved 1,3,4,6},
  Shorttitle               = {Multitopic Conference, 2006. INMIC '06. IEEE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4196428}
}

@Conference{Jawad2006a,
  Title                    = {Online algorithms for complete itemset counts using set-to-string mappings},
  Author                   = {Jawad, A. and Karim, A. and Khan, I.},
  Year                     = {2006},
  Note                     = {cited By (since 1996)0},
  Pages                    = {320-325},

  Abstract                 = {We present two algorithms for maintaining the exact counts of all itemsets over a stream of transactions. The count of each subset in a transaction is maintained by mapping it to substrings of the alphabet. This technique allows efficient time processing of the items in a single pass over the data stream. The two algorithms differ in their mapping schemes and data structures. The first algorithm performs prefix-based-scan of each transaction taken as a Boolean string, while the second algorithm improves on the first by exploiting the capability of suffix tree like structure for online enumeration of transaction suffixes. Correctness proofs and theoretic bounds on time and space complexity of these algorithms are presented. The algorithms are implemented and evaluated on several synthetic datasets. The results confirm that these algorithms are well suited to association rule mining over data streams for many practical business applications. Ã‚Â© 2006 IEEE.},
  Affiliation              = {Dept. of Computer Science, Lahore University of Management Sciences (LUMS), Lahore, Pakistan},
  Art_number               = {4196428},
  Document_type            = {Conference Paper},
  Journal                  = {10th IEEE International Multitopic Conference 2006, INMIC},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Two new algorithms for maintaining the exact counts of all itemsets over a stream of transactions. Allows efficient time processing of the items in a single pass over the data stream. Discarded, not machine learning, just counting. Useful for association rule mining. 1,3,4},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-46449108294&partnerID=40&md5=55fa82419fc1d2363cf6eb1b3e655e72}
}

@InProceedings{Jea2011,
  Title                    = {{A load shedding scheme for frequent pattern mining in transactional data streams}},
  Author                   = {Jea, Kuen-Fang and Li, Chao-Wei and Hsu, Chih-Wei and Lin, Ru-Ping and Yen, Ssu-Fan},
  Booktitle                = {2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)},
  Year                     = {2011},
  Month                    = jul,
  Pages                    = {1294--1299},
  Publisher                = {IEEE},
  Volume                   = {2},

  Abstract                 = {In this paper, we study overload handling for frequent-pattern mining in online data streams. For a mining system with an e-deficient synopsis based algorithm, we propose a load shedding scheme to deal with the overload situation. The heavy workload of the mining algorithm lies mostly in the great deal of itemsets which need to be enumerated and counted by the mining algorithm. Therefore, our proposed scheme of load shedding involves the maintenance of a smaller set of itemsets, so the workload can be lessened accordingly. The unrecorded itemsets can be fast approximated for their counts when necessary. According to experimental results, the load shedding scheme can increase the throughput of the mining system and thus help manage the overload problem effectively to a certain extent.},
  Doi                      = {10.1109/FSKD.2011.6019707},
  ISBN                     = {978-1-61284-180-9},
  Keywords                 = {Algorithm design and analysis,Approximation methods,Data mining,Data models,Data structures,Itemsets,Throughput,data handling,data mining,data overload,data stream,e-deficient synopsis based algorithm,frequent itemset,load shedding,load shedding scheme,online data streams,overload handling,pattern mining,transactional data stream},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Overload handling for frequent-pattern mining in online data streams. Load shedding by having smaller itemsets. According to experimental results, the load shedding scheme can increase the throughput of the mining system and thus help manage the overload problem effectively to a certain extent.
Approved
1,3,6},
  Shorttitle               = {Fuzzy Systems and Knowledge Discovery (FSKD), 2011},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6019707}
}

@Conference{Jea2011a,
  Title                    = {A load shedding scheme for frequent pattern mining in transactional data streams},
  Author                   = {Jea, K.-F. and Li, C.-W. and Hsu, C.-W. and Lin, R.-P. and Yen, S.-F.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1294-1299},
  Volume                   = {2},

  Abstract                 = {In this paper, we study overload handling for frequent-pattern mining in online data streams. For a mining system with an e-deficient synopsis based algorithm, we propose a load shedding scheme to deal with the overload situation. The heavy workload of the mining algorithm lies mostly in the great deal of itemsets which need to be enumerated and counted by the mining algorithm. Therefore, our proposed scheme of load shedding involves the maintenance of a smaller set of itemsets, so the workload can be lessened accordingly. The unrecorded itemsets can be fast approximated for their counts when necessary. According to experimental results, the load shedding scheme can increase the throughput of the mining system and thus help manage the overload problem effectively to a certain extent. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Department of Computer Science and Engineering, National Chung-Hsing University, Taichung 40227, Taiwan},
  Art_number               = {6019707},
  Author_keywords          = {data mining; data overload; data stream; frequent itemset; load shedding},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2011 8th International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2011},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Jea2011.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053399218&partnerID=40&md5=86007eff4bb7891ca372a5f39a0728d4}
}

@InProceedings{JDRL2008,
  Title                    = {{Online data stream Mining of Recent Frequent Itemsets based on Sliding Window model}},
  Author                   = {{Jia-Dong Ren} and {Ke Li}},
  Booktitle                = {2008 International Conference on Machine Learning and Cybernetics},
  Year                     = {2008},
  Month                    = jul,
  Pages                    = {293--298},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Online data stream mining is one of the most important issues in data mining. Identifying the recent knowledge can provide valuable information for the analysis of the data stream. In this paper, we proposed an one-pass data stream mining algorithm to mine the recent frequent itemsets in data streams with a sliding window basing on transactions. To reduce the cost of time and memory needed to slide the windows, each items is denoted a bit-sequence representations. Basing on a priori property, this kind of representations can find frequent items in data streams efficiently. We named this method MRFI-SW (mining recent frequent itemsets by sliding window) algorithm. Experiment results show that the proposed algorithm not only attains highly accurate mining result, but also consumes less memory than existing algorithms for mining frequent itemsets over recent data streams.},
  Doi                      = {10.1109/ICMLC.2008.4620420},
  ISBN                     = {978-1-4244-2095-7},
  Keywords                 = {Cybernetics,Data analysis,Data engineering,Data mining,Educational institutions,Information science,Itemsets,Machine learning,Machine learning algorithms,Online data stream,Partitioning algorithms,Sliding windows,bit-sequence representations,cost reduction,data mining,mining recent frequent itemsets by sliding window,one-pass data stream mining algorithm},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Construct algorithm mining recent frequent itemsets by sliding window. Experiment results show that the proposed algorithm not only attains highly accurate mining result, but also consumes less memory than existing algorithms for mining frequent itemsets over recent data streams.
Approved
1,2,3,4,6},
  Shorttitle               = {Machine Learning and Cybernetics, 2008 Internation},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4620420}
}

@Article{Jiang2011,
  Title                    = {Online mining closed frequent itemsets in the time window over data streams},
  Author                   = {Jiang, M.a b and Ni, Z.a b and Meng, J.a b and Zhiqiang, Z.a b },
  Journal                  = {Journal of University of Science and Technology of China},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Number                   = {8},
  Pages                    = {739-745},
  Volume                   = {41},

  Abstract                 = {When mining closed frequent itemsets over data streams, the available algorithms are often made inefficient due to the fact that they often ignore mode decaying as time passes, and adopt a structure to mark the types of closed frequent itemsets. A method was proposed for mining the closed frequent patterns in the time window of data streams. The pattern of data streams could be completely recorded by scanning the streams only once. And the pruning method of NEWT-moment could reduce the space complexity of sliding window tree and the maintenance cost of the closed frequent patterns tree. To differentiate the historical and the latest patterns, a time decaying model was applied. Additionally, NEWT-tree stores the closed frequent itemsets directly, so they can be read quickly. In contrast with T-moment, and NEWT-moment does not need to delete the historical data, or mark transaction and nodes, which can decrease the time complexity and the space complexity. The experimental results show that the algorithm has good efficiency and accuracy.},
  Affiliation              = {School of Management, Hefei University of Technology, Hefei 230009, China; Key Laboratory of Process Optimization and Intelligent Decision-making, Ministry of Education, Hefei 230009, China},
  Author_keywords          = {Closed frequent itemsets; Data stream; Time decaying; Time window},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {When mining closed frequent itemsets over data streams, the available algorithms are often made inefficient due to the fact that they often ignore mode decaying as time passes. In this paper a time decaying model was applied. In contrast with T-moment, and NEWT-moment their has decreased time and space complexity. The experimental results show that the algorithm has good efficiency and accuracy.
Approved
1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84887230187&partnerID=40&md5=2ee93f7cee3dfd708463b226f88ad5c0}
}

@Misc{Jiang,
  Title                    = {{An Efficient Algorithm to Mine Online Data Streams}},

  Author                   = {Jiang, Nan},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Mining frequent closed itemsets provides complete and condensed information for non-redundant association rules generation. Extensive studies have been done on mining frequent closed itemsets, but they are mainly intended for traditional transaction databases and thus do not take data stream characteristics into consideration. In this paper, we propose a novel approach for mining closed frequent itemsets over data streams. It computes and maintains closed itemsets online and incrementally and can output the current closed frequent itemsets in real time based on users’ specified thresholds. Experimental results show that our proposed method is both time and space efficient, has good scalability as the number of transactions processed increases and adapts very rapidly to the change in data streams.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Much studies have been done on frequent closed itemsets, but mainly fo tradional databases. Propose an Efficient Algorithm to Mine Online Data Streams. User can specify thresholds. xperimental results show that our proposed method is both time and space efficient, has good scalability as the number of transactions processed increases and adapts very rapidly to the change in data streams.
Approved
1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.157.880}
}

@Article{Jiang2007,
  Title                    = {{L.: Estimating Missing Data in Data Streams}},
  Author                   = {Jiang, Nan and Gruenwald, Le},
  Journal                  = {IN: 12TH INTERNATIONAL CONFERENCE ON DATABASE SYSTEMS FOR ADVANCED APPLICATIONS},
  Year                     = {2007},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Networks of thousands of sensors present a feasible and economic solution to some of our most challenging problems, such as real-time traffic modeling, military sensing and tracking. Many research projects have been conducted by different organizations regarding wireless sensor networks; however, few of them discuss how to estimate missing sensor data. In this research we present a novel data estimation technique based on association rules derived from closed frequent itemsets generated by sensors. Experimental results compared with the existing techniques using real-life sensor data show that closed itemset mining effectively imputes missing values as well as achieves time and space efficiency.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. Many research projects have been conducted by different organizations regarding wireless sensor networks; however, few of them discuss how to estimate missing sensor data. In this paper they give a new technique using association rules from frequent itemsets. Experimental results compared with the existing techniques using real-life sensor data show that closed itemset mining effectively imputes missing values
Approved
1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.87.8889}
}

@Conference{Jiang2006,
  Title                    = {CFI-stream: Mining closed frequent itemsets in data streams},
  Author                   = {Jiang, N. and Gruenwald, L.},
  Year                     = {2006},
  Note                     = {cited By (since 1996)50},
  Pages                    = {592-597},
  Volume                   = {2006},

  Abstract                 = {Mining frequent closed itemsets provides complete and condensed information for non-redundant association rules generation. Extensive studies have been done on mining frequent closed itemsets, but they are mainly intended for traditional transaction databases and thus do not take data stream characteristics into consideration. In this paper, we propose a novel approach for mining closed frequent itemsets over data streams. It computes and maintains closed itemsets online and incrementally, and can output the current closed frequent itemsets in real time based on users' specified thresholds. Experimental results show that our proposed method is both time and space efficient, has good scalability as the number of transactions processed increases and adapts very rapidly to the change in data streams. Copyright 2006 ACM.},
  Affiliation              = {School of Computer Science, University of Oklahoma, Norman, OK 73019, United States},
  Author_keywords          = {Association rules; Data stream; Frequent closed itemsets},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Jiang.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33749554404&partnerID=40&md5=c24736392065b70945885094e6f9c761}
}

@InProceedings{Jiang2006a,
  Title                    = {{CFI-Stream}},
  Author                   = {Jiang, Nan and Gruenwald, Le},
  Booktitle                = {Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '06},
  Year                     = {2006},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {592},
  Publisher                = {ACM Press},

  Abstract                 = {Mining frequent closed itemsets provides complete and condensed information for non-redundant association rules generation. Extensive studies have been done on mining frequent closed itemsets, but they are mainly intended for traditional transaction databases and thus do not take data stream characteristics into consideration. In this paper, we propose a novel approach for mining closed frequent itemsets over data streams. It computes and maintains closed itemsets online and incrementally, and can output the current closed frequent itemsets in real time based on users' specified thresholds. Experimental results show that our proposed method is both time and space efficient, has good scalability as the number of transactions processed increases and adapts very rapidly to the change in data streams.},
  Doi                      = {10.1145/1150402.1150473},
  ISBN                     = {1595933395},
  Keywords                 = {association rules,data stream,frequent closed itemsets},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Jiang.
Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1150402.1150473}
}

@Conference{Jonas2006,
  Title                    = {Introducing perpetual analytics},
  Author                   = {Jonas, J.},
  Year                     = {2006},
  Note                     = {cited By (since 1996)0},
  Pages                    = {833},
  Volume                   = {2006},

  Abstract                 = {Common strategies to liberate an organization's information assets for situational awareness frequently rely on infrastructure components such as data integration, enterprise search, federation, data warehousing, and so on. And while these traditional platforms enable analysts to get better and faster answers to their queries, the next big advance will change this paradigm. Users cannot be expected to formulate and ask every smart question every day. And to escape this impractical and un-scalable model, the new paradigm will involve technologies where "the data finds the data" and "relevance finds the user." Perpetual Analytics describes a class of application whereby enterprise context is assembled, in real-time, on data streams as fast as operational systems record observations. Context construction is a "data finds the data" activity which enables events of interest to be streamed to subscribers. In this talk, I will talk at some depth about the dynamics of such systems including scalability and sustainability.},
  Affiliation              = {Entity Analytic Solutions Software Group, IBM},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Perpetual Analytics describes a class of application whereby enterprise context is assembled in real time on data streams as soon as observatinos are made. I will talk at some depth about the dynamics of such systems including scalability and sustainability. Does not deal with any particular software, hardware, algorithm or problem.
Disacrded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33749564072&partnerID=40&md5=54fec87310caecdad0a0a6cfcbb3f8e6}
}

@InProceedings{Jonas2006a,
  Title                    = {{Introducing perpetual analytics}},
  Author                   = {Jonas, Jeff},
  Booktitle                = {Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '06},
  Year                     = {2006},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {833},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/1150402.1150513},
  ISBN                     = {1595933395},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Jonas2006.
Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1150402.1150513}
}

@Misc{Jose,
  Title                    = {{Early Drift Detection Method}},

  Author                   = {Jose, Manuel Baena-Garca and \'{A}vila, Jos\'{e} Del Campo- and Fidalgo, Ra\'{u}l and Bifet, Albert and Gavald\`{a}, Ricard and Morales-bueno, Rafael},

  __markedentry            = {[Alexander:]},
  Abstract                 = {An emerging problem in Data Streams is the detection of concept drift. This problem is aggravated when the drift is gradual over time. In this work we define a method for detecting concept drift, even in the case of slow gradual change. It is based on the estimated distribution of the distances between classification errors. The proposed method can be used with any learning algorithm in two ways: using it as a wrapper of a batch learning algorithm or implementing it inside an incremental and online algorithm. The experimentation results compare our method (EDDM) with a similar one (DDM). Latter uses the error-rate instead of distance-error-rate.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {this work define a method for detecting concept drift, even in the case of slow gradual change. The proposed method can be used with any learning algorithm in two ways: using it as a wrapper of a batch learning algorithm or implementing it inside an incremental and online algorithm. They do experimentation, but does not state their empirical results Weak paper. Interesting method, but no word about novelity, nor anything about their results. 1,5},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.6101}
}

@InProceedings{Kan2010,
  Title                    = {{Design data structure for WAMS datastream mining base on GPS time scale}},
  Author                   = {Kan, Yunqi and Qu, Zhaoyang},
  Booktitle                = {2010 Global Mobile Congress},
  Year                     = {2010},
  Month                    = oct,
  Pages                    = {1--3},
  Publisher                = {IEEE},

  Abstract                 = {Notice of RetractionAfter careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.WAMS application platform to power dynamic real-time monitoring possible, the amount of data generated by WAMS platform very large, and the datastream flow to the control center in High-speed. It is a problem need to Resolved that How to use the WAMS data to judge abnormalities of power system rapidly. For mining in WAMS data stream, this paper explore the model of data stream and elements used to identify disturbance type. This paper explores the datastream model and identify the elements of disturbance, and propose summary of a data stream mining data structure against the feature of power system. It provides an important basis for for further research on data stream mining algorithms.},
  Doi                      = {10.1109/GMC.2010.5634582},
  ISBN                     = {978-1-4244-9001-1},
  Keywords                 = {Data mining,Data models,Data structures,GPS time scale,Global Positioning System,Histograms,Monitoring,Power system dynamics,WAMS,WAMS datastream mining,data mining,data structures,datastream flow,datastream mining,design data structure,histogram,power dynamic real-time monitoring,power engineering computing,power system,power system measurement},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to retraction.},
  Shorttitle               = {Mobile Congress (GMC), 2010 Global},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5634582}
}

@Conference{Kan2010a,
  Title                    = {RETRACTED ARTICLE: Design data structure for WAMS datastream mining base on GPS time scale},
  Author                   = {Kan, Y. and Qu, Z.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {WAMS application platform to power dynamic real-time monitoring possible, the amount of data generated by WAMS platform very large, and the datastream flow to the control center in High-speed. It is a problem need to Resolved that How to use the WAMS data to judge abnormalities of power system rapidly. For mininging in WAMS data stream, this paper explore the model of data stream and elements used to identify disturbance type. This paper explores the datastream model and identify the elements of disturbance, and propose summary of a data stream mining data structure against the feature of power system. It provides an important basis for for further research on data stream mining algorithms. Ã‚Â© 2010 IEEE.},
  Affiliation              = {Northeast Dianli University, Jilin, China},
  Art_number               = {5634582},
  Author_keywords          = {Datastream mining; GPS time scale; Histogram; WAMS},
  Document_type            = {Conference Paper},
  Journal                  = {2010 Global Mobile Congress, GMC'2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to retraction.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650473324&partnerID=40&md5=ca81abf4e327aa5a615b01300c41b8d1}
}

@Conference{Kandogan2014,
  Title                    = {A reference web architecture and patterns for real-time visual analytics on large streaming data},
  Author                   = {Kandogan, E.a and Soroker, D.a and Rohall, S.a and Bak, P.a and Van Ham, F.a and Lu, J.a and Ship, H.-J.a and Wang, C.-F.b and Lai, J.a },
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Volume                   = {9017},

  Abstract                 = {Monitoring and analysis of streaming data, such as social media, sensors, and news feeds, has become increasingly important for business and government. The volume and velocity of incoming data are key challenges. To effectively support monitoring and analysis, statistical and visual analytics techniques need to be seamlessly integrated; analytic techniques for a variety of data types (e.g., text, numerical) and scope (e.g., incremental, rolling-window, global) must be properly accommodated; interaction, collaboration, and coordination among several visualizations must be supported in an efficient manner; and the system should support the use of different analytics techniques in a pluggable manner. Especially in web-based environments, these requirements pose restrictions on the basic visual analytics architecture for streaming data. In this paper we report on our experience of building a reference web architecture for real-time visual analytics of streaming data, identify and discuss architectural patterns that address these challenges, and report on applying the reference architecture for real-time Twitter monitoring and analysis. Ã‚Â© 2014 SPIE-IS&T.},
  Affiliation              = {IBM Research, P.O. Box 218 Route 134, Yorktown Heights, NY, United States; University of California, Davis, 2063 Kemper Hall, 1 Shields Avenue, Davis, CA 95616, United States},
  Art_number               = {901708},
  Author_keywords          = {design patterns; Streaming data; visual analytics architecture; web-scale},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of SPIE - The International Society for Optical Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {this paper report on their experience of building a reference web architecture for real-time visual analytics of streaming data Approved under uncertainty. They say that they use different analytics techniques. No new research, only a platform. The specific problem they apply the software is monitoring and analysis of RT data.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84894537525&partnerID=40&md5=fb5e2e7981c4a2a0d5f15f54aee68cbb}
}

@InProceedings{Kanoun2014,
  Title                    = {{Low Power and Scalable Many-Core Architecture for Big-Data Stream Computing}},
  Author                   = {Kanoun, Karim and Ruggiero, Martino and Atienza, David and van der Schaar, Mihaela},
  Booktitle                = {2014 IEEE Computer Society Annual Symposium on VLSI},
  Year                     = {2014},
  Month                    = jul,
  Pages                    = {468--473},
  Publisher                = {IEEE},

  Abstract                 = {In the last years the process of examining large amounts of different types of data, or Big-Data, in an effort to uncover hidden patterns or unknown correlations has become a major need in our society. In this context, stream mining applications are now widely used in several domains such as financial analysis, video annotation, surveillance, medical services, traffic prediction, etc. In order to cope with the Big-Data stream input and its high variability, modern stream mining applications implement systems with heterogeneous classifiers and adapt online to its input data stream characteristics variation. Moreover, unlike existing architectures for video processing and compression applications, where the processing units are reconfigurable in terms of parameters and possibly even functions as the input data is changing, in Big-Data stream mining applications the complete computing pipeline is changing, as entirely new classifiers and processing functions are invoked depending on the input stream. As a result, new approaches of reconfigurable hardware platform architectures are needed to handle Big-Data streams. However, hardware solutions that have been proposed so far for stream mining applications either target high performance computing without any power consideration (i.e., limiting their applicability in small-scale computing infrastructures or current embedded systems), or they are simply dedicated to a specific learning algorithm (i.e., limited to run with a single type of classifiers). Therefore, in this paper we propose a novel low-power many-core architecture for stream mining applications that is able to cope with the dynamic data-driven nature of stream mining applications while consuming limited power. Our exploration indicates that this new proposed architecture is able to adapt to different classifiers complexities thanks to its multiple scalable vector processing units and their re-configurability feature at run-time. Moreover, our platform archite- ture includes a memory hierarchy optimized for Big-Data streaming and implements modern fine-grained power management techniques over all the different types of cores allowing then minimum energy consumption for each type of executed classifier.},
  Doi                      = {10.1109/ISVLSI.2014.77},
  ISBN                     = {978-1-4799-3765-3},
  Keywords                 = {Big Data,Big-Data,Big-Data stream computing,Big-Data stream handling,Big-Data stream mining applications,Buffer storage,Data mining,Graphics processing units,Hardware,Low-Power,Many-core,Memory Hierarchy,Memory management,Online,Reconfigurable,Stream Mining Application,Streaming application,Streaming media,data mining,energy consumption minimisation,fine-grained power management techniques,heterogeneous classifiers,hidden patterns,high performance computing,input data stream characteristics variation,learning algorithm,low power many-core architecture,low-power electronics,memory architecture,memory hierarchy,multiple scalable vector processing units,multiprocessing systems,parallel processing,pattern classification,power aware computing,processing functions,reconfigurable architectures,reconfigurable hardware platform architectures,scalable many-core architecture},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Hardware solutions that have been proposed so far for stream mining applications either target high performance computing without any power consideration. Propose a low power many core architecture for steram mining. Focuses on hardware but not any particular algorithm or problem.
Discarded.},
  Shorttitle               = {VLSI (ISVLSI), 2014 IEEE Computer Society Annual S},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6903408}
}

@Misc{Karacal,
  Title                    = {{A Novel Approach to Optimal Cutting Tool Replacement}},

  Author                   = {Karacal, Cem and Cho, Sohyung and Yu, William},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In metal cutting industries, mathematical/statistical models are typically used to predict tool replacement time. These off-line methods usually result in less than optimum replacement time thereby either wasting resources or causing quality problems. The few online real-time methods proposed use indirect measurement techniques and are prone to similar errors. Our idea is based on identifying the optimal replacement time using an electronic nose to detect the airborne compounds released when the tool wear reaches to a chemical substrate doped into tool material during the fabrication. The study investigates the feasibility of the idea, possible doping materials and methods along with data stream mining techniques for detection and monitoring different phases of tool wear.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Karacal2009.
Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.193.1097}
}

@Article{Karacal2009,
  Title                    = {A novel approach to optimal cutting tool replacement},
  Author                   = {Karacal, C.a and Cho, S.a and Yu, W.b },
  Journal                  = {World Academy of Science, Engineering and Technology},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {19-23},
  Volume                   = {57},

  Abstract                 = {In metal cutting industries, mathematical/statistical models are typically used to predict tool replacement time. These off-line methods usually result in less than optimum replacement time thereby either wasting resources or causing quality problems. The few online real-time methods proposed use indirect measurement techniques and are prone to similar errors. Our idea is based on identifying the optimal replacement time using an electronic nose to detect the airborne compounds released when the tool wear reaches to a chemical substrate doped into tool material during the fabrication. The study investigates the feasibility of the idea, possible doping materials and methods along with data stream mining techniques for detection and monitoring different phases of tool wear.},
  Affiliation              = {Industrial and Manufacturing Engineering department, Southern Illinois University Edwardsville, Edwardsville, IL 62026, United States; Computer Science department, Southern Illinois University Edwardsville, Edwardsville, IL 62026, United States},
  Author_keywords          = {Cutting tool replacement; Data stream mining; e-Nose; Tool condition monitoring},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In metal cutting industries, mathematical/statistical models are typically used to predict tool replacement time. Offline methods. Detecting optimal tool replacement time using an electronic nose. The study investigates the feasibility of the idea, possible doping materials and methods along with data stream mining techniques for detection and monitoring different phases of tool wear.
Approved
1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78651555714&partnerID=40&md5=22377780e183746a160260406c48c4e0}
}

@Conference{Karacal2006,
  Title                    = {Data stream mining for machine reliability},
  Author                   = {Karacal, S.C.a and Yu, X.b },
  Year                     = {2006},
  Note                     = {cited By (since 1996)2},

  Abstract                 = {Application of Data Stream Mining techniques to machine monitoring is a new concept that can translate into significant improvements in manufacturing tool reliability. The conceptual framework outlined here can be used to integrate some of the data stream mining algorithms for machine monitoring purposes. Recent developments in sensor and wireless technology make it feasible to continuously monitor the status of manufacturing tools to better assess operating conditions. The on-line and real-time processing of vast amount of data presents new challenges both from both computational and reliability points of view.},
  Affiliation              = {Industrial and Manufacturing Engineering, Southern Illinois University Edwardsville, Edwardsville, IL 62026, United States; Computer Science, Southern Illinois University Edwardsville, Edwardsville, IL 62026, United States},
  Author_keywords          = {Data mining; Data streams; Machine reliability},
  Document_type            = {Conference Paper},
  Journal                  = {2006 IIE Annual Conference and Exhibition},
  Owner                    = {Alexander},
  Page_count               = {6},
  Qualityassured           = {qualityAssured},
  Review                   = {Older version of Karacal2009.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84858463960&partnerID=40&md5=2165a16ccc5fbc5e50814badf9470878}
}

@Conference{Kargupta2004,
  Title                    = {VEDAS: A mobile and distributed data stream mining system for real-time vehicle monitoring},
  Author                   = {Kargupta, H.a and Bhargava, R.a and Liu, K.a and Powers, M.a and Blair, P.a and Bushra, S.a and Dull, J.a and Sarkar, K.b and Klein, M.b and Vasa, M.b and Handy, D.b },
  Year                     = {2004},
  Note                     = {cited By (since 1996)10},
  Pages                    = {300-311},

  Abstract                 = {This paper presents an overview of an experimental mobile and distributed data stream mining system that allows real time vehicle-health monitoring and driver characterization. It offers the motivation behind this application, explains the system architecture, discusses many challenges that the project faced, and shares some of the adopted solutions. The main contribution of the paper is our experience in building one of the very early distributed data stream mining systems for wireless applications that performs most of the data analysis related tasks using light-weight on-board computing devices. This paper points out that the distributed data mining technology can play a key role in solving real-life problems in a mobile application environment where computing, storage, power, and communication resources are limited. The paper also illustrates how privacy-preserving distributed data mining can play an important role in this type of applications.},
  Affiliation              = {Computer Science Department, Univ. Maryland at Baltimore County, Baltimore, MD 21250, United States; AGNIK, LLC, MD, United States},
  Document_type            = {Conference Paper},
  Journal                  = {SIAM Proceedings Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {System for vehicle haelth monitoring, real-time. Uses lightweight onboard computers. The paper also illustrates how privacy-preserving distributed data mining can play an important role in this type of applications.
Approved
1},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-2942534530&partnerID=40&md5=53cec66325a903bdae338149b173fc42}
}

@Conference{Karim2014a,
  Title                    = {An adaptive ensemble classifier for mining complex noisy instances in data streams},
  Author                   = {Karim, Md.R. and Farid, D.Md.},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Real-time data streams classification is a challenging data mining task. In real-time streaming environments concepts of instances might change at any time such as weather predictions, astronomical and intrusion detection etc. To address this issue, we present an adaptive ensemble classifier for data streams classification, which uses a set of decision trees for mining complex noisy instances in data streams. The ensemble model updates automatically so that it represents the most recent concepts in data streams. In each iteration, the ensemble model generates a new training data from original training dataset, then builds a decision tree using new training data and assigns a weight to the tree based on its classification accuracy on original training instances. Also it updates the weight of training instances in training dataset. We tested the performance of the proposed ensemble classifier against that of existing C4.5 decision tree classifier using real benchmark datasets from UCI (University of California, Irvine) machine learning repository. The experimental results prove that the proposed ensemble classifier shows great flexibility and robustness in data streams classification. Ã‚Â© 2014 IEEE.},
  Affiliation              = {Department of Computer Science and Engineering, United International University, Bangladesh},
  Art_number               = {6850838},
  Author_keywords          = {Data streams; Decision tree; Ensemble classifier; Multi-class classification; Noisy data; Single classifier},
  Document_type            = {Conference Paper},
  Journal                  = {2014 International Conference on Informatics, Electronics and Vision, ICIEV 2014},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Karim2014.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905041046&partnerID=40&md5=5fb2c9546989a0eb56b04c54c059a977}
}

@InProceedings{Karim2014,
  Title                    = {{An adaptive ensemble classifier for mining complex noisy instances in data streams}},
  Author                   = {Karim, Md. Rejaul and Farid, Dewan Md.},
  Booktitle                = {2014 International Conference on Informatics, Electronics \& Vision (ICIEV)},
  Year                     = {2014},
  Month                    = may,
  Pages                    = {1--4},
  Publisher                = {IEEE},

  Abstract                 = {Real-time data streams classification is a challenging data mining task. In real-time streaming environments concepts of instances might change at any time such as weather predictions, astronomical and intrusion detection etc. To address this issue, we present an adaptive ensemble classifier for data streams classification, which uses a set of decision trees for mining complex noisy instances in data streams. The ensemble model updates automatically so that it represents the most recent concepts in data streams. In each iteration, the ensemble model generates a new training data from original training dataset, then builds a decision tree using new training data and assigns a weight to the tree based on its classification accuracy on original training instances. Also it updates the weight of training instances in training dataset. We tested the performance of the proposed ensemble classifier against that of existing C4.5 decision tree classifier using real benchmark datasets from UCI (University of California, Irvine) machine learning repository. The experimental results prove that the proposed ensemble classifier shows great flexibility and robustness in data streams classification.},
  Doi                      = {10.1109/ICIEV.2014.6850838},
  ISBN                     = {978-1-4799-5180-2},
  Keywords                 = {Accuracy,Adaptation models,C4.5 decision tree classifier,Data mining,Data models,Data streams,Decision trees,Expert systems,Training,UCI machine learning repository,adaptive ensemble classifier,astronomical detection,complex noisy instance mining,data mining,data mining task,decision tree,decision trees,ensemble classifier,ensemble model,intrusion detection,learning (artificial intelligence),multi-class classification,noisy data,pattern classification,real-time data streams classification,single classifier,training dataset,weather predictions},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Adaptive ensemble classifier for drifting data streams classification. In each iteration, the ensemble model generates a new training data from original training dataset with new weights. The experimental results prove that the proposed ensemble classifier shows great flexibility and robustness in data streams classification. Tested against existing classifier.
Approved
1,2,3,6},
  Shorttitle               = {Informatics, Electronics \& Vision (ICIEV), 2014 In},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6850838}
}

@Article{Kasabov2013,
  Title                    = {Dynamic evolving spiking neural networks for on-line spatio- and spectro-temporal pattern recognition },
  Author                   = {Nikola Kasabov and Kshitij Dhoble and Nuttapod Nuntalid and Giacomo Indiveri},
  Journal                  = {Neural Networks },
  Year                     = {2013},
  Note                     = {Special Issue on Autonomous Learning },
  Number                   = {0},
  Pages                    = {188 - 201},
  Volume                   = {41},

  Abstract                 = {On-line learning and recognition of spatio- and spectro-temporal data (SSTD) is a very challenging task and an important one for the future development of autonomous machine learning systems with broad applications. Models based on spiking neural networks (SNN) have already proved their potential in capturing spatial and temporal data. One class of them, the evolving \{SNN\} (eSNN), uses a one-pass rank-order learning mechanism and a strategy to evolve a new spiking neuron and new connections to learn new patterns from incoming data. So far these networks have been mainly used for fast image and speech frame-based recognition. Alternative spike-time learning methods, such as Spike-Timing Dependent Plasticity (STDP) and its variant Spike Driven Synaptic Plasticity (SDSP), can also be used to learn spatio-temporal representations, but they usually require many iterations in an unsupervised or semi-supervised mode of learning. This paper introduces a new class of eSNN, dynamic eSNN, that utilise both rank-order learning and dynamic synapses to learn \{SSTD\} in a fast, on-line mode. The paper also introduces a new model called deSNN, that utilises rank-order learning and \{SDSP\} spike-time learning in unsupervised, supervised, or semi-supervised modes. The \{SDSP\} learning is used to evolve dynamically the network changing connection weights that capture spatio-temporal spike data clusters both during training and during recall. The new deSNN model is first illustrated on simple examples and then applied on two case study applications: (1) moving object recognition using address-event representation (AER) with data collected using a silicon retina device; (2) \{EEG\} \{SSTD\} recognition for brainÃ¢â‚¬â€œcomputer interfaces. The deSNN models resulted in a superior performance in terms of accuracy and speed when compared with other \{SNN\} models that use either rank-order or \{STDP\} learning. The reason is that the deSNN makes use of both the information contained in the order of the first input spikes (which information is explicitly present in input data streams and would be crucial to consider in some tasks) and of the information contained in the timing of the following spikes that is learned by the dynamic synapses as a whole spatio-temporal pattern.},
  Doi                      = {http://dx.doi.org/10.1016/j.neunet.2012.11.014},
  ISSN                     = {0893-6080},
  Keywords                 = {Spatio-temporal pattern recognition},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper introduces a new class of eSNN (evolving spiking neural networks), dynamic eSNN, that utilise both rank-order learning and dynamic synapses to learn \{SSTD\} in a fast, on-line mode. Also introduces a new model called deSNN (d=dynamic), that utilises rank-order learning and \{SDSP\} spike-time learning in unsupervised, supervised, or semi-supervised modes. Model is applied on two case studies. The deSNN models resulted in a superior performance in terms of accuracy and speed when compared with other \{SNN\} models Seems like a good, but heavy paper. 1,2,3,4,5,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0893608012003139}
}

@Article{Kasiviswanathan2013,
  Title                    = {{Novel document detection for massive data streams using distributed dictionary learning}},
  Author                   = {Kasiviswanathan, S. P. and Cong, G. and Melville, P. and Lawrence, R. D.},
  Journal                  = {IBM Journal of Research and Development},
  Year                     = {2013},

  Month                    = may,
  Number                   = {3},
  Pages                    = {9:1--9:15},
  Volume                   = {57},

  Abstract                 = {Given the high volume of content being generated online, it becomes necessary to employ automated techniques to separate out the documents belonging to novel topics from the background discussion, in a robust and scalable manner (with respect to the size of the document set). We present a solution to this challenge based on sparse coding, in which a stream of documents (where each document is modeled as an m-dimensional vector y) can be used to learn a dictionary matrix A of dimension m Ãƒâ€” k, such that the documents can be approximately represented by a linear combination of a few columns of A. If a new document cannot be represented with low error as a sparse linear combination of these columns, then this is a strong indicator of novelty of the document. We scale up this approach to handle millions of documents by parallelizing sparse coding and dictionary learning, and by using the alternating-directions method to solve the resulting optimization problems. We conduct our experiments on high-performance computing clusters with differing architectures and evaluate our approach on news streams and streaming data from TwitterÃ‚Â®. Based on the analysis, we share our insights on the distributed optimization and machine architecture that can help the design of exascale systems supporting data analytics.},
  Doi                      = {10.1147/JRD.2013.2247232},
  ISSN                     = {0018-8646},
  Keywords                 = {Dictionaries,Distibuted processing,Encoding,Information processing,Learning systems,Program processors,Sparse matrices,Twitter},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Novel document detection for massive data streams using distributed dictionary learning. Sparse coding to learn dictionary matrix. Inability to represent it with sparse linear combination of columns indicate novelty of doc. We conduct our experiments on high-performance computing clusters with differing architectures and evaluate our approach on news streams and streaming data from Twitter®.
Approved
1,2,3,6},
  Shorttitle               = {IBM Journal of Research and Development},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6517286}
}

@Misc{Kautz,
  Title                    = {{Data Mining Social Media for Public Health Applications}},

  Author                   = {Kautz, Henry},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The online population creates a vast organic sensor network composed of individuals reporting on their activities, their social interactions, and the events around them. This firehose of data streams in real time, and is often annotated with context including GPS location, relationships, and images. There is much activity in data mining social media for marketing campaigns (Richardson and Domingos 2002; Chen et al. 2010; Kirkpatrick 2012), financial prediction},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Not a full scientific paper.
Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.310.8323}
}

@Article{Kavanaugh2012,
  Title                    = {Social media use by government: From the routine to the critical },
  Author                   = {Andrea L. Kavanaugh and Edward A. Fox and Steven D. Sheetz and Seungwon Yang and Lin Tzy Li and Donald J. Shoemaker and Apostol Natsev and Lexing Xie},
  Journal                  = {Government Information Quarterly },
  Year                     = {2012},
  Note                     = {Social Media in Government - Selections from the 12th Annual International Conference on Digital Government Research (dg.o2011) },
  Number                   = {4},
  Pages                    = {480 - 491},
  Volume                   = {29},

  Abstract                 = {Social media and online services with user-generated content (e.g., Twitter, Facebook, Flickr, YouTube) have made a staggering amount of information (and misinformation) available. Government officials seek to leverage these resources to improve services and communication with citizens. Significant potential exists to identify issues in real time, so emergency managers can monitor and respond to issues concerning public safety. Yet, the sheer volume of social data streams generates substantial noise that must be filtered in order to detect meaningful patterns and trends. Important events can then be identified as spikes in activity, while event meaning and consequences can be deciphered by tracking changes in content and public sentiment. This paper presents findings from a exploratory study we conducted between June and December 2010 with government officials in Arlington, \{VA\} (and the greater National Capitol Region around Washington, D.C.), with the broad goal of understanding social media use by government officials as well as community organizations, businesses, and the public at large. A key objective was also to understand social media use specifically for managing crisis situations from the routine (e.g., traffic, weather crises) to the critical (e.g., earthquakes, floods).},
  Doi                      = {http://dx.doi.org/10.1016/j.giq.2012.06.002},
  ISSN                     = {0740-624X},
  Keywords                 = {Digital government},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to the goal being to "understand social media"},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0740624X12000871}
}

@InProceedings{Kavitha2012,
  Title                    = {{Massive stream data processing to attain anomaly Intrusion Prevention}},
  Author                   = {Kavitha, C. and Suresh, M.},
  Booktitle                = {2012 International Conference on Devices, Circuits and Systems (ICDCS)},
  Year                     = {2012},
  Month                    = mar,
  Pages                    = {572--575},
  Publisher                = {IEEE},

  Abstract                 = {Most of the contemporary intrusion detection systems need the ability to process massive data streams to achieve anomaly prevention. It is a hard issue since the streaming data have some tough characteristics, such as unknown or unbound size, possibly a variable arrival rate, lack of ability to backtrack over previously arrived transactions, and a lack of system control over the order in which the data arrive. This paper will find a network model which is more suitable for high speed processing of massive data streams in real-time from various data sources by considering the frequency property of events. An Intrusion prevention system have been built with online mining of frequent item sets over a stream with Time-sensitive sliding window, which is one of the most important technique in stream data mining with broad applications. This approach will be used to set the rules for Backtracking to determine the intrusion characteristics then to implement the Ã¢â‚¬Å“ Deny All except allowedÃ¢â‚¬ï¿½ policy rules for prevention. Combination of stream processing and backtracking is used to achieve this so-called Intrusion Prevention, so that in addition to detecting the existence of intrusion we do deny of intrusion as prevention.},
  Doi                      = {10.1109/ICDCSyst.2012.6188773},
  ISBN                     = {978-1-4577-1546-4},
  Keywords                 = {Analytical models,Data Stream,Frequent pattern mining,Intrusion Prevention,Maintenance engineering,Real time systems,anomaly intrusion prevention system,backtracking rule,computer network security,contemporary intrusion detection system,data mining,data source,high speed processing,intrusion characteristics,massive stream data processing,network model,online frequent item sets mining,prevention policy rule,stream data mining,time-sensitive sliding window,variable arrival rate},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Anomaly intrusion prevention. his paper will find a network model which is more suitable for high speed processing of massive data streams in real-time from various data sources by considering the frequency property of events. Time-sensitive sliding window.
Approved
1,6},
  Shorttitle               = {Devices, Circuits and Systems (ICDCS), 2012 Intern},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6188773}
}

@InProceedings{Kavitha2012a,
  Title                    = {{Processing Massive Data Streams to Achieve Anomaly Intrusion Prevention}},
  Author                   = {Kavitha, C. and Suresh, M.},
  Booktitle                = {2012 Fourth International Conference on Computational Intelligence and Communication Networks},
  Year                     = {2012},
  Month                    = nov,
  Pages                    = {948--952},
  Publisher                = {IEEE},

  Abstract                 = {Intrusion prevention system is an important technique in the network security architecture. Most of the modern intrusion detection systems lack the ability to process massive data streams to achieve anomaly detection. Instead of Intrusion detection, Intrusion prevention system can be used for both servers and end-hosts to handle the dual challenges of accuracy and performance which the former lacks. Intrusion prevention can be done by processing the data stream on fly. It is a difficult issue since the streaming data have some tough characteristics, such as unknown or unbound size, possibly a variable arrival rate, lack of ability to backtrack over previously arrived transactions, and a lack of system control over the order in which the data arrive. Many applications rely directly or indirectly on finding the frequent items, and implementations are in use in large scale industrial systems. This paper will find a network model which is more suitable for high speed processing of massive data streams in real-time from various data sources by considering the frequency property of events. An Intrusion prevention system have been built with online mining of frequent item sets over a stream with Time-sensitive sliding window, which is one of the most important technique in stream data mining with broad applications. Our method is employed to prevent the system with high efficiency and low use of system resources.},
  Doi                      = {10.1109/CICN.2012.167},
  ISBN                     = {978-0-7695-4850-0},
  Keywords                 = {Computational modeling,Computer architecture,Data Stream,Data mining,Data models,Frequent Pattern Mining,Intrusion Prevention,Intrusion detection,Servers,anomaly intrusion prevention,data mining,intrusion detection,massive data streams,network security architecture,online frequent item set mining,security of data,time-sensitive sliding window},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kavitha2012.
Discarded.},
  Shorttitle               = {Computational Intelligence and Communication Netwo},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6375255}
}

@Conference{Kavitha2012b,
  Title                    = {Massive stream data processing to attain anomaly intrusion prevention},
  Author                   = {Kavitha, C.a and Suresh, M.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)1},
  Pages                    = {572-575},

  Abstract                 = {Most of the contemporary intrusion detection systems need the ability to process massive data streams to achieve anomaly prevention. It is a hard issue since the streaming data have some tough characteristics, such as unknown or unbound size, possibly a variable arrival rate, lack of ability to backtrack over previously arrived transactions, and a lack of system control over the order in which the data arrive. This paper will find a network model which is more suitable for high speed processing of massive data streams in real-time from various data sources by considering the frequency property of events. An Intrusion prevention system have been built with online mining of frequent item sets over a stream with Time-sensitive sliding window, which is one of the most important technique in stream data mining with broad applications. This approach will be used to set the rules for Backtracking to determine the intrusion characteristics then to implement the "Deny All except allowed" policy rules for prevention. Combination of stream processing and backtracking is used to achieve this so-called Intrusion Prevention, so that in addition to detecting the existence of intrusion we do deny of intrusion as prevention. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Department of Computer Science, Government Arts College, Karur, Tamil Nadu, India; Anna University of Technology - Coimbatore, Tamil Nadu, India},
  Art_number               = {6188773},
  Author_keywords          = {Data Stream; Frequent pattern mining; Intrusion Prevention},
  Document_type            = {Conference Paper},
  Journal                  = {2012 International Conference on Devices, Circuits and Systems, ICDCS 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kavitha2012.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861206131&partnerID=40&md5=2cbde86e888104ce09219a429f147c43}
}

@Conference{Kavitha2012c,
  Title                    = {Processing massive data streams to achieve anomaly intrusion prevention},
  Author                   = {Kavitha, C.a and Suresh, M.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {948-952},

  Abstract                 = {Intrusion prevention system is an important technique in the network security architecture. Most of the modern intrusion detection systems lack the ability to process massive data streams to achieve anomaly detection. Instead of Intrusion detection, Intrusion prevention system can be used for both servers and end-hosts to handle the dual challenges of accuracy and performance which the former lacks. Intrusion prevention can be done by processing the data stream on fly. It is a difficult issue since the streaming data have some tough characteristics, such as unknown or unbound size, possibly a variable arrival rate, lack of ability to backtrack over previously arrived transactions, and a lack of system control over the order in which the data arrive. Many applications rely directly or indirectly on finding the frequent items, and implementations are in use in large scale industrial systems. This paper will find a network model which is more suitable for high speed processing of massive data streams in real-time from various data sources by considering the frequency property of events. An Intrusion prevention system have been built with online mining of frequent item sets over a stream with Time-sensitive sliding window, which is one of the most important technique in stream data mining with broad applications. Our method is employed to prevent the system with high efficiency and low use of system resources. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Department of Computer Applications, KSR College of Engineering, Thiruchengode, Tamil Nadu, India; Anna University of Technology, Coimbatore, Tamil Nadu, India},
  Art_number               = {6375255},
  Author_keywords          = {Data Stream; Frequent Pattern Mining; Intrusion Prevention},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 4th International Conference on Computational Intelligence and Communication Networks, CICN 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper will find a network model which is suitable for high speed processing of data streams in real-time from various data sources. An Intrusion prevention system have been built with online mining of frequent item sets over a stream with Time-sensitive sliding window, which is one of the most important technique in stream data mining with broad applications. Our method is employed to prevent the system with high efficiency and low use of system resources. Seems like an intersting paper, trying to create a model for preventing intrusion. Their introduction is very good, but their description of the results are lacking. Could be primary source, but need to read the whole thing. 1,2,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84872027979&partnerID=40&md5=4896ed0f7c6cc58238f7727defa10ca4}
}

@InProceedings{Kavitha2010,
  Title                    = {{Comparing ODAC and Hierarchical algorithm using time series data streams}},
  Author                   = {Kavitha, V. and Punithavalli, M.},
  Booktitle                = {2010 IEEE International Conference on Computational Intelligence and Computing Research},
  Year                     = {2010},
  Month                    = dec,
  Pages                    = {1--4},
  Publisher                = {IEEE},

  Abstract                 = {Mining Time Series data has a tremendous growth of interest in today's world. Clustering time series is a trouble that has applications in an extensive assortment of fields and has recently attracted a large amount of researchers. Time series data are frequently large and may contain outliers. In addition, time series are a special type of data set where elements have a temporal ordering. Therefore clustering of such data stream is an important issue in the data mining process. The clustering algorithms and its effectiveness on various applications are compared to develop a new method to solve the existing problem. This paper presents a comparison between Hierarchical clustering algorithm and Online Divisible Agglomerative Clustering algorithm (ODAC) using ECG data sets.},
  Doi                      = {10.1109/ICCIC.2010.5705858},
  ISBN                     = {978-1-4244-5965-0},
  Keywords                 = {Clustering algorithms,Data Streams,Data mining,ECG data set,Electrocardiography,Hierarchical Clustering,Indexes,Monitoring,ODAC algorithm,Outliers,Partitioning algorithms,Time series analysis,data clustering,data mining,electrocardiography,hierarchical algorithm,medical administrative data processing,online divisible agglomerative clustering algorith,pattern clustering,time series,time series data stream},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Clustering time series. . The clustering algorithms and its effectiveness on various applications are compared to develop a new method to solve the existing problem. This paper has a comparison of algorithms, but state they develop a new method to solve it. Novel, though with some doubt.
Approved
1,2},
  Shorttitle               = {Computational Intelligence and Computing Research },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5705858}
}

@Conference{Kavitha2010a,
  Title                    = {Comparing ODAC and Hierarchical algorithm using time series data streams},
  Author                   = {Kavitha, V.a and Punithavalli, M.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Pages                    = {807-810},

  Abstract                 = {Mining Time Series data has a tremendous growth of interest in today's world. Clustering time series is a trouble that has applications in an extensive assortment of fields and has recently attracted a large amount of researchers. Time series data are frequently large and may contain outliers. In addition, time series are a special type of data set where elements have a temporal ordering. Therefore clustering of such data stream is an important issue in the data mining process. The clustering algorithms and its effectiveness on various applications are compared to develop a new method to solve the existing problem. This paper presents a comparison between Hierarchical clustering algorithm and Online Divisible Agglomerative Clustering algorithm (ODAC) using ECG data sets. Ã‚Â© 2010 IEEE.},
  Affiliation              = {Dept. of Computer Science, Karpagam University, Coimbatore, Tamilnadu, India; Sri Ramakrishna College of Arts and Science for Women, Coimbatore, Tamilnadu, India},
  Art_number               = {5705858},
  Author_keywords          = {Data streams; Hierarchical clustering; Outliers},
  Document_type            = {Conference Paper},
  Journal                  = {2010 IEEE International Conference on Computational Intelligence and Computing Research, ICCIC 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kavitha2010.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79951800938&partnerID=40&md5=7b3e7ae277ee85b15a231e740f65f469}
}

@Article{Keogh2003b,
  Title                    = {{Clustering of Time Series Subsequences is Meaningless: Implications for Past and Future Research}},
  Author                   = {Keogh, Eamonn and Lin, Jessica},
  Journal                  = {IN PROC. OF THE 3RD IEEE INTERNATIONAL CONFERENCE ON DATA MINING},
  Year                     = {2003},
  Pages                    = {115 -- 122},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Time series data is perhaps the most frequently encountered type of data examined by the data mining community. Clustering is perhaps the most frequently used data mining algorithm, being useful in it’s own right as an exploratory technique, and also as a subroutine in more complex data mining algorithms such as rule discovery, indexing, summarization, anomaly detection, and classification. Given these two facts, it is hardly surprising that time series clustering has attracted much attention. The data to be clustered can be in one of two formats: many individual time series, or a single time series, from which individual time series are extracted with a sliding window. Given the recent explosion of interest in streaming data and online algorithms, the latter case has received much attention. In this work we make a surprising claim. Clustering of streaming time series is completely meaningless. More concretely, clusters extracted from streaming time series are forced to obey a certain constraint that is pathologically unlikely to be satisfied by any dataset, and because of this, the clusters extracted by any clustering algorithm are essentially random. While this constraint can be intuitively demonstrated with a simple illustration and is simple to prove, it has never appeared in the literature. We can justify calling our claim surprising, since it invalidates the contribution of dozens of previously published papers. We will justify our claim with a theorem, illustrative examples, and a comprehensive set of experiments on reimplementations of previous work. Although the primary contribution of our work is to draw attention to the fact that an apparent solution to an important problem is incorrect and should no longer be used, we also introduce a novel method which, based on the concept of time series motifs, is able to meaningfully cluster some streaming time series datasets.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Lin2013a.
Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.164.3066}
}

@InProceedings{Keogh2003,
  Title                    = {{Clustering of time series subsequences is meaningless: implications for previous and future research}},
  Author                   = {Keogh, E. and Lin, J. and Truppel, W.},
  Booktitle                = {Third IEEE International Conference on Data Mining},
  Year                     = {2003},
  Pages                    = {115--122},
  Publisher                = {IEEE Comput. Soc},

  Abstract                 = {Time series data is perhaps the most frequently encountered type of data examined by the data mining community. Clustering is perhaps the most frequently used data mining algorithm, being useful in it's own right as an exploratory technique, and also as a subroutine in more complex data mining algorithms such as rule discovery, indexing, summarization, anomaly detection, and classification. Given these two facts, it is hardly surprising that time series clustering has attracted much attention. The data to be clustered can be in one of two formats: many individual time series, or a single time series, from which individual time series are extracted with a sliding window. Given the recent explosion of interest in streaming data and online algorithms, the latter case has received much attention. We make an amazing claim. Clustering of streaming time series is completely meaningless. More concretely, clusters extracted from streaming time series are forced to obey a certain constraint that is pathologically unlikely to be satisfied by any dataset, and because of this, the clusters extracted by any clustering algorithm are essentially random. While this constraint can be intuitively demonstrated with a simple illustration and is simple to prove, it has never appeared in the literature. We can justify calling our claim surprising, since it invalidates the contribution of dozens of previously published papers. We will justify our claim with a theorem, illustrative examples, and a comprehensive set of experiments on reimplementations of previous work.},
  Doi                      = {10.1109/ICDM.2003.1250910},
  ISBN                     = {0-7695-1978-4},
  Keywords                 = {Data mining,anomaly detection,clustering algorithm,computational complexity,data mining,data mining algorithm,many individual time series,pattern clustering,rule discovery,single time series,streaming data,streaming time series,time series,time series clustering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Lin2013a.
Discarded.},
  Shorttitle               = {Data Mining, 2003. ICDM 2003. Third IEEE Internati},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1250910}
}

@Conference{Keogh2003a,
  Title                    = {Clustering of time series subsequences is meaningless: Implications for previous and future research},
  Author                   = {Keogh, E. and Lin, J. and Truppel, W.},
  Year                     = {2003},
  Note                     = {cited By (since 1996)86},
  Pages                    = {115-122},

  Abstract                 = {Time series data is perhaps the most frequently encountered type of data examined by the data mining community. Clustering is perhaps the most frequently used data mining algorithm, being useful in it's own right as an exploratory technique, and also as a subroutine in more complex data mining algorithms such as rule discovery, indexing, summarization, anomaly detection, and classification. Given these two facts, it is hardly surprising that time series clustering has attracted much attention. The data to be clustered can be in one of two formats: many individual time series, or a single time series, from which individual time series are extracted with a sliding window. Given the recent explosion of interest in streaming data and online algorithms, the latter case has received much attention. In this work we make an amazing claim. Clustering of streaming time series is completely meaningless. More concretely, clusters extracted from streaming time series are forced to obey a certain constraint that is pathologically unlikely to be satisfied by any dataset, and because of this, the clusters extracted by any clustering algorithm are essentially random. While this constraint can be intuitively demonstrated with a simple illustration and is simple to prove, it has never appeared in the literature. We can justify calling our claim surprising, since it invalidates the contribution of dozens of previously published papers. We will justify our claim with a theorem, illustrative examples, and a comprehensive set of experiments on reimplementations of previous work. Ã‚Â© 2003 IEEE.},
  Affiliation              = {Computer Science and Engineering Department, University of California - Riverside, Riverside, CA 92521, United States},
  Author_keywords          = {Clustering; Data mining; Rule discovery; Time series},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Lin2013a.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78149351008&partnerID=40&md5=a3be8435264fb3e55e2a142b4badbb4b}
}

@Article{Khalilian2013,
  Title                    = {Different aspects of data stream clustering},
  Author                   = {Khalilian, M. and Mustapha, N. and Sulaiman, M.N. and Mamat, A.},
  Journal                  = {Lecture Notes in Electrical Engineering},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1181-1191},
  Volume                   = {152 LNEE},

  Abstract                 = {Nowadays the growth of the datasets size causes some difficulties to extract useful information and knowledge especially in specific domains. However, new methods in data mining need to be developed in both sides of supervised and unsupervised approaches. Nevertheless, data stream clustering can be taken into account as an effective strategy to apply for huge data as an unsupervised fashion. In this research we not only propose a framework for data stream clustering but also evaluate different aspects of existing obstacles in this arena. The main problem in data stream clustering is visiting data once therefore new methods should be applied. On the other hand, concept drift must be recognized in real-time. In this paper, we try to clarify: first, the different aspects of problem with regard to data stream clustering generally and how several prominent solutions tackle different problems; second, the varying assumptions, heuristics, and intuitions forming the basis of approaches and finally a new framework for data stream clustering is proposed with regard to the specific difficulties encountered in this field of research. Ã‚Â© 2013 Springer Science+Business Media.},
  Affiliation              = {Faculty of Computer Science and Information Technology, University Putra Malaysia, Bintulu, Malaysia},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {In this paper, we try to clarify: first, the different aspects of problem with regard to data stream clustering generally and how several prominent solutions tackle different problems. Doesn't appear to make any contribution except comparison.
Discarded, but put aside.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84866617409&partnerID=40&md5=11a10220edff38095409045fd82552b3}
}

@Conference{Khan2009a,
  Title                    = {Anomaly detection in data streams using fuzzy logic},
  Author                   = {Khan, M.U.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {167-174},

  Abstract                 = {Unsupervised data mining techniques require human intervention for understanding and analysis of the clustering results. This becomes an issue in dynamic users/applications and there is a need for real-time decision making and interpretation. In this paper we will present an approach to automate the annotation of results obtained from data stream clustering to facilitate interpreting that whether the given cluster is an anomaly or not. We use fuzzy logic to label the data. The results will be obtained on the basis of density function & the number of elements in a certain cluster. Ã‚Â© 2009 IEEE.},
  Affiliation              = {Muhammad Ali Jinnah University, Pakistan},
  Art_number               = {5267196},
  Document_type            = {Conference Paper},
  Journal                  = {2009 International Conference on Information and Communication Technologies, ICICT 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Khan2009.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70449746530&partnerID=40&md5=82379102ecd7822f67e42882be30d074}
}

@InProceedings{Khan2009,
  Title                    = {{Anomaly Detection in data streams using fuzzy logic}},
  Author                   = {Khan, Muhammad Umair},
  Booktitle                = {2009 International Conference on Information and Communication Technologies},
  Year                     = {2009},
  Month                    = aug,
  Pages                    = {167--174},
  Publisher                = {IEEE},

  Abstract                 = {Unsupervised data mining techniques require human intervention for understanding and analysis of the clustering results. This becomes an issue in dynamic users/applications and there is a need for real-time decision making and interpretation. In this paper we will present an approach to automate the annotation of results obtained from data stream clustering to facilitate interpreting that whether the given cluster is an anomaly or not. We use fuzzy logic to label the data. The results will be obtained on the basis of density function \& the number of elements in a certain cluster.},
  Doi                      = {10.1109/ICICT.2009.5267196},
  ISBN                     = {978-1-4244-4608-7},
  Keywords                 = {Data mining,Decision making,Expert systems,Fuzzy logic,Fuzzy systems,Humans,Intrusion detection,Monitoring,Particle measurements,Uncertainty,anomaly detection,data mining,data stream clustering,decision making,fuzzy logic,intrusion detection system,machine learning technique,pattern clustering,real-time decision making,real-time interpretation,real-time systems,security of data,unsupervised data mining technique,unsupervised learning},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Anomaly Detection in data streams using fuzzy logic. In this paper we will present an approach to automate the annotation of results obtained from data stream clustering to determine whether cluster is anomaly or not.
Approved
1,6},
  Shorttitle               = {Information and Communication Technologies, 2009. },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5267196}
}

@Misc{Kharazmi2000,
  Title                    = {{-104 A Procedure For On Line Learning And Improvemnet Of Wavelet Based Neural Networks}},

  Author                   = {Kharazmi, Safavi Gunes and Safavi, A. A and Gunes, H. and Kharazmi, M. R. and Romagnoli, J. A.},
  Year                     = {2000},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Document removed.
Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.9691}
}

@InProceedings{Kholghi2010,
  Title                    = {{Classification and evaluation of data mining techniques for data stream requirements}},
  Author                   = {Kholghi, Mahnoosh and Hassanzadeh, Hamed and Keyvanpour, MohammadReza},
  Booktitle                = {2010 International Symposium on Computer, Communication, Control and Automation (3CA)},
  Year                     = {2010},
  Month                    = may,
  Pages                    = {474--478},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {In recent years, the management and processing of data streams has become a topic of active research in several fields of computer science, such as distributed systems, database systems, and data mining. In data streams' applications, such as network monitoring, telecommunication systems and sensor networks, because of online monitoring, answering to the user's queries should be time and space efficient. Generally, two main challenges are to design fast mining methods for data streams and the need to promptly detect changing concepts and data distribution because of highly dynamic nature of data streams. The goal of this article is to analyze and classify the application of diverse data mining techniques in different challenges of data stream mining. For this goal, this article tries to categorize and analyze related researches for better understanding and to reach a framework that can map data mining techniques to data stream mining challenges and requirements.},
  Doi                      = {10.1109/3CA.2010.5533759},
  ISBN                     = {978-1-4244-5565-2},
  Keywords                 = {Algorithm design and analysis,Application software,Automatic control,Computerized monitoring,Data Mining,Data Stream,Data mining,Data stream Mining,Database systems,Design methodology,Distributed computing,Relational databases,Stream Preprocessing,Streaming media,data distribution,data mining,data mining techniques,data stream requirements,database management systems,database systems,distributed systems,network monitoring,online monitoring,pattern classification,sensor networks,telecommunication systems},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {The goal of this article is to analyze and classify the application of diverse data mining techniques in different challenges of data stream mining. For this goal, this article tries to categorize and analyze related researches for better understanding and to reach a framework that can map data mining techniques to data stream mining challenges and requirements. VERY SIMILAR idea to our paper, but poor execution compared.
Discarded, but put aside.},
  Shorttitle               = {Computer Communication Control and Automation (3CA},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5533759}
}

@Conference{Kholghi2010a,
  Title                    = {Classification and evaluation of data mining techniques for data stream requirements},
  Author                   = {Kholghi, M.a and Hassanzadeh, H.a and Keyvanpour, M.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)4},
  Pages                    = {474-478},
  Volume                   = {1},

  Abstract                 = {In recent years, the management and processing of data streams has become a topic of active research in several fields of computer science, such as distributed systems, database systems, and data mining. In data streams' applications, such as network monitoring, telecommunication systems and sensor networks, because of online monitoring, answering to the user's queries should be time and space efficient. Generally, two main challenges are to design fast mining methods for data streams and the need to promptly detect changing concepts and data distribution because of highly dynamic nature of data streams. The goal of this article is to analyze and classify the application of diverse data mining techniques in different challenges of data stream mining. For this goal, this article tries to categorize and analyze related researches for better understanding and to reach a framework that can map data mining techniques to data stream mining challenges and requirements. Ã‚Â© 2010 IEEE.},
  Affiliation              = {Department of Electronic, Computer and IT, Islamic Azad University, Qazvin, Iran; Department of Computer Engineering, Alzahra University, Tehran, Iran},
  Art_number               = {5533759},
  Author_keywords          = {Data Mining; Data Stream; Data stream Mining; Stream Preprocessing},
  Document_type            = {Conference Paper},
  Journal                  = {3CA 2010 - 2010 International Symposium on Computer, Communication, Control and Automation},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kholghi2010.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77956100819&partnerID=40&md5=9430f808ac2b6794b1e1437b845c4344}
}

@Article{Khrouf2014,
  Title                    = {Mining events connections on the social web: Real-time instance matching and data analysis in EventMedia },
  Author                   = {Houda Khrouf and Vuk Milicic and RaphaÃƒÂ«l Troncy},
  Journal                  = {Web Semantics: Science, Services and Agents on the World Wide Web },
  Year                     = {2014},
  Note                     = {The Semantic Web Challenge 2012 },
  Number                   = {0},
  Pages                    = {3 - 10},
  Volume                   = {24},

  Abstract                 = {Abstract Event and media services have recently witnessed a rapid growth driving the way people explore information of interest. A significant amount of social calendars, media memes and background knowledge are daily created on various platforms, conveying event clues or past users experience. Mining, in real-time, the connection of these distributed data fragments provides a key advantage not only to deliver enriched views, but also to gain insight into interesting sociological aspects. To this aim, we harness the power of Semantic Web technologies as means to easily steer the data integration and analysis. Our overall goal is to build a web-based environment that allows users to discover meaningful, surprising or entertaining connections between events, media and people. In this paper, we present EventMedia, a platform that provides descriptions of events associated with media, and interlinked with the Linked Data cloud. It draws on a live data update and a real-time interlinking to face the natural dynamics of events. A user-friendly interface has been designed to meet the user needs: relive experiences based on media and support decision making for attending upcoming events.},
  Doi                      = {http://dx.doi.org/10.1016/j.websem.2014.02.003},
  ISSN                     = {1570-8268},
  Keywords                 = {EventMedia},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining events connections on the social web. Semantic web. Our overall goal is to build a web-based environment that allows users to discover meaningful, surprising or entertaining connections between events, media and people. Provoding a common view to fragmented data. Novel, possibly ML, not sure.
Approved
1},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1570826814000080}
}

@Article{Khrouf2014a,
  Title                    = {Mining events connections on the social web: Real-time instance matching and data analysis in EventMedia},
  Author                   = {Khrouf, H. and Milicic, V. and Troncy, R.},
  Journal                  = {Journal of Web Semantics},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {3-10},
  Volume                   = {24},

  Abstract                 = {Event and media services have recently witnessed a rapid growth driving the way people explore information of interest. A significant amount of social calendars, media memes and background knowledge are daily created on various platforms, conveying event clues or past users experience. Mining, in real-time, the connection of these distributed data fragments provides a key advantage not only to deliver enriched views, but also to gain insight into interesting sociological aspects. To this aim, we harness the power of Semantic Web technologies as means to easily steer the data integration and analysis. Our overall goal is to build a web-based environment that allows users to discover meaningful, surprising or entertaining connections between events, media and people. In this paper, we present EventMedia, a platform that provides descriptions of events associated with media, and interlinked with the Linked Data cloud. It draws on a live data update and a real-time interlinking to face the natural dynamics of events. A user-friendly interface has been designed to meet the user needs: relive experiences based on media and support decision making for attending upcoming events. Ã‚Â© 2014 Elsevier B.V. All rights reserved.},
  Affiliation              = {Multimedia Communications Department, EURECOM, 06410 Sophia Antipolis, France},
  Author_keywords          = {Event-based social network; EventMedia; Instance matching; LODE ontology; Real-time},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Khrouf2014.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84899485093&partnerID=40&md5=e6b1b90d0561f0a465f208aeaed7a394}
}

@Conference{Kim2012,
  Title                    = {Real-time sequential pattern mining for USN system},
  Author                   = {Kim, J. and Choi, P. and Hwang, B.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {In USN systems, data streams are generated from sensor nodes. It is very important to find information from these data stream because data streams present practical phenomena. Data streams have temporal properties, so we can apply sequential pattern mining methods to data streams. However, because data streams are continuous and infinite, we need to develop new methods by considering the conditions in USN environments. In this paper, we propose a real-time sequential pattern mining methods for data stream from USN systems. We define the variable Meaning Window and use HAPT (HAsh based Pattern Tree) as a new data structures for sequential pattern mining. To evaluate the performance of our proposed methods, we compared it with the PrefixSpan method. Through experimentation, we confirmed the effectiveness our methods for USN system environments. Ã‚Â© 2012 ACM.},
  Affiliation              = {Department of Computer Science, Chonnam National University, 300 Yongbong-dong, Gwang-Ju, South Korea},
  Art_number               = {36},
  Author_keywords          = {Data stream; Pattern mining; Real-time; Real-time mining; USN},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 6th International Conference on Ubiquitous Information Management and Communication, ICUIMC'12},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Data mining in Unites States Navy systems streams? In this paper, we propose a real-time sequential pattern mining methods for data stream from USN systems. Use a window method with Hash based Pattern tree for pattern mining. Compared performance with PrefixSpan method. Through experimentation, we confirmed the effectiveness our methods for USN system environments.
Approved
1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84860505731&partnerID=40&md5=a6e7c2a132f10c50341695661c07af9c}
}

@Conference{Kim2012a,
  Title                    = {Real-time pattern map mining for USN application},
  Author                   = {Kim, J. and Choi, P. and Hwang, B.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {In USN system, data streams are generated from several sensor nodes continuously. Therefore, patterns from data streams can be occur continuously and be a very long sequence pattern. However, it is very expensive to mine a very long sequence pattern using existing pattern mining methods. In this paper, we define the Pattern Map to store serial patterns and we propose the Pattern Map mining to discover useful information from the Pattern Map in real-time. Also, we define the Meaning Window to produce transactions from data streams and we define the HAPM(HAsh based Pattern Map) as a new data structure to represent the Pattern Map. Finally, we introduce Local Rules and the Global Rules as a new rule concept for USN application environments. Ã‚Â© 2012 ACM.},
  Affiliation              = {Department of Computer Science, Chonnam National University, 300 Yongbong-dong, Gwang-Ju, South Korea},
  Art_number               = {77},
  Author_keywords          = {Data stream; Pattern map; Pattern map mining; Real-time mining; USN},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 6th International Conference on Ubiquitous Information Management and Communication, ICUIMC'12},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kim2012.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84860537577&partnerID=40&md5=2fd0beda1f5b9ca406fc6cc1f06e14c5}
}

@InProceedings{Kim2012c,
  Title                    = {{Real-time sequential pattern mining for USN system}},
  Author                   = {Kim, Jaein and Choi, Pilsun and Hwang, Buhyun},
  Booktitle                = {Proceedings of the 6th International Conference on Ubiquitous Information Management and Communication - ICUIMC '12},
  Year                     = {2012},

  Address                  = {New York, New York, USA},
  Month                    = feb,
  Pages                    = {1},
  Publisher                = {ACM Press},

  Abstract                 = {In USN systems, data streams are generated from sensor nodes. It is very important to find information from these data stream because data streams present practical phenomena. Data streams have temporal properties, so we can apply sequential pattern mining methods to data streams. However, because data streams are continuous and infinite, we need to develop new methods by considering the conditions in USN environments. In this paper, we propose a real-time sequential pattern mining methods for data stream from USN systems. We define the variable Meaning Window and use HAPT (HAsh based Pattern Tree) as a new data structures for sequential pattern mining. To evaluate the performance of our proposed methods, we compared it with the PrefixSpan method. Through experimentation, we confirmed the effectiveness our methods for USN system environments.},
  Doi                      = {10.1145/2184751.2184796},
  ISBN                     = {9781450311724},
  Keywords                 = {USN,data stream,pattern mining,real-time,real-time mining},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kim2012.
Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2184751.2184796}
}

@InProceedings{Kim2012d,
  Title                    = {{Real-time pattern map mining for USN application}},
  Author                   = {Kim, Jaein and Choi, Pilsun and Hwang, Buhyun},
  Booktitle                = {Proceedings of the 6th International Conference on Ubiquitous Information Management and Communication - ICUIMC '12},
  Year                     = {2012},

  Address                  = {New York, New York, USA},
  Month                    = feb,
  Pages                    = {1},
  Publisher                = {ACM Press},

  Abstract                 = {In USN system, data streams are generated from several sensor nodes continuously. Therefore, patterns from data streams can be occur continuously and be a very long sequence pattern. However, it is very expensive to mine a very long sequence pattern using existing pattern mining methods. In this paper, we define the Pattern Map to store serial patterns and we propose the Pattern Map mining to discover useful information from the Pattern Map in real-time. Also, we define the Meaning Window to produce transactions from data streams and we define the HAPM(HAsh based Pattern Map) as a new data structure to represent the Pattern Map. Finally, we introduce Local Rules and the Global Rules as a new rule concept for USN application environments.},
  Doi                      = {10.1145/2184751.2184843},
  ISBN                     = {9781450311724},
  Keywords                 = {USN,data stream,pattern map,pattern map mining,real-time mining},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kim2012.
Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2184751.2184843}
}

@Article{Kim2012b,
  Title                    = {A sliding window-based false-negative approach for ubiquitous data stream analysis},
  Author                   = {Kim, Y.a and Park, D.-S.b and Kim, H.c and Kim, U.a },
  Journal                  = {International Journal of Communication Systems},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {6},
  Pages                    = {691-716},
  Volume                   = {25},

  Abstract                 = {Ubiquitous data stream mining (UDSM) is the process of performing data analysis on mobile, embedded and ubiquitous devices. In many cases, a large volume of data can be mined for interesting and relevant information in a wide variety of applications. Data stream mining requires computationally intensive mining techniques to be applied in mobile environments constrained by analysis of a real-time single pass with limited computational resources. Therefore, we have to ensure that the result is within the error tolerance range. In this paper, we suggest a method for a false-negative approach based on the Chernoff bound for efficient analysis of the data stream. Hence, we consider the problem of approximating frequency counts for space-efficient computation over data stream sliding windows. We show that a false-negative approach allowing a controlled number of frequent itemsets to be missing from the output is a more promising solution for mining frequent itemsets from a ubiquitous data stream. These are simple to implement, and have provable quality, space, and time guarantees. The experimental results have shown that the proposed algorithms achieve a high accuracy of at least 99% and require a small execution time. Copyright Ã‚Â© 2012 John Wiley & Sons, Ltd.},
  Affiliation              = {School of Information and Communication Engineering, University of Sungkyunkwan, 300 Cheoncheon-dong, Jangan-gu, Suwon 440-746, South Korea; Division of Computer Science and Engineering, University of Soonchunhyang, South Korea; Division of Computer, University of Sahmyook, South Korea},
  Author_keywords          = {approximate counts; Chernoff bound; false negative; frequent itemsets; ubiquitous data stream mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Ubiquitous data stream mining on mobile or embedded devices. Resources are limited, but we have to ensure error is in tolerated range. In this paper, we suggest a method for a false-negative approach based on the Chernoff bound for efficient analysis of the data stream. The problem approached is approximating frequency counts space efficently. The experimental results have shown that the proposed algorithms achieve a high accuracy of at least 99% and require a small execution time.
Approved
1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861806771&partnerID=40&md5=303b63a5ae8cf68d817a6bfbb5786566}
}

@Book{Kiselev2009,
  Title                    = {A multiagent approach to adaptive continuous analysis of streaming data in complex uncertain environments},
  Author                   = {Kiselev, I.a and Alhajj, R.b },
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The data mining task of online unsupervised learning of streaming data continually arriving at the system in complex dynamic environments under conditions of uncertainty is an NP-hard optimization problem for general metric spaces and is computationally intractable for real-world problems of practical interest. The primary contribution of this work is a multi-agent method for continuous agglomerative hierarchical clustering of streaming data, and a knowledge-based selforganizing competitive multi-agent system for implementing it. The reported experimental results demonstrate the applicability and efficiency of the implemented adaptive multi-agent learning system for continuous online clustering of both synthetic datasets and datasets from the following real-world domains: the RoboCup Soccer competition, and gene expression datasets from a bioinformatics test bed. Ã‚Â© 2009 Springer-Verlag US.},
  Affiliation              = {David R. Cheriton School of Computer Science, University of Waterloo, 200 University Avenue West, Waterloo, ON N2L 3G1, Canada; Department of Computer Science, University of Calgary, 2500 University Drive NW, Calgary, AB T2N 1N4, Canada},
  Document_type            = {Book Chapter},
  Journal                  = {Data Mining and Multi-Agent Integration},
  Owner                    = {Alexander},
  Pages                    = {201-218},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The primary contribution of this work is a multi-agent method for continuous agglomerative hierarchical clustering of streaming data, and a knowledge-based selforganizing competitive multi-agent system for implementing it. The reported experimental results demonstrate the applicability and efficiency of the implemented adaptive multi-agent learning system. Tested on RoboCup Soccer data and gene expression data sets.
Approved
1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84887959055&partnerID=40&md5=4cfc6be48359f9d96642128b1f5b4d9d}
}

@Article{Kleinberg2006,
  Title                    = {{Temporal Dynamics of On-Line Information Streams}},
  Author                   = {Kleinberg, Jon},
  Journal                  = {IN DATA STREAM MANAGEMENT: PROCESSING HIGH-SPEED DATA},
  Year                     = {2006},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A number of recent computing applications involve information arriving continuously over time in the form of a data stream, and this has led to new ways of thinking about traditional problems in a variety of areas. In some cases, the rate and overall volume of data in the stream may be so great that it cannot all be stored for processing, and this leads to new requirements for efficiency and scalability. In other cases, the quantities of information may still be manageable, but the data stream perspective takes what has generally been a static view of a problem and adds a strong temporal dimension to it. Our focus here is on some of the challenges that this latter issue raises in the settings of text mining, on-line information, and information retrieval. Many information sources have a stream-like structure, in which the way content arrives over time carries an essential part of its meaning. News coverage is a basic example; understanding the pattern of a developing news},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Focuses on the temporal dimension of streams of in text mining, on-line information, and information retrieval. Lists some other previous techniques. Does not appear to make any comprehension. No Abstract, only Introduction.
Discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.600}
}

@Article{Kloeckl2012,
  Title                    = {Enabling the Real-Time City: LIVE Singapore!},
  Author                   = {Kloeckl, K.a and Senn, O.b and Ratti, C.a },
  Journal                  = {Journal of Urban Technology},
  Year                     = {2012},
  Note                     = {cited By (since 1996)4},
  Number                   = {2},
  Pages                    = {89-112},
  Volume                   = {19},

  Abstract                 = {The increasing pervasiveness of urban systems and networks utilizing digital technologies for their operation generates enormous amounts of digital traces capable of reflecting in real-time how people make use of space and infrastructures in the city. This is not only transforming how we study, design, and manage cities but opens up new possibilities for tools that give people access to up-to-date information about urban dynamics, allowing them to take decisions that are more in sync with their environment. This paper documents the ongoing LIVE Singapore! project which explores the development of an open platform for the collection, elaboration and distribution of a large and growing number of different kinds of real-time data that originate in a city. Inspired by recent data.gov initiatives, the platform is structured to become itself a tool for developer communities, allowing them to analyze data and write applications that create links between a city's different real-time data streams, offering new insights and services to citizens. Being a compact island based city-state metropolis, Singapore offers a unique context for this study. This paper addresses the value of stream data for city planning and management as well as modalities to give citizens meaningful access to large amounts of data capable of informing their decisions. We describe the technology context within which this project is framed, illustrate the requirements and the architecture of the open real-time data platform to serve as a base for programming the city, and finally we present and discuss the first platform prototype (using real-world data from operators of cellphone networks, taxi fleet, public transport, sea port, airport, and others). Based on this prototype a public showcasing of the project was staged in April 2011 at the Singapore Art Museum and the visual data analytics generated are illustrated in the paper. Finally, we draw some conclusions of technical as well as organizational nature regarding the challenges we faced when working in new ways with real-world, real-time data streams in an urban context that will help inform further development of our as well as of related projects in progressing in disclosing the potential of the wealth of digital data generated by urban systems, networks, and infrastructures. Ã‚Â© 2012 Copyright The Society of Urban Technology.},
  Affiliation              = {Senseable City Lab at the Massachusetts Institute of Technology, United States; Singapore-MIT Alliance for Technology, Singapore},
  Author_keywords          = {Feedback Loop; Open Data; Real-Time City; Singapore; Stream Data; Urban Data Platform; Urban Management Systems; Urban System Dynamics},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {LIVE Singapore! project to collect, elaborate and distribute alle the data that come from a city. Interesting system that appears to mainly be about how to handle data.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867211384&partnerID=40&md5=b53aac7b4eba0dea22e210cb8775b9cc}
}

@Article{Kong2010,
  Title                    = {A self-stabilizing \{MSA\} algorithm in high-dimension data stream },
  Author                   = {Xiangyu Kong and Changhua Hu and Chongzhao Han},
  Journal                  = {Neural Networks },
  Year                     = {2010},
  Number                   = {7},
  Pages                    = {865 - 871},
  Volume                   = {23},

  Abstract                 = {Minor subspace analysis (MSA) is a statistical method for extracting the subspace spanned by all the eigenvectors associated with the minor eigenvalues of the autocorrelation matrix of a high-dimension vector sequence. In this paper, we propose a self-stabilizing neural network learning algorithm for tracking minor subspace in high-dimension data stream. Dynamics of the proposed algorithm are analyzed via a corresponding deterministic continuous time (DCT) system and stochastic discrete time (SDT) system methods. The proposed algorithm provides an efficient online learning for tracking the \{MS\} and can track an orthonormal basis of the MS. Computer simulations are carried out to confirm the theoretical results. },
  Doi                      = {http://dx.doi.org/10.1016/j.neunet.2010.04.001},
  ISSN                     = {0893-6080},
  Keywords                 = {Minor subspace analysis (MSA)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We propose a self-stabilizing neural network learning algorithm for tracking minor subspace in high dimensional data streams. Computer simulations are carried out to confirm the theoretical results.
Approved
1,3,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0893608010000821}
}

@Conference{Kong2009,
  Title                    = {The performance analysis of the self-stabilizing Douglas's MCA algorithm},
  Author                   = {Kong, X.a and Hu, C.a and Han, C.b },
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The minor component (MC) is the eigenvector associated with the smallest eigenvalue of the correlation matrix of input data. In many information processing areas, it is important to online extract MC from high-dimensional input data stream. Usually, MCA learning algorithms are described by stochastic discrete time (SDT) systems and the convergence is analyzed via a corresponding DCT system, but some restrictive conditions must be satisfied in this method. The SDT method use directly the stochastic discrete learning laws to analyze the temporal behavior of MCA algorithms and some important results can be obtained. In this paper, the theoretical analysis of Douglas's algorithm for MCA is given by using two methods: deterministic continuous time (DCT) system and stochastic discrete time system. The results of computer simulations are given to confirm the theoretical results. Ã‚Â©2009 IEEE.},
  Affiliation              = {Xi'an Research Institute of High Technology, Xi'an 710025, China; School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an 710049, China},
  Art_number               = {5303452},
  Author_keywords          = {Deterministic continuous time (DCT) system; Minor component analysis; Stochastic discrete time system},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2009 2nd International Congress on Image and Signal Processing, CISP'09},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Extracting Minor component eigenvector from high dimensional input data streams. They give a theorietical analysis of existing methods.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-73849114586&partnerID=40&md5=f413fb57a64b1d554d920f523891a046}
}

@Misc{Kong,
  Title                    = {{An Ensemble-based Approach to Fast Classification of Multi-label Data Streams}},

  Author                   = {Kong, Xiangnan and Yu, Philip S.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Network operators are continuously confronted with online events, such as online messages, blog updates, etc. Due to the huge volume of these events and the fast changes of the topics, it is critical to manage them promptly and effectively. There have been many softwares and algorithms developed to conduct automatic classification over these stream data. Conventional approaches focus on single-label scenarios, where each event can only be tagged with one label. However, in many stream data, each event can be tagged with more than one labels. Effective stream classification systems should be able to consider the unique properties of multi-label stream data, such as large data volumes, label correlations and concept drifts. To address these challenges, in this paper, we propose an efficient and effective method for multi-label stream classification based on an ensemble of fading random trees. The proposed model can efficiently process high-speed multi-label stream data with concept drifts. Empirical studies on real-world tasks demonstrate that our method can maintain a high accuracy in multi-label stream classification, while providing a very efficient solution to the task.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {An Ensemble-based Approach to Fast Classification of Multi-label Data Streams. Conventional approaches focus on single-label scenarios, where each event can only be tagged with one label, but there can be multiple in many streams. Empirical studies on real-world tasks demonstrate that our method can maintain a high accuracy in multi-label stream classification, while providing a very efficient solution to the task.
Approved
1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.361.5745}
}

@Article{KoprowskiJr.2002,
  Title                    = {Data warehouse implementation with clinical pharmacokinetic/pharmacodynamic data},
  Author                   = {Koprowski Jr., S.P. and Barrett, J.S.},
  Journal                  = {International Journal of Clinical Pharmacology and Therapeutics},
  Year                     = {2002},
  Note                     = {cited By (since 1996)8},
  Number                   = {3},
  Pages                    = {S14-S29},
  Volume                   = {40},

  Abstract                 = {Objectives: We have created a data warehouse for human pharmacokinetic (PK) and pharmacodynamic (PD) data generated primarily within the Clinical PK Group of the Drug Metabolism and Pharmacokinetics (DM&PK) Department of DuPont Pharmaceuticals. Methods: Data which enters an Oracle-based LIMS directly from chromatography systems or through files from contract research organizations are accessed via SAS/PH. Kinetics, GLP-compliant data analysis software residing on individual users' workstations. Upon completion of the final PK or PD analysis, data are pushed to a predefined location. Data analyzed/created with other software (i.e., WinNonlin, NONMEM, Adapt, etc.) are added to this file repository as well. The warehouse creates views to these data and accumulates metadata on all data sources defined in the warehouse. The warehouse is managed via the SAS/Warehouse Administrator product that defines the environment, creates summarized data structures, and schedules data refresh. Results: The clinical PK/PD warehouse encompasses laboratory, biometric, PK and PD data streams. Detailed logical tables for each compound are created/updated as the clinical PK/PD data warehouse is populated. The data model defined to the warehouse is based on a star schema. Summarized data structures such as multidimensional data bases (MDDB), infomarts, and datamarts are created from detail tables. Data mining and querying of highly summarized data as well as drill-down to detail data is possible via the creation of exploitation tools which front-end the warehouse data. Based on periodic refreshing of the warehouse data, these applications are able to access the most current data available and do not require a manual interface to update/populate the data store. Prototype applications have been web-enabled to facilitate their usage to varied data customers across platform and location. The warehouse also contains automated mechanisms for the construction of study data listings and SAS transport files for eventual incorporation into an electronic submission. Conclusions: This environment permits the management of online analytical processing via a single administrator once the data model and warehouse configuration have been designed. The expansion of the current environment will eventually connect data from all phases of research and development ensuring the return on investment and hopefully efficiencies in data processing unforeseen with earlier legacy systems.},
  Affiliation              = {Aventis Pharmaceut. Drug Metabolism, Pharmacokineticals Department, Route 202-206, Bridgewater, NJ 08807-0800, United States},
  Author_keywords          = {Data warehouse; Pharmacodynamics; Pharmacokinetics},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being about data warehousing},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0036195774&partnerID=40&md5=3ca08ac8827591171c01c5190eecc329}
}

@Conference{Korn2006,
  Title                    = {Modeling skew in data streams},
  Author                   = {Korn, F.a and Muthukrishnan, S.b and Wu, Y.b },
  Year                     = {2006},
  Note                     = {cited By (since 1996)6},
  Pages                    = {181-192},

  Abstract                 = {Data stream applications have made use of statistical summaries to reason about the data using nonparametric tools such as histograms, heavy hitters, and join sizes. However, relatively little attention has been paid to modeling stream data parametrically, despite the potential this approach has for mining the data. The challenges to do model fitting at streaming speeds are both technical - how to continually find fast and reliable parameter estimates on high speed streams of skewed data using small space - and conceptual - how to validate the goodness-of-fit and stability of the model online.In this paper, we show how to fit hierarchical (binomial multifractal) and non-hierarchical (Pareto) power-law models on a data stream. We address the technical challenges using an approach that maintains a sketch of the data stream and fits least-squares straight lines; it yields algorithms that are fast, space-efficient, and provide approximations of parameter value estimates with a priori quality guarantees relative to those obtained offline. We address the conceptual challenge by designing fast methods for online goodness-of-fit measurements on a data stream; we adapt the statistical testing technique of examining the quantile-quantile (q-q) plot, to perform online model validation at streaming speeds.As a concrete application of our techniques, we focus on network traffic data which has been shown to exhibit skewed distributions. We complement our analytic and algorithmic results with experiments on IP traffic streams in AT&T's Gigascope data stream management system, to demonstrate practicality of our methods at line speeds. We measured the stability and robustness of these models over weeks of operational packet data in an IP network. In addition, we study an intrusion detection application, and demonstrate the potential of online parametric modeling. Copyright 2006 ACM.},
  Affiliation              = {AT and T Labs-Research, United States; Rutgers University, United States},
  Author_keywords          = {Estimation; Modeling; Skew; Streaming algorithms},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Modelling skew in streams. Little work done on modelling streams parametrically. Show how to fit hierarchical (binomial multifractal) and non-hierarchical (Pareto) power-law models on a data stream. Sketches the data stream. Focus on network data as a concrete application. We complement our analytic and algorithmic results with experiments on IP traffic streams in AT&T's Gigascope data stream management system. They measured stability.
Approved
1,2,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34250648954&partnerID=40&md5=6692dd1b09ee5c6e495129a0e469de41}
}

@InProceedings{Korn2006a,
  Title                    = {{Modeling skew in data streams}},
  Author                   = {Korn, Flip and Muthukrishnan, S. and Wu, Yihua},
  Booktitle                = {Proceedings of the 2006 ACM SIGMOD international conference on Management of data - SIGMOD '06},
  Year                     = {2006},

  Address                  = {New York, New York, USA},
  Month                    = jun,
  Pages                    = {181},
  Publisher                = {ACM Press},

  Abstract                 = {Data stream applications have made use of statistical summaries to reason about the data using nonparametric tools such as histograms, heavy hitters, and join sizes. However, relatively little attention has been paid to modeling stream data parametrically, despite the potential this approach has for mining the data. The challenges to do model fitting at streaming speeds are both technical -- how to continually find fast and reliable parameter estimates on high speed streams of skewed data using small space -- and conceptual -- how to validate the goodness-of-fit and stability of the model online.In this paper, we show how to fit hierarchical (binomial multifractal) and non-hierarchical (Pareto) power-law models on a data stream. We address the technical challenges using an approach that maintains a sketch of the data stream and fits least-squares straight lines; it yields algorithms that are fast, space-efficient, and provide approximations of parameter value estimates with a priori quality guarantees relative to those obtained offline. We address the conceptual challenge by designing fast methods for online goodness-of-fit measurements on a data stream; we adapt the statistical testing technique of examining the quantile-quantile (q-q) plot, to perform online model validation at streaming speeds.As a concrete application of our techniques, we focus on network traffic data which has been shown to exhibit skewed distributions. We complement our analytic and algorithmic results with experiments on IP traffic streams in AT&T's Gigascope® data stream management system, to demonstrate practicality of our methods at line speeds. We measured the stability and robustness of these models over weeks of operational packet data in an IP network. In addition, we study an intrusion detection application, and demonstrate the potential of online parametric modeling.},
  Doi                      = {10.1145/1142473.1142495},
  ISBN                     = {1595934340},
  Keywords                 = {estimation,modeling,skew,streaming algorithms},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Korn2006.
Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1142473.1142495}
}

@InProceedings{Kosina2012a,
  Title                    = {{Very Fast Decision Rules for multi-class problems}},
  Author                   = {Kosina, Petr and Gama, Jo\~{a}o},
  Booktitle                = {Proceedings of the 27th Annual ACM Symposium on Applied Computing - SAC '12},
  Year                     = {2012},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {795},
  Publisher                = {ACM Press},

  Abstract                 = {Decision rules are one of the most interpretable and flexible models for data mining prediction tasks. Till now, few works presented online, any-time and one-pass algorithms for learning decision rules in the stream mining scenario. A quite recent algorithm, the Very Fast Decision Rules (VFDR), learns set of rules, where each rule discriminates one class from all the other. In this work we extend the VFDR algorithm by decomposing a multi-class problem into a set of two-class problems and inducing a set of discriminative rules for each binary problem. The proposed algorithm maintains all properties required when learning from stationary data streams: online and any-time classifiers, processing each example once. Moreover, it is able to learn ordered and unordered rule sets. The new approach is evaluated on various real and artificial datasets. The new algorithm improves the performance of the previous version and is competitive with the state-of-the-art decision tree learning method for data streams.},
  Doi                      = {10.1145/2245276.2245431},
  ISBN                     = {9781450308571},
  Keywords                 = {classification,data streams,rule learning},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kosina2012.
Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2245276.2245431}
}

@Conference{Kosina2012,
  Title                    = {Very fast decision rules for multi-class problems},
  Author                   = {Kosina, P.a b and Gama, J.a c },
  Year                     = {2012},
  Note                     = {cited By (since 1996)3},
  Pages                    = {795-800},

  Abstract                 = {Decision rules are one of the most interpretable and flexible models for data mining prediction tasks. Till now, few works presented online, any-time and one-pass algorithms for learning decision rules in the stream mining scenario. A quite recent algorithm, the Very Fast Decision Rules (VFDR), learns set of rules, where each rule discriminates one class from all the other. In this work we extend the VFDR algorithm by decomposing a multi-class problem into a set of two-class problems and inducing a set of discriminative rules for each binary problem. The proposed algorithm maintains all properties required when learning from stationary data streams: online and any-time classifiers, processing each example once. Moreover, it is able to learn ordered and unordered rule sets. The new approach is evaluated on various real and artificial datasets. The new algorithm improves the performance of the previous version and is competitive with the state-of-the-art decision tree learning method for data streams. Ã‚Â© 2012 ACM.},
  Affiliation              = {LIAAD - INESC Porto L.A., Portugal; Fac. of Informatics, Masaryk University, Brno, Portugal; Fac. of Economics, University of Porto, Portugal},
  Author_keywords          = {classification; data streams; rule learning},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM Symposium on Applied Computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A quite recent algorithm, the Very Fast Decision Rules (VFDR), learns set of rules, where each rule discriminates one class from all the other. They extend it by decomposing a multi-class problem into a set of two-class problems and inducing a set of discriminative rules for each binary problem. It is experimentally verified and improves previous version and is competetive with state of the art decision tree learning for streams.
Approved
1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84863600337&partnerID=40&md5=f1b9a24ea52094d6ca5fc6102b4d15ff}
}

@Misc{Kotov,
  Title                    = {{Mining Named Entities with Temporally Correlated Bursts from Multilingual Web News Streams}},

  Author                   = {Kotov, Alexander and Zhai, Chengxiang and Sproat, Richard},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Entity resolution with temprally correlated bursts from news streams, in multiple languages. While mining“bursty”terms in a single text stream has been studied before, the problem of detecting terms with temporally correlated bursts in multilingual Web streams raises two new challenges. We propose a two-stage method for mining items with temporally correlated bursts from multiple data streams. Markov-Modulated Poisson Process. In second stage, dynamic progarmming to find correlations. Experimental results indicate that our method can not only effectively discover named entities with correlated bursts in multilingual Web news streams, but also outperforms two state-of-the-art baseline methods for unsupervised discovery of transliterations in static text collections.
Approved
1,2,3,4,5,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.297.2196}
}

@Article{Kranen2012,
  Title                    = {Stream data mining using the MOA framework},
  Author                   = {Kranen, P.a and Kremer, H.a and Jansen, T.a and Seidl, T.a and Bifet, A.b and Holmes, G.b and Pfahringer, B.b and Read, J.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2012},
  Note                     = {cited By (since 1996)4},
  Number                   = {PART 2},
  Pages                    = {309-313},
  Volume                   = {7239 LNCS},

  Abstract                 = {Massive Online Analysis (MOA) is a software framework that provides algorithms and evaluation methods for mining tasks on evolving data streams. In addition to supervised and unsupervised learning, MOA has recently been extended to support multi-label classification and graph mining. In this demonstrator we describe the main features of MOA and present the newly added methods for outlier detection on streaming data. Algorithms can be compared to established baseline methods such as LOF and ABOD using standard ranking measures including Spearman rank coefficient and the AUC measure. MOA is an open source project and videos as well as tutorials are publicly available on the MOA homepage. Ã‚Â© 2012 Springer-Verlag.},
  Affiliation              = {Data Management and Exploration Group, RWTH Aachen University, Germany; Department of Computer Science, University of Waikato, Hamilton, New Zealand},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Description of MOA framework only, no contribution.
Disacrded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84860668502&partnerID=40&md5=5d583f2830a91e63f2f7a29c1bf6d083}
}

@Article{Kranen2011,
  Title                    = {{Hierarchical clustering for real-time stream data with noise}},
  Author                   = {Kranen, Philipp and Reidl, Felix and Villaamil, Fernando Sanchez and Seidl, Thomas},
  Year                     = {2011},

  Month                    = jul,
  Pages                    = {405--413},

  Abstract                 = {In stream data mining, stream clustering algorithms provide summaries of the relevant data objects that arrived in the stream. The model size of the clustering, i.e. the granularity, is usually determined by the speed (data per time) of the data stream. For varying streams, e.g. daytime or seasonal changes in the amount of data, most algorithms have to heavily restrict their model size such that they can handle the minimal time allowance. Recently the first anytime stream clustering algorithm has been proposed that flexibly uses all available time and dynamically adapts its model size. However, the method exhibits several drawbacks, as no noise detection is performed, since every point is treated equally, and new concepts can only emerge within existing ones. In this paper we propose the LiarTree algorithm, which is capable of anytime clustering and at the same time robust against noise and novelty to deal with arbitrary data streams.},
  ISBN                     = {978-3-642-22350-1},
  Owner                    = {alex},
  Publisher                = {Springer-Verlag},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {For varying streams, e.g. daytime or seasonal changes in the amount of data, most algorithms have to heavily restrict their model size such that they can handle the minimal time allowance. However, the method exhibits several drawbacks. In this paper we propose the LiarTree algorithm, which is capable of anytime clustering and at the same time robust against noise and novelty to deal with arbitrary data streams.
Approved
1,2,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2032397.2032429}
}

@InProceedings{Kranjc2013,
  Title                    = {{Real-time data analysis in ClowdFlows}},
  Author                   = {Kranjc, Janez and Podpecan, Vid and Lavrac, Nada},
  Booktitle                = {2013 IEEE International Conference on Big Data},
  Year                     = {2013},
  Month                    = oct,
  Pages                    = {15--22},
  Publisher                = {IEEE},

  Abstract                 = {ClowdFlows is an open cloud based platform for composition, execution, and sharing of interactive data mining workflows. In this paper we extend the ClowdFlows platform with the ability to mine real-time data streams. This functionality was implemented by creating a specialized type of workflow component and a stream mining daemon that delegates the execution of workflows in real-time. In this way, we have transformed a batch data processing platform into a real-time stream mining platform with an intuitive user interface. The real-time analytics aspect of the platform is demonstrated in a Twitter sentiment analysis use case where the sentiment of tweets about whistleblower Edward Snowden was monitored for approximately one month.},
  Doi                      = {10.1109/BigData.2013.6691682},
  ISBN                     = {978-1-4799-1293-3},
  Keywords                 = {ClowdFlows platform,Data mining,Edward Snowden,Engines,Graphical user interfaces,Real-time systems,Servers,Twitter,Twitter sentiment analysis,Visualization,batch data processing platform,batch processing (computers),cloud computing,data mining,data mining platform,interactive data mining workflows,intuitive user interface,open cloud based platform,public domain software,real-time analytics,real-time data analysis,real-time data streams,real-time stream mining platform,sentiment analysis,stream mining,stream mining daemon,user interfaces,web application,whistleblower,workflow component,workflows},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {ClowdFlows is an open cloud based platform for composition, execution, and sharing of interactive data mining workflows. In this paper we extend the ClowdFlows platform with the ability to mine real-time data streams.The real-time analytics aspect of the platform is demonstrated in a Twitter sentiment analysis use case.
Approved
1,6},
  Shorttitle               = {Big Data, 2013 IEEE International Conference on},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6691682}
}

@Article{Kranjc2014,
  Title                    = {Active learning for sentiment analysis on data streams: Methodology and workflow implementation in the ClowdFlows platform },
  Author                   = {Janez Kranjc and Jasmina SmailoviÃ„â€¡ and Vid PodpeÃ„ï¿½an and Miha GrÃ„ï¿½ar and Martin Ã…Â½nidarÃ…Â¡iÃ„ï¿½ and Nada LavraÃ„ï¿½},
  Journal                  = {Information Processing \& Management },
  Year                     = {2014},
  Number                   = {0},
  Pages                    = { - },

  Abstract                 = {Abstract Sentiment analysis from data streams is aimed at detecting authorsÃ¢â‚¬â„¢ attitude, emotions and opinions from texts in real-time. To reduce the labeling effort needed in the data collection phase, active learning is often applied in streaming scenarios, where a learning algorithm is allowed to select new examples to be manually labeled in order to improve the learnerÃ¢â‚¬â„¢s performance. Even though there are many on-line platforms which perform sentiment analysis, there is no publicly available interactive on-line platform for dynamic adaptive sentiment analysis, which would be able to handle changes in data streams and adapt its behavior over time. This paper describes ClowdFlows, a cloud-based scientific workflow platform, and its extensions enabling the analysis of data streams and active learning. Moreover, by utilizing the data and workflow sharing in ClowdFlows, the labeling of examples can be distributed through crowdsourcing. The advanced features of ClowdFlows are demonstrated on a sentiment analysis use case, using active learning with a linear Support Vector Machine for learning sentiment classification models to be applied to microblogging data streams.},
  Doi                      = {http://dx.doi.org/10.1016/j.ipm.2014.04.001},
  ISSN                     = {0306-4573},
  Keywords                 = {Active learning},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kranjc2014a.
Discarded.},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306457314000296}
}

@Conference{Kranjc2013a,
  Title                    = {Real-time data analysis in ClowdFlows},
  Author                   = {Kranjc, J.a b and Podpecan, V.a and Lavrac, N.a c },
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Pages                    = {15-22},

  Abstract                 = {ClowdFlows is an open cloud based platform for composition, execution, and sharing of interactive data mining workflows. In this paper we extend the ClowdFlows platform with the ability to mine real-time data streams. This functionality was implemented by creating a specialized type of workflow component and a stream mining daemon that delegates the execution of workflows in real-time. In this way, we have transformed a batch data processing platform into a real-time stream mining platform with an intuitive user interface. The real-time analytics aspect of the platform is demonstrated in a Twitter sentiment analysis use case where the sentiment of tweets about whistleblower Edward Snowden was monitored for approximately one month. Ã‚Â© 2013 IEEE.},
  Affiliation              = {JoÃ…Â¾ef Stefan Institute, Jamova 39, 1000 Ljubljana, Slovenia; International Postgraduate School JoÃ…Â¾ef Stefan, Jamova 39, 1000 Ljubljana, Slovenia; University of Nova Gorica, Vipavska 13, 5000 Nova Gorica, Slovenia},
  Art_number               = {6691682},
  Author_keywords          = {data mining platform; real-time data analysis; sentiment analysis; stream mining; web application; workflows},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2013 IEEE International Conference on Big Data, Big Data 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kranjc2013.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893318623&partnerID=40&md5=75b34952ec6db20f424aa218f7bba28e}
}

@Article{Kranjc2014a,
  Title                    = {Active learning for sentiment analysis on data streams: Methodology and workflow implementation in the ClowdFlows platform},
  Author                   = {Kranjc, J.a b and SmailoviÃ„â€¡, J.a b and PodpeÃ„ï¿½an, V.a c and GrÃ„ï¿½ar, M.a and Ã…Â½nidarÃ…Â¡iÃ„ï¿½, M.a and LavraÃ„ï¿½, N.a b d },
  Journal                  = {Information Processing and Management},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0; Article in Press},

  Abstract                 = {Sentiment analysis from data streams is aimed at detecting authors' attitude, emotions and opinions from texts in real-time. To reduce the labeling effort needed in the data collection phase, active learning is often applied in streaming scenarios, where a learning algorithm is allowed to select new examples to be manually labeled in order to improve the learner's performance. Even though there are many on-line platforms which perform sentiment analysis, there is no publicly available interactive on-line platform for dynamic adaptive sentiment analysis, which would be able to handle changes in data streams and adapt its behavior over time. This paper describes ClowdFlows, a cloud-based scientific workflow platform, and its extensions enabling the analysis of data streams and active learning. Moreover, by utilizing the data and workflow sharing in ClowdFlows, the labeling of examples can be distributed through crowdsourcing. The advanced features of ClowdFlows are demonstrated on a sentiment analysis use case, using active learning with a linear Support Vector Machine for learning sentiment classification models to be applied to microblogging data streams. Ã‚Â© 2014.},
  Affiliation              = {JoÃ…Â¾ef Stefan Institute, Jamova cesta 39, 1000 Ljubljana, Slovenia; JoÃ…Â¾ef Stefan International Postgraduate School, Jamova cesta 39, 1000 Ljubljana, Slovenia; University of Ljubljana, Faculty of Mathematics and Physics, Jadranska 19, 1000 Ljubljana, Slovenia; University of Nova Gorica, Vipavska 13, 5000 Nova Gorica, Slovenia},
  Author_keywords          = {Active learning; Data mining platform; Sentiment analysis; Stream mining; Stream-based active learning; Workflows},
  Document_type            = {Article in Press},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {ClowdFlows are demonstrated on a sentiment analysis use case, using active learning with a linear Support Vector Machine for learning sentiment classification models to be applied to microblogging data streams. No contribution otherwise.
Approved
6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84899157812&partnerID=40&md5=244075b2105a27eb8dec5a079e210482}
}

@Article{Krempl2014,
  Title                    = {{Open challenges for data stream mining research}},
  Author                   = {Krempl, Georg and Spiliopoulou, Myra and Stefanowski, Jerzy and \v{Z}liobaite, Indre and Brzeziński, Dariusz and H\"{u}llermeier, Eyke and Last, Mark and Lemaire, Vincent and Noack, Tino and Shaker, Ammar and Sievi, Sonja},
  Journal                  = {ACM SIGKDD Explorations Newsletter},
  Year                     = {2014},

  Month                    = sep,
  Number                   = {1},
  Pages                    = {1--10},
  Volume                   = {16},

  Abstract                 = {Every day, huge volumes of sensory, transactional, and web data are continuously generated as streams, which need to be analyzed online as they arrive. Streaming data can be considered as one of the main sources of what is called big data. While predictive modeling for data streams and big data have received a lot of attention over the last decade, many research approaches are typically designed for well-behaved controlled problem settings, overlooking important challenges imposed by real-world applications. This article presents a discussion on eight open challenges for data stream mining. Our goal is to identify gaps between current research and meaningful applications, highlight open problems, and define new application-relevant research directions for data stream mining. The identified challenges cover the full cycle of knowledge discovery and involve such problems as: protecting data privacy, dealing with legacy systems, handling incomplete and delayed information, analysis of complex data, and evaluation of stream mining algorithms. The resulting analysis is illustrated by practical applications and provides general suggestions concerning lines of future research in data stream mining.},
  Doi                      = {10.1145/2674026.2674028},
  ISSN                     = {19310145},
  Owner                    = {alex},
  Priority                 = {prio3},
  Publisher                = {ACM},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {This article presents a discussion on eight open challenges for data stream mining. Our goal is to identify gaps between current research and meaningful applications. VERY SIMILAR in scope to our paper. DEFINITELY worth discussing.
Discarded. Set Aside.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2674026.2674028}
}

@Conference{Kriminger2012a,
  Title                    = {Nearest Neighbor Distributions for imbalanced classification},
  Author                   = {Kriminger, E.a and PrÃƒÂ­ncipe, J.C.a and Lakshminarayan, C.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The class imbalance problem is pervasive in machine learning. To accurately classify the minority class, current methods rely on sampling schemes to close the gap between classes, or on the application of error costs to create algorithms which favor the minority class. Since the sampling schemes and costs must be specified, these methods are highly dependent on the class distributions present in the training set. This makes them difficult to apply in settings where the level of imbalance changes, such as in online streaming data. Often they cannot handle multi-class problems. We present a novel single-class algorithm called Class Conditional Nearest Neighbor Distribution (CCNND), which mitigates the effects of class imbalance through local geometric structure in the data. Our algorithm can be applied seamlessly to problems with any level of imbalance or number of classes, and new examples are simply added to the training set. We show that it performs as well as or better than top sampling and cost- weighting methods on four imbalanced datasets from the UCI Machine Learning Repository, and then apply it to streaming data from the oil and gas industry alongside a modified nearest neighbor algorithm. Our algorithm's competitive performance relative to the state-of-the-art, coupled with its extremely simple implementation and automatic adjustment for minority classes, demonstrates that it is worth further study. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Deparment of Electrical and Computer Engineering, University of Florida, Gainesville, FL 32611-6200, United States; HP Labs, Palo Alto, CA, United States},
  Art_number               = {6252718},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the International Joint Conference on Neural Networks},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kriminger2012.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84865100421&partnerID=40&md5=48d2946725817861c1ea86435526c4de}
}

@InProceedings{Kriminger2012,
  Title                    = {{Nearest Neighbor Distributions for imbalanced classification}},
  Author                   = {Kriminger, Evan and Principe, Jose C. and Lakshminarayan, Choudur},
  Booktitle                = {The 2012 International Joint Conference on Neural Networks (IJCNN)},
  Year                     = {2012},
  Month                    = jun,
  Pages                    = {1--5},
  Publisher                = {IEEE},

  Abstract                 = {The class imbalance problem is pervasive in machine learning. To accurately classify the minority class, current methods rely on sampling schemes to close the gap between classes, or on the application of error costs to create algorithms which favor the minority class. Since the sampling schemes and costs must be specified, these methods are highly dependent on the class distributions present in the training set. This makes them difficult to apply in settings where the level of imbalance changes, such as in online streaming data. Often they cannot handle multi-class problems. We present a novel single-class algorithm called Class Conditional Nearest Neighbor Distribution (CCNND), which mitigates the effects of class imbalance through local geometric structure in the data. Our algorithm can be applied seamlessly to problems with any level of imbalance or number of classes, and new examples are simply added to the training set. We show that it performs as well as or better than top sampling and cost-weighting methods on four imbalanced datasets from the UCI Machine Learning Repository, and then apply it to streaming data from the oil and gas industry alongside a modified nearest neighbor algorithm. Our algorithm's competitive performance relative to the state-of-the-art, coupled with its extremely simple implementation and automatic adjustment for minority classes, demonstrates that it is worth further study.},
  Doi                      = {10.1109/IJCNN.2012.6252718},
  ISBN                     = {978-1-4673-1490-9},
  ISSN                     = {2161-4393},
  Keywords                 = {Error analysis,Machine learning,Oscillators,Sensitivity,Support vector machines,Training,UCI machine learning repository,class conditional nearest neighbor distribution,class imbalance problem,gas industry,imbalanced classification,learning (artificial intelligence),oil industry,online streaming data,pattern classification,sampling methods,sampling schemes,single-class algorithm,statistical distributions},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Nearest Neighbor Distributions for imbalanced classification. Since the sampling schemes and costs must be specified, these methods are highly dependent on the class distributions present in the training set. Often they cannot handle multi-class problems. Present novel single-class algorithm called Class Conditional Nearest Neighbor Distribution (CCNND), which mitigates the effects of class imbalance through local geometric structure in the data. We show that it performs as well as or better than top sampling and cost-weighting methods on four imbalanced datasets from the UCI Machine Learning Repository, and then apply it to streaming data from the oil and gas industry. It is competetive compared to state of the art.
Approved
1,2,3,4,5,6},
  Shorttitle               = {Neural Networks (IJCNN), The 2012 International Jo},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6252718}
}

@Article{Krishna2010,
  Title                    = {Identification and prediction of air core diameter in a hydrocyclone by a novel online sensor based on digital signal processing technique },
  Author                   = {Venkat Krishna and R. Sripriya and V. Kumar and S. Chakraborty and B.C. Meikap},
  Journal                  = {Chemical Engineering and Processing: Process Intensification },
  Year                     = {2010},
  Number                   = {2},
  Pages                    = {165 - 176},
  Volume                   = {49},

  Abstract                 = {A hydrocyclone is a particle separation device widely used in chemical and allied process industries in which a particle-fluid mixture is injected tangentially creating a strong swirling, recirculation flow. The particle separation efficiency increases by suppressing the air core, so online prediction of air core formation has significant importance in the industrial operations. Performance of hydrocyclone is greatly influenced by shape and size of air core. A novel type of senor technique has been developed to identify and predict the air core diameter from online live data using data acquisition card. The true signal amplitudes change as a function of the time was used with noise interruption for random changes in amplitude. Noises are eliminated by using moving average technique. The slope of the curve is continuously tracked to determine sudden or abrupt change and indicates the formation of air core. It has been observed that a strong air core of diameter 0.95&#xa0;cm to 1.2&#xa0;cm was formed during experimentation and matched with predicted values over an entire flow regime. The experimental and finally an alarm is designed which gives alerts once air core is formed and calculates air core diameter. For calculating air core diameter a polynomial equation is fitted between pressure difference and the pressure transmitter reading. A simple moving average with a smooth width of 10 was used for prediction of air core. Experimental results indicate that the digital signal sensor techniques identify the air core and measure air core diameter very accurately and can be used in many mining and mineral based chemical and allied process industries.},
  Doi                      = {http://dx.doi.org/10.1016/j.cep.2010.01.003},
  ISSN                     = {0255-2701},
  Keywords                 = {Hydrocyclone},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Identification and prediction of air core diameter in a hydrocyclone by a novel online sensor based on digital signal processing technique. Experimental results indicate that the digital signal sensor techniques identify the air core and measure air core diameter very accurately and can be used in many mining and mineral based chemical and allied process industries. VERY simple ML, but still ML.
Approved
1,3,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0255270110000048}
}

@InProceedings{Krishnaswamy2012,
  Title                    = {{Mobile Data Stream Mining: From Algorithms to Applications}},
  Author                   = {Krishnaswamy, Shonali and Gama, Joao and Gaber, Mohamed Medhat},
  Booktitle                = {2012 IEEE 13th International Conference on Mobile Data Management},
  Year                     = {2012},
  Month                    = jul,
  Pages                    = {360--363},
  Publisher                = {IEEE},

  Abstract                 = {This paper presents an overview of the current state-of-the-art in mobile data stream mining. This area of mobile data stream mining is significant for a number of new application domains such as mobile crowd sensing and mobile activity recognition. The paper presents the strategies and techniques for adaptation that are essential in order to perform real-time, continuous data mining on mobile devices. We present an overview of the algorithms research in this area. Finally, we discuss the key toolkits, systems and applications of mobile data stream mining.},
  Doi                      = {10.1109/MDM.2012.37},
  ISBN                     = {978-1-4673-1796-2},
  Keywords                 = {Accuracy,Algorithm design and analysis,Data Stream Mining,Data mining,Data visualization,Distributed databases,Mobile Data Mining,Mobile communication,Mobile handsets,Ubiquitous Data Mining,continuous data mining,data mining,mobile activity recognition,mobile computing,mobile crowd sensing,mobile data stream mining,mobile devices,mobile handsets},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Review                   = {This paper presents an overview of the current state-of-the-art in mobile data stream mining. Overview only.
Discarded. Kind of interesting for discussion.},
  Shorttitle               = {Mobile Data Management (MDM), 2012 IEEE 13th Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6341420}
}

@Conference{Krishnaswamy2012a,
  Title                    = {Mobile data stream mining: From algorithms to applications},
  Author                   = {Krishnaswamy, S.a b and Gama, J.c and Gaber, M.M.d },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {360-363},

  Abstract                 = {This paper presents an overview of the current state-of-the-art in mobile data stream mining. This area of mobile data stream mining is significant for a number of new application domains such as mobile crowd sensing and mobile activity recognition. The paper presents the strategies and techniques for adaptation that are essential in order to perform real-time, continuous data mining on mobile devices. We present an overview of the algorithms research in this area. Finally, we discuss the key toolkits, systems and applications of mobile data stream mining. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Institute for Infocomm Research (I2R), Singapore, Singapore; Faculty of IT, Monash University, Australia; Laboratory of Artificial Intelligence and Decision Support, University of Porto, Portugal; School of Computing, University of Portsmouth, United Kingdom},
  Art_number               = {6341420},
  Author_keywords          = {Data Stream Mining; Mobile Data Mining; Ubiquitous Data Mining},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2012 IEEE 13th International Conference on Mobile Data Management, MDM 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Krishnaswamy2012.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870767948&partnerID=40&md5=8172ca7bddd610925eef0f6ba824cda1}
}

@InProceedings{Kumar2013b,
  Title                    = {{Online identification of frequently executed acyclic paths by leveraging data stream algorithms}},
  Author                   = {Kumar, Gaurav and Roy, Subhajit},
  Booktitle                = {Proceedings of the 28th Annual ACM Symposium on Applied Computing - SAC '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {1694},
  Publisher                = {ACM Press},

  Abstract                 = {Most of the traditional path profilers simply generate a path-frequency table that records the raw frequencies of each path. The compiler is supposed to carry out the herculean task of mining this table for frequently executed paths to drive aggressive profile-guided optimizations. This begs a question: why cannot profilers themselves identify these frequent paths --- produce information that can be consumed directly by the optimizers?
The essential theme of this paper is that the sequence of acyclic paths emitted by a classic Ball-Larus profiler can be viewed as a data-stream: this enables an online extraction of any required statistics (like the frequently executed paths) on the profile information without requiring storage and update of the huge path-frequency tables generated by a long-running program. We adapt a classic data stream algorithm for finding majority elements in a stream (by Karp et al.) for our use, essentially by enabling optimizations that exploit the properties of paths generated off a Ball-Larus profiler. We instantiate our ideas by building an efficient path profiler that identifies all acyclic paths frequented above a user-provided threshold percentage of all executed paths.},
  Doi                      = {10.1145/2480362.2480680},
  ISBN                     = {9781450316569},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Kumar2013a.
Discarded.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2480362.2480680}
}

@Conference{Kumar2013a,
  Title                    = {Online identification of frequently executed acyclic paths by leveraging data stream algorithms},
  Author                   = {Kumar, G.a b and Roy, S.a },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1694-1695},

  Abstract                 = {Most of the traditional path profilers simply generate a path-frequency table that records the raw frequencies of each path. The compiler is supposed to carry out the herculean task of mining this table for frequently executed paths to drive aggressive profile-guided optimizations. This begs a question: why cannot profilers themselves identify these frequent paths - produce information that can be consumed directly by the optimizers? The essential theme of this paper is that the sequence of acyclic paths emitted by a classic Ball-Larus profiler can be viewed as a data-stream: this enables an online extraction of any required statistics (like the frequently executed paths) on the profile information without requiring storage and update of the huge path-frequency tables generated by a long-running program. We adapt a classic data stream algorithm for finding majority elements in a stream (by Karp et al.) for our use, essentially by enabling optimizations that exploit the properties of paths generated off a Ball-Larus profiler. We instantiate our ideas by building an efficient path profiler that identifies all acyclic paths frequented above a user-provided threshold percentage of all executed paths. Copyright 2013 ACM.},
  Affiliation              = {Computer Science and Engineering Department, Indian Institute of Technology, Kanpur, India; Symantec Corporation, India},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM Symposium on Applied Computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Online identification of frequently executed acyclic paths by leveraging data stream algorithms. The compiler is supposed to carry out the herculean task of mining this table for frequently executed paths to drive aggressive profile-guided optimizations - why should it have to? We adapt a classic data stream algorithm for finding majority elements in a stream, so the profiler can do this instead.
Approved
1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84877977017&partnerID=40&md5=7f65d1ea73008c3f85db3ee4e89dc18c}
}

@Misc{Kumar,
  Title                    = {{G. Vijay Kumar, M. Sreedevi \& NVS Pavan Kumar Mining Regular Patterns in Data Streams Using Vertical Format}},

  Author                   = {Kumar, G. Vijay and Sreedevi, M.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The increasing prominence of data streams has been lead to the study of online mining in order to capture interesting trends, patterns and exceptions. Recently, temporal regularity in occurrence behavior of a pattern was treated as an emerging area in several online applications like network traffic, sensor networks, e-business and stock market analysis etc. A pattern is said to be regular in a data stream, if its occurrence behavior is not more than the user given regularity threshold. Although there has been some efforts done in finding regular patterns over stream data, no such method has been developed yet by using vertical data format. Therefore, in this paper we develop a new method called VDSRP-method to generate the complete set of regular patterns over a data stream at a user given regularity threshold. Our experimental results show that highly efficiency in terms of execution and memory consumption.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining Regular Patterns in Data Streams Using Vertical Format. Although there has been some efforts done in finding regular patterns over stream data, no such method has been developed yet by using vertical data format, so we give a new method to do this. Our experimental results show that highly efficiency in terms of execution and memory consumption. Not sure what they mean by vertical data format, but okay.
Approved
1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.232.1125}
}

@InProceedings{Kumar2013,
  Title                    = {{Mining of data stream using Ã¢â‚¬Å“DDenStreamÃ¢â‚¬ï¿½ clustering algorithm}},
  Author                   = {Kumar, Manoj and Sharma, Ashish},
  Booktitle                = {2013 IEEE International Conference in MOOC, Innovation and Technology in Education (MITE)},
  Year                     = {2013},
  Month                    = dec,
  Pages                    = {315--320},
  Publisher                = {IEEE},

  Abstract                 = {Many real time applications, they are generated continues flow of data streams have became more popular now a days. Therefore many researches attracted clustering data streams. Most of data stream clustering algorithms based on distance function which find out clusters with spiracle of shape clusters and unable to deal noisy data. Therefore density based clustering algorithms substitute remarkable solution to find out clusters with arbitrary shapes of cluster and also handling noisy data. In which the clustering is performing with the bases of high density area of objects and also segregate low density objects as noise. In this paper we studied a simple existing data stream clustering algorithm DenStream based on DBScan. Based on DenStream a novel data stream clustering approach Ã¢â‚¬Å“DDenStreamÃ¢â‚¬ï¿½ is proposed. DDenStream is a modified data stream clustering algorithm of DenStream. It is based on fading window model therefore it applies a density decaying technique when the evolving data streams are captured and improved the quality of clusters by extracts the boundary points when two or more than microclusters are overlapping each other by using DCQ-Means algorithms. This approach also resolved the overlapping problem of microclusters. It find out arbitrary specs and good quality of clusters with noise.},
  Doi                      = {10.1109/MITE.2013.6756357},
  ISBN                     = {978-1-4799-1626-9},
  Keywords                 = {Clustering algorithms,DBScan,DCQ-Means algorithms,DDenStream clustering algorithm,Data Mining,Data Stream,Data mining,Denstream,Fading,Merging,Noise,Shape,Vectors,boundary points extraction,cluster quality,data mining,data stream clustering,data stream mining,density based clustering algorithms,density decaying technique,distance function,fading window model,microclusters,noisy data handling,pattern clustering,shape clusters},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {They studied an existing data stream clustering algorithm. No contribution.
Discarded.},
  Shorttitle               = {Innovation and Technology in Education (MITE), 201},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6756357}
}

@InProceedings{Lahiri2009,
  Title                    = {{Finding correlated heavy-hitters over data streams}},
  Author                   = {Lahiri, Bibudh and Tirthapura, Srikanta},
  Booktitle                = {2009 IEEE 28th International Performance Computing and Communications Conference},
  Year                     = {2009},
  Month                    = dec,
  Pages                    = {307--314},
  Publisher                = {IEEE},

  Abstract                 = {We consider online mining of correlated heavy-hitters (CHH) from network data streams. Given a multidimensional dataset, a correlated aggregate query first filters a subset by applying a predicate along a primary dimension, and then computes aggregates along a secondary dimension of that subset data. We consider queries of the following form: "In a stream of (x, y) tuples, on the subset H of all x values that are heavy-hitters, maintain those y values that occur frequently with the x values in H". This query arises naturally in situations where we need to track not only the identity of frequently occurring elements in a stream, but also additional information associated with these elements along other dimensions. Prior work on tracking heavy-hitters has focused only on tracking the identity and frequency of heavy-hitters on a single dimensional stream, and yield little information about correlated heavy-hitters. Our online data stream algorithm is easy to implement and uses workspace which is orders of magnitude smaller than the stream itself. We present provable guarantees on the maximum error estimates, as well as experimental results, that demonstrate the space-accuracy trade-off on a large data stream of packet headers from a backbone network link.},
  Doi                      = {10.1109/PCCC.2009.5403820},
  ISBN                     = {978-1-4244-5737-3},
  ISSN                     = {1097-2641},
  Keywords                 = {Aggregates,Data engineering,Data streams,Databases,Filters,Frequency,Multidimensional systems,Network servers,Spine,Telecommunication traffic,backbone network link,correlated aggregate query,correlated heavy-hitters,correlation,data mining,heavy-hitters,maximum error estimates,network data streams,online mining,packet headers,query processing,sketches,space-accuracy trade-off},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We consider online mining of correlated heavy-hitters (CHH) from network data streams. Prior work on tracking heavy-hitters has focused only on tracking the identity and frequency of heavy-hitters on a single dimensional stream, and yield little information about correlated heavy-hitters. We present provable guarantees on the maximum error estimates, as well as experimental results, that demonstrate the space-accuracy trade-off on a large data stream of packet headers from a backbone network link.
Approved
1,2,3,4},
  Shorttitle               = {Performance Computing and Communications Conferenc},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5403820}
}

@Conference{Lahiri2009a,
  Title                    = {Finding correlated heavy-hitters over data streams},
  Author                   = {Lahiri, B. and Tirthapura, S.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {307-314},

  Abstract                 = {We consider online mining of correlated heavy-hitters (CHH) from network data streams. Given a multidimensional dataset, a correlated aggregate query first filters a subset by applying a predicate along a primary dimension, and then computes aggregates along a secondary dimension of that subset data. We consider queries of the following form: "In a stream of (x, y) tuples, on the subset H of all x values that are heavy-hitters, maintain those y values that occur frequently with the x values in H". This query arises naturally in situations where we need to track not only the identity of frequently occurring elements in a stream, but also additional information associated with these elements along other dimensions. Prior work on tracking heavy-hitters has focused only on tracking the identity and frequency of heavy-hitters on a single dimensional stream, and yield little information about correlated heavy-hitters. Our online data stream algorithm is easy to implement and uses workspace which is orders of magnitude smaller than the stream itself. We present provable guarantees on the maximum error estimates, as well as experimental results, that demonstrate the space-accuracy trade-off on a large data stream of packet headers from a backbone network link. Ã‚Â© 2009 IEEE.},
  Affiliation              = {Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, United States},
  Art_number               = {5403820},
  Author_keywords          = {Correlation; Data streams; Heavy-hitters; Sketches},
  Document_type            = {Conference Paper},
  Journal                  = {2009 IEEE 28th International Performance Computing and Communications Conference, IPCCC 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Lahiri2009a.
Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77951177325&partnerID=40&md5=146ab2b4a1089e079235786363b27755}
}

@Article{Laleh2010,
  Title                    = {A hybrid fraud scoring and spike detection technique in streaming data},
  Author                   = {Laleh, N. and Abdollahi Azgomi, M.},
  Journal                  = {Intelligent Data Analysis},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Number                   = {6},
  Pages                    = {773-800},
  Volume                   = {14},

  Abstract                 = {The aim has been to propose a fraud detection system with capabilities of minimizing false alarms. In this paper we introduce a technique, which uses a hybrid fraud scoring and spike detection technique in streaming data over time and space. The technique itself differentiates normal, fraud and anomalous links, and increases the suspicion of fraud links with a dynamic global black list. Also, it mitigates the suspicion of normal links with a dynamic global white list. In addition, this technique uses spike detection technique to highlight the sudden and sharp rises in data, which can be indicative of abuse. The purpose is to derive two accurate suspicion scores for all incoming new examples in real-time. Results on mining several thousand credit application data demonstrate that the proposed technique reduces false alarm rates while maintaining a reasonable hit rate. In addition, new insights have been observed from the relationships between examples. The proposed technique takes the advantages of anomaly detection and supervised techniques. However by employing the spike detection technique, the false alarm rate is decreased. By this novel integration of techniques, the proposed technique is able to foil fraudsters' attempts, which continuously morph their styles to avoid to be detected. The results of the experiments to demonstrate the benefits of the technique are also presented in this paper. Ã‚Â© 2010 - IOS Press and the authors. All rights reserved.},
  Affiliation              = {School of Computer Engineering, Iran University of Science and Technology, Hengam St., 1684613114 Tehran, Iran},
  Author_keywords          = {anomaly detection; Fraud detection; spike detection; streaming data},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The aim has been to propose a fraud detection system with capabilities of minimizing false alarms. In this paper we introduce a technique, which uses a hybrid fraud scoring and spike detection technique in streaming data over time and space.The results of the experiments to demonstrate the benefits of the technique are also presented in this paper. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650371537&partnerID=40&md5=9f909394e9120fa024a00af31854382b}
}

@Article{Lambert2001,
  Title                    = {{Mining a stream of transactions for customer patterns}},
  Author                   = {Lambert, Diane and Pinheiro, Jos C.},
  Journal                  = {IN PROCEEDINGS OF THE 7TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD 2001},
  Year                     = {2001},
  Pages                    = {26 -- 29},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Transaction data can arrive at a ferocious rate in the or-der that transactions are completed. The data contain an enormous amount of information about customers, not just transactions, but extracting up-to-date customer informa-tion from an ever changing stream of data and mining it in real-time is a challenge. This paper describes a statistically principled approach to designing short, accurate summaries or signatures of high dimensional customer behavior that can be kept current with a stream of transactions. A signature database can then be used for data mining and to provide approximate answers to many kinds of queries about current customers quickly and accurately, as an empirical study of the calling patterns of 96,000 wireless customers who maxie about 18 million wireless calls over a three month period shows.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Mining a stream of transactions for customer patterns. This paper describes a statistically principled approach to designing short, accurate summaries or signatures of high dimensional customer behavior. Tested on wireless customers and proved to provide apprximate nswers quickly and accurately to customer queries. Approved 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.137.3271}
}

@Book{Last2007,
  Title                    = {Data mining},
  Author                   = {Last, M.},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Data mining is a growing collection of computational techniques for automatic analysis of structured, semi-structured, and unstructured data with the purpose of identifying important trends and previously unknown behavioral patterns. Data mining is widely recognized as the most important and central technology for homeland security in general and for cyber warfare in particular. This chapter covers the following relevant areas of data mining: Ã¢â‚¬Â¢ Web mining is the application of data mining techniques to web-based data. While Web usage mining is already used by many intrusion detection systems, Web content mining can lead to automated identification of terrorist-related content on the Web. Ã¢â‚¬Â¢ Web information agents are responsible for filtering and organizing unrelated and scattered data in large amounts of web documents. Agents represent a key technology to cyber warfare due to their capability to monitor multiple diverse locations, communicate their findings asynchronously, collaborate with each other, and profile possible threats. Ã¢â‚¬Â¢ Anomaly detection and activity monitoring. Real-time monitoring of continuous data streams can lead to timely identification of abnormal, potentially criminal activities. Anomalous behavior can be automatically detected by a variety of data mining methods. Ã‚Â© 2008, IGI Global.},
  Affiliation              = {Ben-Gurion University of the Negev, Israel},
  Document_type            = {Book Chapter},
  Journal                  = {Cyber Warfare and Cyber Terrorism},
  Owner                    = {Alexander},
  Pages                    = {358-365},
  Qualityassured           = {qualityAssured},
  Review                   = {Book chapter on data mining},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84898267357&partnerID=40&md5=e96f5f93f7ce71c4b5c5b1c03fc4d997}
}

@Misc{Last,
  Title                    = {{Enhanced Anytime Algorithm for Induction of Oblivious Decision Trees}},

  Author                   = {Last, Mark and Saveliev, Albina},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Real-time data mining of high-speed and non-stationary data streams has a large potential in such fields as efficient operation of machinery and vehicles, wireless sensor networks, urban traffic control, stock data analysis etc.. These domains are characterized by a great volume of noisy, uncertain data, and restricted amount of resources (mainly computational time). Anytime algorithms offer a tradeoff between solution quality and computation time, which has proved useful in applying artificial intelligence techniques to timecritical problems. In this paper we are presenting a new, enhanced version of an anytime algorithm for constructing a classification model called Information Network (IN). The algorithm improvement is aimed at reducing its computational cost while preserving the same level of model quality. The quality of the induced model is evaluated by its classification accuracy using the standard 10-fold cross validation. The improvement in the algorithm anytime performance is demonstrated on several benchmark data streams.},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present a new, enhanced version of an anytime algorithm for constructing a classification model called Information Network (IN). The algorithm improvement is aimed at reducing its computational cost while preserving the same level of model quality. The quality of the induced model is evaluated by its classification accuracy using the standard 10-fold cross validation. The improvement in the algorithm anytime performance is demonstrated on several benchmark data streams. Can't tell if this algorithm works in an online real-time fashion. Since it needs to be validated, indications are not.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.422.9735}
}

@Article{Latif2014,
  Title                    = {Analyzing feasibility for deploying very fast decision tree for DDoS attack detection in cloud-assisted WBAN},
  Author                   = {Latif, R.a and Abbas, H.a b and Assar, S.c and Latif, S.a },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {507-519},
  Volume                   = {8588 LNCS},

  Abstract                 = {In cloud-assisted wireless body area networks (WBAN), the data gathered by sensor nodes are delivered to a gateway node that collects and aggregates data and transfer it to cloud storage; making it vulnerable to numerous security attacks. Among these, Distributed Denial of Service (DDoS) attack could be considered as one of the major security threats against cloud-assisted WBAN security. To overcome the effects of DDoS attack in cloud-assisted WBAN environment various techniques have been explored during this research. Among these, data mining classification techniques have proven itself as a valuable tool to identify misbehaving nodes and thus for detecting DDoS attacks. Further classifying data mining techniques, Very Fast Decision Tree (VFDT) is considered as the most promising solution for real-time data mining of high speed and non- stationary data streams gathered from WBAN sensors and therefore is selected, studied and explored for efficiently analyzing and detecting DDoS attack in cloud-assisted WBAN environment. Ã‚Â© 2014 Springer International Publishing Switzerland.},
  Affiliation              = {National University of Sciences and Technology, Islamabad, Pakistan; Centre of Excellence in Information Assurance (COEIA), King Saud University, Saudi Arabia; Telecom Ecole de Management Information System Department, Institut Mines-TÃƒÂ©lÃƒÂ©com, France},
  Author_keywords          = {Cloud-assisted WBAN; Data mining (DM); Decision trees; Distributed denial of service (DDoS) attack; Very fast decision trees (VFDT)},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Very Fast Decision Tree (VFDT) is considered as the most promising solution for real-time data mining of high speed and non- stationary data streams gathered from WBAN sensors and therefore is selected, studied and explored for efficiently analyzing and detecting DDoS attack in cloud-assisted WBAN environment. THey analyse the VFDT solution to stop DDoS attacks on WBAN. Nothing innovative, only analysis. Approved under uncertainty. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84904599872&partnerID=40&md5=1f729ed8e65c56919311c9b569f66237}
}

@Conference{Lee2005,
  Title                    = {Finding maximal frequent itemsets over online data streams adaptively},
  Author                   = {Lee, D. and Lee, W.},
  Year                     = {2005},
  Note                     = {cited By (since 1996)27},
  Pages                    = {266-273},

  Abstract                 = {Due to the characteristics of a data stream, it is very important to confine the memory usage of a data mining process regardless of the amount of information generated in the data stream. For this purpose, this paper proposes a CP-tree (Compressed-prefix tree) that can be effectively used in finding either frequent or maximal frequent itemsets over an online data stream. Unlike a prefix tree, a node of a CP-tree can maintain the information of several item-sets together. Based on this characteristic, the size of a CP-tree can be flexibly controlled by merging or splitting nodes. In this paper, a mining method employing a CP-tree is proposed and an adaptive memory utilization scheme is also presented in order to maximize the mining accuracy of the proposed method for confined memory space at all times. Finally, the performance of the proposed method is analyzed by a series of experiments to identify its various characteristics. Ã‚Â© 2005 IEEE.},
  Affiliation              = {Department of Computer Science, Yonsei University, South Korea},
  Art_number               = {1565688},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {, this paper proposes a CP-tree (Compressed-prefix tree) that can be effectively used in finding either frequent or maximal frequent itemsets over an online data stream. , a mining method employing a CP-tree is proposed and an adaptive memory utilization scheme is also presented. Experiments are done. Weak abstract, Though the use of CP-trees have been seen in other works, by Li if i'm not mistaken. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33748463833&partnerID=40&md5=f2e0875413c29a5037318aefbbb8ea33}
}

@Conference{Lee2007,
  Title                    = {A single pass algorithm of finding frequent vibrated items over online data streams},
  Author                   = {Lee, G. and Chen, Q.-T.},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Volume                   = {1},

  Abstract                 = {Data streams are data items generated unbounded and continuously. To detect the vibration of data item's quantity, a single pass algorithm is proposed for mining vibrated items over online data streams in this paper. The change of data item can be reported at once by measuring its vibrated slope. Not only the change of data item will be detected, the period in which the data item is frequent vibrated is also reported. Moreover, a set of simulations is performed to show the benefit of our approach. Ã‚Â©2007 IEEE.},
  Affiliation              = {Department of Computer Science and Information Engineering, National Dong Hwa University, Hualien, Taiwan},
  Art_number               = {4444224},
  Document_type            = {Conference Paper},
  Journal                  = {2007 2nd International Conference on Digital Information Management, ICDIM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {a single pass algorithm is proposed for mining vibrated items over online data streams in this paper. set of simulations is performed to show the benefit of our approach weak paper. There are other research done on vibrated items with better abstracts. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-50149102224&partnerID=40&md5=be57d922d0a7ce2bf18ba275f9743500}
}

@InProceedings{Lee2008,
  Title                    = {{A coarse-grain grid-based subspace clustering method for online multi-dimensional data streams}},
  Author                   = {Lee, Jae Woo and Lee, Won Suk},
  Booktitle                = {Proceeding of the 17th ACM conference on Information and knowledge mining - CIKM '08},
  Year                     = {2008},

  Address                  = {New York, New York, USA},
  Month                    = oct,
  Pages                    = {1521},
  Publisher                = {ACM Press},

  Abstract                 = {This paper proposes a subspace clustering algorithm which combines grid-based clustering with frequent itemset mining. Given a d-dimensional data stream, the on-going distribution statistics of its data elements in every one-dimensional data space is monitored by a list of fine-grain grid-cells called a sibling list, so that all the one-dimensional clusters are accurately identified. By tracing a set of frequently co-occurred one-dimensional clusters, it is possible to find a coarse-grain dense rectangular space in a higher dimensional subspace. An ST-tree is introduced to continuously monitor dense rectangular spaces in all the subspaces of the d dimensions. Among the spaces, those ones whose densities are greater than or equal to a user defined minimum support threshold Smin are corresponding to final clusters.},
  Doi                      = {10.1145/1458082.1458366},
  ISBN                     = {9781595939913},
  Keywords                 = {data mining,data streams,grid-based clustering,st-tree,subspace clustering},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes a subspace clustering algorithm which combines grid-based clustering with frequent itemset mining. Given a d-dimensional data stream, the on-going distribution statistics of its data elements in every one-dimensional data space is monitored by a list of fine-grain grid-cells called a sibling list, so that all the one-dimensional clusters are accurately identified 1,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1458082.1458366}
}

@Article{Lee2009,
  Title                    = {Efficiently tracing clusters over high-dimensional on-line data streams },
  Author                   = {Jae Woo Lee and Nam Hun Park and Won Suk Lee},
  Journal                  = {Data \& Knowledge Engineering },
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {362 - 379},
  Volume                   = {68},

  Abstract                 = {A good clustering method should provide flexible scalability on the number of dimensions as well as the size of a data set. This paper proposes a method of efficiently tracing the clusters of a high-dimensional on-line data stream. While tracing the one-dimensional clusters of each dimension independently, a technique which is similar to frequent itemset mining is employed to find the set of multi-dimensional clusters. By finding a frequently co-occurred set of one-dimensional clusters, it is possible to trace a multi-dimensional rectangular space whose range is defined by the one-dimensional clusters collectively. In order to trace such candidates over a multi-dimensional online data stream, a cluster-statistics tree (CS-Tree) is proposed in this paper. A k-depth node(k <= d) in the CS-tree is corresponding to a k-dimensional rectangular space. Each node keeps track of the density of data elements in its corresponding rectangular space. Only a node corresponding to a dense rectangular space is allowed to have a child node. The scalability on the number of dimensions is greatly enhanced while sacrificing the accuracy of identified clusters slightly.},
  Doi                      = {http://dx.doi.org/10.1016/j.datak.2008.11.004},
  ISSN                     = {0169-023X},
  Keywords                 = {Data stream},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A good clustering method should provide flexible scalability on the number of dimensions as well as the size of a data set. This paper proposes a method of efficiently tracing the clusters of a high-dimensional on-line data stream. While tracing the one-dimensional clusters of each dimension independently, a technique which is similar to frequent itemset mining is employed to find the set of multi-dimensional clusters No experimentation, very theory heavy. 1,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0169023X0800164X}
}

@Article{Leite2012,
  Title                    = {Evolving fuzzy granular modeling from nonstationary fuzzy data streams},
  Author                   = {Leite, D.a and Ballini, R.b and Costa, P.c and Gomide, F.a },
  Journal                  = {Evolving Systems},
  Year                     = {2012},
  Note                     = {cited By (since 1996)23},
  Number                   = {2},
  Pages                    = {65-79},
  Volume                   = {3},

  Abstract                 = {Evolving granular modeling is an approach that considers online granular data stream processing and structurally adaptive rule-based models. As uncertain data prevail in stream applications, excessive data granularity becomes unnecessary and inefficient. This paper introduces an evolving fuzzy granular framework to learn from and model time-varying fuzzy input-output data streams. The fuzzy-set based evolving modeling framework consists of a one-pass learning algorithm capable to gradually develop the structure of rule-based models. This framework is particularly suitable to handle potentially unbounded fuzzy data streams and render singular and granular approximations of nonstationary functions. The main objective of this paper is to shed light into the role of evolving fuzzy granular computing in providing high-quality approximate solutions from large volumes of real-world online data streams. An application example in weather temperature prediction using actual data is used to evaluate and illustrate the usefulness of the modeling approach. The behavior of nonstationary fuzzy data streams with gradual and abrupt regime shifts is also verified in the realm of the weather temperature prediction. Ã‚Â© 2012 Springer-Verlag.},
  Affiliation              = {School of Electrical and Computer Engineering, University of Campinas, Campinas, SP, Brazil; Institute of Economics, University of Campinas, Campinas, SP, Brazil; Graduate Program in Electrical Engineering, Pontifical Catholic University of Minas Gerais, Belo Horizonte, MG, Brazil},
  Author_keywords          = {Fuzzy data stream; Granular computing; Information granule; Online learning; Time series prediction},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The main objective of this paper is to shed light into the role of evolving fuzzy granular computing in providing high-quality approximate solutions from large volumes of real-world online data streams. An application example in weather temperature prediction using actual data is used to evaluate and illustrate the usefulness of the modeling approach This author has written many papers on this topic. Newer versions seems more complete. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84860424873&partnerID=40&md5=bff459feca980aec9ab69d02598fb4d3}
}

@InProceedings{Leite2014,
  Title                    = {{Parameter estimation of dynamic fuzzy models from uncertain data streams}},
  Author                   = {Leite, Daniel and Caminhas, Walmir and Lemos, Andre and Palhares, Reinaldo and Gomide, Fernando},
  Booktitle                = {2014 IEEE Conference on Norbert Wiener in the 21st Century (21CW)},
  Year                     = {2014},
  Month                    = jun,
  Pages                    = {1--7},
  Publisher                = {IEEE},

  Abstract                 = {Modeling of time-varying dynamic systems in real time requires the use of streams of sensor data and incremental learning algorithms. This paper introduces an incremental fuzzy modeling approach based on uncertain data streams. By uncertain data we mean data originated from unreliable sensors, imprecise perception, or description of the value of a variable represented as a fuzzy interval. An online incremental learning algorithm is used to develop the antecedent part of functional fuzzy rules and the rule base that assembles the model. A recursive least squares-like algorithm updates the parameters of a discrete state-space representation of the fuzzy rule consequents. Data uncertainty is accounted for using specificity measures of the input data. An illustrative example concerning the Lorenz attractor is given.},
  Doi                      = {10.1109/NORBERT.2014.6893892},
  ISBN                     = {978-1-4799-4562-7},
  Keywords                 = {Computational modeling,Data models,Equations,Fuzzy sets,Lorenz attractor,Mathematical model,Numerical models,Uncertainty,antecedent part,data handling,data uncertainty,discrete state-space representation,dynamic fuzzy models,functional fuzzy rules,fuzzy interval,fuzzy rule consequents,fuzzy set theory,incremental fuzzy modeling approach,knowledge based systems,learning (artificial intelligence),least squares approximations,modelling,online incremental learning algorithm,parameter estimation,recursive least squares-like algorithm,rule base,sensor data streams,time-varying dynamic systems modeling,uncertain data streams,uncertainty handling,unreliable sensors},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper introduces an incremental fuzzy modeling approach based on uncertain data streams. By uncertain data we mean data originated from unreliable sensors, imprecise perception, or description of the value of a variable represented as a fuzzy interval. An online incremental learning algorithm is used to develop the antecedent part of functional fuzzy rules and the rule base that assembles the model. Same author as Leite2014, still no experimentation. Is this the same experiment? 1,6},
  Shorttitle               = {Norbert Wiener in the 21st Century (21CW), 2014 IE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6893892}
}

@Article{Leite2013,
  Title                    = {Evolving granular neural networks from fuzzy data streams },
  Author                   = {Daniel Leite and Pyramo Costa and Fernando Gomide},
  Journal                  = {Neural Networks },
  Year                     = {2013},
  Number                   = {0},
  Pages                    = {1 - 16},
  Volume                   = {38},

  Abstract                 = {This paper introduces a granular neural network framework for evolving fuzzy system modeling from fuzzy data streams. The evolving granular neural network (eGNN) is able to handle gradual and abrupt parameter changes typical of nonstationary (online) environments. eGNN builds interpretable multi-sized local models using fuzzy neurons for information fusion. An online incremental learning algorithm develops the neural network structure from the information contained in data streams. We focus on trapezoidal fuzzy intervals and objects with trapezoidal membership function representation. More precisely, the framework considers triangular, interval, and numeric types of data to construct granular fuzzy models as particular arrangements of trapezoids. Application examples in classification and function approximation in material and biomedical engineering are used to evaluate and illustrate the neural network usefulness. Simulation results suggest that the eGNN fuzzy modeling approach can handle fuzzy data successfully and outperforms alternative state-of-the-art approaches in terms of accuracy, transparency and compactness.},
  Doi                      = {http://dx.doi.org/10.1016/j.neunet.2012.10.006},
  ISSN                     = {0893-6080},
  Keywords                 = {Evolving systems},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper introduces a granular neural network framework for evolving fuzzy system modeling from fuzzy data streams. The evolving granular neural network (eGNN) is able to handle gradual and abrupt parameter changes typical of nonstationary (online) environments. Simulation results suggest that the eGNN fuzzy modeling approach can handle fuzzy data successfully and outperforms alternative state-of-the-art approaches in terms of accuracy, transparency and compactness.

1,3,4,5,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0893608012002791}
}

@Article{Leite2014a,
  Title                    = {{Evolving Granular Fuzzy Model-Based Control of Nonlinear Dynamic Systems}},
  Author                   = {Leite, Daniel and Palhares, Reinaldo and Campos, Victor and Gomide, Fernando},
  Journal                  = {IEEE Transactions on Fuzzy Systems},
  Year                     = {2014},
  Number                   = {99},
  Pages                    = {1--1},
  Volume                   = {PP},

  Abstract                 = {Unknown nonstationary processes require modeling and control design to be done in real time using streams of data collected from the process. The purpose is to stabilize the closed-loop system under changes of the operating conditions and process parameters. This paper introduces a model-based evolving granular fuzzy control approach as a step toward the development of a general framework for online modeling and control of unknown nonstationary processes with no human intervention. An incremental learning algorithm is introduced to develop and adapt the structure and parameters of the process model and controller based on information extracted from uncertain data streams. State feedback control laws and closedloop stability are obtained from the solution of relaxed linear matrix inequalities derived from a fuzzy Lyapunov function. Bounded control inputs are also taken into account in the control system design. We explain the role of fuzzy granular data and the use of parallel distributed compensation. Fuzzy granular computation provides a way to handle data uncertainty and facilitates incorporation of domain knowledge. Although the evolving granular approach is oriented to control systems whose dynamics is complex and unknown, for expositional clarity, we consider online modeling and stabilization of the well-known Lorenz chaos as an illustrative example.},
  Doi                      = {10.1109/TFUZZ.2014.2333774},
  ISSN                     = {1063-6706},
  Keywords                 = {Adaptation models,Control systems,Data models,Fuzzy control,Mathematical model,Numerical models,Process control},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper introduces a model-based evolving granular fuzzy control approach as a step toward the development of a general framework for online modeling and control of unknown nonstationary processes with no human intervention. An incremental learning algorithm is introduced to develop and adapt the structure and parameters of the process model and controller based on information extracted from uncertain data streams This seems to be a exploratory study, without any implementations or experimentation. I don't know anything about fuzzy granular data, so I'm having trouble with this abstract.},
  Shorttitle               = {Fuzzy Systems, IEEE Transactions on},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6846287}
}

@Misc{Leontyev,
  Title                    = {{Predicting Maximum Data Staleness in Real-Time Warehouses âˆ—}},

  Author                   = {Leontyev, Hennadiy and Johnson, Theodore and Anderson, James H.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper presents an analysis technique for estimating maximum data staleness in a data warehouse that collects “near-real-time ” data streams. Data is pushed to the warehouse from a variety of external sources with a wide range of inter-arrival times (e.g., once a minute to once a day). In prior work, ad hoc heuristic algorithms have been proposed for scheduling warehouse updates. In this paper, global multiprocessor real-time scheduling algorithms are considered as an alternative. It is shown that schedulability results concerning such algorithms can be used to analytically derive upper bounds on maximum data staleness based upon characteristics of warehouse tables and the parameters of update tasks. Simulation experiments are presented that show the effectiveness of the proposed approach},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {A new analysis technique for estimating maximum data staleness in a data warehouse that collects “near-real-time ” data streams. In this paper, global multiprocessor real-time scheduling algorithms are considered as an alternative. It is shown that schedulability results concerning such algorithms can be used to analytically derive upper bounds on maximum data staleness based upon characteristics. Simulation experiments are presented that show the effectiveness of the proposed approach Approved 1,2,3,4},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.153.2566}
}

@Article{Li2013,
  Title                    = {An approach of support approximation to discover frequent patterns from concept-drifting data streams based on concept learning},
  Author                   = {Li, C.-W. and Jea, K.-F.},
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0; Article in Press},
  Pages                    = {1-33},

  Abstract                 = {In an online data stream, the composition and distribution of the data may change over time, which is a phenomenon known as concept drift. The occurrence of concept drift can affect considerably the performance of a data stream mining method, especially in relation to mining accuracy. In this paper, we study the problem of mining frequent patterns from transactional data streams in the presence of concept drift, considering the important issue of mining accuracy preservation. In terms of frequent-pattern mining, we give the definitions of concept and concept drift with respect to streaming data; moreover, we present a categorization for concept drift. The concept of streaming data is considered the relationships of frequency between different patterns. Accordingly, we devise approaches to describe the concept concretely and to learn the concept through frequency relationship modeling. Based on concept learning, we propose a method of support approximation for discovering data stream frequent patterns. Our analyses and experimental results have shown that in several studied cases of concept drift, the proposed method not only performs efficiently in terms of time and memory but also preserves mining accuracy well on concept-drifting data streams. Ã‚Â© 2013 Springer-Verlag London.},
  Affiliation              = {Department of Computer Science and Engineering, National Chung Hsing University, Taichung, Taiwan},
  Author_keywords          = {Concept drift; Concept learning; Data stream mining; Frequent pattern; Support approximation},
  Document_type            = {Article in Press},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. Based on concept learning, we propose a method of support approximation for discovering data stream frequent patterns. Our analyses and experimental results have shown that in several studied cases of concept drift, the proposed method not only performs efficiently in terms of time and memory but also preserves mining accuracy well on concept-drifting data streams capture and categorize concept drift is the main goal 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84878223503&partnerID=40&md5=16296d10b472bc1e222307d56239f92e}
}

@Article{Li2012,
  Title                    = {Research of internet Traffic Identification Scheme based on machine learning algorithms},
  Author                   = {Li, D.a and An, W.a and Gong, Z.a and Luo, S.a and Xin, Y.b and Du, X.b and Cui, X.c },
  Journal                  = {Advances in Information Sciences and Service Sciences},
  Year                     = {2012},
  Note                     = {cited By (since 1996)7},
  Number                   = {8},
  Pages                    = {217-228},
  Volume                   = {4},

  Abstract                 = {As the development of network applications, old technologies like identifying traffic based on "well-known" TCP or UDP port numbers or based on the payload inspection were already inaccurate or wasteful of time and storage space. To get over the challenges that referred above, statistical technology and machine learning (ML) are introduced to traffic classification. The paper focuses on emerging hybrid research - blend of network and data mining techniques. We summarize ML approaches briefly, review significant works that cover the period from 2004 TO 2010 and categorize them by ML methods and major contribution. Considered data stream characteristics of network traffic flow, we proposed a Traffic Classification Scheme based on Data Stream Clustering Techniques, which has the capability to achieve real-time traffic classification, application clusters evolution analysis, and outline analysis for massive, high-speed, dynamic traffic flows. As an expansion, further research in this field is discussed at the end.},
  Affiliation              = {Information Security Center, Beijing University of Posts and Telecommunications, Beijing 100876, China; Beijing Safe-Code Technology Co., Ltd, Beijing 100876, China; Science and Technology on Communication Security Laboratory, Chendu 610041, China},
  Author_keywords          = {Data stream; Information security; Machine learning; Traffic classification},
  Document_type            = {Review},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {The paper focuses on emerging hybrid research - blend of network and data mining techniques. We summarize ML approaches briefly, review significant works that cover the period from 2004 TO 2010 and categorize them by ML methods and major contribution A review of mix of ML and networks. Set aside},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861495133&partnerID=40&md5=1006d14367b747ff6308689868326d57}
}

@Conference{Li2008,
  Title                    = {An improved algorithm of decision trees for streaming data based on VFDT},
  Author                   = {Li, F. and Liu, Q.},
  Year                     = {2008},
  Note                     = {cited By (since 1996)2},
  Pages                    = {597-600},
  Volume                   = {1},

  Abstract                 = {Decision tree is a good model of Classification. Recently, there has been much interest in mining streaming data. Because streaming data is large and no limited, it is unpractical that passing the entire data over more than one time. A one pass online algorithm is necessary. One of the most successful algorithms for mining data streams is VFDT(Very Fast Decision Tree).we extend the VFDT system to EVFDT(Efficient-VFDT) in two directions: (1)We present Uneven Interval Numerical Pruning (shortly UINP) approach for efficiently processing numerical attributes. (2)We use naive Bayes classifiers associated with the node to process the samples to detect the outlying samples and reduce the scale of the trees. From the experimental comparison, the two techniques significantly improve the efficiency and the accuracy of decision tree construction on streaming data. Ã‚Â© 2008 IEEE.},
  Affiliation              = {Provincial Key Laboratory for Computer Information Processing Technology, Soochow University, Suzhou, 215006, China},
  Art_number               = {4732288},
  Author_keywords          = {Decision trees; Naive Bayes classifiers; Streaming data mining; Unequal Interval Numerical Pruning(UINP)},
  Document_type            = {Conference Paper},
  Journal                  = {2008 International Symposium on Information Science and Engineering, ISISE 2008},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {One of the most successful algorithms for mining data streams is VFDT(Very Fast Decision Tree). They extend the VFDT system to EVFDT(Efficient-VFDT). From the experimental comparison, the two techniques significantly improve the efficiency and the accuracy of decision tree construction on streaming data. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-62449279687&partnerID=40&md5=00a5a91a6d43ac997d57e262a4a7b6e5}
}

@InProceedings{Li2007,
  Title                    = {{Predictive Queries Algorithm Based on Probability Model over Data Streams}},
  Author                   = {Li, Guohui and Chen, Hui and Yang, Bing and Chen, Gang and Xiang, Jun},
  Booktitle                = {Third International Conference on Natural Computation (ICNC 2007)},
  Year                     = {2007},
  Pages                    = {256--260},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Mining the evolving trends of an online data stream and forecasting the data values in the future can provide important support for the decision-making in many time-sensitive applications. This paper models an online data stream as a continuous state transitions process by mapping the possibly infinite stream data into finite states, and uses state transition disGraph (STG) to maintain the track of the state transactions. By studying the statistic information of the history state transitions, the future values can be predicted based on the theory of Markov chain. Extensive simulation experiments are conducted and show that the predictive performance of our method is preferable to that of the existing analogous algorithms.},
  Doi                      = {10.1109/ICNC.2007.566},
  ISBN                     = {0-7695-2875-9},
  Keywords                 = {Application software,Computer science,Decision making,History,Markov chain,Markov processes,Monitoring,Prediction algorithms,Predictive models,Sensor systems and applications,Statistics,Technology forecasting,data mining,data streams,decision-making,graph theory,predictive queries algorithm,probability model,query processing,state transactions,state transition disGraph},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2007a},
  Shorttitle               = {Natural Computation, 2007. ICNC 2007. Third Intern},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4344193}
}

@Conference{Li2007a,
  Title                    = {Predictive queries algorithm based on probability model over data streams},
  Author                   = {Li, G. and Chen, H. and Yang, B. and Chen, G. and Xiang, J.},
  Booktitle                = {Third International Conference on Natural Computation (ICNC 2007)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {256-260},
  Volume                   = {1},

  Abstract                 = {Mining the evolving trends of an online data stream and forecasting the data values in the future can provide important support for the decision-making in many time-sensitive applications. This paper models an online data stream as a continuous state transitions process by mapping the possibly infinite stream data into finite states, and uses State Transition disGraph (STG) to maintain the track of the state transactions. By studying the statistic information of the history state transitions, the future values can be predicted based on the Theory of Markov Chain. Extensive simulation experiments are conducted and show that the predictive performance of our method is preferable to that of the existing analogous algorithms. Ã‚Â© 2007 IEEE.},
  Affiliation              = {School of Computer Science and Technology, Huazhong University of Science and Technology, No. 1037, Luoyu Road, Wuhan, 430074, China},
  Art_number               = {4304394},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - Third International Conference on Natural Computation, ICNC 2007},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {his paper models an online data stream as a continuous state transitions process by mapping the possibly infinite stream data into finite states, and uses State Transition disGraph (STG) to maintain the track of the state transactions. Future values are predicted using Markov Chains. Experiments show that thepredictive performance of their method is preferable to that of the existing analogous algorithms I don't see how this can handle concept drift, (changing data). Seems like bullshit.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38049084049&partnerID=40&md5=70d0589fe4aa4182b25becbbed791afa}
}

@Article{Li2014,
  Title                    = {Forest cover types classification based on online machine learning on distributed cloud computing platforms of storm and SAMOA},
  Author                   = {Li, G.D. and Wang, G.Y. and Zhang, X.R. and Deng, W.H. and Zhang, F.},
  Journal                  = {Advanced Materials Research},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {3803-3812},
  Volume                   = {955-959},

  Abstract                 = {Storm is the most popular realtime stream processing platform, which can be used to deal with online machine learning. Similar to how Hadoop provides a set of general primitives for doing batch processing, Storm provides a set of general primitives for doing realtime computation. SAMOA includes distributed algorithms for the most common machine learning tasks like Mahout for Hadoop. SAMOA is both a platform and a library. In this paper, Forest cover types, a large benchmaking dataset available at the UCI KDD Archive is used as the data stream source. Vertical Hoeffding Tree, a parallelizing streaming decision tree induction for distributed enviroment, which is incorporated in SAMOA API is applied on Storm platform. This study compared stream prcessing technique for predicting forest cover types from cartographic variables with traditional classic machine learning algorithms applied on this dataset. The test then train method used in this system is totally different from the traditional train then test. The results of the stream processing technique indicated that it's output is aymptotically nearly identical to that of a conventional learner, but the model derived from this system is totally scalable, real-time, capable of dealing with evolving streams and insensitive to stream ordering. Ã‚Â© (2014) Trans Tech Publications, Switzerland.},
  Affiliation              = {Institute of Electronic Information and Technology, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing 400714, China},
  Author_keywords          = {Forest cover types; Online machine learning; SAMOA; Storm; Vertical Hoeffding Tree},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper uses Vertical Hoeffding Tree, a parallelizing streaming decision tree induction for distributed enviroment, which is incorporated in SAMOA API is applied on Storm platform. The results of the stream processing technique indicated that it's output is aymptotically nearly identical to that of a conventional learner, but the model is scalable and capable of dealing with evolving streams. Paper seems interesting, especially since it talks about implementing in a specific platform. THe english is really poor though. Not sure how innovative the approach is. vertical Hoeffding trees are mentioned in other papers. 2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84904211295&partnerID=40&md5=50b90de897fbe2c43753f8535386a632}
}

@Article{Li2008a,
  Title                    = {Mining the frequent patterns in an arbitrary sliding window over online data streams},
  Author                   = {Li, G.-H. and Chen, H.},
  Journal                  = {Ruan Jian Xue Bao/Journal of Software},
  Year                     = {2008},
  Note                     = {cited By (since 1996)15},
  Number                   = {10},
  Pages                    = {2585-2596},
  Volume                   = {19},

  Abstract                 = {Because of the fluidity and continuity of data stream, the knowledge embedded in stream data is most likely to be changed as time goes by. Thus, in most data stream applications, people are more interested in the information of the recent transactions than that of the old. This paper proposes a method for mining the frequent patterns in an arbitrary sliding window of data streams. As data stream flows, the contents of the data stream are captured with a compact prefix-tree by scanning the stream only once. And the obsolete and infrequent items are deleted by periodically pruning the tree. To differentiate the patterns of recently generated transactions from those of historic transactions, a time decaying model is also applied. Extensive simulations are conducted and the experimental results show that the proposed method is efficient and scalable, and also superior to other analogous algorithms.},
  Affiliation              = {School of Computer Science and Technology, Huazhong Univ. of Sci. and Technol., Wuhan 430074, China},
  Author_keywords          = {Data stream; Frequent pattern mining; Sliding window; Time decaying model},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. This paper proposes a method for mining the frequent patterns in an arbitrary sliding window of data streams. To differentiate the patterns of recently generated transactions from those of historic transactions, a time decaying model is also applied. experimental results show that the proposed method is efficient and scalable, and also superior to other analogous algorithms. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-55149125179&partnerID=40&md5=6327a261a02bf31f347c8ce98cff209d}
}

@Conference{Li2014a,
  Title                    = {Online learning with mobile sensor data for user recognition},
  Author                   = {Li, H.a and Wu, X.b and Li, Z.c },
  Booktitle                = {Proceedings of the 29th Annual ACM Symposium on Applied Computing - SAC '14},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {64-70},

  Abstract                 = {Currently, mobile devices built with powerful embedded sensors create new opportunities for data mining applications such as monitoring user activity. In this paper, we target at user recognition based on sensor data of remote control, in which activity recognition determines a user's action that is in favor of collecting one's individual sensor data to identify different users. This new problem faces two challenges: first, sensor data is sensitive and constantly changing which is difficult to obtain meaningful features; second, streaming sensor data for online learning is usually imbalanced on which traditional classifiers are not well performed. To address these challenges, we introduce an efficient activity recognition algorithm by exploring the physical appearance of sensor data, and then an online incremental classifier to deal with imbalanced data streams by adaptively generating training data. Extensive online and offline experiments demonstrate that our proposed method outperforms state-of-the-art algorithms in terms of accuracy. Copyright 2014 ACM.},
  Affiliation              = {Dept. of Computer Science, University of Vermont, 33 Colchester Ave, Burlington VT 05405, United States; Dept. of Computer Science, University of Vermont, 33 Colchester Ave, Burlington, VT 05405, United States; TCL Research America, 2870 Zanker Road, San Jose, CA 95134, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM Symposium on Applied Computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They introduce an efficient activity recognition algorithm by exploring the physical appearance of sensor data, and then an online incremental classifier to deal with imbalanced data streams by adaptively generating training data. Extensive online and offline experiments demonstrate that our proposed method outperforms state-of-the-art algorithms in terms of accuracy Using sensors in mobiles, they try to determine a user's actions. Could be interesting for Telenor 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905647027&partnerID=40&md5=01f3449e0de17b38bb6b923ef4511b81}
}

@InProceedings{Li2014b,
  Title                    = {{Online learning with mobile sensor data for user recognition}},
  Author                   = {Li, Haiguang and Wu, Xindong and Li, Zhao},
  Booktitle                = {Proceedings of the 29th Annual ACM Symposium on Applied Computing - SAC '14},
  Year                     = {2014},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {64--70},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/2554850.2554877},
  ISBN                     = {9781450324694},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2014a},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2554850.2554877}
}

@Misc{Lia,
  Title                    = {{Online Mining of Frequent Query Trees over XML Data Streams}},

  Author                   = {Li, Hua-fu},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In this paper, we proposed an online algorithm, called FQT-Stream (Frequent Query Trees of Streams), to mine the set of all frequent tree patterns over a continuous XML data stream. A new numbering method is proposed to represent the tree structure of a XML query tree. An effective sub-tree numeration approach is developed to extract the essential information from the XML data stream. The extracted information is stored in an effective summary data structure. Frequent query trees are mined from the current summary data structure by a depth-first-search manner.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2006e},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.79.9874}
}

@Article{Li2011,
  Title                    = {MHUI-max: An efficient algorithm for discovering high-utility itemsets from data streams},
  Author                   = {Li, H.-F.},
  Journal                  = {Journal of Information Science},
  Year                     = {2011},
  Note                     = {cited By (since 1996)4},
  Number                   = {5},
  Pages                    = {532-545},
  Volume                   = {37},

  Abstract                 = {Online mining of utility itemsets from data streams is one of the most interesting research issues in stream data mining. Although a number of relevant approaches have been proposed in recent years, they have the drawback of producing a large number of candidate itemsets for high-utility itemset mining. In this paper, an efficient algorithm, called MHUI-max (Mining High-Utility Itemsets based on LexTree-maxHTU), is proposed for mining high-utility itemsets from data streams with fewer candidates. Based on the framework of the MHUI-max algorithm, an effective representation of item information, called TID-list, and a new lexicographical tree-based data structure, called LexTree-maxHTU, has been developed to improve the efficiency of discovering high-utility itemsets with positive profits from data streams. Experimental results show that the proposed algorithm, MHUI-max, outperforms the existing approaches, MHUI-TID and THUI-Mine, for mining high-utility itemsets from data streams over transaction-sensitive sliding windows. Ã‚Â© Chartered Institute of Library and Information Professionals 2011.},
  Affiliation              = {Department of Information Management, Kainan University, Taoyuan 338, Taiwan},
  Author_keywords          = {data mining; data stream mining; Data streams; high-utility itemset; utility mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {an efficient algorithm, called MHUI-max (Mining High-Utility Itemsets based on LexTree-maxHTU), is proposed for mining high-utility itemsets from data streams with fewer candidates. Based on the framework of the MHUI-max algorithm, an effective representation of item information, called TID-list, and a new lexicographical tree-based data structure, called LexTree-maxHTU, has been developed. Experimental results show that the proposed algorithm, MHUI-max, outperforms the existing approaches, MHUI-TID and THUI-Mine, for mining high-utility itemsets from data streams over transaction-sensitive sliding windows 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054055829&partnerID=40&md5=b2b9a0fef94137c5c7ffc77a1277e985}
}

@InProceedings{Li2006,
  Title                    = {{A New Algorithm for Maintaining Closed Frequent Itemsets in Data Streams by Incremental Updates}},
  Author                   = {Li, Hua-fu and Ho, Chin-chuan and Kuo, Fang-fei and Lee, Suh-yin},
  Booktitle                = {Sixth IEEE International Conference on Data Mining - Workshops (ICDMW'06)},
  Year                     = {2006},
  Pages                    = {672--676},
  Publisher                = {IEEE},

  Abstract                 = {Online mining of closed frequent itemsets over streaming data is one of the most important issues in mining data streams. In this paper, we propose an efficient one-pass algorithm, NewMoment to maintain the set of closed frequent itemsets in data streams with a transaction-sensitive sliding window. An effective bit-sequence representation of items is used in the proposed algorithm to reduce the time and memory needed to slide the windows. Experiments show that the proposed algorithm not only attain highly accurate mining results, but also run significant faster and consume less memory than existing algorithm Moment for mining closed frequent itemsets over recent data streams},
  Doi                      = {10.1109/ICDMW.2006.15},
  ISBN                     = {0-7695-2702-7},
  Keywords                 = {Algorithm design and analysis,Character generation,Computer science,Control systems,Data analysis,Data mining,Electronic mail,Error correction,Itemsets,NewMoment algorithm,Size control,bit-sequence representation,closed frequent itemsets,data mining,data streams,incremental updates,knowledge representation,one-pass algorithm,online mining,transaction processing,transaction-sensitive sliding window},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2006f},
  Shorttitle               = {Data Mining Workshops, 2006. ICDM Workshops 2006. },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4063710}
}

@Conference{Li2006f,
  Title                    = {A new algorithm for maintaining closed frequent itemsets in data streams by incremental updates},
  Author                   = {Li, H.-F. and Ho, C.-C. and Kuo, F.-F. and Lee, S.-Y.},
  Year                     = {2006},
  Note                     = {cited By (since 1996)5},
  Pages                    = {672-676},

  Abstract                 = {Online mining of closed frequent itemsets over streaming data is one of the most important issues in mining data streams. In this paper, we propose an efficient one-pass algorithm, NewMoment to maintain the set of closed frequent itemsets in data streams with a transaction-sensitive sliding window. An effective bit-sequence representation of items is used in the proposed algorithm to reduce the time and memory needed to slide the windows. Experiments show that the proposed algorithm not only attain highly accurate mining results, but also run significant faster and consume less memory than existing algorithm Moment for mining closed frequent itemsets over recent data streams. Ã‚Â© 2006 IEEE.},
  Affiliation              = {Department of Computer Science, National Chiao Tung University, Hsinchu, 300, Taiwan},
  Art_number               = {4063710},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {newer version in Li2009},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78449279190&partnerID=40&md5=ba2e8551f3ec02b6fc704ffe2f314113}
}

@Article{Li2009,
  Title                    = {Incremental updates of closed frequent itemsets over continuous data streams },
  Author                   = {Hua-Fu Li and Chin-Chuan Ho and Suh-Yin Lee},
  Journal                  = {Expert Systems with Applications },
  Year                     = {2009},
  Number                   = {2, Part 1},
  Pages                    = {2451 - 2458},
  Volume                   = {36},

  Abstract                 = {Online mining of closed frequent itemsets over streaming data is one of the most important issues in mining data streams. In this paper, we propose an efficient one-pass algorithm, NewMoment to maintain the set of closed frequent itemsets in data streams with a transaction-sensitive sliding window. An effective bit-sequence representation of items is used in the proposed algorithm to reduce the time and memory needed to slide the windows. Experiments show that the proposed algorithm not only attain highly accurate mining results, but also run significant faster and consume less memory than existing algorithm Moment for mining closed frequent itemsets over recent data streams.},
  Doi                      = {http://dx.doi.org/10.1016/j.eswa.2007.12.054},
  ISSN                     = {0957-4174},
  Keywords                 = {Data mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Online mining of closed frequent itemsets. propose an efficient one-pass algorithm, NewMoment to maintain the set of closed frequent itemsets in data streams with a transaction-sensitive sliding window. Experiments show that the proposed algorithm not only attain highly accurate mining results, but also run significant faster and consume less memory than existing algorithm Moment Approved 3,4,6 Chang2013 claims to have made a better algorithm.},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0957417407006793}
}

@Conference{Li2007b,
  Title                    = {Efficient maintenance and mining of frequent itemsets over online data streams with a sliding window},
  Author                   = {Li, H.-F.a and Ho, C.-C.a and Shan, M.-K.b and Lee, S.-Y.a },
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {2672-2677},
  Volume                   = {3},

  Abstract                 = {Online mining of streaming data is one of the most important issues in data mining. In this paper, we proposed an efficient one-pass algorithm, called MFI-TransSW (Mining Frequent Itemsets over a Transaction-sensitive Sliding Window), to mine the set of all frequent itemsets in data streams with a transaction-sensitive sliding window. An effective bit-sequence representation of items is used in the proposed algorithm to reduce the time and memory needed to slide the windows. The experiments show that the proposed algorithm not only attain highly accurate mining results, but also run significant faster and consume less memory than existing algorithms for mining frequent itemsets over recent data streams. Ã‚Â© 2006 IEEE.},
  Affiliation              = {Department of Computer Science, National Chiao-Tung University, Hsinchu, 300, Taiwan; Department of Computer Science, National Chengchi University, Taipei, 116, Taiwan},
  Art_number               = {4274273},
  Document_type            = {Conference Paper},
  Journal                  = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {proposed an efficient one-pass algorithm, called MFI-TransSW (Mining Frequent Itemsets over a Transaction-sensitive Sliding Window), to mine the set of all frequent itemsets in data streams with a transaction-sensitive sliding window. The experiments show that the proposed algorithm not only attain highly accurate mining results, but also run significant faster and consume less memory than existing algorithms for mining frequent itemsets over recent data streams Newer version, with better abstract in Li2009a. Same algorithm.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34548128868&partnerID=40&md5=53c8d53dc22cbd2016db9106d3a2e94d}
}

@InProceedings{Li2006a,
  Title                    = {{Efficient Maintenance and Mining of Frequent Itemsets over Online Data Streams with a Sliding Window}},
  Author                   = {Li, Hua-Fu and Ho, Chin-Chuan and Shan, Man-Kwan and Lee, Suh-Yin},
  Booktitle                = {2006 IEEE International Conference on Systems, Man and Cybernetics},
  Year                     = {2006},
  Month                    = oct,
  Pages                    = {2672--2677},
  Publisher                = {IEEE},
  Volume                   = {3},

  Abstract                 = {Online mining of streaming data is one of the most important issues in data mining. In this paper, we proposed an efficient one-pass algorithm, called MFI-TransSW (mining frequent itemsets over a transaction-sensitive sliding window), to mine the set of all frequent itemsets in data streams with a transaction-sensitive sliding window. An effective bit-sequence representation of items is used in the proposed algorithm to reduce the time and memory needed to slide the windows. The experiments show that the proposed algorithm not only attain highly accurate mining results, but also run significant faster and consume less memory than existing algorithms for mining frequent itemsets over recent data streams.},
  Doi                      = {10.1109/ICSMC.2006.385267},
  ISBN                     = {1-4244-0099-6},
  Keywords                 = {Algorithm design and analysis,Computer science,Cybernetics,Data mining,Data structures,Data warehouses,Itemsets,Measurement,Monitoring,Real time systems,data analysis,data mining,frequent itemset,online data stream,sliding window},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2006a},
  Shorttitle               = {Systems, Man and Cybernetics, 2006. SMC '06. IEEE },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4274273}
}

@Article{Li2006h,
  Title                    = {{Efficient Maintenance and Mining of Frequent Itemsets over Online Data Streams with a Sliding Window, in}},
  Author                   = {Li, Hua-fu and Ho, Chin-chuan and Shan, Man-kwan and Lee, Suh-yin},
  Journal                  = {PROC. IEEE SMC},
  Year                     = {2006},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2007b},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.127.8601}
}

@Conference{Li2008c,
  Title                    = {Efficiently mining frequent patterns in recent music query streams},
  Author                   = {Li, H.-F.a and Hsiao, M.-H.b and Chen, H.-S.b },
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1269-1272},

  Abstract                 = {Mining frequent melody structures from music data is one of the most important issues in multimedia data mining. In this paper, we proposed an efficient online algorithm, called BVMDS (Bit-Vector based Mining of Data Streams), to mine all frequent temporal patterns over sliding windows of music melody sequence streams. An effective bit-sequence representation is used in BVMDS to reduce the time and memory needed to slide the windows. An effective list structure is used to overcome the performance bottleneck of previous work, FTP-stream. Experiments show that the BVMDS algorithm outperforms FTP-stream algorithm, and just scans the streaming data once. Ã‚Â© 2008 IEEE.},
  Affiliation              = {Department of Computer Science, Kainan University, Taoyuan, Taiwan; Department of Computer Science, National Chiao-Tung University, Taiwan},
  Art_number               = {4607673},
  Document_type            = {Conference Paper},
  Journal                  = {2008 IEEE International Conference on Multimedia and Expo, ICME 2008 - Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They proposed an efficient online algorithm, called BVMDS (Bit-Vector based Mining of Data Streams), to mine all frequent temporal patterns over sliding windows of music melody sequence streams. Experiments show that the BVMDS algorithm outperforms FTP-stream algorithm, and just scans the streaming data once 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-54049111505&partnerID=40&md5=1f6dbd52cbf61d8903559660009ff7f2}
}

@Article{Li2009a,
  Title                    = {Mining frequent itemsets over data streams using efficient window sliding techniques },
  Author                   = {Hua-Fu Li and Suh-Yin Lee},
  Journal                  = {Expert Systems with Applications },
  Year                     = {2009},
  Number                   = {2, Part 1},
  Pages                    = {1466 - 1477},
  Volume                   = {36},

  Abstract                 = {Online mining of frequent itemsets over a stream sliding window is one of the most important problems in stream data mining with broad applications. It is also a difficult issue since the streaming data possess some challenging characteristics, such as unknown or unbound size, possibly a very fast arrival rate, inability to backtrack over previously arrived transactions, and a lack of system control over the order in which the data arrive. In this paper, we propose an effective bit-sequence based, one-pass algorithm, called MFI-TransSW (Mining Frequent Itemsets within a Transaction-sensitive Sliding Window), to mine the set of frequent itemsets from data streams within a transaction-sensitive sliding window which consists of a fixed number of transactions. The proposed MFI-TransSW algorithm consists of three phases: window initialization, window sliding and pattern generation. First, every item of each transaction is encoded in an effective bit-sequence representation in the window initialization phase. The proposed bit-sequence representation of item is used to reduce the time and memory needed to slide the windows in the following phases. Second, MFI-TransSW uses the left bit-shift technique to slide the windows efficiently in the window sliding phase. Finally, the complete set of frequent itemsets within the current sliding window is generated by a level-wise method in the pattern generation phase. Experimental studies show that the proposed algorithm not only attain highly accurate mining results, but also run significant faster and consume less memory than do existing algorithms for mining frequent itemsets over data streams with a sliding window. Furthermore, based on the MFI-TransSW framework, an extended single-pass algorithm, called MFI-TimeSW (Mining Frequent Itemsets within a Time-sensitive Sliding Window) is presented to mine the set of frequent itemsets efficiently over time-sensitive sliding windows.},
  Doi                      = {http://dx.doi.org/10.1016/j.eswa.2007.11.061},
  ISSN                     = {0957-4174},
  Keywords                 = {Data mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an effective bit-sequence based, one-pass algorithm, called MFI-TransSW (Mining Frequent Itemsets within a Transaction-sensitive Sliding Window), to mine the set of frequent itemsets from data streams within a transaction-sensitive sliding window which consists of a fixed number of transactions. Experimental studies show that the proposed algorithm not only attain highly accurate mining results, but also run significant faster and consume less memory than do existing algorithms for mining frequent itemsets over data streams with a sliding window 1,2,3,4,(5?),6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0957417407006057}
}

@Conference{Li2004,
  Title                    = {Single-pass algorithms for mining frequency change patterns with limited space in evolving append-only and dynamic transaction data streams},
  Author                   = {Li, H.-F. and Lee, S.-Y.},
  Year                     = {2004},
  Note                     = {cited By (since 1996)2},
  Pages                    = {215-222},

  Abstract                 = {In this paper, we propose an online single-pass algorithm MFC-append (Mining Frequency Change patterns in append-only data streams) for online mining frequent frequency change items in continuous append-only data streams. An online space-efficient data structure called Change-Sketch is developed for providing fast response time to compute dynamic frequency changes between data streams. A modified approach MFC-dynamic (Mining Frequency Change patterns in dynamic data streams) is also presented to mine frequency changes in dynamic data streams. The theoretic analyses show that our algorithms meet the major performance requirements of single-pass, bounded storage, and real time for streaming data mining.},
  Affiliation              = {Department of Computer Science, National Chiao-Tung University, Hisnchu, Taiwan},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2004 IEEE International Conference on e-Technology, e-Commerce and e-Service, EEE 2004},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2004c, newer version in Li2005a},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-4544253122&partnerID=40&md5=2e327d516210f5a73696bb033b96accd}
}

@Article{Li2004c,
  Title                    = {{Single-pass algorithms for mining frequency change patterns with limited space in evolving append-only and dynamic transaction data streams}},
  Author                   = {Li, Hua-fu and Lee, Suh-yin},
  Journal                  = {IN: PROC EEE},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In this paper, we propose an online single-pass algorithm MFC-append (Mining Frequency Change patterns in append-only data streams) for online mining frequent frequency change items in continuous append-only data streams. An online space-efficient data structure called Change-Sketch is developed for providing fast response time to compute dynamic frequency changes between data streams. A modified approach MFCdynamic (Mining Frequency Change patterns in dynamic data streams) is also presented to mine frequency changes in dynamic data streams. The theoretic analyses show that our algorithms meet the major performance requirements of single-pass, bounded storage, and real time for streaming data mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Newer, better version in Li2005a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.123.7131}
}

@Article{Li2006c,
  Title                    = {DSM-PLW: Single-pass mining of path traversal patterns over streaming Web click-sequences },
  Author                   = {Hua-Fu Li and Suh-Yin Lee and Man-Kwan Shan},
  Journal                  = {Computer Networks },
  Year                     = {2006},
  Note                     = {I. Web Dynamics II. Algorithms for Distributed Systems },
  Number                   = {10},
  Pages                    = {1474 - 1487},
  Volume                   = {50},

  Abstract                 = {Mining Web click streams is an important data mining problem with broad applications. However, it is also a difficult problem since the streaming data possess some interesting characteristics, such as unknown or unbounded length, possibly a very fast arrival rate, inability to backtrack over previously arrived click-sequences, and a lack of system control over the order in which the data arrive. In this paper, we propose a projection-based, single-pass algorithm, called DSM-PLW (Data Stream Mining for Path traversal patterns in a Landmark Window), for online incremental mining of path traversal patterns over a continuous stream of maximal forward references generated at a rapid rate. According to the algorithm, each maximal forward reference of the stream is projected into a set of reference-suffix maximal forward references, and these reference-suffix maximal forward references are inserted into a new in-memory summary data structure, called SP-forest (Summary Path traversal pattern forest), which is an extended prefix tree-based data structure for storing essential information about frequent reference sequences of the stream so far. The set of all maximal reference sequences is determined from the SP-forest by a depth-first-search mechanism, called MRS-mining (Maximal Reference Sequence mining). Theoretical analysis and experimental studies show that the proposed algorithm has gently growing memory requirements and makes only one pass over the streaming data.},
  Doi                      = {http://dx.doi.org/10.1016/j.comnet.2005.10.018},
  ISSN                     = {1389-1286},
  Keywords                 = {Web click-sequence streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a projection-based, single-pass algorithm, called DSM-PLW (Data Stream Mining for Path traversal patterns in a Landmark Window), for online incremental mining of path traversal patterns over a continuous stream of maximal forward references generated at a rapid rate. experimental studies show that the proposed algorithm has gently growing memory requirements and makes only one pass over the streaming data. 1,6 Ren2008 claims to have made a better algorithm},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S138912860500366X}
}

@Conference{Li2005,
  Title                    = {Online mining (recently) maximal frequent itemsets over data streams},
  Author                   = {Li, H.-F.a and Lee, S.-Y.a and Shan, M.-K.b },
  Year                     = {2005},
  Note                     = {cited By (since 1996)27},
  Pages                    = {11-18},

  Abstract                 = {A data stream is a massive, open-ended sequence of data elements continuously generated at a rapid rate. Mining data streams is more difficult than mining static databases because the huge, high-speed and continuous characteristics of streaming data. In this paper, we propose a new one-pass algorithm called DSM-MFI (stands for Data Stream Mining for Maximal Frequent Itemsets), which mines the set of all maximal frequent itemsets in landmark windows over data streams. A new summary data structure called summary frequent itemset forest (abbreviated as SFI-forest) is developed for incremental maintaining the essential information about maximal frequent itemsets embedded in the stream so far. Theoretical analysis and experimental studies show that the proposed algorithm is efficient and scalable for mining the set of all maximal frequent itemsets over the entire history of the data streams. Ã‚Â© 2005 IEEE.kl},
  Affiliation              = {Department of Computer Science and Information Engineering, National Chiao-Tung University, Hsinchu, Taiwan; Department of Computer Science, National Chengchi University, Taipei, Taiwan},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the IEEE International Workshop on Research Issues in Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new one-pass algorithm called DSM-MFI (stands for Data Stream Mining for Maximal Frequent Itemsets), which mines the set of all maximal frequent itemsets in landmark windows over data streams. A new summary data structure is developed for incremental maintaining the essential information about maximal frequent itemsets in the stream. Theoretical analysis and experimental studies show efficiency and scalability 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-27144549849&partnerID=40&md5=bb05c9bcdf2a0675b95d332f7f7f992c}
}

@Article{Li2005a,
  Title                    = {Online mining changes of items over continuous append-only and dynamic data streams},
  Author                   = {Li, H.-F.a and Lee, S.-Y.a and Shan, M.-K.b },
  Journal                  = {Journal of Universal Computer Science},
  Year                     = {2005},
  Note                     = {cited By (since 1996)13},
  Number                   = {8},
  Pages                    = {1411-1425},
  Volume                   = {11},

  Abstract                 = {Online mining changes over data streams has been recognized to be an important task in data mining. Mining changes over data streams is both compelling and challenging. In this paper, we propose a new, single-pass algorithm, called MFC-append (Mining Frequency Changes of append-only data streams), for discovering the frequent frequency-changed items, vibrated frequency changed items, and stable frequency changed items over continuous append-only data streams. A new summary data structure, called Change-Sketch, is developed to compute the frequency changes between two continuous data streams as fast as possible. Moreover, a MFC-append-based algorithm, called MFC-dynamic (Mining Frequency Changes of dynamic data streams), is proposed to find the frequency changes over dynamic data streams. Theoretical analysis and experimental results show that our algorithms meet the major performance requirements, namely single-pass, bounded space requirement, and real-time computing, in mining data streams. Ã‚Â© J.UCS.},
  Affiliation              = {Department of Computer Science and Information Engineering, National Chiao-Tung University, 1001. Ta Hsueh Road, Hsinchu 300, Taiwan; Department of Computer Science, National Chengchi University, 64, Sec. 2, Zhi-nan Road, Wenshan, Taipei 116, Taiwan},
  Author_keywords          = {Change mining; Data streams; Single-pass algorithm},
  Document_type            = {Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new, single-pass algorithm, called MFC-append (Mining Frequency Changes of append-only data streams), for discovering the frequent frequency-changed items, vibrated frequency changed items, and stable frequency changed items over continuous append-only data streams. experimental results show that their algorithms meet the major performance requirements, namely single-pass, bounded space requirement, and real-time computing, in mining data streams. It meets the requirements, but nothing more than that? 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-25444443331&partnerID=40&md5=043b45516ad4227f1fad134b8894409a}
}

@Conference{Li2005b,
  Title                    = {DSM-TKP: Mining top-K path traversal patterns over web click-streams},
  Author                   = {Li, H.-F.a and Lee, S.-Y.a and Shan, M.-K.b },
  Year                     = {2005},
  Note                     = {cited By (since 1996)8},
  Pages                    = {326-329},
  Volume                   = {2005},

  Abstract                 = {Online, single-pass mining Web click streams poses some interesting computational issues, such as unbounded length of streaming data, possibly very fast arrival rate, and just one scan over previously arrived click-sequences. In this paper, we propose a new, single-pass algorithm, called DSM-TKP (Data Stream Mining for Top-K Path traversal patterns), for mining top-k path traversal patterns, where k is the desired number of path traversal patterns to be mined. An effective summary data structure called TKP-forest (Top-K Path forest) is used to maintain the essential information about the top-k path traversal patterns of the click-stream so far. Experimental studies show that DSM-TKP algorithm uses stable memory usage and makes only one pass over the streaming data. Ã‚Â© 2005 IEEE.},
  Affiliation              = {Department of Computer Science and Information Engineering, National Chiao-Tung University, Hsinchu 300, Taiwan; Department of Computer Science, National Chengchi University, Taipei 116, Taiwan},
  Art_number               = {1517866},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2005 IEEE/WIC/ACM InternationalConference on Web Intelligence, WI 2005},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {newer version in Li2009b.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33748870796&partnerID=40&md5=9abb768c6224914a46e5762acc4bc703}
}

@InProceedings{Li2005d,
  Title                    = {{DSM-TKP: Mining Top-K Path Traversal Patterns over Web Click-Streams}},
  Author                   = {Li, Hua-Fu and Lee, Suh-Yin and Shan, Man-Kwan},
  Booktitle                = {The 2005 IEEE/WIC/ACM International Conference on Web Intelligence (WI'05)},
  Year                     = {2005},
  Month                    = sep,
  Pages                    = {326--329},
  Publisher                = {IEEE},

  Doi                      = {10.1109/WI.2005.56},
  ISBN                     = {0-7695-2415-X},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2005b},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1092358.1092495}
}

@Conference{Li2004a,
  Title                    = {Mining frequent closed structures in streaming melody sequences},
  Author                   = {Li, H.-F.a and Lee, S.-Y.a and Shan, M.-K.b },
  Year                     = {2004},
  Note                     = {cited By (since 1996)0},
  Pages                    = {2031-2034},
  Volume                   = {3},

  Abstract                 = {In this paper, we study the problem of mining frequent closed structures in a continuous, infinite-sized, and fast changing music melody stream. By modeling a music melody as a sequence of chord-sets, we propose an efficient algorithm FCS-stream (Frequent Closed Structures of streaming melody sequences) for incremental mining of frequent closed structures in one scan of the continuous stream of chord-set sequences. An extended prefix-tree structure called TCS-tree (Temporal Closed Structure tree) is developed for storing compact, essential information about the frequent closed structures of the stream. Results from our theoretical analysis and experimental studies with synthetic data show that algorithm FCS-stream satisfies the main performance requirements, namely, single-pass, bounded memory, and real-time, for data stream mining.},
  Affiliation              = {Department of Computer Science, National Chiao-Tung University, Hsinchu, Taiwan; Department of Computer Science, National Cheng Chi University, Taipei, Taiwan},
  Document_type            = {Conference Paper},
  Journal                  = {2004 IEEE International Conference on Multimedia and Expo (ICME)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an efficient algorithm FCS-stream (Frequent Closed Structures of streaming melody sequences) for incremental mining of frequent closed structures in one scan of the continuous stream of chord-set sequences. FCS-stream satisfies the main performance requirements, namely, single-pass, bounded memory, and real-time, for data stream mining. Music stream analysis again, The same author has a different algorithm for the same problem in another paper. 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-11244347661&partnerID=40&md5=f4222d04a775d178205703adf38dad31}
}

@Article{Li2004b,
  Title                    = {{An Efficient Algorithm for Mining Frequent Itemsets over the entire History of Data Streams}},
  Author                   = {Li, Hua-fu and Lee, Suh-yin and Shan, Man-kwan},
  Journal                  = {IN PROC. OF FIRST INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY IN DATA STREAMS},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A data stream is a continuous, huge, fast changing, rapid, infinite sequence of data elements. The nature of streaming data makes it essential to use online algorithms which require only one scan over the data for knowledge discovery. In this paper, we propose a new single-pass algorithm, called DSM-FI (Data Stream Mining for Frequent Itemsets), to mine all frequent itemsets over the entire history of data streams. DSM-FI has three major features, namely single streaming data scan for counting itemsets ’ frequency information, extended prefix-tree-based compact pattern representation, and top-down frequent itemset discovery scheme. Our performance study shows that DSM-FI outperforms the well-known algorithm Lossy Counting in the same streaming environment},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {Same algorithm is talked about in Li2008b, which I guess is the better abstract.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.81.9955}
}

@Article{Li2008b,
  Title                    = {DSM-FI: An efficient algorithm for mining frequent itemsets in data streams},
  Author                   = {Li, H.-F.a and Shan, M.-K.b and Lee, S.-Y.c },
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2008},
  Note                     = {cited By (since 1996)18},
  Number                   = {1},
  Pages                    = {79-97},
  Volume                   = {17},

  Abstract                 = {Online mining of data streams is an important data mining problem with broad applications. However, it is also a difficult problem since the streaming data possess some inherent characteristics. In this paper, we propose a new single-pass algorithm, called DSM-FI (data stream mining for frequent itemsets), for online incremental mining of frequent itemsets over a continuous stream of online transactions. According to the proposed algorithm, each transaction of the stream is projected into a set of sub-transactions, and these sub-transactions are inserted into a new in-memory summary data structure, called SFI-forest (summary frequent itemset forest) for maintaining the set of all frequent itemsets embedded in the transaction data stream generated so far. Finally, the set of all frequent itemsets is determined from the current SFI-forest. Theoretical analysis and experimental studies show that the proposed DSM-FI algorithm uses stable memory, makes only one pass over an online transactional data stream, and outperforms the existing algorithms of one-pass mining of frequent itemsets. Ã‚Â© Springer-Verlag London Limited 2007.},
  Affiliation              = {Department of Computer Science, Kainan University, Taoyuan, Taiwan; Department of Computer Science, National Chengchi University, Taipei, Taiwan; Department of Computer Science, National Chiao-Tung University, Hsinchu, Taiwan},
  Author_keywords          = {Data mining; Data streams; Frequent itemsets; Landmark window; Single-pass algorithm},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new single-pass algorithm, called DSM-FI (data stream mining for frequent itemsets), for online incremental mining of frequent itemsets over a continuous stream of online transactions. Experimental studies show that the proposed DSM-FI algorithm uses stable memory, makes only one pass over an online transactional data stream, and outperforms the existing algorithms of one-pass mining of frequent itemsets. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-54049106902&partnerID=40&md5=91fc0de8f6b0f805d60790652eb7affc}
}

@Conference{Li2006e,
  Title                    = {Online mining of frequent query trees over XML data streams},
  Author                   = {Li, H.-F.a and Shan, M.-K.b and Lee, S.-Y.a },
  Year                     = {2006},
  Note                     = {cited By (since 1996)3},
  Pages                    = {959-960},

  Abstract                 = {In this paper, we proposed an online algorithm, called FQT-Stream (Frequent Query Trees of Streams), to mine the set of all frequent tree patterns over a continuous XML data stream. A new numbering method is proposed to represent the tree structure of a XML query tree. An effective sub-tree numeration approach is developed to extract the essential information from the XML data stream. The extracted information is stored in an effective summary data structure. Frequent query trees are mined from the current summary data structure by a depth-first-search manner.},
  Affiliation              = {Department of Computer Science, National Chiao-Tung University, Hsinchu, 300, Taiwan; Department of Computer Science, National Chengchi University, Taipei, 116, Taiwan},
  Author_keywords          = {Data streams; Frequent query trees; Online mining; Web mining; XML},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 15th International Conference on World Wide Web},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an online algorithm, called FQT-Stream (Frequent Query Trees of Streams), to mine the set of all frequent tree patterns over a continuous XML data stream. The extracted information is stored in an effective summary data structure. Frequent query trees are mined from the current summary data structure by a depth-first-search manner. Weak abstract. nothing about experimentation or results. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34250621417&partnerID=40&md5=588397e657a96d4f2684cbb011a3aac7}
}

@InProceedings{Li2006g,
  Title                    = {{Online mining of frequent query trees over XML data streams}},
  Author                   = {Li, Hua-Fu and Shan, Man-Kwan and Lee, Suh-Yin},
  Booktitle                = {Proceedings of the 15th international conference on World Wide Web - WWW '06},
  Year                     = {2006},

  Address                  = {New York, New York, USA},
  Month                    = may,
  Pages                    = {959},
  Publisher                = {ACM Press},

  Abstract                 = {In this paper, we proposed an online algorithm, called FQT-Stream (Frequent Query Trees of Streams), to mine the set of all frequent tree patterns over a continuous XML data stream. A new numbering method is proposed to represent the tree structure of a XML query tree. An effective sub-tree numeration approach is developed to extract the essential information from the XML data stream. The extracted information is stored in an effective summary data structure. Frequent query trees are mined from the current summary data structure by a depth-first-search manner.},
  Doi                      = {10.1145/1135777.1135964},
  ISBN                     = {1595933239},
  Keywords                 = {XML,data streams,frequent query trees,online mining,web mining},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2006e},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1135777.1135964}
}

@Article{Li2009b,
  Title                    = {Mining Top-K path traversal patterns over streaming Web click-sequences},
  Author                   = {Li, H.-F.a b and Lee, S.-Y.b },
  Journal                  = {Journal of Information Science and Engineering},
  Year                     = {2009},
  Note                     = {cited By (since 1996)2},
  Number                   = {4},
  Pages                    = {1121-1133},
  Volume                   = {25},

  Abstract                 = {Online, one-pass mining Web click streams poses some interesting computational issues, such as unbounded length of streaming data, possibly very fast arrival rate, and just one scan over previously arrived Web click-sequences. In this paper, we propose a new, single-pass algorithm, called DSM-TKP (Data Stream Mining for Top-K. Path traversal patterns), for mining a set of top-k path traversal patterns, where k is the desired number of path traversal patterns to be mined. An effective summary data structure, called TKP-forest (a forest of Top-K Path traversal patterns), is used to maintain the essential information about the top-k path traversal patterns generated so far. Experimental studies show that the proposed DSM-TKP algorithm uses stable memory usage and makes only one pass over the streaming Web click-sequences.},
  Affiliation              = {Department of Computer Science, Kainan University, Taoyuan, 338, Taiwan; Department of Computer Science, National Chiao Tung University, Hsinchu, 300, Taiwan},
  Author_keywords          = {Data streams; Path traversal patterns; Single-pass mining; Top-K pattern mining; Web usage mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new, single-pass algorithm, called DSM-TKP (Data Stream Mining for Top-K. Path traversal patterns), for mining a set of top-k path traversal patterns, where k is the desired number of path traversal patterns to be mined. Experimental studies show that the proposed DSM-TKP algorithm uses stable memory usage and makes only one pass over the streaming Web click-sequences. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-69549122284&partnerID=40&md5=d348dada2de5a7d359f61dca367f5e9f}
}

@Article{Li2012a,
  Title                    = {Predicting sequential pattern changes in data streams},
  Author                   = {Li, I.-H.a b and Huang, J.-Y.a and Liao, I.-E.a },
  Journal                  = {International Journal of Innovative Computing, Information and Control},
  Year                     = {2012},
  Note                     = {cited By (since 1996)2},
  Number                   = {1 A},
  Pages                    = {285-302},
  Volume                   = {8},

  Abstract                 = {Data streams are utilized in an increasing number of real-time information technology applications. Unlike traditional datasets, data streams are temporally ordered, fast changing and massive. Due to their tremendous volume, performing multiple scans of the entire data stream is impractical. Thus, traditional sequential pattern mining algorithms cannot be applied. Accordingly, the present study proposes a new sequential pattern mining model for predicting sequential pattern changes in data streams. The experimental results show that the prediction performance of the proposed model is better than that of two linear regression-based models. Ã‚Â© 2012 ICIC International.},
  Affiliation              = {Department of Computer Science and Engineering, National Chung Hsing University, No. 250, Kuo Kuang Rd, Taichung 402, Taiwan; Department of Information Networking and System Administration, Ling Tung University, No. 1, Ling Tung Rd, Taichung 408, Taiwan},
  Author_keywords          = {Data streams; Pattern changes; Prediction; Sequential pattern mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {the present study proposes a new sequential pattern mining model for predicting sequential pattern changes in data streams. The experimental results show that the prediction performance of the proposed model is better than that of two linear regression-based models. A little weak on the details about their new model. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84863023463&partnerID=40&md5=dae9f09e1bc8b2b2736126be5ae9370e}
}

@Article{Li2011a,
  Title                    = {Top-k-FCI: mining top-k frequent closed itemsets in data streams},
  Author                   = {Li, J. and Gong, S.},
  Journal                  = {Journal of Computational Information Systems},
  Year                     = {2011},
  Note                     = {cited By (since 1996)3},
  Number                   = {13},
  Pages                    = {4819-4826},
  Volume                   = {7},

  Abstract                 = {With the generation and analysis of stream data, such as network monitoring in real time, log records, click streams, a great deal of attention has been concerned on data streams mining in the field of data mining. In the process of the data streams mining, it is more reasonable to ask users to set a bound on the result size. Therefore, in this paper, an real-time single-pass algorithm, called Top-k-FCI (top-K frequent closed itemsets of data streams), is proposed for mining top-K closed itemsets from data streams efficiently. A novel algorithm, called can (T) (candidate itemset of the T), is developed for mining the essential candidate of closed itemsets generated so far. Experimental results show that the proposed Top-k-FCI algorithm is an efficient method for mining top-K frequent itemsets from data streams. Ã‚Â© 2011 Binary Information Press December, 2011.},
  Affiliation              = {Henan University, Kaifeng 475001, China},
  Author_keywords          = {Data mining; Data streams; Frequent closed Itemset; Top-K},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Cao2012},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-83255175010&partnerID=40&md5=941da6cdfc03b60b801fe82ecae9405b}
}

@Article{Li2012e,
  Title                    = {{Mining Recurring Concept Drifts with Limited Labeled Streaming Data}},
  Author                   = {Li, Peipei and Wu, Xindong and Hu, Xuegang},
  Journal                  = {ACM Transactions on Intelligent Systems and Technology},
  Year                     = {2012},

  Month                    = feb,
  Number                   = {2},
  Pages                    = {1--32},
  Volume                   = {3},

  Abstract                 = {Tracking recurring concept drifts is a significant issue for machine learning and data mining that frequently appears in real-world stream classification problems. It is a challenge for many streaming classification algorithms to learn recurring concepts in a data stream environment with unlabeled data, and this challenge has received little attention from the research community. Motivated by this challenge, this article focuses on the problem of recurring contexts in streaming environments with limited labeled data. We propose a semi-supervised classification algorithm for data streams with REcurring concept Drifts and Limited LAbeled data, called REDLLA, in which a decision tree is adopted as the classification model. When growing a tree, a clustering algorithm based on k-means is installed to produce concept clusters and unlabeled data are labeled in the method of majority-class at leaves. In view of deviations between history and new concept clusters, potential concept drifts are distinguished and recurring concepts are maintained. Extensive studies on both synthetic and real-world data confirm the advantages of our REDLLA algorithm over three state-of-the-art online classification algorithms of CVFDT, DWCDS, and CDRDT and several known online semi-supervised algorithms, even in the case with more than 90% unlabeled data.},
  Doi                      = {10.1145/2089094.2089105},
  ISSN                     = {21576904},
  Keywords                 = {Data stream,clustering,concept drift,decision tree},
  Owner                    = {alex},
  Publisher                = {ACM},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2012b},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2089094.2089105}
}

@Article{Li2010,
  Title                    = {Mining recurring concept drifts with limited labeled streaming data},
  Author                   = {Li, P.a and Wu, X.b and Hu, X.a },
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},
  Note                     = {cited By (since 1996)4},
  Pages                    = {241-252},
  Volume                   = {13},

  Abstract                 = {Tracking recurring concept drifts in data streams is a significant and challenging issue for machine learning and data mining that frequently appears in real world stream classification problems. However, it has received little attention from the research community. Motivated by this, we propose a Semi-supervised classification algorithm for data streams with REcurring concept Drifts and Limited LAbeled data, called REDLLA, in which, a decision tree is adopted as the classification model. When growing a tree, a clustering algorithm based on k-Means is installed to produce concept clusters and label unlabeled data at leaves. In view of deviations between history concept clusters and new ones, potential concept drifts are distinguished and recurring concepts are maintained. Extensive studies on both synthetic and real-world data confirm the advantages of our REDLLA algorithm over two state-of-the-art online classification algorithms and several known online semi-supervised algorithms, even in the case with more than 90% unlabeled data. Ã‚Â© 2010 Peipei Li, Xindong Wu, and Xuegang Hu.},
  Affiliation              = {School of Computer Science and Information Engineering, Hefei University of Technology, 230009, China; Department of Computer Science, University of Vermont, Vermont, 05405, United States},
  Author_keywords          = {Clustering; Concept drift; Data stream; Decision tree},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Newer and better version in Li2012b},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84858710401&partnerID=40&md5=6893c43a264bbffb1e692dd7917dec7b}
}

@Article{Li2012b,
  Title                    = {Mining recurring concept drifts with limited labeled streaming data},
  Author                   = {Li, P.a and Wu, X.a b and Hu, X.a },
  Journal                  = {ACM Transactions on Intelligent Systems and Technology},
  Year                     = {2012},
  Note                     = {cited By (since 1996)8},
  Number                   = {2},
  Volume                   = {3},

  Abstract                 = {Tracking recurring concept drifts is a significant issue for machine learning and data mining that frequently appears in real-world stream classification problems. It is a challenge for many streaming classification algorithms to learn recurring concepts in a data stream environment with unlabeled data, and this challenge has received little attention from the research community. Motivated by this challenge, this article focuses on the problem of recurring contexts in streaming environments with limited labeled data. We propose a semi-supervised classification algorithm for data streams with REcurring concept Drifts and Limited LAbeled data, called REDLLA, in which a decision tree is adopted as the classification model. When growing a tree, a clustering algorithm based on k-means is installed to produce concept clusters and unlabeled data are labeled in the method of majority-class at leaves. In view of deviations between history and new concept clusters, potential concept drifts are distinguished and recurring concepts are maintained. Extensive studies on both synthetic and real-world data confirm the advantages of our REDLLA algorithm over three state-of-the-art online classification algorithms of CVFDT, DWCDS, and CDRDT and several known online semi-supervised algorithms, even in the case with more than 90% unlabeled data. Ã‚Â© 2012 ACM.},
  Affiliation              = {School of Computer Science and Information Engineering, Hefei University of Technology, China; Department of Computer Science, University of Vermont, Vermont, United States},
  Art_number               = {29},
  Author_keywords          = {Clustering; Concept drift; Data stream; Decision tree},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a semi-supervised classification algorithm for data streams with REcurring concept Drifts and Limited LAbeled data, called REDLLA, in which a decision tree is adopted as the classification model. Extensive studies on both synthetic and real-world data confirm the advantages of our REDLLA algorithm over three state-of-the-art online classification algorithms of CVFDT, DWCDS, and CDRDT and several known online semi-supervised algorithms, even in the case with more than 90% unlabeled data. 1,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84863283905&partnerID=40&md5=5d9a1de0c20462211e5317f0576bb1e0}
}

@Conference{Li2005c,
  Title                    = {A real-time architecture for NIDS based on sequence analysis},
  Author                   = {Li, Q.-H.a b and Zhao, F.a b and Zhao, Y.-B.a b },
  Year                     = {2005},
  Note                     = {cited By (since 1996)1},
  Pages                    = {1893-1896},

  Abstract                 = {Due to customers' demands, Network Intrusion Detection Systems (NIDS) are required more real time. Since traditional intelligent NIDS are constructed on the basis of historical network data and system logs, they are expensive and not real time in a network stream environment. This paper presents an improved real time model that based on sequence mining to accelerate the accuracy and efficiency. In this paper, multidimensional item set is used to describes network events, sliding window is used to gather network data stream, and sequence mining algorithms are applied to discover intrusions from normal network stream. Analysis and study on this model indicate that it provide a more accurate and efficient way to building real-time NIDS. Ã‚Â© 2005 IEEE.},
  Affiliation              = {School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan 430074, China; National High Performance Computing Center(WuHan), Wuhan 430074, China},
  Author_keywords          = {IDS; Intrusion; Real time; Sequence; Sliding window},
  Document_type            = {Conference Paper},
  Journal                  = {2005 International Conference on Machine Learning and Cybernetics, ICMLC 2005},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. This paper presents an improved real time model that based on sequence mining to accelerate the accuracy and efficiency. Multidimensional item set is used to describes network events, sliding window is used to gather network data stream, and sequence mining algorithms are applied to discover intrusions from normal network stream. 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-28444448363&partnerID=40&md5=45194195aed65417212af37d960a98ca}
}

@Misc{Li,
  Title                    = {{Edited by}},

  Author                   = {Li, Tao and Perng, Charles and Wang, Haixun and Domeniconi, Carlotta},

  __markedentry            = {[Alexander:]},
  Abstract                 = {aims to bring together researchers from both industry and academia with diverse backgrounds: data mining, machine learning, database, statistical analysis, and application knowledge to foster interactions, to propose new ideas, to identify promising technologies, to create a forum for discussing recent advances, to better understand the practical challenges in applications, and to inspire new research directions. Many real-world applications deal with huge amounts of temporal data. Examples include alarms/events and performance measurements generated by distributed computer systems and by telecommunication networks, the web server logs, online transaction logs, financial data, workflow process logs, and sensor data collected from sensor networks. Conventionally, temporal data is classified to either categorical event streams or numerical time series and both types have been intensively studied in data mining and statistics. However, several previously less emphasized aspects of temporal data have proven their importance in emerging applications and posed several challenges calling for more research. The major topics of the workshop include but are not limited to: Temporal data benchmarking Temporal pattern discovery Temporal data clustering Anomaly and change detection of streaming data Prediction for temporal data Temporal data characterization and analysis Statistical analysis of temporal data Accommodating domain knowledge in the temporal mining process, Complexity, efficiency and s},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Just an invitation to a workshop.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.161.6815}
}

@Conference{Li2012c,
  Title                    = {Online windowed subsequence matching over probabilistic sequences},
  Author                   = {Li, Z. and Ge, T.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)3},
  Pages                    = {277-288},

  Abstract                 = {Windowed subsequence matching over deterministic strings has been studied in previous work in the contexts of knowledge discovery, data mining, and molecular biology. However, we observe that in these applications, as well as in data stream monitoring, complex event processing, and time series data processing in which streams can be mapped to strings, the strings are often noisy and probabilistic. We study this problem in the online setting where efficiency is paramount. We first formulate the query semantics, and propose an exact algorithm. Then we propose a randomized approximation algorithm that is faster and, in the mean time, provably accurate. Moreover, we devise a filtering algorithm to further enhance the efficiency with an optimization technique that is adaptive to sequence stream contents. Finally, we propose algorithms for patterns with negations. In order to verify the algorithms, we conduct a systematic empirical study using three real datasets and some synthetic datasets. Ã‚Â© 2012 ACM.},
  Affiliation              = {University of Massachusetts, Lowell, MA, United States},
  Author_keywords          = {online; subsequence matching; uncertain sequence},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Li2012d},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84862661901&partnerID=40&md5=d025c5b5f8e81dc977da196b1b6a658e}
}

@InProceedings{Li2012d,
  Title                    = {{Online windowed subsequence matching over probabilistic sequences}},
  Author                   = {Li, Zheng and Ge, Tingjian},
  Booktitle                = {Proceedings of the 2012 international conference on Management of Data - SIGMOD '12},
  Year                     = {2012},

  Address                  = {New York, New York, USA},
  Month                    = may,
  Pages                    = {277},
  Publisher                = {ACM Press},

  Abstract                 = {Windowed subsequence matching over deterministic strings has been studied in previous work in the contexts of knowledge discovery, data mining, and molecular biology. However, we observe that in these applications, as well as in data stream monitoring, complex event processing, and time series data processing in which streams can be mapped to strings, the strings are often noisy and probabilistic. We study this problem in the online setting where efficiency is paramount. We first formulate the query semantics, and propose an exact algorithm. Then we propose a randomized approximation algorithm that is faster and, in the mean time, provably accurate. Moreover, we devise a filtering algorithm to further enhance the efficiency with an optimization technique that is adaptive to sequence stream contents. Finally, we propose algorithms for patterns with negations. In order to verify the algorithms, we conduct a systematic empirical study using three real datasets and some synthetic datasets. Ã‚Â© 2012 ACM.},
  Doi                      = {10.1145/2213836.2213868},
  ISBN                     = {9781450312479},
  Keywords                 = {online,subsequence matching,uncertain sequence},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They work on time series data processing in which streams can be mapped to strings. They propose a randomized approximation algorithm, a filtering algorithm and algorithms for patterns with negations. They test empirically on three real datasets and some synthetical. 3,4},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2213836.2213868}
}

@InProceedings{Li2006b,
  Title                    = {{A Unifying Method for Outlier and Change Detection from Data Streams}},
  Author                   = {Li, Zhi and Ma, Hong and Zhou, Yongdao},
  Booktitle                = {2006 International Conference on Computational Intelligence and Security},
  Year                     = {2006},
  Month                    = nov,
  Pages                    = {580--585},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Detection of outliers and identification of change points in a data stream are two very exciting topics in the area of data mining. This paper explores the relationship between these two issues, and presents a unifying method for dealing with both of them. This approach is based on a probabilistic model of time series whose parameters are updated adaptively. The forward and backward prediction errors over a sliding window are used to represent the deviation extent of an outlier and the change degree of a change point. Unlike former approaches, the present one uses fuzzy partition method and fuzzy decision principle to alarm possible outliers and changes, which is more appropriate for online and interactive data mining from data streams. Simulation results confirm the effectiveness of the proposed method},
  Doi                      = {10.1109/ICCIAS.2006.294202},
  ISBN                     = {1-4244-0604-8},
  Keywords                 = {Autoregressive processes,Data mining,Event detection,Fuzzy neural networks,Hidden Markov models,Intrusion detection,Mathematics,Monitoring,Statistical analysis,Statistics,backward prediction error,change point identification,data mining,data stream change detection,forward prediction error,fuzzy decision principle,fuzzy partition method,fuzzy systems,interactive data mining,online data mining,outlier detection,probabilistic model,sliding window,time series,unifying method},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present a unifying method for dealing with detection of outliers and identification of change points in a data stream. Simulation results confirm the effectiveness of the proposed method Very weak abstract, no details about experimentation, nothing about algorithm 1,6},
  Shorttitle               = {Computational Intelligence and Security, 2006 Inte},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4072155}
}

@Misc{Lian2008,
  Title                    = {{Efficient Similarity Search over Future Stream Time Series}},

  Author                   = {Lian, Xiang and Chen, Lei},
  Year                     = {2008},

  __markedentry            = {[Alexander:]},
  Abstract                 = {With the advance of hardware and communication technologies, stream time series is gaining ever-increasing attention due to its importance in many applications such as financial data processing, network monitoring, Web click-stream analysis, sensor data mining, and anomaly detection. For all of these applications, an efficient and effective similarity search over stream data is essential. Because of the unique characteristics of the stream, for example, data are frequently updated and real-time response is required, the previous approaches proposed for searching through archived data may not work in the stream scenarios. Especially, in the cases where data often arrive periodically for various reasons (for example, the communication congestion or batch processing), queries on such incomplete time series or even future time series may result in inaccuracy using traditional approaches. Therefore, in this paper, we propose three approaches, polynomial, Discrete Fourier Transform (DFT), and probabilistic, to predict the unknown values that have not arrived at the system and answer similarity queries based on the predicted data. We also apply efficient indexes, that is, a multidimensional hash index and a B þ-tree, to facilitate the prediction and similarity search on future time series, respectively. Extensive experiments demonstrate the efficiency and effectiveness of our methods for prediction and answering querie},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose three approaches, polynomial, Discrete Fourier Transform (DFT), and probabilistic, to predict the unknown values that have not arrived at the system and answer similarity queries based on the predicted data. We also apply efficient indexes, that is, a multidimensional hash index and a B þ-tree, to facilitate the prediction and similarity search on future time series, respectively. Extensive experiments demonstrate the efficiency and effectiveness of our methods for prediction and answering queries. 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.140.4254}
}

@Article{Liang2007,
  Title                    = {Continuous adaptive mining the thin skylines over evolving data stream},
  Author                   = {Liang, G.a and Su, L.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {254-264},
  Volume                   = {4882 LNCS},

  Abstract                 = {Skyline queries, which return the objects that are better than or equal in all dimensions and better in at least one dimension, are useful in many decision making and real-time monitor applications. With the number of dimensions increasing and continuous large volume data arriving, mining the thin skylines over data stream under control of losing quality is a more meaningful problem. In this paper, firstly, we propose a novel concept, called thin skyline, which uses a skyline object that represents its nearby skyline neighbors within e-distance (acceptable difference). Then, two algorithms are developed which prunes the skyline objects within the acceptable difference and adopts correlation coefficient to adjust adaptively thin skyline query quality. Furthermore, our experimental performance study shows that the proposed methods are both efficient and effective. Ã‚Â© Springer-Verlag Berlin Heidelberg 2007.},
  Affiliation              = {Computer Engineering Department, Shenzhen Polytechnic, Shenzhen 518055, China; School of Computer Science, National University of Defense Technology, Changsha 410073, China},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a novel concept, called thin skyline, which uses a skyline object that represents its nearby skyline neighbors within e-distance (acceptable difference). Then, two algorithms are developed which prunes the skyline objects within the acceptable difference and adopts correlation coefficient to adjust adaptively thin skyline query quality. Furthermore, our experimental performance study shows that the proposed methods are both efficient and effective. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38149070837&partnerID=40&md5=4e5f4663454107ad56eaf3d0e3f25697}
}

@Misc{Liao,
  Title                    = {{c â—‹ 2010 Binbin LiaoANOMALY DETECTION IN GPS DATA BASED ON VISUAL ANALYTICS BY}},

  Author                   = {Liao, Binbin},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Liao2010a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.225.1637}
}

@InProceedings{Liao2010,
  Title                    = {{Anomaly detection in GPS data based on visual analytics}},
  Author                   = {Liao, Zicheng and Yu, Yizhou and Chen, Baoquan},
  Booktitle                = {2010 IEEE Symposium on Visual Analytics Science and Technology},
  Year                     = {2010},
  Month                    = oct,
  Pages                    = {51--58},
  Publisher                = {IEEE},

  Abstract                 = {Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure.},
  Doi                      = {10.1109/VAST.2010.5652467},
  ISBN                     = {978-1-4244-9488-0},
  Keywords                 = {Data models,Data visualization,Feature evaluation and selection,GPS Visual Analytics System,Global Positioning System,H.1.2 [Models and Principles]: User/Machine System,H.5.2 [Information Interfaces and Presentation]: U,Histograms,Humans,I.5.2 [Pattern Recognition]: Design Methodology-Pa,Machine learning,Training,anomaly detection,conditional random field model,data analysis,data driven modeling,data flow analysis,data visualisation,domain specific expertise,graphical user interfaces,high level intelligence,human computer interaction,information extraction,information retrieval,interactive user interface,learning (artificial intelligence),machine learning,real time data behavior,visual databases,visualization},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Liao2010a},
  Shorttitle               = {Visual Analytics Science and Technology (VAST), 20},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5652467}
}

@Conference{Liao2010a,
  Title                    = {Anomaly detection in GPS data based on visual analytics},
  Author                   = {Liao, Z.a and Yu, Y.a and Chen, B.b },
  Booktitle                = {2010 IEEE Symposium on Visual Analytics Science and Technology},
  Year                     = {2010},
  Note                     = {cited By (since 1996)8},
  Pages                    = {51-58},

  Abstract                 = {Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure. Ã‚Â©2010 IEEE.},
  Affiliation              = {University of Illinois, Urbana-Champaign, IL, United States; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China},
  Art_number               = {5652467},
  Author_keywords          = {H.1.2 [models and principles]: user/Machine systems - human information processing; H.5.2 [information interfaces and presentation]: user interfaces - graphics user interfaces; I.5.2 [pattern recognition]: design methodology - pattern analysis, feature evaluation and selection},
  Document_type            = {Conference Paper},
  Journal                  = {VAST 10 - IEEE Conference on Visual Analytics Science and Technology 2010, Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream. Mix of ML and human expertise. no experimentation, but rather a presentation of their system. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650933347&partnerID=40&md5=1b439cbeb56bf3e677cfb0d8c79170dd}
}

@InProceedings{Li-li2009,
  Title                    = {{Real-time Detection for Anomaly Data in Microseismic Monitoring System}},
  Author                   = {Li-li, Liu and Chang-peng, Ji},
  Booktitle                = {2009 International Conference on Computational Intelligence and Natural Computing},
  Year                     = {2009},
  Month                    = jun,
  Pages                    = {307--310},
  Publisher                = {IEEE},
  Volume                   = {2},

  Abstract                 = {Microseismic monitoring means to records microseismic activities caused by the changes of the rock physical properties continuously through the high sensitivity seismic sensor placed in mine. How to make real-time detection of abnormal data in mine microseisms positioning system is a extremely important task. Forecast model and mechanism of data stream in the mine microcosmic monitoring system are given through the linear self-regression analysis. Based on this prediction model, a detection method of abnormal data is proposed. This method detects whether real-time data is abnormal by calculating the ratio of real-time forecast error and average forecast error and making a comparison between the ratio and predefined threshold. Experimental results verified correctness and effectiveness of the prediction model to show that the model can realize real-time detection of abnormal event in mine earthquake.},
  Doi                      = {10.1109/CINC.2009.44},
  ISBN                     = {978-0-7695-3645-3},
  Keywords                 = {Acoustic noise,Data mining,Earthquakes,Event detection,Interference,Intrusion detection,Linear regression,Monitoring,Predictive models,Real time systems,abnormal event detection,anomaly data,anomaly data detection,anomaly events,condition monitoring,high sensitivity seismic sensor,linear self-regression analysis,microseismic activities,microseismic monitoring,microseismic monitoring system,microsensors,mine earthquake,mine microseisms positioning system,real-time detection,real-time prediction mechanism,regression analysis,rock physical properties,seismology},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Based on this prediction model, a detection method of abnormal data is proposed. This method detects whether real-time data is abnormal by calculating the ratio of real-time forecast error and average forecast error and making a comparison between the ratio and predefined threshold. Experimental results verified correctness and effectiveness of the prediction model to show that the model can realize real-time detection of abnormal event in mine earthquake. Not sure if this is relevant for us, but it seems to be ML. 1,4,6},
  Shorttitle               = {Computational Intelligence and Natural Computing, },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5230963}
}

@Misc{Lin,
  Title                    = {{(Not) Finding Rules in Time Series: A Surprising Result with Implications for Previous and Future Research}},

  Author                   = {Lin, Jessica and Keogh, Eamonn},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Lin2003},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.386.7950}
}

@Article{Lin2003b,
  Title                    = {{Clustering of streaming time series is meaningless}},
  Author                   = {Lin, Jessica and Keogh, Eamonn},
  Journal                  = {IN PROC. OF THE SIGMOD WORKSHOP IN DATA MINING AND KNOWLEDGE DISCOVERY},
  Year                     = {2003},
  Pages                    = {56 -- 65},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Lin2003a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.386.8095}
}

@Conference{Lin2003,
  Title                    = {(Not) finding rules in time series: A surprising result with implications for previous and future research},
  Author                   = {Lin, J. and Keogh, E. and Truppel, W.},
  Year                     = {2003},
  Note                     = {cited By (since 1996)2},
  Pages                    = {55-61},
  Volume                   = {1},

  Abstract                 = {Time series data is perhaps the most frequently encountered type of data examined by the data mining community. Clustering is perhaps the most frequently used data mining algorithm, being useful in it's own right as an exploratory technique, and also as a subroutine in more complex data mining algorithms such as rule discovery, indexing, summarization, anomaly detection, and classification. Given these two facts, it is hardly surprising that time series clustering has attracted much attention. The data to be clustered can be in one of two formats: many individual time series, or a single time series, from which individual time series are extracted with a sliding window. Given the recent explosion of interest in streaming data and online algorithms, the latter case has received much attention. In this work we make a surprising claim. Clustering of streaming time series is completely meaningless. More concretely, clusters extracted from streaming time series are forced to obey a certain constraint that is pathologically unlikely to be satisfied by any dataset, and because of this, the clusters extracted by any clustering algorithm are essentially random. While this constraint can be intuitively demonstrated with a simple illustration and is simple to prove, it has never appeared in the literature. An important implication of our findings is that widely used, time series rule discovery algorithms are producing random results!},
  Affiliation              = {Computer Sci. and Engineering Dept., University of California - Riverside, Riverside, CA 92521, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the International Conference on Artificial Intelligence IC-AI 2003},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {In this work we make a surprising claim. Clustering of streaming time series is completely meaningless. More concretely, clusters extracted from streaming time series are forced to obey a certain constraint that is pathologically unlikely to be satisfied by any dataset, and because of this, the clusters extracted by any clustering algorithm are essentially random. They clain clustering is meaningles on time series, but this is old, and i'm pretty sure newer research has claimed to do this.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-1642272852&partnerID=40&md5=5438713560cb1a2f990f342a83c1b628}
}

@Conference{Lin2003a,
  Title                    = {Clustering of streaming time series is meaningless},
  Author                   = {Lin, J. and Keogh, E. and Truppel, W.},
  Booktitle                = {IN PROC. OF THE SIGMOD WORKSHOP IN DATA MINING AND KNOWLEDGE DISCOVERY},
  Year                     = {2003},
  Note                     = {cited By (since 1996)10},
  Pages                    = {56-65},

  Abstract                 = {Time series data is perhaps the most frequently encountered type of data examined by the data mining community. Clustering is perhaps the most frequently used data mining algorithm, being useful in it's own right as an exploratory technique, and also as a subroutine in more complex data mining algorithms such as rule discovery, indexing, summarization, anomaly detection, and classification. Given these two facts, it is hardly surprising that time series clustering has attracted much attention. The data to be clustered can be in one of two formats: many individual time series, or a single time series, from which individual time series are extracted with a sliding window. Given the recent explosion of interest in streaming data and online algorithms, the latter case has received much attention.In this work we make a surprising claim. Clustering of streaming time series is completely meaningless. More concretely, clusters extracted from streaming time series are forced to obey a certain constraint that is pathologically unlikely to be satisfied by any dataset, and because of this, the clusters extracted by any clustering algorithm are essentially random. While this constraint can be intuitively demonstrated with a simple illustration and is simple to prove, it has never appeared in the literature.We can justify calling our claim surprising, since it invalidates the contribution of dozens of previously published papers. We will justify our claim with a theorem, illustrative examples, and a comprehensive set of experiments on reimplementations of previous work. Although the primary contribution of our work is to draw attention to the fact that an apparent solution to an important problem is incorrect and should no longer be used, we also introduce a novel method which, based on the concept of time series motifs, is able to meaningfully cluster some streaming time series datasets. Copyright 2003 ACM.},
  Affiliation              = {University of California - Riverside, Computer Science and Engineering Department, Riverside, CA 92521, United States},
  Author_keywords          = {Clustering; Data mining; Data streams; Rule discovery; Time series},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 8th ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery, DMKD '03},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They introduce a novel method which, based on the concept of time series motifs, is able to meaningfully cluster some streaming time series datasets This is old, and the paper seems mostly to do assessment of other studies, but they do introduce a novel method, so approved under uncertainty.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-26444586342&partnerID=40&md5=569c5c3e2d3fa86d621dd98c76ee287e}
}

@Article{Lin2006b,
  Title                    = {{Approximate processing of massive continuous quantile queries over high-speed data streams}},
  Author                   = {Lin, Xuemin and Xu, Jian and Zhang, Qing and Lu, Hongjun and Yu, Jeffrey Xu and Society, Ieee Computer and Zhou, Xiaofang and Yuan, Yidong},
  Journal                  = {TKDE},
  Year                     = {2006},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Lin2006a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.158.1751}
}

@Article{Lin2006,
  Title                    = {{Approximate processing of massive continuous quantile queries over high-speed data streams}},
  Author                   = {Lin, X. and Xu, J. and Zhang, Q. and Zhou, X. and Yuan, Y.},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2006},

  Month                    = may,
  Number                   = {5},
  Pages                    = {683--698},
  Volume                   = {18},

  Abstract                 = {Quantile computation has many applications including data mining and financial data analysis. It has been shown that an ε-approximate summary can be maintained so that, given a quantile query (φ,ε), the data item at rank ┌φN┐ may be approximately obtained within the rank error precision εN over all N data items in a data stream or in a sliding window. However, scalable online processing of massive continuous quantile queries with different φ and ε poses a new challenge because the summary is continuously updated with new arrivals of data items. In this paper, first we aim to dramatically reduce the number of distinct query results by grouping a set of different queries into a cluster so that they can be processed virtually as a single query while the precision requirements from users can be retained. Second, we aim to minimize the total query processing costs. Efficient algorithms are developed to minimize the total number of times for reprocessing clusters and to produce the minimum number of clusters, respectively. The techniques are extended to maintain near-optimal clustering when queries are registered and removed in an arbitrary fashion against whole data streams or sliding windows. In addition to theoretical analysis, our performance study indicates that the proposed techniques are indeed scalable with respect to the number of input queries as well as the number of items and the item arrival rate in a data stream.},
  Doi                      = {10.1109/TKDE.2006.73},
  ISSN                     = {1041-4347},
  Keywords                 = {Application software,Clustering algorithms,Computer Society,Computer applications,Computer science,Costs,Data analysis,Data mining,Query processing,Stock markets,computational complexity,data mining,data mining.,financial data analysis,high-speed data stream,massive continuous quantile query processing,online computation,quantile computation,query processing,sliding window},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Lin2006a},
  Shorttitle               = {Knowledge and Data Engineering, IEEE Transactions },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1613870}
}

@Article{Lin2006a,
  Title                    = {Approximate processing of massive continuous quantile queries over high-speed data streams},
  Author                   = {Lin, X.a b g h and Xu, J.a c i and Zhang, Q.a d j and Yu, J.X.a e k and Zhou, X.f l m n o and Yuan, Y.b p},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2006},
  Note                     = {cited By (since 1996)8},
  Number                   = {5},
  Pages                    = {683-697},
  Volume                   = {18},

  Abstract                 = {Quantile computation has many applications including data mining and financial data analysis. It has been shown that an ε-approximate summary can be maintained so that, given a quantile query (φ,ε), the data item at rank ┌φN┐ may be approximately obtained within the rank error precision εN over all N data items in a data stream or in a sliding window. However, scalable online processing of massive continuous quantile queries with different φ and ε poses a new challenge because the summary is continuously updated with new arrivals of data items. In this paper, first we aim to dramatically reduce the number of distinct query results by grouping a set of different queries into a cluster so that they can be processed virtually as a single query while the precision requirements from users can be retained. Second, we aim to minimize the total query processing costs. Efficient algorithms are developed to minimize the total number of times for reprocessing clusters and to produce the minimum number of clusters, respectively. The techniques are extended to maintain near-optimal clustering when queries are registered and removed in an arbitrary fashion against whole data streams or sliding windows. In addition to theoretical analysis, our performance study indicates that the proposed techniques are indeed scalable with respect to the number of input queries as well as the number of items and the item arrival rate in a data stream.},
  Affiliation              = {IEEE Computer Society, Australia; NICTA, School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia; Department of Computer Science, University of British Columbia, 201-2366 Main Mall, Vancouver, BC V6T 1Z4, Canada; e-Health Research Centre, CSIRO ICT Centre, Lvl 20, 300 Adelaide St, Brisbane, QLD 4000, Australia; Department of Systems Engineering and Engineering Management, Chinese University of Hong Kong, Shatin, New Territories, Hong Kong; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD 4072, Australia; School of Computer Science and Engineering, University of New South Wales (UNSW), Australia; Database Research Group, UNSW, Australia; Computer Science Department, University of British Columbia, Canada; e-Health Research Center, CSIRO ICT Center, Australia; Department of Systems Engineering and Engineering Management, Chinese University of Hong Kong, Hong Kong; University of Queensland, Australia; Australia Research Council (ARC), Research Network, Enterprise Information Infrastructure (EII), Australia; ARC Centre in Bioinformatics, Australia; National ICT Australia (NICTA), Australia; School of Computer Science and Engineering, University of New South Wales, Australia},
  Author_keywords          = {Data mining; Online computation; Query processing},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Efficient algorithms are developed to minimize the total number of times for reprocessing clusters and to produce the minimum number of clusters, respectively. The techniques are extended to maintain near-optimal clustering when queries are registered and removed in an arbitrary fashion against whole data streams or sliding windows. Experiments indicates that the proposed techniques are indeed scalable with respect to the number of input queries as well as the number of items and the item arrival rate in a data stream. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33645691628&partnerID=40&md5=d1b172468511de338244f0fedf707bae}
}

@InProceedings{Lin2012,
  Title                    = {{Research into the network security model blended of data stream mining and intrusion detection system}},
  Author                   = {Lin, Zhu and Can-Shi, Zhu},
  Booktitle                = {2012 7th International Conference on Computer Science \& Education (ICCSE)},
  Year                     = {2012},
  Month                    = jul,
  Pages                    = {496--499},
  Publisher                = {IEEE},

  Abstract                 = {In response of the fact that traditional intrusion detection systems are not able to fulfill the requirements for specific network security, such as fast processing speed, stronger defense capability, and higher real-time performance, a model of network security defense is built on the integration of data stream mining and intrusion detection; and, a data stream clustering algorithm is designed for mining in the model. Through analysis and simulation, the model turns out to be higher in detection rate and lower in false-alarming or false negative rate, thus achieving a better result.},
  Doi                      = {10.1109/ICCSE.2012.6295122},
  ISBN                     = {978-1-4673-0242-5},
  Keywords                 = {Clustering algorithms,Data Stream Mining,Data mining,Data models,Educational institutions,Intrusion Detection,Intrusion detection,Network Security,Training data,data mining,data stream clustering algorithm,data stream mining,intrusion detection system,network security model,security of data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {model of network security defense is built on the integration of data stream mining and intrusion detection; and, a data stream clustering algorithm is designed for mining in the model. Through analysis and simulation, the model turns out to be higher in detection rate and lower in false-alarming or false negative rate, thus achieving a better result. weak abstract. about intrusion detection. 1,3,4,6},
  Shorttitle               = {Computer Science \& Education (ICCSE), 2012 7th Int},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6295122}
}

@Misc{Ling,
  Title                    = {{Stream Data Classification Using Improved Fisher Discriminate Analysis}},

  Author                   = {Ling, Chen and Ling-jun, Zou and Li, Tu},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A modified Fisher discriminate analysis method for classifying stream data is presented. To satisfy the realtime demand in classifying stream data, this method defines a new criterion for Fisher discriminate analysis. Since the new criterion requires less computation and memory space, it is much faster and more suitable for online processing in stream data environment. It can overcome the problem of singular within-class scatter matrix in traditional FDA. Our algorithm speeds up the mining process while maintaining the high classification accuracy and capturing the up-todate trends in the stream. Experiments on real and synthetic data sets show that our algorithm can improve the classification accuracy and speed for stream data classification.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A modified Fisher discriminate analysis method for classifying stream data is presented. To satisfy the realtime demand in classifying stream data, this method defines a new criterion for Fisher discriminate analysis. Experiments on real and synthetic data sets show that our algorithm can improve the classification accuracy and speed for stream data classification, and capturing the up-todate trends in the stream. 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.183.7075}
}

@Conference{Liu2003,
  Title                    = {Step-by-step regression: A more efficient Alternative for polynomial multiple linear regression in stream cube},
  Author                   = {Liu, C.a and Zhang, M.a and Zheng, M.a and Chen, Y.b },
  Year                     = {2003},
  Note                     = {cited By (since 1996)1},
  Pages                    = {437-448},
  Volume                   = {2637},

  Abstract                 = {Facing tremendous and potentially infinite stream data, it is impossible to record them entirely. Thus synopses are required to be generated timely to capture the underlying model for stream management systems. Traditionally, curve fitting through Multiple Linear Regression (MLR) is a powerful and efficient modeling tool. In order to further accelerate its processing efficiency, we propose Step-by-step Regression (SR) as a more efficient alternative. As revealed in experiments, it speeds up for more than 40 times. In addition, inspired by previous work, we integrated SR into cube environment through similar compression technique to perform online analytical processing and mining over data stream. Finally, experiments show that SR not only significantly alleviates the computation pressure on the front ends of data stream management systems, but also results in a much smaller stream cube for on line analysis and real-time surveillance.},
  Affiliation              = {Sch. Electron. Eng. and Comp. Sci., Peking University, Beijing, 100871, China; Department of Computer Science, Univ. Illinois at Urbana-Champaign, Urbana, IL 110871, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose Step-by-step Regression (SR) as a more efficient alternative to tradional curve-fitting with Multiple Linear Regression (MLR) . it speeds up for more than 40 times. They then integrated SR into cube environment through similar compression technique to perform online analytical processing and mining over data stream 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-7444226341&partnerID=40&md5=ca3cb5fefd139fec30e69c25214dc94d}
}

@Article{Liu2003a,
  Title                    = {{Step-by-step regression: a more efficient alternative for polynomial multiple linear regression in stream cube}},
  Author                   = {Liu, Chao and Zhang, Ming and Zheng, Minrui and Chen, Yixin},
  Year                     = {2003},

  Month                    = apr,
  Pages                    = {437--448},

  ISBN                     = {3-540-04760-3},
  Owner                    = {alex},
  Publisher                = {Springer-Verlag},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Liu2003},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1760894.1760953}
}

@Article{Liu2008b,
  Title                    = {Online mining frequent closed itemsets over data stream},
  Author                   = {Liu, C. and Zheng, Z. and Cai, K. and Zhang, S.},
  Journal                  = {Beijing Hangkong Hangtian Daxue Xuebao/Journal of Beijing University of Aeronautics and Astronautics},
  Year                     = {2008},
  Note                     = {cited By (since 1996)1},
  Number                   = {8},
  Pages                    = {969-972},
  Volume                   = {34},

  Abstract                 = {Based on the algorithm LossCounting, a novel approach called LossyCounting_Closed (LC_Closed) for mining closed frequent itemsets over data stream was proposed. A new summary data structure called Closed-Itemsets-forest (Cl-forest) was developed for maintaining only closed frequent itemsets. The insertion and query of closed itemsets can be rapidly made based on the data structure Cl-forest, and the location of the associated historical closed itemsets in the stage of dealing with the new transaction is also facilitated by Cl-forest. Since the algorithm maintains closed itemsets online, the current closed frequent itemsets can be output in real time based on user's specified thresholds. The effectiveness of the proposed method is shown in the experimental results.},
  Affiliation              = {School of Automation Science and Electrical Engineering, Beijing University of Aeronautics and Astronautics, Beijing 100191, China},
  Author_keywords          = {Data mining; Data stream; Frequent closed itemsets; Online},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Based on the algorithm LossCounting, a novel approach called LossyCounting_Closed (LC_Closed) for mining closed frequent itemsets over data stream was proposed. Since the algorithm maintains closed itemsets online, the current closed frequent itemsets can be output in real time based on user's specified thresholds. The effectiveness of the proposed method is shown in the experimental results. 1,2,3,6 Seems very similar to Loo2005},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-51649108064&partnerID=40&md5=e8b9f22d7a6f46dd7a231f1b61126ce3}
}

@Conference{Liu2014,
  Title                    = {Online Chinese restaurant process},
  Author                   = {Liu, C.-L.a and Tsai, T.-H.b and Lee, C.-H.b },
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {591-600},

  Abstract                 = {Processing large volumes of streaming data in near-real-time is becoming increasingly important as the Internet, sensor networks and network traffic grow. Online machine learning is a typical means of dealing with streaming data, since it allows the classification model to learn one instance of data at a time. Although many online learning methods have been developed since the development of the Perceptron algorithm, existing online methods assume that the number of classes is available in advance of classification process. However, this assumption is unrealistic for large scale or streaming data sets. This work proposes an online Chinese restaurant process (CRP) algorithm, which is an online and nonparametric algorithm, to tackle this problem. This work proposes a relaxing function as part of the prior and updates the parameters with the likelihood function in terms of the consistency between the true label information and predicted result. This work presents two Gibbs sampling algorithms to perform posterior inference. In the experiments, the online CRP is applied to three massive data sets, and compared with several online learning and batch learning algorithms. One of the data sets is obtained from Wikipedia, which comprises approximately two million documents. The experimental results reveal that the proposed online CRP performs well and efficiently on massive data sets. Finally, this work proposes two methods to update the hyperparameter ÃŽÂ± of the online CRP. The first method is based on the posterior distribution of ÃŽÂ±, and the second exploits the property of online learning, namely adapting to change, to adjust ÃŽÂ± dynamically. Ã‚Â© 2014 ACM.},
  Affiliation              = {Industrial Technology Research Institute, Computational Intelligence Technology Center, Bldg. 51, 195, Sec. 4. Chung Hsing Rd., Chutung. Hsinchu, 310, Taiwan; National Chiao Tung University, Department of Computer Science, 1001 University Road, Hsinchu, 300, Taiwan},
  Author_keywords          = {adaptive learning; chinese restaurant process; nonparametric; online learning},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This work proposes an online Chinese restaurant process (CRP) algorithm, which is an online and nonparametric algorithm, to tackle this problem (online classification). In the experiments, the online CRP is applied to three massive data sets, and compared with several online learning and batch learning algorithms. The experimental results reveal that the proposed online CRP performs well and efficiently on massive data sets Very heavy abstract, but seems interesting. Good experiment details. 1,2,3,4,(5?),6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84907030846&partnerID=40&md5=696a3f10718663cd4ad9a3fba9f35724}
}

@Conference{Liu2013,
  Title                    = {Application of data stream outlier mining techniques in steam generator safety early warning system of nuclear power plant},
  Author                   = {Liu, D. and Zheng, K. and Yan, Q.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {287-290},

  Abstract                 = {Mining outliers in data streams is a popular research issue in data mining field, which can help to find outliers under abnormal condition and then corresponding measures can be taken. The security guarantee of nuclear power plant is the center topic for discussion of the development of nuclear power plant (NPP). As an important equipment of NPP, steam generator (SG) will produce large amounts of real-time data streams in the process of running every day, such as temperature streams of U-shaped tubes. Mining temperature stream outliers (TSO) of U-shaped tubes is helpful to the implementation of early warning behavior, which contributes to the safety of NPP. In this paper, the authors propose a novel algorithm for mining TSO of U-shaped tubes. By using data stream labels to mark the abnormal frequent items, the data stream is considered to be abnormal if it is marked three times continuously. The proposed algorithm is tested by experiments. And experimental results show that the algorithm has higher accuracy and better scalability. Ã‚Â© 2013 IEEE.},
  Affiliation              = {North Building NO.3, South China University of Technology, Guangzhou 510640, China},
  Art_number               = {6493723},
  Author_keywords          = {Data stream; NPP; Outlier mining; Safety early warning system},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2013 5th Conference on Measuring Technology and Mechatronics Automation, ICMTMA 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {the authors propose a novel algorithm for mining TSO (outliers) of U-shaped tubes. By using data stream labels to mark the abnormal frequent items, the data stream is considered to be abnormal if it is marked three times continuously. The proposed algorithm is tested by experiments. And experimental results show that the algorithm has higher accuracy and better scalability. algo for outlier detection in nuclear power plants. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84876527339&partnerID=40&md5=9f64ac63710c3289907f53632eafb1c7}
}

@Article{Liu2011,
  Title                    = {Methods for mining frequent items in data streams: An overview},
  Author                   = {Liu, H.a and Lin, Y.b and Han, J.c },
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2011},
  Note                     = {cited By (since 1996)33},
  Number                   = {1},
  Pages                    = {1-30},
  Volume                   = {26},

  Abstract                 = {In many real-world applications, information such as web click data, stock ticker data, sensor network data, phone call records, and traffic monitoring data appear in the form of data streams. Online monitoring of data streams has emerged as an important research undertaking. Estimating the frequency of the items on these streams is an important aggregation and summary technique for both stream mining and data management systems with a broad range of applications. This paper reviews the state-of-the-art progress on methods of identifying frequent items from data streams. It describes different kinds of models for frequent items mining task. For general models such as cash register and Turnstile, we classify existing algorithms into sampling-based, counting-based, and hashing-based categories. The processing techniques and data synopsis structure of each algorithm are described and compared by evaluation measures. Accordingly, as an extension of the general data stream model, four more specific models including time-sensitive model, distributed model, hierarchical and multi-dimensional model, and skewed data model are introduced. The characteristics and limitations of the algorithms of each model are presented, and open issues waiting for study and improvement are discussed. Ã‚Â© 2009 Springer-Verlag London Limited.},
  Affiliation              = {School of Economics and Management, Tsinghua University, 100084 Beijing, China; Information School, University of Washington, Seattle, WA 98195-2840, United States; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801, United States},
  Author_keywords          = {Data mining; Data stream; Frequent items; Mining methods and algorithms},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper reviews the state-of-the-art progress on methods of identifying frequent items from data streams classify existing algorithms into sampling-based, counting-based, and hashing-based categories. Set aside as background info},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650983135&partnerID=40&md5=0af3201f84ab8a2a2c48aecf26e334e5}
}

@InProceedings{Liu2009c,
  Title                    = {{Effects of multiple collaborated data streams in wireless sensor networks}},
  Author                   = {Liu, Li and Hong, Xiaoyan and Zhang, Jingyuan},
  Booktitle                = {Proceedings of the 47th Annual Southeast Regional Conference on - ACM-SE 47},
  Year                     = {2009},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {1},
  Publisher                = {ACM Press},

  Abstract                 = {Wireless sensor networks, in our paper, MICAz radio boards with sensors attached to them. Allow us to collect many information around us. When multiple collaborated input streams present, understanding the data with correct data fusion algorithms is important. In this paper, we will present the influences of the thresholds on data from wireless sensors. The hardware used in our project is the Berkeley mote MPR2400 and the MTS310 sensor board. The MIB600 is used as the Ethernet gateway interface for the motes. The MTS310 sensor is used successfully in the project to collect data from passing vehicles. The main topic of this project was to implement a form of machine learning by having the back end computer predict with high confidence that there is a vehicle present. The program MoteView is very efficient in configuring and surveying the motes in real time. This paper is an attempt to demonstrate the abilities of the current wireless sensor network technology.},
  Doi                      = {10.1145/1566445.1566560},
  ISBN                     = {9781605584218},
  Keywords                 = {algorithms,fault tolerance,networks,sensor,wireless protocols},
  Owner                    = {alex},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The main topic of this project was to implement a form of machine learning by having the back end computer predict with high confidence that there is a vehicle present. The program MoteView is very efficient in configuring and surveying the motes in real time. This paper is an attempt to demonstrate the abilities of the current wireless sensor network technology. Approved, but it focuses on hardware it seems. Can't tell if they developed the ML part themself or off the shelf.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1566445.1566560}
}

@Article{Liu2004,
  Title                    = {Online supervised learning for digital library},
  Author                   = {Liu, N.a and Zhang, B.b and Yan, J.c and Xi, W.d and Yan, S.b and Chen, Z.b and Bai, F.a and Ma, W.-Y.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2004},
  Note                     = {cited By (since 1996)0},
  Pages                    = {683},
  Volume                   = {3334},

  Abstract                 = {We propose an online learning algorithm for digital library. It learns from a data stream and overcomes the inherent problem of other incremental operations. Experiments on RCV1 show the superior performance of it. Ã‚Â© Springer-Verlag Berlin Heidelberg 2004.},
  Affiliation              = {Department of Mathematics, Tsinghua University, Beijing 100084, China; Microsoft Research Asia, 49 Zhichun Road, Beijing, China; LMAM, School of Mathematical Sciences, Peking University, Beijing, China; Virginia Polytechnic Institute and State University, Blacksburg, VA 24060, United States},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We propose an online learning algorithm for digital library. It learns from a data stream and overcomes the inherent problem of other incremental operations. Experiments on RCV1 show the superior performance of it. This is literally the whole abstract. Bad english, what is RCV1? 4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-35048898386&partnerID=40&md5=c23c46b7ba4fe3bd7cee847cb1be7b7c}
}

@Book{Liu2010,
  Title                    = {Kernel Adaptive Filtering: A Comprehensive Introduction},
  Author                   = {Liu, W. and PrÃƒÂ­ncipe, J.C. and Haykin, S.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)117},

  Abstract                 = {Online learning from a signal processing perspective. There is increased interest in kernel learning algorithms in neural networks and a growing need for nonlinear adaptive algorithms in advanced signal processing, communications, and controls. Kernel Adaptive Filtering is the first book to present a comprehensive, unifying introduction to online learning algorithms in reproducing kernel Hilbert spaces. Based on research being conducted in the Computational Neuro-Engineering Laboratory at the University of Florida and in the Cognitive Systems Laboratory at McMaster University, Ontario, Canada, this unique resource elevates the adaptive filtering theory to a new level, presenting a new design methodology of nonlinear adaptive filters. Covers the kernel least mean squares algorithm, kernel affine projection algorithms, the kernel recursive least squares algorithm, the theory of Gaussian process regression, and the extended kernel recursive least squares algorithm. Presents a powerful model-selection method called maximum marginal likelihood. Addresses the principal bottleneck of kernel adaptive filters-their growing structure. Features twelve computer-oriented experiments to reinforce the concepts, with MATLAB codes downloadable from the authors' Web site. Concludes each chapter with a summary of the state of the art and potential future directions for original research. Kernel Adaptive Filtering is ideal for engineers, computer scientists, and graduate students interested in nonlinear adaptive systems for online applications (applications where the data stream arrives one sample at a time and incremental optimal solutions are desirable). It is also a useful guide for those who look for nonlinear adaptive filtering methodologies to solve practical problems. Ã‚Â© 2010 John Wiley & Sons, Inc.},
  Document_type            = {Book},
  Journal                  = {Kernel Adaptive Filtering: A Comprehensive Introduction},
  Owner                    = {Alexander},
  Pages                    = {1-209},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {A book about Kernel Adaptive filtering.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84888754031&partnerID=40&md5=0ed28502c58f94b84974ab3267998ad3}
}

@Article{Liu2009,
  Title                    = {Mining frequent closed itemsets from a landmark window over online data streams },
  Author                   = {Xuejun Liu and Jihong Guan and Ping Hu},
  Journal                  = {Computers \& Mathematics with Applications },
  Year                     = {2009},
  Note                     = {Advances in Fuzzy Sets and Knowledge Discovery },
  Number                   = {6},
  Pages                    = {927 - 936},
  Volume                   = {57},

  Abstract                 = {The frequent closed itemsets determine exactly the complete set of frequent itemsets and are usually much smaller than the later. However, mining frequent closed itemsets from a landmark window over data streams is a challenging problem. To solve the problem, this paper presents a novel algorithm (called FP-CDS) that can capture all frequent closed itemsets and a new storage structure (called FP-CDS tree) that can be dynamically adjusted to reflect the evolution of itemsetsÃ¢â‚¬â„¢ frequencies over time. A landmark window is divided into several basic windows and these basic windows are used as updating units. Potential frequent closed itemsets in each basic window are mined and stored in FP-CDS tree based on some proposed strategies. Extensive experiments are conducted to validate the proposed method.},
  Doi                      = {http://dx.doi.org/10.1016/j.camwa.2008.10.060},
  ISSN                     = {0898-1221},
  Keywords                 = {Data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {this paper presents a novel algorithm (called FP-CDS) that can capture all frequent closed itemsets and a new storage structure (called FP-CDS tree) that can be dynamically adjusted to reflect the evolution of itemsets' frequencies over time. . Extensive experiments are conducted to validate the proposed method. 1,3,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0898122108005683}
}

@Article{Liu2005,
  Title                    = {Mining frequent patterns in data streams},
  Author                   = {Liu, X.a b and Xu, H.a and Dong, Y.a and Wang, Y.a and Qian, J.a },
  Journal                  = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
  Year                     = {2005},
  Note                     = {cited By (since 1996)7},
  Number                   = {12},
  Pages                    = {2192-2198},
  Volume                   = {42},

  Abstract                 = {Finding frequent items is one of the most basic problems in the data streams. The limitless and mobility of data streams make the traditional frequent-pattern algorithm difficult to extend to data streams. According to data streams characteristic, inspired by the fact that the FP-growth provides an effective algorithm for frequent pattern mining, a new FP-DS algorithm for mining frequent patterns from data streams is proposed. In addition, the method, in which data streams are partitioned and frequent items are mined step by step, is adopted in the algorithm. So users may continuously get present frequent items online and any length frequent patterns for data streams can effectively be mined. Through introducing error ÃŽÂµ, a large number of non- frequent items will be cut down and the storage space of the data streams can be reduced. Based on this algorithm, the error of support is guaranteed not to exceed ÃŽÂµ. The analysis and experiments show that this algorithm has good performance.},
  Affiliation              = {Department of Computer Science and Technology, Southeast University, Nanjing 210096, China; College of Information Science and Engineering, Nanjing University of Technology, Nanjing 210009, China},
  Author_keywords          = {Data streams; FP-DS algorithm; Frequent patterns; Stream data mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {a new FP-DS algorithm for mining frequent patterns from data streams is proposed. In addition, the method, in which data streams are partitioned and frequent items are mined step by step, is adopted in the algorithm. The analysis and experiments show that this algorithm has good performance. Frequent pattern minign based on FP growth. Feel like I've seen this before. Maybe it's just a variation. 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-30044433854&partnerID=40&md5=6984b4ea73670b3922a1a267e9da0552}
}

@Article{Liu2005a,
  Title                    = {Dynamically mining frequent patterns over online data streams},
  Author                   = {Liu, X.a b and Xu, H.a and Dong, Y.a and Wang, Y.a and Qian, J.a },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Pages                    = {645-654},
  Volume                   = {3758 LNCS},

  Abstract                 = {Data streams are massive unbounded sequence of data elements continuously generated at a rapid rate. Consequently, it is challenge to find frequent items over data streams in a dynamic environment. In this paper, a new novel algorithm was proposed, which can capture frequent items with any length online continuously. Furthermore, several optimization techniques are devised to minimize processing time as well as main memory usage. Compared with related algorithm, it is more suitable for the mining of long frequent items. Finally, the proposed method is analyzed by a series of experiments and the results show that this algorithm owns significantly better performance than before. Ã‚Â© Springer-Verlag Berlin Heidelberg 2005.},
  Affiliation              = {Department of Computer Science and Technology, Southeast University, Nanjing 210096, China; College of Information Science and Engineering, Nanjing University of Technology, Nanjing 210009, China},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A novel algorithm was proposed, which can capture frequent items with any length online continuously. Furthermore, several optimization techniques are devised to minimize processing time as well as main memory usage. Experiments show that this algorithm owns significantly better performance than before. Bad english. weak abstract. 1,2,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33646691215&partnerID=40&md5=593936236b262cdb8cc34d48c8101e05}
}

@Article{Liu2007,
  Title                    = {Clustering massive text data streams by semantic smoothing model},
  Author                   = {Liu, Y.a and Cai, J.a and Yin, J.a and Fu, A.W.-C.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)1},
  Pages                    = {389-400},
  Volume                   = {4632 LNAI},

  Abstract                 = {Clustering text data streams is an important issue in data mining community and has a number of applications such as news group filtering, text crawling, document organization and topic detection and tracing etc. However, most methods are similarity-based approaches and use the TF*IDF scheme to represent the semantics of text data and often lead to poor clustering quality. In this paper, we firstly give an improved semantic smoothing model for text data stream environment. Then we use the improved semantic model to improve the clustering quality and present an online clustering algorithm for clustering massive text data streams. In our algorithm, a new cluster statistics structure, cluster profile, is presented in which the semantics of text data streams are captured. We also present the experimental results illustrating the effectiveness of our technique. Ã‚Â© Springer-Verlag Berlin Heidelberg 2007.},
  Affiliation              = {Department of Computer Science, Sun Yat-Sen University, Guangzhou, 510275, China; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, Hong Kong},
  Author_keywords          = {Clustering; Semantic smoothing; Text data streams},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Newer and better version in Liu2008a},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38049026484&partnerID=40&md5=ac9ae6387a897b7a52e3ea4cc62798dd}
}

@Conference{Liu2008,
  Title                    = {Real-time data pre-processing technique for efficient feature extraction in large scale datasets},
  Author                   = {Liu, Y.a and Lita, L.V.b and Niculescu, R.S.b and Bai, K.a and Mitra, P.a and Giles, C.L.a },
  Year                     = {2008},
  Note                     = {cited By (since 1996)3},
  Pages                    = {981-990},

  Abstract                 = {Due to the continuous and rampant increase in the size of domain specific data sources, there is a real and sustained need for fast processing in time-sensitive applications, such as medical record information extraction at the point of care, genetic feature extraction for personalized treatment, as well as off-line knowledge discovery such as creating evidence based medicine. Since parallel multi-string matching is at the core of most data mining tasks in these applications, faster on-line matching in static and streaming data is needed to improve the overall efficiency of such knowledge discovery. To solve this data mining need not efficiently handled by traditional information extraction and retrieval techniques, we propose a Block Suffix Shifting-based approach, which is an improvement over the state of the art multi-string matching algorithms such as Aho-Corasick, Commentz-Walter, and Wu-Manber. The strength of our approach is its ability to exploit the different block structures of domain specific data for off-line and online parallel matching. Experiments on several real world datasets show how our approach translates into significant performance improvements. Copyright 2008 ACM.},
  Affiliation              = {College of IST, Pennsylvania State University, University Park, PA 16802, United States; Siemens Medical Solutions, 51 Valley Stream Parkway, Malven, PA 19335, United States},
  Author_keywords          = {Block suffix shift; Feature extraction; Multiple-pattern matching; Pre-processing},
  Document_type            = {Conference Paper},
  Journal                  = {International Conference on Information and Knowledge Management, Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a Block Suffix Shifting-based approach, which is an improvement over the state of the art multi-string matching algorithms such as Aho-Corasick, Commentz-Walter, and Wu-Manber. The strength of our approach is its ability to exploit the different block structures of domain specific data for off-line and online parallel matching. Experiments on several real world datasets show how our approach translates into significant performance improvements. 1,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70349248441&partnerID=40&md5=2f85095c9ec7e4cc132a4628523567d8}
}

@Misc{Liu,
  Title                    = {{Real-Time Data Pre-Processing Technique for Efficient Feature Extraction in Large Scale Datasets}},

  Author                   = {Liu, Ying and Lita, Lucian V. and Niculescu, R. Stefan and Bai, Kun and Mitra, Prasenjit and Giles, C. Lee},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Due to the continuous and rampant increase in the size of domain specific data sources, there is a real and sustained need for fast processing in time-sensitive applications, such as medical record information extraction at the point of care, genetic feature extraction for personalized treatment, as well as off-line knowledge discovery such as creating evidence based medicine. Since parallel multi-string matching is at the core of most data mining tasks in these applications, faster on-line matching in static and streaming data is needed to improve the overall efficiency of such knowledge discovery. To solve this data mining need not efficiently handled by traditional information extraction and retrieval techniques, we propose a Block Suffix Shifting-based approach, which is an improvement over the state of the art multi-string matching algorithms such as Aho-Corasick, Commentz-Walter, and Wu-Manber. The strength of our approach is its ability to exploit the different block structures of domain specific data for off-line and online parallel matching. Experiments on several real world datasets show how our approach translates into significant performance improvements.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Liu2008},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.157.1447}
}

@Article{Liu2008a,
  Title                    = {Clustering text data streams},
  Author                   = {Liu, Y.-B.a and Cai, J.-R.a and Yin, J.a and Fu, A.W.-C.b },
  Journal                  = {Journal of Computer Science and Technology},
  Year                     = {2008},
  Note                     = {cited By (since 1996)22},
  Number                   = {1},
  Pages                    = {112-128},
  Volume                   = {23},

  Abstract                 = {Clustering text data streams is an important issue in data mining community and has a number of applications such as news group filtering, text crawling, document organization and topic detection and tracing etc. However, most methods are similarity-based approaches and only use the TF*IDF scheme to represent the semantics of text data and often lead to poor clustering quality. Recently, researchers argue that semantic smoothing model is more efficient than the existing TF*IDF scheme for improving text clustering quality. However, the existing semantic smoothing model is not suitable for dynamic text data context. In this paper, we extend the semantic smoothing model into text data streams context firstly. Based on the extended model, we then present two online clustering algorithms OCTS and OCTSM for the clustering of massive text data streams. In both algorithms, we also present a new cluster statistics structure named cluster profile which can capture the semantics of text data streams dynamically and at the same time speed up the clustering process. Some efficient implementations for our algorithms are also given. Finally, we present a series of experimental results illustrating the effectiveness of our technique. Ã‚Â© 2008 Science Press, Beijing, China and Springer Science + Business Media, LLC, USA.},
  Affiliation              = {Department of Computer Science, Sun Yat-Sen University, Guangzhou 510275, China; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, Hong Kong},
  Author_keywords          = {Clustering; Data mining; Database applications; Text data streams},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They extend the semantic smoothing model into text data streams context firstly. Based on the extended model, we then present two online clustering algorithms OCTS and OCTSM for the clustering of massive text data streams. In both algorithms, we also present a new cluster statistics structure named cluster profile which can capture the semantics of text data streams dynamically. THey present a series of experimental results illustrating the effectiveness of their technique. 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38849191210&partnerID=40&md5=8325254c789c9c125545a3baf2e172f1}
}

@Article{Liu2009b,
  Title                    = {A decentralized control mechanism for stream processing networks},
  Author                   = {Liu, Z.a and Tang, A.b and Xia, C.H.a and Zhang, L.a },
  Journal                  = {Annals of Operations Research},
  Year                     = {2009},
  Note                     = {cited By (since 1996)3},
  Number                   = {1},
  Pages                    = {161-182},
  Volume                   = {170},

  Abstract                 = {Data streaming applications are becoming more and more common due to the rapid development in emerging areas such as sensor networks, multimedia streaming, and on-line data mining, etc. These applications are often running in a decentralized, distributed environment. The requirements for processing large volumes of streaming data at real time have posed many great design challenges. One of the critical issues is to optimize the ongoing resource consumption of multiple, distributed, cooperating processing units. In this paper, we consider a generic model for the general stream data processing systems. We address the resource allocation problem for a collection of processing units so as to maximize the weighted sum of the throughput of different streams. Each processing unit may require multiple input data streams simultaneously and produce one or many valuable output streams. We develop decentralized control mechanisms that maximize the overall system throughput in such data stream processing networks. Performance analysis on the optimality and complexity of these mechanisms are also provided. Ã‚Â© 2008 Springer Science+Business Media, LLC.},
  Affiliation              = {IBM T.J. Watson Research Center, 19 Skyline Drive, Hawthorne, NY 10532, United States; Department of Electrical Engineering, California Institute of Technology, Pasadena, CA 91125, United States},
  Author_keywords          = {Distributed algorithm; Resource allocation; Stream processing},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {consider a generic model for the general stream data processing systems. We address the resource allocation problem for a collection of processing units so as to maximize the weighted sum of the throughput of different streams Discarded. It's about designing a processing allocation system, no ML},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-65049091479&partnerID=40&md5=05074519031566e2b892aae4bee0f28a}
}

@Article{Loo2005,
  Title                    = {{Online Algorithms for Mining Inter-Stream Associations from Large Sensor Networks}},
  Author                   = {Loo, K. K. and Tong, Ivy and Kao, Ben and Cheung, David},
  Journal                  = {IN PAKDD},
  Year                     = {2005},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We study the problem of mining frequent value sets from a large sensor network. We discuss how sensor stream data could be represented that facilitates e#cient online mining and propose the interval-list representation. Based on Lossy Counting, we propose ILB, an intervallist -based online mining algorithm for discovering frequent sensor value sets. Through extensive experiments, we compare the performance of ILB against an application of Lossy Counting (LC) using a weighted transformation method. Results show that ILB outperforms LC significantly for large sensor networks.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They study the problem of mining frequent value sets from a large sensor network. Based on Lossy Counting, they propose ILB, an intervallist -based online mining algorithm for discovering frequent sensor value sets. Through extensive experiments, we compare the performance of ILB against an application of Lossy Counting (LC) using a weighted transformation method. Results show that ILB outperforms LC significantly for large sensor networks. 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.1494}
}

@InProceedings{Looks2007,
  Title                    = {{Streaming Hierarchical Clustering for Concept Mining}},
  Author                   = {Looks, Moshe and Levine, Andrew and Covington, G. Adam and Loui, Ronald P. and Lockwood, John W. and Cho, Young H.},
  Booktitle                = {2007 IEEE Aerospace Conference},
  Year                     = {2007},
  Pages                    = {1--12},
  Publisher                = {IEEE},

  Abstract                 = {We are concerned with the general problem of concept mining - discovering useful associations, relationships, and groupings in large collections of data. Mathematical transformation algorithms have proven effective at reducing the content of multilingual, unstructured data into a vector that describes the content. Such methods are particularly desirable in fields undergoing information explosions, such as network traffic analysis, bioinformatics, and the intelligence community. In response, concept mining methodology is being extended to improve performance and permit hardware implementation -traditional methods are not sufficiently scalable. Hardware-accelerated systems have proven effective at automatically classifying such content when topics are known in advance. Our complete system builds on our past work in this area, presented in the Aerospace 2005 and 2006 conferences, where we described a novel algorithmic approach for extracting semantic content from unstructured text document streams. However, there is an additional need within the intelligence community to cluster related sets of content without advance training. To allow this function to happen at high speed, we have implemented a system that hierarchically clusters streaming content. The method, streaming hierarchical partitioning, is designed to be implemented in hardware and handle extremely high ingestion rates. As new documents are ingested, they are dynamically organized into a hierarchy, which has a fixed maximal size. Once this limit is reached, documents must consequently be excreted at a rate equaling their ingestion. The choice of documents to excrete is a point of interest -we present several autonomous heuristics for doing so intelligently, as well as a proposal for incorporating user interaction to focus attention on concepts of interest. A related desideratum is robust accommodation of concept drift -gradual change in the distribution and content of the document stream over time. Accordin- gly, we present and analyze experimental results for document streams evolving over time under several regimes. Current and proposed methods for concisely and informatively presenting derived content from streaming hierarchical clustering to the user for analysis are presented in this content. To support our claims of eventual hardware implementation and real-time performance with a high ingestion rate, we provide a detailed hardware-ready design, with asymptotic analysis and performance predictions. The system has been prototyped and tested on a Xeon processor as well as on a PowerPC embedded within a Xilinx Virtex2 FPGA. In summary, we describe a system designed to satisfy three primary goals: (1) real-time concept mining of high-volume data streams; (2) dynamic organization of concepts into a relational hierarchy; (3) adaptive reorganization of the concept hierarchy in response to evolving circumstances and user feedback.},
  Doi                      = {10.1109/AERO.2007.352792},
  ISBN                     = {1-4244-0524-6},
  ISSN                     = {1095-323X},
  Keywords                 = {Bioinformatics,Clustering algorithms,Explosions,Hardware,Information analysis,Intelligent networks,Performance analysis,Proposals,Robustness,Telecommunication traffic,concept mining,data collection,data mining,database management systems,mathematical transformation algorithms,streaming hierarchical clustering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Looks2007a},
  Shorttitle               = {Aerospace Conference, 2007 IEEE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4161605}
}

@Conference{Looks2007a,
  Title                    = {Streaming hierarchical clustering for concept mining},
  Author                   = {Looks, M. and Levine, A. and Covington, G.A. and Loui, R.P. and Lockwood, J.W. and Cho, Y.H.},
  Booktitle                = {2007 IEEE Aerospace Conference},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {We are concerned with the general problem of concept mining - discovering useful associations, relationships, and groupings in large collections of data. Mathematical transformation algorithms have proven effective at reducing the content of multilingual, unstructured data into a vector that describes the content. Such methods are particularly desirable in fields undergoing information explosions, such as network traffic analysis, bioinformatics, and the intelligence community. In response, concept mining methodology is being extended to improve performance and permit hardware implementation - traditional methods are not sufficiently scalable. Hardware-accelerated systems have proven effective at automatically classifying such content when topics are known in advance. Our complete system builds on our past work in this area, presented in the Aerospace 2005 and 2006 conferences, where we described a novel algorithmic approach for extracting semantic content from unstructured text document streams. However, there is an additional need within the intelligence community to cluster related sets of content without advance training. To allow this function to happen at high speed, we have implemented a system that hierarchically clusters streaming content. The method, streaming hierarchical partitioning, is designed to be implemented in hardware and handle extremely high ingestion rates. As new documents are ingested, they are dynamically organized into a hierarchy, which has a fixed maximal size. Once this limit is reached, documents must consequently be excreted at a rate equaling their ingestion. The choice of documents to excrete is a point of interest - we present several autonomous heuristics for doing so intelligently, as well as a proposal for incorporating user interaction to focus attention on concepts of interest. A related desideratum is robust accommodation of concept drift - gradual change in the distribution and content of the document stream over time. Accordingly, we present and analyze experimental results for document streams evolving over time under several regimes. Current and proposed methods for concisely and informatively presenting derived content from streaming hierarchical clustering to the user for analysis are presented in this content. To support our claims of eventual hardware implementation and real-time performance with a high ingestion rate, we provide a detailed hardware-ready design, with asymptotic analysis and performance predictions. The system has been prototyped and tested on a Xeon processor as well as on a PowerPC embedded within a Xilinx Virtex2 FPGA. In summary, we describe a system designed to satisfy three primary goals: (1) real-time concept mining of high-volume data streams; (2) dynamic organization of concepts into a relational hierarchy; (3) adaptive reorganization of the concept hierarchy in response to evolving circumstances and user feedback. Ã‚Â© 2007 IEEE.},
  Affiliation              = {Reconfigurable Network Group, Washington University in St. Louis, 1 Brookings Drive},
  Art_number               = {4161605},
  Document_type            = {Conference Paper},
  Journal                  = {IEEE Aerospace Conference Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Earlier work described a novel algorithmic approach for extracting semantic content from unstructured text document streams. Now they've built a system that hierarchically clusters streaming content. They provide a detailed hardware-ready design, with asymptotic analysis and performance predictions. In summary, They describe a system designed to satisfy three primary goals: (1) real-time concept mining of high-volume data streams; (2) dynamic organization of concepts into a relational hierarchy; (3) adaptive reorganization of the concept hierarchy in response to evolving circumstances and user feedback. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34548809093&partnerID=40&md5=e6250249b3a84a13c61288953327627c}
}

@Conference{Loperfido2007,
  Title                    = {Near real-time sensing of clear creek water quality},
  Author                   = {Loperfido, J.V.a b and Schnoor, J.L.b and Just, C.L.b },
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The transport of sediments, nutrients, and fecal bacteria from agricultural runoff through a watershed can have deleterious effects on receiving streams. It can impair aquatic ecosystems and cause excessive export of nutrients downstream contributing to hypoxia. The ability to sense concentrations of sediment and nutrients in real-time could greatly improve our ability to understand and protect downstream water quality. Observations by sensors placed in streams can relay measurements to databases, and data mining can be used to glean information from streaming data for statistical and mathematical assimilation. Results from models can be used to provide advanced warning of harmful events and/or implement remedial measures. The goal of this research is to install and operate the initial station of the Environmental Field Facility located in Clear Creek, Iowa. This station consists of several components including data loggers, telemetry hardware, and water quality sensors. Measurements collected at this field facility include conductivity, dissolved oxygen, pH, temperature, and turbidity which can be used as input to water quality models at the hillslope scale. This Environmental Field Facility will lay the groundwork for a large-scale cyber network. Ã‚Â© 2007 ASCE.},
  Affiliation              = {Environmental Engineering and Sciences Laboratory, Department of Civil and Environmental Engineering, University of Iowa, Iowa, IA 52242-1527, United States; 4105 Seamans Center for the Engineering Arts and Sciences, University of Iowa, Iowa, IA 52242-1527, United States},
  Document_type            = {Conference Paper},
  Journal                  = {Restoring Our Natural Habitat - Proceedings of the 2007 World Environmental and Water Resources Congress},
  Owner                    = {Alexander},
  Page_count               = {9},
  Qualityassured           = {qualityAssured},
  Review                   = {Not about ML},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80051625354&partnerID=40&md5=c359618fed5635aca88bef3938b2157d}
}

@Article{Luan2014,
  Title                    = {{The design of a live social observatory system}},
  Author                   = {Luan, Huanbo and Li, Juanzi and Sun, Maosong and Chua, Tat-Seng},
  Year                     = {2014},

  Month                    = apr,
  Pages                    = {1025--1030},

  Abstract                 = {With the emergence of social networks and their potential impact on society, many research groups and originations are collecting huge amount of social media data from various sites to serve different applications. These systems offer insights on different facets of society at different moments of time. Collectively they are known as social observatory systems. This paper describes the architecture and implementation of a live social observatory system named 'NExT-Live'. It aims to analyze the live online social media data streams to mine social senses, phenomena, influences and geographical trends dynamically. It incorporates an efficient and robust set of crawlers to continually crawl online social interactions on various social network sites. The data crawled are stored and processed in a distributed Hadoop architecture. It then performs the analysis on these social media streams jointly to generate analytics at different levels. In particular, it generates high-level analytics about the sense of different target entitles, including People, Locations, Topics and Organizations. NExT-Live offers a live observatory platform that enables people to know the happenings of the place in order to lead better life.},
  Doi                      = {10.1145/2567948.2579214},
  ISBN                     = {978-1-4503-2745-9},
  Keywords                 = {UGC,live,monitoring,next,observatory,social media},
  Owner                    = {alex},
  Priority                 = {prio2},
  Publisher                = {International World Wide Web Conferences Steering Committee},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper describes the architecture and implementation of a live social observatory system named 'NExT-Live'. It aims to analyze the live online social media data streams to mine social senses, phenomena, influences and geographical trends dynamically Cant say that this does Real-time analysis on streams, just classical crawl and mine approach using Hadoop.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2567948.2579214}
}

@Conference{Lunteren2012a,
  Title                    = {Designing a programmable wire-speed regular-expression matching accelerator},
  Author                   = {Lunteren, J.V.a and Hagleitner, C.a and Heil, T.b and Biran, G.c and Shvadron, U.c and Atasu, K.a},
  Booktitle                = {2012 45th Annual IEEE/ACM International Symposium on Microarchitecture},
  Year                     = {2012},
  Note                     = {cited By (since 1996)4},
  Pages                    = {461-472},

  Abstract                 = {A growing number of applications rely on fast pattern matching to scan data in real-time for security and analytics purposes. The RegX accelerator in the IBM Power Edge of Network (PowerEN) processor supports these applications using a combination of fast programmable state machines and simple processing units to scan data streams against thousands of regular-expression patterns at state-of-the-art Ethernet link speeds. RegX employs a special rule cache and includes several new micro-architectural features that enable various instruction dispatch and execution options for the processing units. The architecture applies RISC philosophy to special-purpose computing: hardware provides fast, simple primitives, typically performed in a single cycle, which are exploited by an intelligent compiler and system software for high performance. This approach provides the flexibility required to achieve good performance across a wide range of workloads. As implemented in the PowerEN processor, the accelerator achieves a theoretical peak scan rate of 73.6 Gbit/s, and a measured scan rate of about 15 to 40 Gbit/s for typical intrusion detection workloads. Ã‚Â© 2012 IEEE.},
  Affiliation              = {IBM Research, Zurich, Switzerland; IBM Systems and Technology Group, Rochester, MN, United States; IBM Research and Development Labs, Haifa, Israel},
  Art_number               = {6493642},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2012 IEEE/ACM 45th International Symposium on Microarchitecture, MICRO 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Using The RegX accelerator in the IBM Power Edge of Network (PowerEN) processor supports these applications using a combination of fast programmable state machines and simple processing units to scan data streams against thousands of regular-expression patterns at state-of-the-art Ethernet link speeds About fast pattern matching. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84876514773&partnerID=40&md5=853e6fe03b7da7ac28c5532a0c4d0b69}
}

@InProceedings{Lunteren2012,
  Title                    = {{Designing a Programmable Wire-Speed Regular-Expression Matching Accelerator}},
  Author                   = {Lunteren, Jan Van and Hagleitner, Christoph and Heil, Timothy and Biran, Giora and Shvadron, Uzi and Atasu, Kubilay},
  Booktitle                = {2012 45th Annual IEEE/ACM International Symposium on Microarchitecture},
  Year                     = {2012},
  Month                    = dec,
  Pages                    = {461--472},
  Publisher                = {IEEE},

  Abstract                 = {A growing number of applications rely on fast pattern matching to scan data in real-time for security and analytics purposes. The RegX accelerator in the IBM Power Edge of NetworkTM (PowerEN) processor supports these applications using a combination of fast programmable state machines and simple processing units to scan data streams against thousands of regular-expression patterns at state-of-the-art Ethernet link speeds. RegX employs a special rule cache and includes several new micro-architectural features that enable various instruction dispatch and execution options for the processing units. The architecture applies RISC philosophy to special-purpose computing: hardware provides fast, simple primitives, typically performed in a single cycle, which are exploited by an intelligent compiler and system software for high performance. This approach provides the flexibility required to achieve good performance across a wide range of workloads. As implemented in the PowerENTM processor, the accelerator achieves a theoretical peak scan rate of 73.6 Gbit/s, and a measured scan rate of about 15 to 40 Gbit/s for typical intrusion detection workloads.},
  Doi                      = {10.1109/MICRO.2012.49},
  ISBN                     = {978-1-4673-4819-5},
  ISSN                     = {1072-4451},
  Keywords                 = {Ethernet link speeds,IBM Power Edge of Network processor,PowerEN processor,RISC,RegX accelerator,analytics,cache storage,computer network security,data stream scanning,finite state machines,grammable state machines,instruction dispatch,instruction execution,intelligent compiler,local area networks,microarchitectural features,network intrusion detection,pattern matching,peak scan rate,processing units,program compilers,programmable wire-speed regular-expression matchin,reduced instruction set computing,scan rate measurement,security,system software},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Lunteren2012a},
  Shorttitle               = {Microarchitecture (MICRO), 2012 45th Annual IEEE/A},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6493642}
}

@InProceedings{Ma2011,
  Title                    = {{Continuous, online monitoring and analysis in large water distribution networks}},
  Author                   = {Ma, Xiuli and Xiao, Hongmei and Xie, Shuiyuan and Li, Qiong and Luo, Qiong and Tian, Chunhua},
  Booktitle                = {2011 IEEE 27th International Conference on Data Engineering},
  Year                     = {2011},
  Month                    = apr,
  Pages                    = {1332--1335},
  Publisher                = {IEEE},

  Abstract                 = {Clean drinking water and safe water supply is vital to our life. Recent advances in technologies have made it possible to deploy smart sensor networks in large water distribution networks to monitor and identify the water quality online. In such a large-scale real-time monitoring application, large amounts of data stream out of multiple concurrent sensors continuously. In this paper, we present a system to monitor and analyze the sensor data streams online, find and summarize the spatio-temporal distribution patterns and correlations in co-evolving data, detect contamination events rapidly and facilitate corrective actions or notification. The system consists of an online data mining engine and a GUI providing the user with the current patterns discovered in the network, and an alerter notifying the user if there is anomalous water quality in the network.},
  Doi                      = {10.1109/ICDE.2011.5767947},
  ISBN                     = {978-1-4244-8959-6},
  ISSN                     = {1063-6382},
  Keywords                 = {Correlation,GUI,Graphical user interfaces,Intelligent sensors,Monitoring,Real time systems,Water pollution,clean drinking water,computerised monitoring,contamination,contamination events,data mining,graphical user interfaces,intelligent sensors,large water distribution networks,large-scale real-time monitoring,multiple concurrent sensors,online data mining engine,online monitoring,safe water supply,sensor data streams,smart sensor networks,spatio-temporal distribution patterns,water quality,water supply},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a duplicate of Ma2011a},
  Shorttitle               = {Data Engineering (ICDE), 2011 IEEE 27th Internatio},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5767947}
}

@Conference{Ma2011a,
  Title                    = {Continuous, online monitoring and analysis in large water distribution networks},
  Author                   = {Ma, X.a b and Xiao, H.a b and Xie, S.a b and Li, Q.a b and Luo, Q.c and Tian, C.d },
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1332-1335},

  Abstract                 = {Clean drinking water and safe water supply is vital to our life. Recent advances in technologies have made it possible to deploy smart sensor networks in large water distribution networks to monitor and identify the water quality online. In such a large-scale real-time monitoring application, large amounts of data stream out of multiple concurrent sensors continuously. In this paper, we present a system to monitor and analyze the sensor data streams online, find and summarize the spatio-temporal distribution patterns and correlations in co-evolving data, detect contamination events rapidly and facilitate corrective actions or notification. The system consists of an online data mining engine and a GUI providing the user with the current patterns discovered in the network, and an alerter notifying the user if there is anomalous water quality in the network. Ã‚Â© 2011 IEEE.},
  Affiliation              = {School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Key Laboratory on Machine Perception, Peking University, Ministry of Education, Beijing, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, Hong Kong; IBM Research-China, Beijing, China},
  Art_number               = {5767947},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present a system to monitor and analyze the sensor data streams online, find and summarize the spatio-temporal distribution patterns and correlations in co-evolving data Accepted, but weak abstract, no empirical results 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79957820462&partnerID=40&md5=82209f5c0d07c70eb7d0fbfb265b0df9}
}

@Article{Madia2014,
  Title                    = {Exploring streaming data in real time: Turn streaming data into instant actionable insight by applying visual data discovery to data in motion},
  Author                   = {Madia, K. and Potter, D.},
  Journal                  = {IBM Data Management Magazine},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {4},

  Abstract                 = {The world of business intelligence (BI) and analytics is undergoing significant changes. Streaming data holds the potential to dramatically reduce the time to deliver business-critical information if it can be processed, understood, and analyzed in real time. The amount of streaming data being generated is exploding rapidly from the growing variety of interconnected machines, devices, sensors, and consumer content. And the amount of data generated from any one source can be staggering. One big benefit of combining streaming data with visual data discovery is the ability to strike while the iron is hot. Seeing live, actionable information in an intuitive visual display helps organizations monitor precisely how their business is doing at that instant. Visual data discovery and streaming analytics represent the future of big data analytics initiatives. Organizations can begin to prepare for the changes today by deploying a streaming infrastructure such as the InfoSphere Streams Quick Start edition and the Datawatch Desktop trial edition.},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Rejected, This is a sales pitch, they don't present anything scientific},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84900031829&partnerID=40&md5=f74a1ebf785eafd80c3859753f17d05f}
}

@Article{Magdy2010,
  Title                    = {SIC-means: A semi-fuzzy approach for clustering data streams using C-means},
  Author                   = {Magdy, A. and Bassiouny, M.K.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2010},
  Note                     = {cited By (since 1996)1},
  Pages                    = {96-107},
  Volume                   = {5998 LNAI},

  Abstract                 = {In recent years, data streaming has gained a significant importance. Advances in both hardware devices and software technologies enable many applications to generate continuous flows of data. This increases the need to develop algorithms that are able to efficiently process data streams. Additionaly, real-time requirements and evolving nature of data streams make stream mining problems, including clustering, challenging research problems. Fuzzy solutions are proposed in the literature for clustering data streams. In this work, we propose a Soft Incremental C-Means variant to enhance the fuzzy approach performance. The experimental evaluation has shown better performance for our approach in terms of Xie-Beni index compared with the pure fuzzy approach with changing different factors that affect the clustering results. In addition, we have conducted a study to analyze the sensitivity of clustering results to the allowed fuzziness level and the size of data history used. This study has shown that different datasets behave differently with changing these factors. Dataset behavior is correlated with the separation between clusters of the dataset. Ã‚Â© 2010 Springer-Verlag.},
  Affiliation              = {Computer and Systems Engineering, Alexandria University, Egypt},
  Author_keywords          = {C-means; Clustering data streams; Data streams; Fuzz clustering; Soft clustering},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a Soft Incremental C-Means variant to enhance the fuzzy approach performance of clustering data streams. Experiments show better performance than pure fuzzy approach. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77952366294&partnerID=40&md5=19593040685ca0b7bd8682f5aeb78cba}
}

@Misc{Mahabal,
  Title                    = {{Towards Real-time Classification of Astronomical Transients}},

  Author                   = {Mahabal, A. and Djorgovski, S. G. and Williams, R. and Drake, A. and Donalek, C. and Moghaddam, B. and Turmon, M. and Jewell, J. and Khosla, A.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Exploration of time domain is now a vibrant area of research in astronomy, driven by the advent of digital synoptic sky surveys. While panoramic surveys can detect variable or transient events, typically some follow-up observations are needed; for short-lived phenomena, a rapid response is essential. Ability to automatically classify and prioritize transient events for follow-up studies becomes critical as the data rates increase. We have been developing such methods using the data streams from the Palomar-Quest survey, the Catalina Sky Survey and others, using the VOEventNet framework. The goal is to automatically classify transient events, using the new measurements, combined with archival data (previous and multi-wavelength measurements), and contextual information (e.g.. Galactic or ecliptic latitude, presence of a possible host galaxy nearby, etc.); and to iterate them dynamically as the follow-up data come in (e.g., light curves or colors). We have been investigating Bayesian methodologies for classification, as well as discriminated follow-up to optimize the use of available resources, including Naive Bayesian approach, and the non-parametric Gaussian process regression. We will also be deploying variants of the traditional machine learning techniques such as Neural Nets and Support Vector Machines on datasets of reliably classified transients as they build up.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Rejected. Only outlines building a system, produces no tangible results.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.153.1642}
}

@Misc{Mahmood,
  Title                    = {{Representation Search through Generate and Test}},

  Author                   = {Mahmood, Ashique Rupam and Sutton, Richard S.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Learning representations from data is one of the fundamental problems of artificial intelligence and machine learning. Many different approaches exist for learning representations, but what constitutes a good representation is not yet well understood. In this work, we view the problem of representation learning as one of learning features (e.g., hidden units of neural networks) such that performance of the underlying base system continually improves. We study an important case where learning is done fully online (i.e., on an example-by-example basis) from an unending stream of data. In the presence of an unending stream of data, the computational cost of the learning element should not grow with time and cannot be much more than that of the performance element. Few methods can be used effectively in this case. We show that a search approach to representation learning can naturally fit with this setting. In this approach good representations are searched by generating different features and then testing them for utility. We develop new representation-search methods and show that the generate-and-test approach can be utilized in a simple and effective way for learning representations. Our methods are fully online and add only a small fraction to the overall computation. They constitute an important step toward effective and inexpensive solutions to representation learning problems.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They develop new representation-search methods and show that the generate-and-test approach can be utilized in a simple and effective way for learning representations. They develop a new search method, but does not confirm if they have done any testing or comparisons on their solution. 1,2,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.420.4139}
}

@Misc{Mala,
  Title                    = {{DATA STREAM MINING ALGORITHMS â€“ A REVIEW OF ISSUES AND EXISTING APPROACHES}},

  Author                   = {Mala, A. and Dhanaseelan, F. Ramesh},

  __markedentry            = {[Alexander:]},
  Abstract                 = {More and more applications such as traffic modeling, military sensing and tracking, online data processing etc., generate a large amount of data streams every day. Efficient knowledge discovery of such data streams is an emerging active research area in data mining with broad applications. Different from data in traditional static databases, data streams typically arrive continuously in high speed with huge amount and changing data distribution. This raises new issues that need to be considered when developing association rule mining techniques for stream data. Due to the unique features of data stream, traditional data mining techniques which require multiple scans of the entire data sets can not be applied directly to mine stream data, which usually allows only one scan and demands fast response time.},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a review. Set aside as similar study},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.302.5514}
}

@Misc{Malini,
  Title                    = {{Knowledge Discovery in Data Mining and Massive Data Mining}},

  Author                   = {Malini, Mrs and Patil, M},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Knowledge discovery is a process of non trivial extraction of previously unknown and presently useful information. The rapid advancement of the technology resulted in the increasing rate of data distributions. The data generated from mobile applications, sensor applications, network monitoring, traffic management, weblogs etc. can be referred as a data stream. The data streams are massive in nature. The present work mainly aims at knowledge discovery using data mining and massive data mining techniques. The knowledge discovery process in both the techniques is compared by developing a classification model using Naive bayes classifier. The former case uses Edu-data, a data collected from technical education system and the latter case uses massive online analysis frame work to generate the data streams. Mining data stream is referred as Massive Data Mining. The data streams must be processed under very strict constraints of space and time using sophisticated techniques. The traditional data mining techniques are not advised on this massive data. Therefore the massive online analysis framework is used to mine the data streams. The present work happens to be unique in the literature.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The present work mainly aims at knowledge discovery using data mining and massive data mining techniques. This paper seems to have done comparisons on established ML techniques, by developing a new classifier based on Naive Bayes. Accepted under uncertainty. 1,2,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.380.3202}
}

@Conference{Manohar2013,
  Title                    = {A privacy preserving data mining methodology for dynamically predicting emerging human threats},
  Author                   = {Manohar, G.a and Tucker, C.S.b },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Volume                   = {2 A},

  Abstract                 = {This paper proposes a privacy preserving data mining driven methodology for predicting emerging human threats in a public space by capturing large scale, real time body movement data (spatial data represented in X, Y, Z coordinate space) using Red- Green-Blue (RGB) image, infrared depth and skeletal image sensing technology. Unlike traditional passive surveillance systems (e.g., CCTV video surveillance systems), multimodal surveillance technologies have the ability to capture multiple data streams in a real time dynamic manner. However, mathematical models based on machine learning principles are needed to convert the large-scale data into knowledge to serve as a decision support system for autonomously predicting emerging threats, rather than just recording and observing them as they occur. To this end, the authors of this work present a privacy preserving data mining driven methodology that captures emergent behavior of individuals in a public space and classifies them as a threat or not a threat, based on the underlying body movements through space and time. An audience in a public environment is presented as the case study for this paper with the aim of classifying individuals in the audience as threats (or not), based on their temporal body behavior profiles. Copyright Ã‚Â© 2013 by ASME.},
  Affiliation              = {Industrial Engineering, Pennsylvania State University, University Park, PA 16802, United States; Engineering Design and Industrial Engineering, Pennsylvania State University, University Park, PA 16802, United States},
  Art_number               = {V02AT02A069},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ASME Design Engineering Technical Conference},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes a privacy preserving data mining driven methodology for predicting emerging human threats in a public space by capturing large scale, real time body movement data. Getting multimodal images as a data stream, they have made a methodology that identifies threats. Their results is a case study, therefore qualitative research. Nothing written about the success of their implementation. 1,2,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84896954129&partnerID=40&md5=0771fb71244dfdc45ebeaa7f1ec65eb0}
}

@Misc{Mao,
  Title                    = {{Online Mining of Maximal Frequent Itemsequences from Data Streams}},

  Author                   = {Mao, Guojun and Wu, Xindong and Liu, Chunnian and Zhu, Xingquan and Chen, Gong and Sun, Yue and Liu, Xu},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Mining data streams often requires real-time extraction of interesting patterns from dynamic and continuously growing data. This requirement has imposed challenges on discovering and outputting current useful patterns in an instant way, commonly referred to as online streaming data mining. In this paper, we present INSTANT, a novel algorithm that explores maximal frequent itemsequences from streaming data in an online fashion. We first provide useful operators on the lattice of itemsequential sets, and then apply them to the algorithm design of INSTANT. In comparison with the most popular methods such as close-itemset based mining algorithms, INSTANT has solid theoretical foundations to ensure that it employs more compact in-memory data structures than closed itemsequences. Experimental results show that our method can achieve better results than previous related methods in terms of both time and space efficiency},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper present INSTANT, a novel algorithm that explores maximal frequent itemsequences from streaming data in an online fashion. In comparison with the most popular methods such as close-itemset based mining algorithms, INSTANT has solid theoretical foundations to ensure that it employs more compact in-memory data structures than closed itemsequences. Experiments better results in term of time and space efficieny 1,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.302.3510}
}

@Article{Mao2007,
  Title                    = {Mining maximal frequent itemsets from data streams},
  Author                   = {Mao, G.a b and Wu, X.a and Zhu, X.a and Chen, G.a and Liu, C.b },
  Journal                  = {Journal of Information Science},
  Year                     = {2007},
  Note                     = {cited By (since 1996)37},
  Number                   = {3},
  Pages                    = {251-262},
  Volume                   = {33},

  Abstract                 = {Frequent pattern mining from data streams is an active research topic in data mining. Existing research efforts often rely on a two-phase framework to discover frequent patterns: (1) using internal data structures to store meta-patterns obtained by scanning the stream data; and (2) re-mining the meta-patterns to finalize and output frequent patterns. The defectiveness of such a two-phase framework lies in the fact that the two stages provide barriers to dynamically and immediately finding frequent patterns with online functionalities. It is expected that a single-phase algorithm can fulfil frequent pattern mining from data streams in such a way that the users can see patterns in an immediate and dynamic manner, as soon as the patterns have become frequent. In this paper, we propose INSTANT, a single-phase algorithm for discovering frequent itemsets from data streams. The theoretical foundation of INSTANT is based on a framework theory on a set of itemsets, which is also presented in the paper. The novel design of INSTANT ensures that it employs compact data structures to mine frequent patterns from data streams in a single phase. Our experimental results demonstrate the time and space efficiency of the proposed algorithm. Ã‚Â© CILIP.},
  Affiliation              = {Department of Computer Science, University of Vermont, Burlington, VT 05405, United States; School of Computer Science, Beijing University of Technology, Beijing 100022, China},
  Author_keywords          = {Data mining; Data stream; Frequent itemset; Set of itemsets},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose INSTANT, a single-phase algorithm for discovering frequent itemsets from data stream. The novel design of INSTANT ensures that it employs compact data structures to mine frequent patterns from data streams in a single phase. Our experimental results demonstrate the time and space efficiency of the proposed algorithm Basically the same abstract as Mao, just a little bit better. In this version they compare themself to existing research 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34248150950&partnerID=40&md5=7ac871ae6081b736caff838111c5b4ad}
}

@Conference{Mao2011a,
  Title                    = {Medical data mining for early deterioration warning in general hospital wards},
  Author                   = {Mao, Y.a and Chen, Y.b and Hackmann, G.b and Chen, M.b and Lu, C.b and Kollef, M.c and Bailey, T.C.c },
  Year                     = {2011},
  Note                     = {cited By (since 1996)2},
  Pages                    = {1042-1049},

  Abstract                 = {Data mining on medical data has great potential to improve the treatment quality of hospitals and increase the survival rate of patients. Every year, 4-17% of patients undergo cardiopulmonary or respiratory arrest while in hospitals. Early prediction techniques have become an apparent need in many clinical area. Clinical study has found early detection and intervention to be essential for preventing clinical deterioration in patients at general hospital units. In this paper, based on data mining technology, we propose an early warning system (EWS) designed to identify the signs of clinical deterioration and provide early warning for serious clinical events. Our EWS is designed to provide reliable early alarms for patients at the general hospital wards (GHWs). EWS automatically identifies patients at risk of clinical deterioration based on their existing electronic medical record. The main task of EWS is a challenging classification problem on high-dimensional stream data with irregular, multi-scale data gaps, measurement errors, outliers, and class imbalance. In this paper, we propose a novel data mining framework for analyzing such medical data streams. The framework addresses the above challenges and represents a practical approach for early prediction and prevention based on data that would realistically be available at GHWs. We assess the feasibility of the proposed EWS approach through retrospective study that includes data from 28,927 visits at a major hospital. Finally, we apply our system in a real-time clinical trial and obtain promising results. This project is an example of multidisciplinary cyber-physical systems involving researchers in clinical science, data mining, and nursing staff in the hospital. Our early warning algorithm shows promising result: the transfer of patients to ICU was predicted with sensitivity of 0.4127 and specificity of 0.950 in the real time system. Ã‚Â© 2011 IEEE.},
  Affiliation              = {School of Electromechanical Engineering, Xidian University, Xi'an, China; Department of Computer Science and Engineering, Washington University in St. Louis, Saint Louis, United States; Department of Medicine, Washington University School of Medicine, St. Louis, United States},
  Art_number               = {6137495},
  Author_keywords          = {Bootstrap aggregating; Early warning system; EMA (exponential moving average); Exploratory undersampling; Logistic regression},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, based on data mining technology, they propose an early warning system (EWS) designed to identify the signs of clinical deterioration and provide early warning for serious clinical events. The main task of EWS is a challenging classification problem on high-dimensional stream data. They propose a novel framework for analyzing medical data streams. They apply their system in a real-time clinical trial and obtain promising results: the transfer of patients to ICU was predicted with sensitivity of 0.4127 and specificity of 0.950 in the real time system. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84863129844&partnerID=40&md5=b2807ba4cd0eb0f440a43149ca78ae2d}
}

@Misc{Maoa,
  Title                    = {{Medical Data Mining 1 Early Deterioration Warning for Hospitalized Patients by Mining Clinical Data}},

  Author                   = {Mao, Yi and Chen, Yixin and Hackmann, Gregory and Chen, Minmin and Lu, Chenyang and Kollef, Marin and Bailey, Thomas C.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Data mining on medical data has great potential to improve the treatment quality of hospitals and increase the survival rate of patients. Every year, 4--17%of patients undergo cardiopulmonary or respiratory arrest while in hospitals. Early prediction techniques have become an apparent need in many clinical areas. Clinical study has found early detection and intervention to be essential for preventing clinical deterioration in patients at general hospital units. In this paper, based on data mining technology, we propose an early warning system (EWS) designed to identify the signs of clinical deterioration and provide early warning for serious clinical events. Our EWS is designed to provide reliable early alarms for patients at the general hospital wards (GHWs). The main task of EWS is a challenging classification problem on high-dimensional stream data with irregular, multi-scale data gaps, measurement errors, outliers, and class imbalance. In this paper, we propose a novel data mining framework for analyzing such medical data streams. The framework addresses the above challenges and represents a practical approach to early prediction and prevention based on data that would realistically be available at GHWs. We assess the feasibility of the proposed EWS approach through retrospective study that includes data from 41,503 visits at a major hospital. Finally, we apply our system in a clinical trial at a major hospital and obtain promising results. This project is an example of multidisciplinary cyber-physical systems involving researchers in clinical science, data mining, and nursing staff. Our early warning algorithm shows promising result: the transfer of patients to ICU was predicted with sensitivity of 0.4127 and specificity of 0.950 in the real time system.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a duplicate of Mao2011a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.221.7771}
}

@InProceedings{Mao2011,
  Title                    = {{Medical Data Mining for Early Deterioration Warning in General Hospital Wards}},
  Author                   = {Mao, Yi and Chen, Yixin and Hackmann, Gregory and Chen, Minmin and Lu, Chenyang and Kollef, Marin and Bailey, Thomas C.},
  Booktitle                = {2011 IEEE 11th International Conference on Data Mining Workshops},
  Year                     = {2011},
  Month                    = dec,
  Pages                    = {1042--1049},
  Publisher                = {IEEE},

  Abstract                 = {Data mining on medical data has great potential to improve the treatment quality of hospitals and increase the survival rate of patients. Every year, \$4\$ -- \$17\%\$ of patients undergo cardiopulmonary or respiratory arrest while in hospitals. Early prediction techniques have become an apparent need in many clinical area. Clinical study has found early detection and intervention to be essential for preventing clinical deterioration in patients at general hospital units. In this paper, based on data mining technology, we propose an early warning system (EWS) designed to identify the signs of clinical deterioration and provide early warning for serious clinical events. Our EWS is designed to provide reliable early alarms for patients at the general hospital wards (GHWs). EWS automatically identifies patients at risk of clinical deterioration based on their existing electronic medical record. The main task of EWS is a challenging classification problem on high-dimensional stream data with irregular, multi-scale data gaps, measurement errors, outliers, and class imbalance. In this paper, we propose a novel data mining framework for analyzing such medical data streams. The framework addresses the above challenges and represents a practical approach for early prediction and prevention based on data that would realistically be available at GHWs. We assess the feasibility of the proposed EWS approach through retrospective study that includes data from 28,927 visits at a major hospital. Finally, we apply our system in a real-time clinical trial and obtain promising results. This project is an example of multidisciplinary cyber-physical systems involving researchers in clinical science, data mining, and nursing staff in the hospital. Our early warning algorithm shows promising result: the transfer of patients to ICU was predicted with sensitivity of 0.4127 and specificity of 0.950 in the real time system.},
  Doi                      = {10.1109/ICDMW.2011.117},
  ISBN                     = {978-1-4673-0005-6},
  Keywords                 = {Accuracy,Bagging,Bootstrap Aggregating,Data mining,EMA (exponential moving average),Early Warning System,Exploratory undersampling,Hospitals,Logistic Regression,Logistics,Prediction algorithms,Real time systems,alarm systems,clinical deterioration,clinical science,data mining,early deterioration warning,early warning algorithm,early warning system,electronic medical record,general hospital wards,medical data mining,multidisciplinary cyber physical systems,nursing staff,patient treatment,retrospective study},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a duplicate of Mao2011a},
  Shorttitle               = {Data Mining Workshops (ICDMW), 2011 IEEE 11th Inte},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6137495}
}

@Article{Mao2013,
  Title                    = {Fast mining of closed frequent itemsets in data streams},
  Author                   = {Mao, Y.a and Chen, Z.b and Liu, L.b },
  Journal                  = {Applied Mechanics and Materials},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 1},
  Pages                    = {231-240},
  Volume                   = {263-266},

  Abstract                 = {With the emergence of large-volume and high-speed streaming data, traditional techniques for mining closed frequent itemsets has become inefficient. Online mining of closed frequent itemsets over streaming data is one of the most important issues in mining data streams. In this paper, a combinative data structure is designed by using an effective bit-victor to represent items and an extended dictionary frequent item list to record the current closed frequent information in streams. For tremendous reduction of search space, some new search strategies are proposed to avoid a large number of intermediate itemsets generated. Meanwhile, some new pruning strategies are also proposed for the purpose of efficiently and dynamically maintaining of all the closure check operations. Experimental results show that the method proposed is efficient in time, with sound scalability as the number of transactions processed increases and adapts rapidly to the changes in data streams. Ã‚Â© (2013) Trans Tech Publications, Switzerland.},
  Affiliation              = {Applied Science Institute, Jiangxi University of Science and Technology, China; School of Information Science and Engineering, Central South University, China},
  Author_keywords          = {Closed frequent item; Data mining; Data streams; Frequent itemsets},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper has made new data structures, new search strategies, and some new pruning strategies, so that they can mine closed frequent itemsets on large-volume and high-speed streaming data. Experimental results show that the method proposed is efficient in time, with sound scalability as the number of transactions processed increases and adapts rapidly to the changes in data streams 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84872484210&partnerID=40&md5=cbf8a2a7a4ab4ca8d4b574d02ebd5c6b}
}

@InProceedings{Mao2009,
  Title                    = {{A Mining Maximal Frequent Itemsets over the Entire History of Data Streams}},
  Author                   = {Mao, Yinmin and Li, Hong and Yang, Lumin and Chen, Zhigang and Liu, Lixin},
  Booktitle                = {2009 First International Workshop on Database Technology and Applications},
  Year                     = {2009},
  Month                    = apr,
  Pages                    = {413--417},
  Publisher                = {IEEE},

  Abstract                 = {Mining maximal frequent itemsets has been widely concerned. However, mining data streams is more difficult than mining static databases because of the huge, high-speed and continuous characteristics of streaming data. This paper presents an algorithm, called IDSM-MFI. The algorithm uses a synopsis data structure to store the items of transactions embedded data streams so far. It adopts a top-bottom and bottom-top method to mine the set of all maximal frequent itemsets in landmark windows over data stream, which can be output in real time based on users' specified thresholds. Theoretical analysis and experimental results show that our algorithm is efficient and scalable for mining the set of all maximal frequent itemsets over the entire history of data stream.},
  Doi                      = {10.1109/DBTA.2009.125},
  ISBN                     = {978-0-7695-3604-0},
  Keywords                 = {Algorithm design and analysis,Data engineering,Data mining,Data structures,Frequency,History,IDSM-MFI algorithm,Information science,Itemsets,Sensor phenomena and characterization,Transaction databases,bottom-top method,data mining,data streams,data streams mining,data structures,landmark windows,maximal frequent itemset mining,maximal frequent itemsets,synopsis data structure,top-bottom method},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a duplicate of Mao2009a},
  Shorttitle               = {Database Technology and Applications, 2009 First I},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5207728}
}

@Conference{Mao2009a,
  Title                    = {A mining maximal frequent itemsets over the entire history of data streams},
  Author                   = {Mao, Y. and Li, H. and Yang, L. and Chen, Z. and Liu, L.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {413-417},

  Abstract                 = {Mining maximal frequent itemsets has been widely concerned. However, mining data streams is more difficult than mining static databases because of the huge, high-speed and continuous characteristics of streaming data. This paper presents an algorithm, called IDSM-MFI. The algorithm uses a synopsis data structure to store the items of transactions embedded data streams so far. It adopts a topbottom and bottom-top method to mine the set of all maximal frequent itemsets in landmark windows over data stream, which can be output in real time based on users' specified thresholds. Theoretical analysis and experimental results show that our algorithm is efficient and scalable for mining the set of all maximal frequent itemsets over the entire history of data stream. Ã‚Â© 2009 IEEE.},
  Affiliation              = {School of Information Science and Engineering, Central South Unversity, Changsha, China},
  Art_number               = {5207728},
  Author_keywords          = {Data mining; Data streams; Maximal frequent itemsets},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2009 1st International Workshop on Database Technology and Applications, DBTA 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents an algorithm, called IDSM-MFI. It adopts a topbottom and bottom-top method to mine the set of all maximal frequent itemsets in landmark windows over data stream, which can be output in real time based on users' specified thresholds. Theoretical analysis and experimental results show that the algorithm is efficient and scalable 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70449378903&partnerID=40&md5=725304cfeefd76e940cda3b61d6cb158}
}

@Article{Mao2011b,
  Title                    = {An intrusion detection model based on data mining over data},
  Author                   = {Mao, Y.-M.a b and Yang, L.-M.a and Chen, Z.-G.a and Liu, L.-X.a },
  Journal                  = {Zhongnan Daxue Xuebao (Ziran Kexue Ban)/Journal of Central South University (Science and Technology)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Number                   = {9},
  Pages                    = {2720-2728},
  Volume                   = {42},

  Abstract                 = {Aiming at the current problems of inadequacy in intrusion-detection system response speed and detecting precision of data mining techniques based on association rules of data streams, an intrusion detection system model of MMFIID-DS based on maximal frequent pattern of data streams was proposed. A variety of pruning strategies were proposed to mine the maximal frequent itemsets on trained normal data set, abnormal data set and current data streams to establish normal and abnormal behavior pattern as well as user behavior pattern of the system in order to improve response speed of the system by greatly reducing search space. Besides, misuse detection and anomaly detection techniques were combined to implement online real-time intrusion detection and improve detection precision of the system. Both theoretical and experimental results indicate that the MMFIID-DS intrusion detection system is fairly sound in performance.},
  Affiliation              = {School of Information Science and Engineering, Central South University, Changsha 410083, China; Institute of Applied Science, Jiangxi University of Science and Technology, Ganzhou 341000, China},
  Author_keywords          = {Anomaly detection; Data streams; Maximal frequent itemsets; Misuse detection},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {an intrusion detection system model of MMFIID-DS based on maximal frequent pattern of data streams was proposed. Misuse detection and anomaly detection techniques were combined to implement online real-time intrusion detection and improve detection precision of the system. Both theoretical and experimental results indicate that the MMFIID-DS intrusion detection system is fairly sound in performance. They've made a fairly sound intrusion detection system, based on both historical data, and incoming data stream. A bit weak when describing their results. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80355145898&partnerID=40&md5=ddf5bada900d221ddae3035e9f651cdd}
}

@Conference{Mardani2014a,
  Title                    = {Imputation of streaming low-rank tensor data},
  Author                   = {Mardani, M. and Mateos, G. and Giannakis, G.B.},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {433-436},

  Abstract                 = {Unraveling latent structure by means of multilinear models of tensor data is of paramount importance in timely inference tasks encountered with 'Big Data' analytics. However, increasingly noisy, heterogeneous, and incomplete datasets as well as the need for real-time processing of streaming data pose major challenges to this end. The present paper introduces a novel online (adaptive) algorithm to decompose low-rank tensors with missing entries, and perform imputation as a byproduct. The novel estimator minimizes an exponentially- weighted least-squares fitting error along with a separable regularizer of the PARAFAC decomposition factors, to trade-off fidelity for complexity of the approximation captured by the decomposition's rank. Leveraging stochastic gradient descent iterations, a scalable, real-time algorithm is developed and its convergence is established under simplifying technical assumptions. Simulated tests with cardiac magnetic resonance imagery (MRI) data confirm the efficacy of the proposed algorithm in imputing up to 75% missing entries. Ã‚Â© 2014 IEEE.},
  Affiliation              = {Dept. of ECE and Digital Technology Center, University of Minnesota, United States},
  Art_number               = {6882433},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the IEEE Sensor Array and Multichannel Signal Processing Workshop},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The paper introduces a novel online (adaptive) algorithm to decompose low-rank tensors with missing entries, and perform imputation as a byproduct. Leveraging stochastic gradient descent iterations, a scalable, real-time algorithm is developed. Simulated tests with cardiac magnetic resonance imagery (MRI) data confirm the efficacy of the proposed algorithm in imputing up to 75\% missing entries 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84907420135&partnerID=40&md5=5449336c6ba1cd675289b330332a737f}
}

@InProceedings{Mardani2014,
  Title                    = {{Imputation of streaming low-rank tensor data}},
  Author                   = {Mardani, Morteza and Mateos, Gonzalo and Giannakis, Georgios B.},
  Booktitle                = {2014 IEEE 8th Sensor Array and Multichannel Signal Processing Workshop (SAM)},
  Year                     = {2014},
  Month                    = jun,
  Pages                    = {433--436},
  Publisher                = {IEEE},

  Abstract                 = {Unraveling latent structure by means of multilinear models of tensor data is of paramount importance in timely inference tasks encountered with `Big Data' analytics. However, increasingly noisy, heterogeneous, and incomplete datasets as well as the need for real-time processing of streaming data pose major challenges to this end. The present paper introduces a novel online (adaptive) algorithm to decompose low-rank tensors with missing entries, and perform imputation as a byproduct. The novel estimator minimizes an exponentially-weighted least-squares fitting error along with a separable regularizer of the PARAFAC decomposition factors, to trade-off fidelity for complexity of the approximation captured by the decomposition's rank. Leveraging stochastic gradient descent iterations, a scalable, real-time algorithm is developed and its convergence is established under simplifying technical assumptions. Simulated tests with cardiac magnetic resonance imagery (MRI) data confirm the efficacy of the proposed algorithm in imputing up to 75\% missing entries.},
  Doi                      = {10.1109/SAM.2014.6882435},
  ISBN                     = {978-1-4799-1481-4},
  Keywords                 = {Approximation algorithms,Arrays,Magnetic resonance imaging,Matrix decomposition,PARAFAC decomposition factors,Real-time systems,Signal processing algorithms,Tensile stress,adaptive algorithm,approximation complexity,big-data analytics,biomedical MRI,cardiac MRI data,cardiac magnetic resonance imagery data,decomposition rank,exponentially-weighted least-square fitting error,gradient methods,latent structure,least squares approximations,low-rank tensor data streaming,medical image processing,multilinear model,online algorithm,real-time processing,scalable real-time algorithm,stochastic gradient descent iterations,stochastic processes,tensors,timely-inference tasks},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a duplicate of Mardani2014a},
  Shorttitle               = {Sensor Array and Multichannel Signal Processing Wo},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6882435}
}

@Article{Marrs2012,
  Title                    = {The use of time stamps in handling latency and concept drift in online learning},
  Author                   = {Marrs, G.R. and Black, M.M. and Hickey, R.J.},
  Journal                  = {Evolving Systems},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {4},
  Pages                    = {203-220},
  Volume                   = {3},

  Abstract                 = {Online classification learners operating under concept drift can be subject to latency in example arrival at the training base. The impact of such latency on the definition of a time stamp is discussed against the background of the online learning life cycle. Data stream latency is modeled in an example life-cycle integrated simulation environment. Two new algorithms are presented: CDTC versions 1 and 2, in which a specific time stamp protocol is used representing the time of classification. Comparison of these algorithms against previous time stamp learning algorithms CD3 and CD5 is made. A time stamp definition and algorithmic solution is presented for handling latency in data streams and improving classification recovery in such affected domains. Ã‚Â© 2012 Springer-Verlag.},
  Affiliation              = {University of Ulster, County Londonderry, United Kingdom},
  Author_keywords          = {Classification; Concept drift; Latency; Online learning; Time stamp},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a duplicate of Marrs2011},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84869460327&partnerID=40&md5=19a6ee1b65fa51143c2cd7c5719fe432}
}

@Article{Marrs2011,
  Title                    = {Time stamping in the presence of latency and drift},
  Author                   = {Marrs, G.R. and Hickey, R.J. and Black, M.M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {64-75},
  Volume                   = {6943 LNAI},

  Abstract                 = {Online classification learners operating under concept drift can be subject to latency in example arrival at the training base. The impact of such latency on the definition of a time stamp is discussed against the background of the Online Learning Life Cycle (OLLC). Data stream latency is modeled in Example Life-cycle Integrated Simulation Environment (ELISE). Two new algorithms are presented: CDTC versions 1 and 2, in which a specific time stamp protocol is used representing the time of classification. Comparison of these algorithms against previous time stamp learning algorithms CD3 and CD5 is made. A time stamp definition and algorithmic solution is presented for handling latency in data streams and improving classification recovery in such affected domains. Ã‚Â© 2011 Springer-Verlag.},
  Affiliation              = {School of Computing and Engineering, University of Ulster, Coleraine, County Londonderry, United Kingdom},
  Author_keywords          = {Classification; Concept Drift; Latency; Online Learning; Time Stamp},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes two new timestamp algorithms to combat time latency in Online classification learners operating with concept drift, after arguing such latency's impact on the learners. They compare the algorithms against two previous algorithms. A time stamp definition and algorithmic solution is presented for handling latency in data streams and improving classification recovery in such affected domains 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053325979&partnerID=40&md5=c19adca14dcba4b178a4a6fc36f7a9a6}
}

@InProceedings{Mauer2011,
  Title                    = {{Heuristic methods for automating event detection on sensor data in near real-time}},
  Author                   = {Mauer, Daniel and Lai, Barry and Casper, Jennifer and Leveille, Peter and Hu, Jing and Albuquerque, Ronald and Cheung, Eddy},
  Booktitle                = {2011 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)},
  Year                     = {2011},
  Month                    = feb,
  Pages                    = {1--8},
  Publisher                = {IEEE},

  Abstract                 = {Moving target indicator (MTI) analysts in the field are responsible for processing the increasing amounts of live streaming data. Analysts manually access unique data sources through a set of tools, and perform analysis on the available data. Operationally, analysts can only concentrate on small areas of interest and are subject to attentional blindness. Abnormalities in the periphery are often not detected until the forensic stage. Analysts are in need of assistance in performing data analysis. This paper presents the implementation of a heuristic-based stream mining approach for cueing the analyst user on geospatial temporal patterns (termed Ã¢â‚¬Å“eventÃ¢â‚¬ï¿½ for this effort) in near real-time. This approach is designed to aid analysts in detecting noteworthy events scattered within the overabundance of data, a problem which is well-documented and recognized. The implementation involves two phases: the isolation of areas of unusual activity using density grids, followed by event detection within those areas. Four analyst-identified events - starburst, inverse starburst, fanning, and inverse fanning - were identified for automated detection using these techniques. The event detection method was employed as a service within the Sensor Data \& Analysis Framework (SDAF). The algorithm implementation and evaluation produced findings and informal user feedback. The results of this effort aids in establishing the foundation for near real-time event detection in MTI data analysis.},
  Doi                      = {10.1109/COGSIMA.2011.5753446},
  ISBN                     = {978-1-61284-785-6},
  Keywords                 = {Algorithm design and analysis,Clustering algorithms,Data mining,Event detection,Forensics,Geospatial analysis,MTI,Real time systems,automating event detection,data analysis,geospatial temporal patterns,heuristic methods,military computing,moving target indicator,sensor data,sensor fusion,streaming data analysis,target tracking},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a duplicate of Mauer2011a},
  Shorttitle               = {Cognitive Methods in Situation Awareness and Decis},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5753446}
}

@Conference{Mauer2011a,
  Title                    = {Heuristic methods for automating event detection on sensor data in near real-time},
  Author                   = {Mauer, D. and Lai, B. and Casper, J. and Leveille, P. and Hu, J. and Albuquerque, R. and Cheung, E.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1-8},

  Abstract                 = {Moving target indicator (MTI) analysts in the field are responsible for processing the increasing amounts of live streaming data. Analysts manually access unique data sources through a set of tools, and perform analysis on the available data. Operationally, analysts can only concentrate on small areas of interest and are subject to attentional blindness. Abnormalities in the periphery are often not detected until the forensic stage. Analysts are in need of assistance in performing data analysis. This paper presents the implementation of a heuristic-based stream mining approach for cueing the analyst user on geospatial temporal patterns (termed "event" for this effort) in near real-time. This approach is designed to aid analysts in detecting noteworthy events scattered within the overabundance of data, a problem which is well-documented and recognized [1], [2]. The implementation involves two phases: the isolation of areas of unusual activity using density grids, followed by event detection within those areas. Four analyst-identified events - starburst, inverse starburst, fanning, and inverse fanning - were identified for automated detection using these techniques. The event detection method was employed as a service within the Sensor Data & Analysis Framework (SDAF). The algorithm implementation and evaluation produced findings and informal user feedback. The results of this effort aids in establishing the foundation for near real-time event detection in MTI data analysis. Ã‚Â© 2011 IEEE.},
  Affiliation              = {MITRE Corporation, Bedford, MA 01730-1420, United States},
  Art_number               = {5753446},
  Document_type            = {Conference Paper},
  Journal                  = {2011 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support, CogSIMA 2011},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents the implementation of a heuristic-based stream mining approach for cueing the analyst user on geospatial temporal patterns (termed "event" for this effort) in near real-time. The algorithm implementation and evaluation produced findings and informal user feedback. The results of this effort aids in establishing the foundation for near real-time event detection in MTI data analysis Only qualitative results. This is a introductionary effort for event detection in Moving Target Indicator (for cameras? I'm not sure) so to aid analyst in detecting events. 1,2,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79956131499&partnerID=40&md5=d651476e43b55eeaa5834cbbf5d65dcf}
}

@Article{Mavani2013,
  Title                    = {MapReduce frame work: Investigating suitability for faster data analytics},
  Author                   = {Mavani, M.a and Ragha, L.b },
  Journal                  = {Communications in Computer and Information Science},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {119-130},
  Volume                   = {361 CCIS},

  Abstract                 = {Faster data analytics is the ability to generate the desired report in near real time. Any application that looks at an aggregated view of a stream of data can be considered as an analytic application. The demand to process vast amounts of data to produce various market trends, user behavior, fraud behavior etc. becomes not just useful, but critical to the success of the business. In the past few years, fast data, i.e., high-speed data streams, has also exploded in volume and availability. Prime examples include sensor data streams, real-time stock market data, and social-media feeds such as Twitter, Facebook etc. New models for distributed stream processing have been evolved over a time. This research investigates the suitability of Google's MapReduce (MR) parallel programming frame work for faster data processing. Originally MapReduce systems are geared towards batch processing. This paper proposes some optimizations to original MR framework for faster distributed data processing applications using distributed shared memory to store intermediate data and use of Remote Direct Access (RDMA) technology for faster data transfer across network. Ã‚Â© 2013 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {SIES College of Management Studies, Navi Mumbai, India; Ramrao Adik Institute of Technology, Navi Mumbai, India},
  Author_keywords          = {distributed shared memory; faster data analytics; Map Reduce; Remote Direct Memory Access},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {This research investigates the suitability of Google's MapReduce (MR) parallel programming frame work for faster data processing. This paper proposes some optimizations to original MR framework for faster distributed data processing applications using distributed shared memory to store intermediate data and use of Remote Direct Access (RDMA) technology for faster data transfer across network Discarded, only about data processing, no ML used. Could have information about the suitability of using MR for our purpose},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84872366890&partnerID=40&md5=31c75897f6b5877caed9fc32c872d336}
}

@Misc{Mazur,
  Title                    = {{Towards Scalable One-Pass Analytics Using MapReduce}},

  Author                   = {Mazur, Edward and Li, Boduo and Diao, Yanlei and Shenoy, Prashant},
  Year                     = {2011},

  __markedentry            = {[Alexander:]},
  Abstract                 = {An integral part of many data-intensive applications is the need to collect and analyze enormous datasets efficiently. Concurrent with such application needs is the increasing adoption of MapReduce as a programming model for processing large datasets using a cluster of machines. Current MapReduce systems, however, require the data set to be loaded into the cluster before running analytical queries, and thereby incur high delays to start query processing. Furthermore, existing systems are geared towards batch processing. In this paper, we seek to answer a fundamental question: what architectural changes are necessary to bring the benefits of the MapReduce computation model to incremental, onepass analytics, i.e., to support stream processing and online aggregation? To answer this question, we first conduct a detailed empirical performance study of current MapReduce implementations including Hadoop and MapReduce Online using a variety of workloads. By doing so, we identify several drawbacks of existing systems for one-pass analytics. Based on the insights from our study, we list key design requirements for incremental one-pass analytics and argue for architectural changes of MapReduce systems to overcome their current limitations. We conclude by sketching an initial design of our new MapReduce-based platform for incremental one-pass analytics and showing promising preliminary results. Keywords-MapReduce; performance analysis; data streams; parallel data processing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper seek to answer the question: what architectural changes are necessary to bring the benefits of the MapReduce computation model to incremental, onepass analytics, i.e., to support stream processing and online aggregation? They conduct a empirical performance study of current MapReduce implementations including Hadoop and MapReduce Online using a variety of workloads and identify many drawbacks. They then list design requirements for one-pass analytics. . They conclude by sketching an initial design of a new MapReduce-based platform for incremental one-pass analytics and showing promising preliminary results. An exploratory study with promising results. Could be a primary study. 1,2,3,4,5,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.224.1924}
}

@Misc{Mckelvey,
  Title                    = {{Design and Prototyping of a Social Media Observatory}},

  Author                   = {Mckelvey, Karissa},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The broad adoption of online social networking platforms has made it possible to study communication networks at an unprecedented scale. With social media and micro-blogging platforms such as Twitter, we can observe high-volume data streams of online discourse. However, it is a challenge to collect, manage, analyze, visualize, and deliver large amounts of data, even by experts in the computational sciences. In this paper, we describe our recent extensions to Truthy, a social media observatory that collects and analyzes discourse on Twitter dating from August 2010. We introduce several interactive visualizations and analytical tools with the goal of enabling researchers to study online social networks with mixed methods at multiple scales. We present design considerations and a prototype for integrating social media observatories as important components of a web observatory framework.},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. The word analytical tool does not seem to imply ML techniques has been used.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.401.7864}
}

@InProceedings{Melville2013,
  Title                    = {{Amplifying the voice of youth in Africa via text analytics}},
  Author                   = {Melville, Prem and Chenthamarakshan, Vijil and Lawrence, Richard D. and Powell, James and Mugisha, Moses and Sapra, Sharad and Anandan, Rajesh and Assefa, Solomon},
  Booktitle                = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {1204},
  Publisher                = {ACM Press},

  Abstract                 = {U-report is an open-source SMS platform operated by UNICEF Uganda, designed to give community members a voice on issues that impact them. Data received by the system are either SMS responses to a poll conducted by UNICEF, or unsolicited reports of a problem occurring within the community. There are currently 200,000 U-report participants, and they send up to 10,000 unsolicited text messages a week. The objective of the program in Uganda is to understand the data in real-time, and have issues addressed by the appropriate department in UNICEF in a timely manner. Given the high volume and velocity of the data streams, manual inspection of all messages is no longer sustainable. This paper describes an automated message-understanding and routing system deployed by IBM at UNICEF. We employ recent advances in data mining to get the most out of labeled training data, while incorporating domain knowledge from experts. We discuss the trade-offs, design choices and challenges in applying such techniques in a real-world deployment.},
  Doi                      = {10.1145/2487575.2488216},
  ISBN                     = {9781450321747},
  Keywords                 = {machine learning,text classification},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {U-report is an open-source SMS platform. The objective of the program in Uganda is to understand the data in real-time. This paper describes an automated message-understanding and routing system deployed by IBM. They employ advances in data mining to get the most out of labeled training data, while incorporating domain knowledge from experts. They discuss the trade-offs, design choices and challenges in applying such techniques in a real-world deployment. This paper describes using ML techniques on a open source SMS-platform to facilitate action. Could be a primary source. 1,2,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2487575.2488216}
}

@Misc{Melville2011,
  Title                    = {{Amplifying the Voice of Youth in Africa via Text Analytics}},

  Author                   = {Melville, Prem and Chenthamarakshan, Vijil and Powell, James and Mugisha, Moses and Lawrence, Richard D.},
  Year                     = {2011},

  __markedentry            = {[Alexander:]},
  Abstract                 = {U-report is an open-source SMS platform operated by UNICEF Uganda, designed to give community members a voice on issues that impact them. Data received by the system are either SMS responses to a poll conducted by UNICEF, or unsolicited reports of a problem occurring within the community. There are currently 200,000 U-report participants, and they send up to 10,000 unsolicited text messages a week. The objective of the program in Uganda is to understand the data in real-time, and have issues addressed by the appropriate department in UNICEF in a timely manner. Given the high volume and velocity of the data streams, manual inspection of all messages is no longer sustainable. This paper describes an automated message-understanding and routing system deployed by IBM at UNICEF. We employ recent advances in data mining to get the most out of labeled training data, while incorporating domain knowledge from experts. We discuss the trade-offs, design choices and challenges in applying such techniques in a real-world deployment.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a duplicate of Melville2013},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.414.3237}
}

@Article{Meng2006,
  Title                    = {Mining developing trends of dynamic spatiotemporal data streams},
  Author                   = {Meng, Y. and Dunham, M.H.},
  Journal                  = {Journal of Computers},
  Year                     = {2006},
  Note                     = {cited By (since 1996)3},
  Number                   = {3},
  Pages                    = {43-50},
  Volume                   = {1},

  Abstract                 = {This paper1 presents an efficient modeling technique for data streams in a dynamic spatiotemporal environment and its suitability for mining developing trends. The streaming data are modeled using a data structure that interleaves a semi-unsupervised clustering algorithm with a dynamic Markov chain. The granularity of the clusters is calibrated using global constraints inherent to the data streams. Novel operations are proposed for identifying developing trends. These operations include deleting obsolete events using a sliding window scheme and identifying emerging events based on a scoring scheme derived from the synopsis obtained from the modeling process. The proposed technique is incremental, scalable, adaptive, and suitable for online processing. Algorithm analysis and experiments demonstrate the efficiency and effectiveness of the proposed technique. Ã‚Â© 2006 ACADEMY PUBLISHER.},
  Affiliation              = {Department of Computer Science and Engineering, Southern Methodist University, Dallas, United States},
  Author_keywords          = {Clustering; Data mining; Data stream; Developing trend; Markov chain},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents an efficient modeling technique for data streams in a dynamic spatiotemporal environment, using semi-unsupervised clustering with a dynamic Markov Chain. Novel operations are proposed for identifying developing trends. The proposed technique is incremental, scalable, adaptive, and suitable for online processing. Algorithm analysis and experiments demonstrate the efficiency and effectiveness of the proposed technique. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77955133761&partnerID=40&md5=e42bf3eb8ab8db7f3918d2098f786e2c}
}

@Misc{Meng,
  Title                    = {{Mining Developing Trends of Dynamic Spatiotemporal Data Streams}},

  Author                   = {Meng, Yu and Dunham, Margaret H.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper 1 presents an efficient modeling technique for data streams in a dynamic spatiotemporal environment and its suitability for mining developing trends. The streaming data are modeled using a data structure that interleaves a semi-unsupervised clustering algorithm with a dynamic Markov chain. The granularity of the clusters is calibrated using global constraints inherent to the data streams. Novel operations are proposed for identifying developing trends. These operations include deleting obsolete events using a sliding window scheme and identifying emerging events based on a scoring scheme derived from the synopsis obtained from the modeling process. The proposed technique is incremental, scalable, adaptive, and suitable for online processing. Algorithm analysis and experiments demonstrate the efficiency and effectiveness of the proposed technique. Index Terms—data mining, data stream, clustering, Markov chain, developing trend},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being a duplicate of Meng2006},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.92.8504}
}

@Conference{Miao2010,
  Title                    = {A heuristic method for unstructured pattern management over data streams},
  Author                   = {Miao, G.a and Li, H.b and Wang, T.c },
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Pages                    = {468-471},

  Abstract                 = {Pattern management is an important task in data stream mining and has attracted increasing attention recently. Variations of data stream patterns typically imply some fundamental changes of underlying objects and possess significant domain meanings. Many database applications require investigating the history information to get the knowledge about the evolving process of data streams. However, in most circumstances, the data stream patterns are unstructured: limited memory space cannot record all the patterns discovered online, no training sets or predefined models are available, and large numbers of noises bring another nontrivial challenge. This paper presents our research effort in online pattern management over such streams. A novel algorithm is proposed to detect stream changes, organize meaningful patterns and distinguish useful variations from noises. It extracts new trends from unstructured data heuristically, and involves a special parameter to identify whether the current event should be treated as significant. Several experiments are performed and the results prove this new method feasible and efficient. Ã‚Â© 2010 IEEE.},
  Affiliation              = {School of Electronics Engineering and Computer Science, Peking University, Beijing 100080, China; Key Laboratory of Machine Perception, Peking University, Ministry of Education, China; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, China},
  Art_number               = {5474089},
  Document_type            = {Conference Paper},
  Journal                  = {Advances in Web Technologies and Applications - Proceedings of the 12th Asia-Pacific Web Conference, APWeb 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents the research effort in online pattern management over streams. A novel algorithm is proposed to detect stream changes, organize meaningful patterns and distinguish useful variations from noises. . It extracts new trends from unstructured data heuristically by using a special parameter. Experiments show feasability and efficieny 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954258474&partnerID=40&md5=1f5d545ca213810e3f5a3a0bdbe91f45}
}

@Conference{Michael2009,
  Title                    = {Real-time spatio-temporal data mining with the "streamonas" data stream management system},
  Author                   = {Michael, P.A. and Stott Parker, D.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {113-122},
  Volume                   = {42},

  Abstract                 = {Data Stream Management Systems (DSMSs) have not yet reached a mature enough stage to effectively run data mining algorithms, as they still face challenges within the streaming environment. Streamonas DSMS, as presented in a recent publication, is the first DSMS to reach the maximum level of difficulty supported by the Linear Road Benchmark which is 10 Expressways. The powerful engine of Streamonas can manage an input stream of 20,368 tuples/second with an average query latency of 0.000026 seconds, 192,307 times faster when compared to the 5 seconds maximum query latency the benchmark allows. The on-line data mining over streams presented in this work, is the first effort to apply spatio-temporal data mining algorithms on the Streamonas DSMS system. Dynamic clustering of spatio-temporal subsequences in real-time has been performed successfully, within the large space, high bandwidth, heavy load linear road benchmark streaming platform. Dynamic clustering queries have been expressed in a novel SQL-like language, which we name Streamonas-SQL. Ã‚Â© 2009 WIT Press.},
  Affiliation              = {Computer Science Department, University of California Los Angeles, United States},
  Author_keywords          = {Data mining; Dynamic clustering; Linear road benchmark; Pattern matching; Query latency; Real-time; Semantic space; Spatio-temporal; Streamonas; Streamonas-SQL; Throughput},
  Document_type            = {Conference Paper},
  Journal                  = {WIT Transactions on Information and Communication Technologies},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The on-line data mining over streams presented in this work, is the first effort to apply spatio-temporal data mining algorithms on the Streamonas DSMS system (A SotA Data Stream Management System). Dynamic clustering of spatio-temporal subsequences in real-time has been performed successfully, within the large space, high bandwidth, heavy load linear road benchmark streaming platform This paper seems very interesting. They do clustering in real-time on a SotA system and are among the first to do so. The paper is 6 years old though, so the system might be outdated. 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-71649100638&partnerID=40&md5=bf88457f8b0fa5ef8881f3eadcdb9356}
}

@Article{MillAƒA¡n-Giraldo2008,
  Title                    = {A comparative study of simple online learning strategies for streaming data},
  Author                   = {MillÃƒÂ¡n-Giraldo, M. and SÃƒÂ¡nchez, J.S.},
  Journal                  = {WSEAS Transactions on Circuits and Systems},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Number                   = {10},
  Pages                    = {900-910},
  Volume                   = {7},

  Abstract                 = {Since several years ago, the analysis of data streams has attracted considerably the attention in various research fields, such as databases systems and data mining. The continuous increase in volume of data and the high speed that they arrive to the systems challenge the computing systems to store, process and transmit. Furthermore, it has caused the development of new online learning strategies capable to predict the behavior of the streaming data. This paper compares three very simple learning methods applied to static data streams when we use the 1-Nearest Neighbor classifier, a linear discriminant, a quadratic classifier, a decision tree, and the NaÃƒÂ¯ve Bayes classifier. The three strategies have been taken from the literature. One of them includes a time-weighted strategy to remove obsolete objects from the reference set. The experiments were carried out on twelve real data sets. The aim of this experimental study is to establish the most suitable online learning model according to the performance of each classifier.},
  Affiliation              = {Universitat Jaume I, Dept. Llenguatges i Sistemes InformÃƒÂ¡tics, Av. Sos Baynat s/n, 12071 CastellÃƒÂ³ de la Plana, Spain},
  Author_keywords          = {Data mining; Forgetting; Online learning; Static streaming data},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. They only review three classic learning methods applied to static data streams. Could be a similar study or background info.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-59249085929&partnerID=40&md5=0fb7b9f8e39d5c0d8e29767dbb0dd589}
}

@Conference{Mimran2014,
  Title                    = {Data stream mining with multiple sliding windows for continuous prediction},
  Author                   = {Mimran, O. and Even, A.},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Data stream mining (DSM) deals with continuous online processing and evaluation of fast-accumulating data, in cases where storing and evaluating large historical datasets is neither feasible nor efficient. This research introduces the Multiple Sliding Windows (MSW) algorithm, and demonstrates its application for a DSM scenario with discrete independent variables and a continuous dependent variable. The MSW development emerged from the need to dynamically allocate computational resources that are shared by many tasks, and predicts the required resources per task. The algorithm was evaluated with a large real-world dataset that reflects resource allocation at Intel's global data servers cloud. The evaluation assesses three MSW treatments: the use of multiple sliding-windows, a novel iterative mechanism for feature selection, and adaptive detection of concept drifts. The evaluation showed positive and significant results in terms of prediction quality and the ability to adapt to swift and/or graduate changes in data stream characteristics. Following the successful evaluation, the adoption of the proposed MSW solution by Intel led to cost savings estimated in millions of dollars annually. While evaluated in a specific context, the generic and modular definition of the MSW permits implementation in other domains that deal with DSM problems of similar nature.},
  Affiliation              = {Ben-Gurion University, Beer-Sheva, Israel},
  Author_keywords          = {Concept Drift; Data Stream Mining; Dynamic Resource Allocation; Real-Time Business Intelligence; Sliding Windows},
  Document_type            = {Conference Paper},
  Journal                  = {ECIS 2014 Proceedings - 22nd European Conference on Information Systems},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This research introduces the Multiple Sliding Windows (MSW) algorithm, and demonstrates its application for a DSM scenario with discrete independent variables and a continuous dependent variable. The evaluation assesses three MSW treatments: the use of multiple sliding-windows, a novel iterative mechanism for feature selection, and adaptive detection of concept drifts, and provided promising results in prediction and adaptability. This seems interesting. It seems the paper made a new algorithm which saved Intel millions of dollars. A possible primary source. 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905845471&partnerID=40&md5=14cb834cdb96275c656a23810eb66071}
}

@InProceedings{Mingliang2009,
  Title                    = {{Data stream mining based real-time highspeed traffic classification}},
  Author                   = {Mingliang, Guo and Xiaohong, Huang and Xu, Tian and Yan, Ma and Zhenhua, Wang},
  Booktitle                = {2009 2nd IEEE International Conference on Broadband Network \& Multimedia Technology},
  Year                     = {2009},
  Month                    = oct,
  Pages                    = {700--705},
  Publisher                = {IEEE},

  Abstract                 = {In current high-speed network, Peer-to-Peer (P2P) applications have overtaken Web applications as the major contribution on the Internet. Thereby, how to identify P2P traffic in real-time accurately and efficiently is a key step for network management. In this paper, we highlight the importance of applying data stream method in traffic classification to achieve real-time P2P traffic identification. We not only introduce a VFDT-based real-time highspeed traffic classification method, but also take thoroughly analysis on how to select a reasonable tie confidence (TieC), minimum gathering flow (MinGF) and category number (CaNum). Meanwhile, analysis has been done to ascertain the packet's interval which is used to calculate flow's real-time attribute. Experiment results have shown that when TieC is less than threshold, the larger TieC is, the better accuracy of identification is; when TieC exceeds threshold, decision trees are the same. Concerning MinGF and CaNum, although the smaller both of them are, the better performance of decision tree is, the value of them must be properly set according to requirements of classification system.},
  Doi                      = {10.1109/ICBNMT.2009.5347837},
  ISBN                     = {978-1-4244-4590-5},
  Keywords                 = {Application software,Data mining,Data stream,Decision trees,High speed,High-speed networks,IP networks,Intelligent networks,Internet,Laboratories,Machine learning,P2P traffic identification,Real-time,Streaming media,Telecommunication traffic,Traffic classification,VFDT,VFDT based realtime classification method,category number,data mining,data stream mining,highspeed traffic classification,minimum gathering flow,pattern classification,peer-to-peer computing,reasonable tie confidence},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being duplicate of Mingliang2009a},
  Shorttitle               = {Broadband Network \& Multimedia Technology, 2009. I},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5347837}
}

@Conference{Mingliang2009a,
  Title                    = {Data stream mining based real-time highspeed traffic classification},
  Author                   = {Mingliang, G.a and Xiaohong, H.a and Xu, T.a and Yan, M.a b and Zhenhua, W.a },
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {700-705},

  Abstract                 = {In current high-speed network, Peer-to-Peer(P2P) applications have overtaken Web applications as the major contribution on the Internet. Thereby, how to identify P2P traffic in real-time accurately and efficiently is a key step for network management. In this paper, we highlight the importance of applying data stream method in traffic classification to achieve real-time P2P traffic identification. We not only introduce a VFDT-based real-time highspeed traffic classification method, but also take thoroughly analysis on how to select a reasonable tie confidence (TieC), minimum gathering flow (MinGF) and category number (CaNum). Meanwhile, analysis has been done to ascertain the packet's interval which is used to calculate flow's real-time attribute. Experiment results have shown that when TieC is less than threshold, the larger TieC is, the better accuracy of identification is; when TieC exceeds threshold, decision trees are the same. Concerning MinGF and CaNum, although the smaller both of them are, the better performance of decision tree is, the value of them must be properly set according to requirements of classification system. Ã‚Â©2009 IEEE.},
  Affiliation              = {Information Network Center, Research Institute of Networking Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China; Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing 100876, China},
  Art_number               = {5347837},
  Author_keywords          = {Data stream; High speed; Real-time; Traffic classification; VFDT},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of 2009 2nd IEEE International Conference on Broadband Network and Multimedia Technology, IEEE IC-BNMT2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper highlight the importance of applying data stream method in traffic classification to achieve real-time P2P traffic identification. They introduce a VFDT-based real-time highspeed traffic classification method, but also provide analysis on how to select a some key charactheristics. These are used in experimentation to find the most accurate identification. So this paper is about classyfying traffic in RT P2P. Might be interesting. Not sure about what SotA in this field are. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-74549143739&partnerID=40&md5=245445c6b26f878a2361561790e9ff11}
}

@Article{Miotto2011,
  Title                    = {The TDAQ analytics dashboard: A real-time web application for the ATLAS TDAQ control infrastructure},
  Author                   = {Miotto, G.L. and Magnoni, L. and Sloper, J.E.},
  Journal                  = {Journal of Physics: Conference Series},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 2},
  Volume                   = {331},

  Abstract                 = {The ATLAS Trigger and Data Acquisition (TDAQ) infrastructure is responsible for filtering and transferring ATLAS experimental data from detectors to mass storage systems. It relies on a large, distributed computing system composed of thousands of software applications running concurrently. In such a complex environment, information sharing is fundamental for controlling applications behavior, error reporting and operational monitoring. During data taking, the streams of messages sent by applications and data published via information services are constantly monitored by experts to verify the correctness of running operations and to understand problematic situations. To simplify and improve system analysis and errors detection tasks, we developed the TDAQ Analytics Dashboard, a web application that aims to collect, correlate and visualize effectively this real time flow of information. The TDAQ Analytics Dashboard is composed of two main entities that reflect the twofold scope of the application. The first is the engine, a Java service that performs aggregation, processing and filtering of real time data stream and computes statistical correlation on sliding windows of time. The results are made available to clients via a simple web interface supporting SQL-like query syntax. The second is the visualization, provided by an Ajax-based web application that runs on client's browser. The dashboard approach allows to present information in a clear and customizable structure. Several types of interactive graphs are proposed as widgets that can be dynamically added and removed from visualization panels. Each widget acts as a client for the engine, querying the web interface to retrieve data with desired criteria. In this paper we present the design, development and evolution of the TDAQ Analytics Dashboard. We also present the statistical analysis computed by the application in this first period of high energy data taking operations for the ATLAS experiment.},
  Affiliation              = {European Laboratory for Particle Physics (CERN), Geneva, Switzerland},
  Art_number               = {22019},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They developed the TDAQ Analytics Dashboard, a web application that aims to collect, correlate and visualize effectively this real time flow of information from the TDAQ infrastructure. Consists of two entities: One that performs aggregation, processing and filtering of real time data stream and computes statistical correlation on sliding windows of time. The second is the visualization. They have made an analytics engine for existing infrastructure for distributed software. It seem they perform ML on the data streams from TDAQ, so the paper is approved. Not sure if there is any learning though 1,2,3},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84858119861&partnerID=40&md5=afdeb264cb8d0f79bcb046e191337e82}
}

@InProceedings{Mishin2012,
  Title                    = {{Incremental and Parallel Analytics on Astrophysical Data Streams}},
  Author                   = {Mishin, Dmitry and Budavari, Tamas and Szalay, Alexander and Ahmad, Yanif},
  Booktitle                = {2012 SC Companion: High Performance Computing, Networking Storage and Analysis},
  Year                     = {2012},
  Month                    = nov,
  Pages                    = {1078--1086},
  Publisher                = {IEEE},

  Abstract                 = {Stream processing methods and online algorithms are increasingly appealing in the scientific and large-scale data management communities due to increasing ingestion rates of scientific instruments, the ability to produce and inspect results interactively, and the simplicity and efficiency of sequential storage access over enormous datasets. This article will showcase our experiences in using off-the-shelf streaming technology to implement incremental and parallel spectral analysis of galaxies from the Sloan Digital Sky Survey (SDSS) to detect a wide variety of galaxy features. The technical focus of the article is on a robust, highly scalable principal components analysis (PCA) algorithm and its use of coordination primitives to realize consistency as part of parallel execution. Our algorithm and framework can be readily used in other domains.},
  Doi                      = {10.1109/SC.Companion.2012.130},
  ISBN                     = {978-0-7695-4956-9},
  Keywords                 = {PCA algorithm,Sloan Digital Sky Survey,Streaming analysis,astronomy computing,astrophysical data stream,coordination primitive,data analysis,data management community,galaxies,galaxy analysis,galaxy spectra,incremental analytics,parallel analytics,parallel execution,parallel processing,principal component analysis,principal components analysis,robust PCA,sequential storage,stream processing method,streaming PCA,streaming algorithm},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Not producing anything innovative, only highlighting their experiences using off-the-shelf software.,},
  Shorttitle               = {High Performance Computing, Networking, Storage an},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6495912}
}

@InProceedings{Mohamed2009,
  Title                    = {{Internet Information Retrieval for Enabling Student Projects}},
  Author                   = {Mohamed, Nader and Al-Jaroodi, Jameela and Jawhar, Imad},
  Booktitle                = {2009 Sixth International Conference on Information Technology: New Generations},
  Year                     = {2009},
  Pages                    = {987--992},
  Publisher                = {IEEE},

  Abstract                 = {Project-based learning (PBL) is becoming an integral part of many information technology (IT) courses. Students are guided through individual or group projects to learn and apply many of the IT concepts they learn in a course. However, a significant percentage of IT projects depend on the existence of large sets of information or live data. Therefore, it becomes difficult to complete and properly test many of the implemented projects. Some examples of such projects are financial data mining, information notification systems, weather monitoring systems, and decision support systems. While the needed information for the student projects is usually available over the Internet, there is no easy way to retrieve and reuse the required information. In this paper, we propose, describe, and discuss a tool called InetRetriever. This tool can be easily used by students to retrieve in real-time any required real information from the Internet. The students can use this tool to implement, execute, and test their projects with real life data. This tool was tested in different information technology courses to enable effective and realistic project-based learning. Using this tool we observed increased student interest in the project development and higher levels of interactions and learning.},
  Doi                      = {10.1109/ITNG.2009.280},
  ISBN                     = {978-1-4244-3770-2},
  Keywords                 = {Data mining,Decision making,Decision support systems,Educational institutions,InetRetriever,Information retrieval,Information technology,Internet,Internet information retrieval,Life testing,Monitoring,Problem-solving,computer aided instruction,decision support systems,educational courses,educational tools,financial data mining,information notification systems,information retrieval,information science education,information technology courses,project-based learning,student projects,weather monitoring systems},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {a significant percentage of IT projects depend on the existence of large sets of information or live data, so they are hard to test, especially for students. In this paper, we propose, describe, and discuss a tool called InetRetriever. Approved under strong doubt. IR system might be using machine learning 1,3,4},
  Shorttitle               = {Information Technology: New Generations, 2009. ITN},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5070752}
}

@Conference{Mohamed2009a,
  Title                    = {Internet information retrieval for enabling student projects},
  Author                   = {Mohamed, N. and Al-Jaroodi, J. and Jawhar, I.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {987-992},

  Abstract                 = {Project-based learning (PBL) is becoming an integral part of many information technology (IT) courses. Students are guided through individual or group projects to learn and apply many of the IT concepts they learn in a course. However, a significant percentage of IT projects depend on the existence of large sets of information or live data. Therefore, it becomes difficult to complete and properly test many of the implemented projects. Some examples of such projects are financial data mining, information notification systems, weather monitoring systems, and decision support systems. While the needed information for the student projects is usually available over the Internet, there is no easy way to retrieve and reuse the required information. In this paper, we propose, describe, and discuss a tool called InetRetriever. This tool can be easily used by students to retrieve in real-time any required real information from the Internet. The students can use this tool to implement, execute, and test their projects with real life data. This tool was tested in different information technology courses to enable effective and realistic project-based learning. Using this tool we observed increased student interest in the project development and higher levels of interactions and learning. Ã‚Â© 2009 IEEE.},
  Affiliation              = {College of Information Technology, United Arab Emirates University, P.O. Box 17551, Al Ain, United Arab Emirates},
  Art_number               = {5070752},
  Author_keywords          = {Educational tools; Information retrieval; Internet; Project-based learning},
  Document_type            = {Conference Paper},
  Journal                  = {ITNG 2009 - 6th International Conference on Information Technology: New Generations},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Mohamed2009},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77951109040&partnerID=40&md5=c70e0753bf269f9b11f18b46e5bcfe35}
}

@Article{Montana2009,
  Title                    = {Flexible least squares for temporal data mining and statistical arbitrage },
  Author                   = {Giovanni Montana and Kostas Triantafyllopoulos and Theodoros Tsagaris},
  Journal                  = {Expert Systems with Applications },
  Year                     = {2009},
  Number                   = {2, Part 2},
  Pages                    = {2819 - 2830},
  Volume                   = {36},

  Abstract                 = {A number of recent emerging applications call for studying data streams, potentially infinite flows of information updated in real-time. When multiple co-evolving data streams are observed, an important task is to determine how these streams depend on each other, accounting for dynamic dependence patterns without imposing any restrictive probabilistic law governing this dependence. In this paper we argue that flexible least squares (FLS), a penalized version of ordinary least squares that accommodates for time-varying regression coefficients, can be deployed successfully in this context. Our motivating application is statistical arbitrage, an investment strategy that exploits patterns detected in financial data streams. We demonstrate that \{FLS\} is algebraically equivalent to the well-known Kalman filter equations, and take advantage of this equivalence to gain a better understanding of \{FLS\} and suggest a more efficient algorithm. Promising experimental results obtained from a FLS-based algorithmic trading system for the S&amp;P 500 Futures Index are reported.},
  Doi                      = {http://dx.doi.org/10.1016/j.eswa.2008.01.062},
  ISSN                     = {0957-4174},
  Keywords                 = {Temporal data mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper propose an algorithm called Flexible Least Squares to determine if co-evolving data streams depend on each other. FLS is demonstrated to be algebraically equivalent to the well-known Kalman filter equations, and they use this suggest a more efficient algoithm. Experiments shows promise. Not sure if these guys came up with FLS on their own, but it seems like they have come up with improvements. 1,2,3,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0957417408000614}
}

@Conference{Mora2011,
  Title                    = {Service-based approach for intelligent agent frameworks},
  Author                   = {Mora, R.P.a and Hill, J.L.b },
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Volume                   = {47},

  Abstract                 = {This paper describes a service-based Intelligent Agent (IA) approach for machine learning and data mining of distributed heterogeneous data streams. We focus on an open architecture framework that enables the programmer/analyst to build an IA suite for mining, examining and evaluating heterogeneous data for semantic repre-sentations, while iteratively building the probabilistic model in real-time to improve predictability. The Framework facilitates model development and evaluation while delivering the capability to tune machine learning algorithms and models to deliver increasingly favorable scores prior to production deployment. The IA Framework focuses on open standard interoperability, simplifying integration into existing envi-ronments.},
  Affiliation              = {Avum Inc., Malibu, CA 90265, United States; Avum Inc., Atascadero, CA 93422, United States},
  Author_keywords          = {Bayesian priors; Intelligent agent; PMML; Probabilistic grammar; Service-based framework},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the International Telemetering Conference},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper describes a service-based Intelligent Agent (IA) approach for machine learning and data mining of distributed heterogeneous data streams Approved under doubt. Can not tell whether or not these guys developed this framework, and what ML techniques they use. 1},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84879018385&partnerID=40&md5=8e44011f38315854129bd1059b3e7d70}
}

@Misc{Morinaga,
  Title                    = {{Industry/Government Track Poster Tracking Dynamics of Topic Trends Using a Finite Mixture Model}},

  Author                   = {Morinaga, Satoshi and Yamanishi, Kenji},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In a wide range of business areas dealing with text data streams, including CRM, knowledge management, and Web monitoring services, it is an important issue to discover topic trends and analyze their dynamics in real-time.Specifically we consider the following three tasks in topic trend analysis: 1)Topic Structure Identification; identifying what kinds of main topics exist and how important they are, 2)Topic Emergence Detection; detecting the emergence of a new topic and recognizing how it grows, 3)Topic Characterization; identifying the characteristics for each of main topics. For real topic analysis systems, we may require that these three tasks be performed in an on-line fashion rather than in a retrospective way, and be dealt with in a single framework. This paper proposes a new topic analysis framework which satisfies this requirement from a unifying viewpoint that a topic structure is modeled using a finite mixture model and that any change of a topic trend is tracked by learning the finite mixture model dynamically.In this framework we propose the usage of a time-stamp based discounting learning algorithm in order to realize real-time topic structure identification.This enables tracking the topic structure adaptively by forgetting out-of-date statistics.Further we apply the theory of dynamic model selection to detecting changes of main components in the finite mixture model in order to realize topic emergence detection.We demonstrate the effectiveness of our framework using real data collected at a help desk to show that we are able to track dynamics of topic trends in a timely fashion.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being duplicate of Morinaga2004},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.375.126}
}

@Conference{Morinaga2004,
  Title                    = {Tracking dynamics of topic trends using a finite mixture model},
  Author                   = {Morinaga, S. and Yamanishi, K.},
  Year                     = {2004},
  Note                     = {cited By (since 1996)40},
  Pages                    = {811-816},

  Abstract                 = {In a wide range of business areas dealing with text data streams, including CRM, knowledge management, and Web monitoring services, it is an important issue to discover topic trends and analyze their dynamics in real-time. Specifically we consider the following three tasks in topic trend analysis: 1) Topic Structure Identification; identifying what kinds of main topics exist and how important they are, 2) Topic Emergence Detection; detecting the emergence of a new topic and recognizing how it grows, 3) Topic Characterization; identifying the characteristics for each of main topics. For real topic analysis systems, we may require that these three tasks be performed in an on-line fashion rather than in a retrospective way, and be dealt with in a single framework. This paper proposes a new topic analysis framework which satisfies this requirement from a unifying viewpoint that a topic structure is modeled using a finite mixture model and that any change of a topic trend is tracked by learning the finite mixture model dynamically. In this framework we propose the usage of a time-stamp based discounting learning algorithm in order to realize real-time topic structure identification. This enables tracking the topic structure adaptively by forgetting out-of-date statistics. Further we apply the theory of dynamic model selection to detecting changes of main components in the finite mixture model in order to realize topic emergence detection. We demonstrate the effectiveness of our framework using real data collected at a help desk to show that we are able to track dynamics of topic trends in a timely fashion.},
  Affiliation              = {NEC Corporation, 4-1-1, Miyazaki, Miyamae, Kawasaki, Kanagawa 216-8555, Japan},
  Author_keywords          = {CRM; Model selection; Text mining; Topic analysis},
  Document_type            = {Conference Paper},
  Journal                  = {KDD-2004 - Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes a new topic analysis framework modeled using a finite mixture model and that any change of a topic trend is tracked by learning the finite mixture model dynamically. They propose the usage of a time-stamp based discounting learning algorithm in order to realize real-time topic structure identification. They demonstrate effectiveness using real data to track dynamics of topic trends. Heavy abstract, did not make it completely clear what they were working on. Good introdution to their research though. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-12244292946&partnerID=40&md5=e6067d1a5af9cb25e59a3b08dc112efe}
}

@InProceedings{Morinaga2004a,
  Title                    = {{Tracking dynamics of topic trends using a finite mixture model}},
  Author                   = {Morinaga, Satoshi and Yamanishi, Kenji},
  Booktitle                = {Proceedings of the 2004 ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '04},
  Year                     = {2004},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {811},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/1014052.1016919},
  ISBN                     = {1581138889},
  Keywords                 = {CRM,model selection,text mining,topic analysis},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Morinaga2004},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1014052.1016919}
}

@Misc{Mousavi,
  Title                    = {{Fast Computation of Approximate Biased Histograms on Sliding Windows over Data Streams.}},

  Author                   = {Mousavi, Hamid and Zaniolo, Carlo},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Mousavi2013},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.407.3977}
}

@Conference{Mousavi2013,
  Title                    = {Fast computation of approximate biased histograms on sliding windows over data streams},
  Author                   = {Mousavi, H. and Zaniolo, C.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Histograms provide effective synopses of large data sets, and are thus used in a wide variety of applications, including query optimization, approximate query answering, distribution fitting, parallel database partitioning, and data mining. Moreover, very fast approximate algorithms are needed to compute accurate histograms on fast-arriving data streams, whereby online queries can be supported within the given memory and computing resources. Many real-life applications require that the data distribution in certain regions must be modeled with greater accuracy, and Biased Histograms are designed to address this need. In this paper, we define biased histograms over data streams and sliding windows on data streams, and propose the Bar Splitting Biased Histogram (BSBH) algorithm to construct them efficiently and accurately. We prove that BSBH generates expected o-approximate biased histograms for data streams with stationary distributions, and our experiments show that BSBH also achieves good approximation in the presence of concept shifts, even major ones. Additionally, BSBH employs a new biased sampling technique which outperforms uniform sampling in terms of accuracy, while using about the same amount of time and memory. Therefore, BSBH outperforms previously proposed algorithms for computing biased histograms over the whole data stream, and it is the first algorithm that supports windows. Copyright Ã‚Â© 2013 ACM.},
  Affiliation              = {Computer Science Department, UCLA, Los Angeles, United States},
  Art_number               = {13},
  Author_keywords          = {Biased histograms; Data streams; Quantiles; Sliding windows},
  Document_type            = {Conference Paper},
  Journal                  = {ACM International Conference Proceeding Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we define biased histograms over data streams and sliding windows on data streams, and propose the Bar Splitting Biased Histogram (BSBH) algorithm to construct them efficiently and accurately. experiments show that BSBH also achieves good approximation in the presence of concept shifts, even major ones. BSBH outperforms previously proposed algorithms for computing biased histograms over the whole data stream, and it is the first algorithm that supports windows. Not sure how useful histograms over data streams are. 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84882974290&partnerID=40&md5=643aca4628cb4db4eb78ac1f8abe77d5}
}

@InProceedings{Mousavi2013a,
  Title                    = {{Fast computation of approximate biased histograms on sliding windows over data streams}},
  Author                   = {Mousavi, Hamid and Zaniolo, Carlo},
  Booktitle                = {Proceedings of the 25th International Conference on Scientific and Statistical Database Management - SSDBM},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = jul,
  Pages                    = {1},
  Publisher                = {ACM Press},

  Abstract                 = {Histograms provide effective synopses of large data sets, and are thus used in a wide variety of applications, including query optimization, approximate query answering, distribution fitting, parallel database partitioning, and data mining. Moreover, very fast approximate algorithms are needed to compute accurate histograms on fast-arriving data streams, whereby online queries can be supported within the given memory and computing resources. Many real-life applications require that the data distribution in certain regions must be modeled with greater accuracy, and Biased Histograms are designed to address this need. In this paper, we define biased histograms over data streams and sliding windows on data streams, and propose the Bar Splitting Biased Histogram (BSBH) algorithm to construct them efficiently and accurately. We prove that BSBH generates expected ∈-approximate biased histograms for data streams with stationary distributions, and our experiments show that BSBH also achieves good approximation in the presence of concept shifts, even major ones. Additionally, BSBH employs a new biased sampling technique which outperforms uniform sampling in terms of accuracy, while using about the same amount of time and memory. Therefore, BSBH outperforms previously proposed algorithms for computing biased histograms over the whole data stream, and it is the first algorithm that supports windows.},
  Doi                      = {10.1145/2484838.2484851},
  ISBN                     = {9781450319218},
  Keywords                 = {biased histograms,data streams,quantiles,sliding windows},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2484838.2484851}
}

@InProceedings{Mozafari2008,
  Title                    = {{Verifying and Mining Frequent Patterns from Large Windows over Data Streams}},
  Author                   = {Mozafari, Barzan and Thakkar, Hetal and Zaniolo, Carlo},
  Booktitle                = {2008 IEEE 24th International Conference on Data Engineering},
  Year                     = {2008},
  Month                    = apr,
  Pages                    = {179--188},
  Publisher                = {IEEE},

  Abstract                 = {Mining frequent itemsets from data streams has proved to be very difficult because of computational complexity and the need for real-time response. In this paper, we introduce a novel verification algorithm which we then use to improve the performance of monitoring and mining tasks for association rules. Thus, we propose a frequent itemset mining method for sliding windows, which is faster than the state-of-the-art methods - in fact, its running time that is nearly constant with respect to the window size entails the mining of much larger windows than it was possible before. The performance of other frequent itemset mining methods (including those on static data) can be improved likewise, by replacing their counting methods (e.g., those using hash trees) by our verification algorithm.},
  Doi                      = {10.1109/ICDE.2008.4497426},
  ISBN                     = {978-1-4244-1836-7},
  Keywords                 = {Association rules,Computational complexity,Computer science,Computerized monitoring,Credit cards,Data mining,Delay,Frequency,Itemsets,Partitioning algorithms,association rules,computational complexity,data mining,data streams,frequent mining itemsets,verification algorithm},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Approved. Introduce a novel verification algorithm which is used to improve the performance of monitoring and mining tasks for association rules. This verification algorithm can improve other frequent itemset mining algorithms. Uncertain what lies in a verification algorithm, is it a preprocessing step? 1,3,4,5,6},
  Shorttitle               = {Data Engineering, 2008. ICDE 2008. IEEE 24th Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4497426}
}

@Conference{Mozafari2008a,
  Title                    = {Verifying and mining frequent patterns from large windows over data streams},
  Author                   = {Mozafari, B. and Thakkar, H. and Zaniolo, C.},
  Year                     = {2008},
  Note                     = {cited By (since 1996)38},
  Pages                    = {179-188},

  Abstract                 = {Mining frequent itemsets from data streams has proved to be very difficult because of computational complexity and the need for real-time response. In this paper, we introduce a novel verification algorithm which we then use to improve the performance of monitoring and mining tasks for association rules. Thus, we propose a frequent itemset mining method for sliding windows, which is faster than the state-of-the-art methods-in fact, its running time that is nearly constant with respect to the window size entails the mining of much larger windows than it was possible before. The performance of other frequent itemset mining methods (including those on static data) can be improved likewise, by replacing their counting methods (e.g., those using hash trees) by our verification algorithm. Ã‚Â© 2008 IEEE.},
  Affiliation              = {Computer Science Department, University of California, Los Angeles, CA, United States},
  Art_number               = {4497426},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Mozafaru2008},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-52649129706&partnerID=40&md5=91842681f9cd0e828ff716b689ac5b30}
}

@Article{Mozafari2007,
  Title                    = {{Verifying and mining frequent patterns from large windows over data streams}},
  Author                   = {Mozafari, Barzan and Thakkar, Hetal and Zaniolo, Carlo},
  Year                     = {2007},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Mozafari2008},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.6060}
}

@Conference{Mueller2006,
  Title                    = {Algorithms for on-line differentiation of neuroelectric activities},
  Author                   = {Mueller, K.-R.a b },
  Year                     = {2006},
  Note                     = {cited By (since 1996)0},
  Pages                    = {6525},

  Abstract                 = {Brain Computer Interfacing (BCI) aims at making use of brain signals for e.g. the control of objects, spelling, gaming and so on. This talk will first provide a very brief overview of Brain Computer Interface from a machine learning and signal processing perspective. In particular it shows the wealth, the complexity and the difficulties of the data available, a truely enormous challenge: In real-time a multi-variate very strongly noise contaminated data stream is to be processed and neuroelectric activities are to be accurately differentiated. Finally, I report in more detail about the Berlin Brain Computer (BBCI) Interface that is based on EEG signals and take the audience all the way from the measured signal, the preprocessing and filtering, the classification to the respective application. BCI as a new channel for man-machine communication is discussed in a clincial setting and for gaming. Ã‚Â© 2006 IEEE.},
  Affiliation              = {Intelligent Data Analysis Group, Fraunhofer FIRST, Berlin, Germany; Neuroinformatics Group, Department of Computer Science, University of Potsdam, Germany},
  Art_number               = {4030588},
  Document_type            = {Conference Paper},
  Journal                  = {Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, This is a talk, not a paper},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34047160007&partnerID=40&md5=1facd2b3bd65bf853b16b8a512470a43}
}

@Misc{Mukherjee,
  Title                    = {{Self-Managing Energy-Efficient Multicast Support in MANETs under End-to-End Reliability Constraints}},

  Author                   = {Mukherjee, Tridib and Varsamopoulos, Georgios and Gupta, Eep K. S.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Dynamic networks, e.g. Mobile Ad Hoc Networks (MANETs), call for self-healing routing protocols to tolerate topological changes imposed by node mobility. Moreover, emerging time-critical MANET applications such as disaster response and rescue, and battlefield operations, require support for real-time, reliable data streaming, while maintaining energy efficiency. However, most of the energy-efficient routing protocols rely on configuration parameters which need to be estimated and specified before the deployment phase. This paper proposes a self-managing, energy-efficient multicast routing suite based on the self stabilization paradigm. This suite uses (i) WECM, a Waste Energy Cost Metric designed for energy-efficient route selection, (ii) SS-SPST-E, a Self-Stabilizing, Shortest-Path Spanning Tree protocol for Energy efficiency based on WECM to maintain an energy-efficient, self-healing routing structure, (iii) SS-SPST-Efc, an enhanced SS-SPST-E with fault containment to decrease stabilization latency, (iv) AMO, an Analytical Model for Optimization framework to reduce the energy overhead of the route maintenance mechanism, and (v) self-configuration mechanisms that observe, estimate and disseminate the optimization parameters. The WECM’s innovation is that it considers the overhearing energy wasted. The AMO framework considers the link state change rate, application data traffic intensity, application packet delivery requirements, and the stabilization latency. Numerical evaluations show that SS-SPST-E slightly increases the energy consumption when compared with non-adaptive energy-efficient protocols such as EWMA because of its mechanism to handle mobility. Simulation results show that SS-SPST-Efc achieves the maximum balance},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, They propose a routing suite that does not use ML},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.161.3238}
}

@InProceedings{Murakami2012,
  Title                    = {{Data-Centered Service Composition for Information Analysis}},
  Author                   = {Murakami, Yohei and Tanaka, Masahiro and Bramantoro, Arif and Zettsu, Koji},
  Booktitle                = {2012 IEEE Ninth International Conference on Services Computing},
  Year                     = {2012},
  Month                    = jun,
  Pages                    = {602--608},
  Publisher                = {IEEE},

  Abstract                 = {In e-Science, many scientific workflow management systems have been developed to integrate distributed computation resources, data sets, and mining algorithms. Users usually modify and rerun a workflow while repeating procedures: preprocess of data, selection of features, modification of data, selection of mining algorithms, generation of models, and evaluation of the models. These procedures are continued until the domain knowledge is acquired. However, as the size of the data increases, the execution time of the workflow becomes longer and longer, which drives up the cost of rerunning the modified workflow. As a result, it becomes hard to quickly obtain the analysis result. In this research, we avoided the rerun of the workflow by storing service invocation results on a platform and realized data-centered service composition by adding and deleting rules to be fired. To validate the effectiveness of our proposed platform, we created two rule-based services to analyze real-time data: stream message data and sensing data.},
  Doi                      = {10.1109/SCC.2012.88},
  ISBN                     = {978-1-4673-3049-7},
  Keywords                 = {Data mining,Data models,Earthquakes,Engines,PaaS,Protocols,Real time systems,Sensors,data mining,data sets,data-centered service composition,data-driven,distributed computation resources,domain knowledge,e-Science,information analysis,mining algorithms,rule-based,rule-based services,scientific information systems,scientific workflow management systems,sensing data,service composition,stream message data,workflow management software},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Murakami2012a},
  Shorttitle               = {Services Computing (SCC), 2012 IEEE Ninth Internat},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6274196}
}

@Conference{Murakami2012a,
  Title                    = {Data-centered service composition for information analysis},
  Author                   = {Murakami, Y. and Tanaka, M. and Bramantoro, A. and Zettsu, K.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)1},
  Pages                    = {602-608},

  Abstract                 = {In e-Science, many scientific workflow management systems have been developed to integrate distributed computation resources, data sets, and mining algorithms. Users usually modify and rerun a workflow while repeating procedures: preprocess of data, selection of features, modification of data, selection of mining algorithms, generation of models, and evaluation of the models. These procedures are continued until the domain knowledge is acquired. However, as the size of the data increases, the execution time of the workflow becomes longer and longer, which drives up the cost of rerunning the modified workflow. As a result, it becomes hard to quickly obtain the analysis result. In this research, we avoided the rerun of the workflow by storing service invocation results on a platform and realized data-centered service composition by adding and deleting rules to be fired. To validate the effectiveness of our proposed platform, we created two rule-based services to analyze real-time data: stream message data and sensing data. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Information Services Platform Laboratory, National Institute of Information and Communications Technology (NICT), Kyoto, Japan},
  Art_number               = {6274196},
  Author_keywords          = {data-driven; PaaS; rule-based; service composition},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2012 IEEE 9th International Conference on Services Computing, SCC 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this research, we avoided the rerun of the workflow by storing service invocation results on a platform and realized data-centered service composition by adding and deleting rules to be fired Approved under uncertainty. Does Machine learning, but not sure if applicable to data streams},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867364003&partnerID=40&md5=1ad7a2609f8a4eef81541f171abb881c}
}

@Misc{Nabil,
  Title                    = {{Mining Frequent Itemsets from Online Data Streams: Comparative Study}},

  Author                   = {Nabil, Hebatallah Mohamed and Eldin, Ahmed Sharaf and Abd, Mohamed and Belal, El-fattah},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Online mining of data streams poses many new challenges more than mining static databases. In addition to the one-scan nature, the unbounded memory requirement, the high data arrival rate of data streams and the combinatorial explosion of itemsets exacerbate the mining task. The high complexity of the frequent itemsets mining problem hinders the application of the stream mining techniques. In this review, we present a comparative study among almost all, as we are acquainted, the algorithms for mining frequent itemsets from online data streams. All those techniques immolate with the accuracy of the results due to the relatively limited storage, leading, at all times, to approximated results. Keywords—Data mining; frequent itemsets; data stream; sliding window model; landmark model; fading mode},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.403.8575}
}

@InProceedings{Naeimi2013,
  Title                    = {{Innovative practices session 5C: Cloud atlas Ã¢â‚¬â€� Unreliability through massive connectivity}},
  Author                   = {Naeimi, Helia and Natarajan, Suriya and Vaid, Kushagra and Kudva, Prabhakar and Natu, Mahesh},
  Booktitle                = {2013 IEEE 31st VLSI Test Symposium (VTS)},
  Year                     = {2013},
  Month                    = apr,
  Pages                    = {1--1},
  Publisher                = {IEEE},

  Abstract                 = {The rapid pace of integration, emergence of low power, low cost computing elements, and ubiquitous and ever-increasing bandwidth of connectivity have given rise to data center and cloud infrastructures. These infrastructures are beginning to be used on a massive scale across vast geographic boundaries to provide commercial services to businesses such as banking, enterprise computing, online sales, and data mining and processing for targeted marketing to name a few. Such an infrastructure comprises of thousands of compute and storage nodes that are interconnected by massive network fabrics, each of them having their own hardware and firmware stacks, with layers of software stacks for operating systems, network protocols, schedulers and application programs. The scale of such an infrastructure has made possible service that has been unimaginable only a few years ago, but has the downside of severe losses in case of failure. A system of such scale and risk necessitates methods to (a) proactively anticipate and protect against impending failures, (b) efficiently, transparently and quickly detect, diagnose and correct failures in any software or hardware layer, and (c) be able to automatically adapt itself based on prior failures to prevent future occurrences. Addressing the above reliability challenges is inherently different from the traditional reliability techniques. First, there is a great amount of redundant resources available in the cloud from networking to computing and storage nodes, which opens up many reliability approaches by harvesting these available redundancies. Second, due to the large scale of the system, techniques with high overheads, especially in power, are not acceptable. Consequently, cross layer approaches to optimize the availability and power have gained traction recently. This session will address these challenges in maintaining reliable service with solutions across the hardware/software stacks. The currently available commercial data-cente- and cloud infrastructures will be reviewed and the relative occurrences of different causalities of failures, the level to which they are anticipated and diagnosed in practice, and their impact on the quality of service and infrastructure design will be discussed. A study on real-time analytics to proactively address failures in a private, secure cloud engaged in domain-specific computations, with streaming inputs received from embedded computing platforms (such as airborne image sources, data streams, or sensors) will be presented next. The session concludes with a discussion on the increased relevance of resiliency features built inside individual systems and components (private cloud) and how the macro public cloud absorbs innovations from this realm.},
  Doi                      = {10.1109/VTS.2013.6548907},
  ISBN                     = {978-1-4673-5543-8},
  ISSN                     = {1093-0167},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This is a symposium session, not a paper},
  Shorttitle               = {VLSI Test Symposium (VTS), 2013 IEEE 31st},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6548907}
}

@Article{Nakasumi2005,
  Title                    = {A Programmable Pipelined Queue for approximate string matching},
  Author                   = {Nakasumi, M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Pages                    = {503-508},
  Volume                   = {3684 LNAI},

  Abstract                 = {Mining data streams is an emerging area of research given the potentially large number of business applications. A significant challenge in analyzing/mining data streams is the high data rate of the stream. In this paper, we explain a Programmable Pipelined Queue to cope with the high data rate of incoming data streams. It can be added easily to general computer system. And we apply the Programmable Pipelined Queue to online string matching. Ã‚Â© Springer-Verlag Berlin Heidelberg 2005.},
  Affiliation              = {Faculty of Economics, Komazawa University, 1-23-1 komazawa, Setagaya-ku Tokyo, Japan},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This is a pipeline improvement that can facilitate data stream mining, no ML used},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33745313157&partnerID=40&md5=546f5593a551cb23f81aa387477b03a7}
}

@InProceedings{Namadchian2012,
  Title                    = {{DSCLU: A New Data Stream Clustring Algorithm for Multi Density Environments}},
  Author                   = {Namadchian, Amin and Esfandani, Gholamreza},
  Booktitle                = {2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing},
  Year                     = {2012},
  Month                    = aug,
  Pages                    = {83--88},
  Publisher                = {IEEE},

  Abstract                 = {Recently, data stream has become popular in many contexts of data mining. Due to the high amount of incoming data, traditional clustering algorithms are not suitable for this family of problems. Many data stream clustering algorithms proposed in recent years considered the scalability of data, but most of them did not attend the following issues: (1) The quality of clustering can be dramatically low over the time. (2) Some of the algorithms cannot handle arbitrary shapes of data stream and consequently the results are limited to specific regions. (3) Most of the algorithms have not been evaluated in multi-density environments. Identifying appropriate clusters for data stream by handling the arbitrary shapes of clusters is the aim of this paper. The gist of the overall approach in this paper can be stated in two phases. In online phase, data manipulate with specific data structure called micro cluster. This phase is activated by incoming of data. The offline phase is manually activated by coming a request from user. The algorithm handles clusters by considering with micro clusters created by the online phase. The experimental evaluation showed that proposed algorithm has suitable quality and also returns appropriate results even in multi-density environments.},
  Doi                      = {10.1109/SNPD.2012.119},
  ISBN                     = {978-1-4673-2120-4},
  Keywords                 = {Approximation algorithms,Clustering algorithms,DSCLU,Data mining,Data structures,Shape,Vectors,clustering quality,data manipulation,data mining,data scalability,data stream clustering,data stream clustering algorithm,data structure,density-based clustering,microcluster,multi density environment clustering,multidensity environment,pattern clustering,user request},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Namadchian2012},
  Shorttitle               = {Software Engineering, Artificial Intelligence, Net},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6299262}
}

@Conference{Namadchian2012a,
  Title                    = {DSCLU: A new data stream CLUstring algorithm for multi density environments},
  Author                   = {Namadchian, A.a and Esfandani, G.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)1},
  Pages                    = {83-88},

  Abstract                 = {Recently, data stream has become popular in many contexts of data mining. Due to the high amount of incoming data, traditional clustering algorithms are not suitable for this family of problems. Many data stream clustering algorithms proposed in recent years considered the scalability of data, but most of them did not attend the following issues: (1) The quality of clustering can be dramatically low over the time. (2) Some of the algorithms cannot handle arbitrary shapes of data stream and consequently the results are limited to specific regions. (3) Most of the algorithms have not been evaluated in multi-density environments. Identifying appropriate clusters for data stream by handling the arbitrary shapes of clusters is the aim of this paper. The gist of the overall approach in this paper can be stated in two phases. In online phase, data manipulate with specific data structure called micro cluster. This phase is activated by incoming of data. The offline phase is manually activated by coming a request from user. The algorithm handles clusters by considering with micro clusters created by the online phase. The experimental evaluation showed that proposed algorithm has suitable quality and also returns appropriate results even in multi-density environments. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Department of Computer, Shahid Rajaee University, Tehran, Iran; Department of Computer Engineering, Sharif University of Technology, Tehran, Iran},
  Art_number               = {6299262},
  Author_keywords          = {data stream clustering; density-based clustering; DSCLU; multi density environment clustering},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing, SNPD 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Identifying appropriate clusters for data stream by handling the arbitrary shapes of clusters is the aim of this paper. The experimental evaluation showed that proposed algorithm has suitable quality and also returns appropriate results even in multi-density environments. Really bad english, 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84868568501&partnerID=40&md5=a40037dc3745037cd3bb88459310e72f}
}

@InProceedings{Nassar2013,
  Title                    = {{The integrating between web usage mining and data mining techniques}},
  Author                   = {Nassar, Omer Adel and {Al Saiyd}, Nedhal A.},
  Booktitle                = {2013 5th International Conference on Computer Science and Information Technology},
  Year                     = {2013},
  Month                    = mar,
  Pages                    = {243--247},
  Publisher                = {IEEE},

  Abstract                 = {Clickstream data is one of the most important sources of information in websites usage and customers' behavior in Banks e-services. A number of web usage mining scenarios are possible depending on the available information. While simple traffic analysis based on click stream data may easily be performed to improve the e-banks services. The banks need data mining techniques to substantially improve Banks e-services activities. The relationships between data mining techniques and the Web usage mining are studied. Web structure mining, has three types these types are web usage structure, mining data streams and web content. The integration between the Web usage mining and data mining techniques are presented for processes at different stages, including the pattern discovery phases, and introduces banks cases, that have analytical mining technique. A general framework for fully integrating domain Web usage mining and data mining techniques is represented for processes at different stages. Data Mining techniques can be very helpful to the banks for better performance, acquiring new customers, fraud detection in real time, providing segment based products, and analysis of the customers purchase patterns over time.},
  Doi                      = {10.1109/CSIT.2013.6588787},
  ISBN                     = {978-1-4673-5825-5},
  Keywords                 = {Banking,Banking Sector,Business,Clickstream,Computer science,Data Mining,Data Mining Techniques,Data mining,Data models,Decision trees,Information technology,Web Mining,Web content,Web sites,Web structure mining,Web usage structure,Website usage mining,banking,banks e-services activities,clickstream data,consumer behaviour,customer acquisition,customer behavior,customer purchase pattern analysis,data mining,data mining techniques,data stream mining,fraud,fraud detection,pattern discovery phase,purchasing,segment based products,traffic analysis},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Shorttitle               = {Computer Science and Information Technology (CSIT)},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6588787}
}

@Conference{Nassar2013a,
  Title                    = {The integrating between web usage mining and data mining techniques},
  Author                   = {Nassar, O.A. and Al Saiyd, N.A.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {243-247},

  Abstract                 = {Clickstream data is one of the most important sources of information in websites usage and customers' behavior in Banks e-services. A number of web usage mining scenarios are possible depending on the available information. While simple traffic analysis based on click stream data may easily be performed to improve the e-banks services. The banks need data mining techniques to substantially improve Banks e-services activities. The relationships between data mining techniques and the Web usage mining are studied. Web structure mining, has three types these types are web usage structure, mining data streams and web content. presented for processes at different stages, including the pattern discovery phases, and introduces banks cases, that have analytical mining technique. A general framework for fully integrating domain Web usage mining and data mining techniques is represented for processes at different stagespresented for processes at different stages, including the pattern discovery phases, and introduces banks cases, that have analytical mining technique. A general framework for fully integrating domain Web usage mining and data mining techniques is represented for processes at different stages. Data Mining techniques can be very helpful to the banks for better performance, acquiring new customers, fraud detection in real time, providing segment based products, and analysis of the customers purchase patterns over time. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Computer Science Dept., Faculty of Information Technology, Applied Science University, Amman, Jordan},
  Art_number               = {6588787},
  Author_keywords          = {Banking Sector; Clickstream; Data Mining; Data Mining Techniques; Web Mining},
  Document_type            = {Conference Paper},
  Journal                  = {2013 5th International Conference on Computer Science and Information Technology, CSIT 2013 - Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {A general framework for fully integrating domain Web usage mining and data mining techniques is represented for processes at different stages Discarded. Have not made anything innovative, only a general framework for existing technique. Says nothing about real-time handling either},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84884824480&partnerID=40&md5=c339aa50a7ed5a3e41e2fd178e683357}
}

@Misc{Natha,
  Title                    = {{Online Maintenance of Very Large Random Samples on Flash Storage ABSTRACT}},

  Author                   = {Nath, Suman},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Recent advances in flash media have made it an attractive alternative for data storage in a wide spectrum of computing devices, such as embedded sensors, mobile phones, PDA’s, laptops, and even servers. However, flash media has many unique characteristics that make existing data management/analytics algorithms designed for magnetic disks perform poorly with flash storage. For example, while random (page) reads are as fast as sequential reads, random (page) writes and in-place data updates are orders of magnitude slower than sequential writes. In this paper, we consider an important fundamental problem that would seem to be particularly challenging for flash storage: efficiently maintaining a very large (100 MBs or more) random sample of a data stream (e.g., of sensor readings). First, we show that previous algorithms such as reservoir sampling and geometric file are not readily adapted to flash. Second, we propose B-FILE, an energy-efficient abstraction for flash media to store self-expiring items, and show how a B-FILE can be used to efficiently maintain a large sample in flash. Our solution is simple, has a small (RAM) memory footprint, and is designed to cope with flash constraints in order to reduce latency and energy consumption. Third, we provide techniques to maintain biased samples with a B-FILE and to query the large sample stored in a B-FILE for a subsample of an arbitrary size. Finally, we present an evaluation with flash media that shows our techniques are several orders of magnitude faster and more energy-efficient than (flash-friendly versions of) reservoir sampling and geometric file. A key finding of our study, of potential use to many flash algorithms beyond sampling, is that “semi-random ” writes (as defined in the paper) on flash cards are over two orders of magnitude faster and more energy-efficient than random writes},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {efficient storage of sample of a data stream on flash storage, which is problematic because of slow writes and updates relative to read speed. New algorithm to make this updating storage more efficient. Discarded, not using machine learning. 1,2,3,4},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.140.6933}
}

@Misc{Nath,
  Title                    = {{Noname manuscript No. (will be inserted by the editor) Online Maintenance of Very Large Random Samples on Flash Storage}},

  Author                   = {Nath, Suman and Gibbons, Phillip B.},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Natha},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.148.9239}
}

@Article{Nath2009,
  Title                    = {{Online maintenance of very large random samples on flash storage}},
  Author                   = {Nath, Suman and Gibbons, Phillip B.},
  Journal                  = {The VLDB Journal},
  Year                     = {2009},

  Month                    = sep,
  Number                   = {1},
  Pages                    = {67--90},
  Volume                   = {19},

  Abstract                 = {Recent advances in flash media have made it an attractive alternative for data storage in a wide spectrum of computing devices, such as embedded sensors, mobile phones, PDA's, laptops, and even servers. However, flash media has many unique characteristics that make existing data management/analytics algorithms designed for magnetic disks perform poorly with flash storage. For example, while random (page) reads are as fast as sequential reads, random (page) writes and in-place data updates are orders of magnitude slower than sequential writes. In this paper, we consider an important fundamental problem that would seem to be particularly challenging for flash storage: efficiently maintaining a very large (100 MBs or more) random sample of a data stream (e.g., of sensor readings). First, we show that previous algorithms such as reservoir sampling and geometric file are not readily adapted to flash. Second, we propose B-FILE, an energy-efficient abstraction for flash media to store self-expiring items, and show how a B-FILE can be used to efficiently maintain a large sample in flash. Our solution is simple, has a small (RAM) memory footprint, and is designed to cope with flash constraints in order to reduce latency and energy consumption. Third, we provide techniques to maintain biased samples with a B-FILE and to query the large sample stored in a B-FILE for a subsample of an arbitrary size. Finally, we present an evaluation with flash media that shows our techniques are several orders of magnitude faster and more energy-efficient than (flash-friendly versions of) reservoir sampling and geometric file. A key finding of our study, of potential use to many flash algorithms beyond sampling, is that "semi-random" writes (as defined in the paper) on flash cards are over two orders of magnitude faster and more energy-efficient than random writes.},
  Doi                      = {10.1007/s00778-009-0164-z},
  ISSN                     = {1066-8888},
  Keywords                 = {Flash storage,Random sample,Semi-random writes,Sensor networks},
  Owner                    = {alex},
  Publisher                = {Springer-Verlag New York, Inc.},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Natha},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1731351.1731355}
}

@Article{Nath2008,
  Title                    = {{Online maintenance of very large random samples on flash storage}},
  Author                   = {Nath, Suman and Gibbons, Phillip B.},
  Journal                  = {Proceedings of the VLDB Endowment},
  Year                     = {2008},

  Month                    = aug,
  Number                   = {1},
  Pages                    = {970--983},
  Volume                   = {1},

  Doi                      = {10.14778/1453856.1453961},
  ISSN                     = {21508097},
  Owner                    = {alex},
  Publisher                = {VLDB Endowment},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Natha},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1453856.1453961}
}

@Conference{Nelson2013,
  Title                    = {Modeling microtext with higher order learning},
  Author                   = {Nelson, C.a and Keiler, H.b and Pottenger, W.M.c },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {24-31},
  Volume                   = {SS-13-01},

  Abstract                 = {Processing data manually is especially problematic during a natural disaster, where aid and response are quickly and urgently needed. In real time scenarios, a difficult yet important problem is to be able to get an accurate picture of needs from streaming data in a short time. When the streaming data includes microtext, this problem becomes even more challenging. In the application of emergency response, modeling microtext in real-time is especially important. Once messages have been classified and/or topics learned, the predicted categories and/or topics can be used by emergency responders to rapidly respond to needs. In this effort, microtext from social media and text messages during the 2010 Haitian earthquake were modeled using novel machine learning algorithms: Higher-Order Naïve Bayes (HONB) and Higher-Order Latent Dirichlet Allocation (HO-LDA). Both illustrate that Higher-Order Learning can be valuabte in classifying text data. Higher-Order Learning improves model generalization in online or real-time scenarios when smaller amounts of data are available for learning. Results from this research are promising in that when using samples of training data, the HONB classifier statistically significantly outperformed Naïve Bayes in all trials based on the accuracy metric. Promising results were also obtained in the comparison of HO-LDA versus traditional Latent Dirichlet Allocation. Copyright © 2013, AAAI Press.},
  Affiliation              = {RUTCOR, Rutgers University, United States; Statistics, Columbia University, United States; DIMACS and RUTCOR, Rutgers University, United States},
  Document_type            = {Conference Paper},
  Journal                  = {AAAI Spring Symposium - Technical Report},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper propose novel machine learning algorithms: Higher-Order Naïve Bayes (HONB) and Higher-Order Latent Dirichlet Allocation (HO-LDA). Both illustrate that Higher-Order Learning can be valuabte in classifying microtext. The data was sms and social media posts from the Haiti disaster. the HONB classifier statistically significantly outperformed Naïve Bayes in all trials. The HO-LDA also had promising results Seems like an interesting paper about classifying microtext in real-time. Could be a primary source. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84883269791&partnerID=40&md5=a0516910904e61966ee8abc19c499bc5}
}

@Misc{Neophytou2011,
  Title                    = {{CONFLuEnCE: Implementation and application design}},

  Author                   = {Neophytou, P. and Chrysanthis, P.K. and Labrinidis, A.},
  Year                     = {2011},

  Abstract                 = {Data streams have become pervasive and data production rates are increasing exponentially, driven by advances in technology, for example the proliferation of sensors, smart phones, and their applications. This fact effectuates an unprecedented opportunity to build real-time monitoring and analytics applications, which when used collaboratively and interactively, will provide insights to every aspect of our environment, both in the business and scientific domains. In our previous work, we have identified the need for workflow management systems which are capable of orchestrating the processing of multiple heterogeneous data streams, while enabling their users to interact collaboratively with the workflows in real time. In this paper, we describe CONFLuEnCE (CONtinuous workFLow ExeCution Engine), which is an implementation of our continuous workflow model. CONFLuEnCE is built on top of Kepler, an existing workflow management system, by fusing stream semantics and stream processing methods as another computational domain. Furthermore, we explicate our experiences in designing and implementing real-life business and scientific continuous workflow monitoring applications, which attest to the ease of use and applicability of our system.},
  Keywords                 = {Availability,CONFLuEnCE,Engines,Indexes,Kepler,Monitoring,Receivers,Semantics,business data processing,business domain,collaborative interaction,continuous workflow execution engine,continuous workflows,data production rate,data streams,groupware,interactive systems,monitoring applications,multiple heterogeneous data streams,real-time monitoring,scientific domain,scientific information systems,sensor fusion,stream processing method,stream semantics,workflow,workflow management software,workflow management system},
  Owner                    = {Alexander},
  Pages                    = {181--190},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper describe CONFLuEnCE (CONtinuous workFLow ExeCution Engine), which is an implementation of their continuous workflow model from earlier work. l. CONFLuEnCE is built on top of Kepler, an existing workflow management system, by fusing stream semantics and stream processing methods Discarded, This paper has built a system that monitors workflows.},
  Shorttitle               = {Collaborative Computing: Networking, Applications },
  Timestamp                = {2014.10.15}
}

@Conference{Neophytou2011a,
  Title                    = {CONFLuEnCE: Implementation and application design},
  Author                   = {Neophytou, P. and Chrysanthis, P.K. and Labrinidis, A.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)2},
  Pages                    = {181-190},

  Abstract                 = {Data streams have become pervasive and data production rates are increasing exponentially, driven by advances in technology, for example the proliferation of sensors, smart phones, and their applications. This fact effectuates an unprecedented opportunity to build real-time monitoring and analytics applications, which when used collaboratively and interactively, will provide insights to every aspect of our environment, both in the business and scientific domains. In our previous work, we have identified the need for workflow management systems which are capable of orchestrating the processing of multiple heterogeneous data streams, while enabling their users to interact collaboratively with the workflows in real time. In this paper, we describe CONFLuEnCE (CONtinuous workFLow ExeCution Engine), which is an implementation of our continuous workflow model. CONFLuEnCE is built on top of Kepler, an existing workflow management system, by fusing stream semantics and stream processing methods as another computational domain. Furthermore, we explicate our experiences in designing and implementing real-life business and scientific continuous workflow monitoring applications, which attest to the ease of use and applicability of our system. Ã‚Â© 2011 ICST.},
  Affiliation              = {Advanced Data Management Technologies Laboratory, Department of Computer Science, University of Pittsburgh, United States},
  Art_number               = {6144803},
  Author_keywords          = {continuous workflows; data streams; monitoring applications; workflow},
  Document_type            = {Conference Paper},
  Journal                  = {ColiaborateCom 2011 - Proceedings of the 7th International Conference on Collaborative Computing: Networking, Applications and Worksharing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Neophytou2011},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84857508888&partnerID=40&md5=0f031d344228af073c460aaa65299fdf}
}

@Misc{Neophytou,
  Title                    = {{CONFLuEnCE: Implementation and Application Design}},

  Author                   = {Neophytou, Panayiotis and Chrysanthis, Panos K. and Labrinidis, Ros},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Neophytou2011},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.233.2993}
}

@Article{Neumeyer2010,
  Title                    = {{S4: Distributed stream computing platform}},
  Author                   = {Neumeyer, Leonardo and Robbins, Bruce and Kesari, Anand},
  Journal                  = {IN INTL. WORKSHOP ON KNOWLEDGE DISCOVERY USING CLOUD AND DISTRIBUTED COMPUTING PLATFORMS (KDCLOUD},
  Year                     = {2010},

  __markedentry            = {[Alexander:]},
  Abstract                 = {S4 is a general-purpose, distributed, scalable, partially fault-tolerant, pluggable platform that allows programmers to easily develop applications for processing continuous unbounded streams of data. Keyed data events are routed with affinity to Processing Elements (PEs), which consume the events and do one or both of the following: (1) emit one or more events which may be consumed by other PEs, (2) publish results. The architecture resembles the Actors model [1], providing semantics of encapsulation and location transparency, thus allowing applications to be massively concurrent while exposing a simple programming interface to application developers. In this paper, we outline the S4 architecture in detail, describe various applications, including real-life deployments. Our design is primarily driven by large scale applications for data mining and machine learning in a production environment. We show that the S4 design is surprisingly flexible and lends itself to run in large clusters built with commodity hardware. Keywords-actors programming model; complex event processing; concurrent programming; data processing; distributed programming; map-reduce; middleware; parallel programming; real-time search; software design; stream computing},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded under uncertainty. About a programming model for stream mining},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.304.3588}
}

@InProceedings{Ng2008,
  Title                    = {{A change detector for mining frequent patterns over evolving data streams}},
  Author                   = {Ng, Willie and Dash, Manoranjan},
  Booktitle                = {2008 IEEE International Conference on Systems, Man and Cybernetics},
  Year                     = {2008},
  Month                    = oct,
  Pages                    = {2407--2412},
  Publisher                = {IEEE},

  Abstract                 = {Mining data streams for frequent patterns is important in many applications. Unlike traditional static databases, the underlying process that generates the data streams evolves over time. Past data may become outdated and of little use when compared to the most recent one. When a significant change occurs, much harm is done to the mining result if it is not properly handled. In this paper, an online algorithm for change detection in frequent pattern mining is proposed. Although there have been several studies mainly for adapting to changes, we contend that this is not enough. The ability to detect and characterize change is essential in many applications. A novel test strategy is designed to gather the ldquoevidencerdquo sufficient to conclude on whether the current sample differ significantly from a reference sample. Different statistical tests are evaluated and our study shows that the chi-square test is the most suitable for enumerated or count data.},
  Doi                      = {10.1109/ICSMC.2008.4811655},
  ISBN                     = {978-1-4244-2383-5},
  ISSN                     = {1062-922X},
  Keywords                 = {Application software,Change Detection,Change detection algorithms,Data Stream,Data mining,Databases,Detectors,Feeds,Frequent Pattern Mining,Information systems,Itemsets,Sampling methods,Testing,change detector,chi-square test,data mining,data streams,frequent pattern mining,statistical testing,statistical tests},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ng2008a},
  Shorttitle               = {Systems, Man and Cybernetics, 2008. SMC 2008. IEEE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4811655}
}

@Article{Ng2008a,
  Title                    = {A test paradigm for detecting changes in transactional data streams},
  Author                   = {Ng, W. and Dash, M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Pages                    = {204-219},
  Volume                   = {4947 LNCS},

  Abstract                 = {A pattern is considered useful if it can be used to help a person to achieve his goal. Mining data streams for useful patterns is important in many applications. However, data stream can change their behavior over time and, when significant change occurs, much harm is done to the mining result if it is not properly handled. In the past, there have been many studies mainly on adapting to changes in data streams. We contend that adapting to changes is simply not enough. The ability to detect and characterize change is also essential in many applications, for example intrusion detection, network traffic analysis, data streams from intensive care units etc. Detecting changes is nontrivial. In this paper, an online algorithm for change detection in utility mining is proposed. In order to provide a mechanism for making quantitative description of the detected change, we adopt the statistical test. We believe there is the opportunity for an immensely rewarding synergy between data mining and statistic. Different statistical significance tests are evaluated and our study shows that the Chi-square test is the most suitable for enumerated or count data (as is the case for high utility itemsets). We demonstrate the effectiveness of the proposed method by testing it on IBM QUEST market-basket data. Ã‚Â© 2008 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {Centre for Advanced Information Systems, Nanyang Technological University, Singapore 639798, Singapore},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, an online algorithm for change detection in frequent pattern mining is proposed. In order to provide a mechanism for making quantitative description of the detected change, we adopt the statistical test. Abstract lack information about what's innovative with their algorithm, and details about the testing done on it. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-47349093896&partnerID=40&md5=c63b610cf9d5dfed7b84fc1f1748082e}
}

@Conference{Ng2008b,
  Title                    = {A change detector for mining frequent patterns over evolving data streams},
  Author                   = {Ng, W.a and Dash, M.b },
  Year                     = {2008},
  Note                     = {cited By (since 1996)1},
  Pages                    = {2407-2412},

  Abstract                 = {Mining data streams for frequent patterns is important in many applications. Unlike traditional static databases, the underlying process that generates the data streams evolves over time. Past data may become outdated and of little use when compared to the most recent one. When a signi.cant change occurs, much harm is done to the mining result if it is not properly handled. In this paper, an online algorithm for change detection in frequent pattern mining is proposed. Although there have been several studies mainly for adapting to changes, we contend that this is not enough. The ability to detect and characterize change is essential in many applications. A novel test strategy is designed to gather the "evidence" suf.cient to conclude on whether the current sample differ signi.cantly from a reference sample. Different statistical tests are evaluated and our study shows that the Chi-square test is the most suitable for enumerated or count data. Ã‚Â© 2008 IEEE.},
  Affiliation              = {Centre for Advance Information Systems, Nanyang Technological University, N4-B3C, Nanyang Avenue, Singapore 639798, Singapore; School of Computer Engineering, Nanyang Technological University, N4-02C-85, Nanyang Avenue, Singapore 639798, Singapore},
  Art_number               = {4811655},
  Author_keywords          = {Change detection; Data stream; Frequent pattern mining},
  Document_type            = {Conference Paper},
  Journal                  = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ng2008a},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-69949137272&partnerID=40&md5=055150d18980bf690453e9ee49eba632}
}

@Article{Ng2011,
  Title                    = {Towards a privacy-aware stream data management system for cloud applications},
  Author                   = {Ng, W.S.a and Kirchberg, M.b and Bressan, S.c and Tan, K.-L.b },
  Journal                  = {International Journal of Web and Grid Services},
  Year                     = {2011},
  Note                     = {cited By (since 1996)7},
  Number                   = {3},
  Pages                    = {246-267},
  Volume                   = {7},

  Abstract                 = {The rapidly increasing number of sensors and devices as well as the coming of age of cloud computing are fuelling the need for real-time stream data management tools. In a world that is highly submerged in data, data analytics and higher forms of data exploitation are fundamental to most decision making processes. However, enabling such technology requires several factors related to security, privacy, performance and costing to be addressed. In this paper, we discuss the various challenges in greater detail and propose our vision of a Privacy-aware Data Stream Cloud architecture that enables secure, privacy-preserving data analytics services. Ã‚Â© 2011 Inderscience Enterprises Ltd.},
  Affiliation              = {Institute for Infocomm Research, ASTAR, Singapore, Singapore; School of Computing, National University of Singapore, Singapore, Singapore; Centre for Maritime Studies, National University of Singapore, Singapore, Singapore},
  Author_keywords          = {Cloud computing; Data privacy; Stream data management},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded They only propose Privacy-aware Data Stream Cloud architecture. No tangible results, only blueprints.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84857155500&partnerID=40&md5=dc0c1e2df33659dd92685c725590072f}
}

@Conference{Nguyen2011a,
  Title                    = {Online learning from imbalanced data streams},
  Author                   = {Nguyen, H.M.a and Cooper, E.W.b and Kamei, K.b },
  Year                     = {2011},
  Note                     = {cited By (since 1996)8},
  Pages                    = {347-352},

  Abstract                 = {Learning from imbalanced data has conventionally been conducted on stationary data sets. Recently, there have been several methods proposed for mining imbalanced data streams, in which training data is read in consecutive data chunks. Each data chunk is considered as a conventional imbalanced data set, making it easy to apply sampling methods to balance data chunks. However, one drawback of chunk-based learning methods is that the update of classification models is delayed until a full data chunk is received. Therefore, this paper proposes a new method for online learning from imbalanced data streams, which uses naive Bayes as the base learner. To deal with the problem of class imbalance, a new training instance from the minority class is always involved in learning, but one from the majority class is only used with a small probability. In effect, this method corresponds to an under-sampling technique on imbalanced data streams. We show the effectiveness of the proposed online learning method on ten UCI data sets of various domains. Problems in the performance of naive Bayes on imbalanced data sets are also discussed. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; College of Information Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan},
  Art_number               = {6089268},
  Author_keywords          = {class imbalance; data streams; naive bayes; online learning; under-sampling},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2011 International Conference of Soft Computing and Pattern Recognition, SoCPaR 2011},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {this paper proposes a new method for online learning from imbalanced data streams, which uses naive Bayes as the base learner They show the effectiveness of the proposed online learning method on ten UCI data sets. Problems in the performance of naive Bayes on imbalanced data sets are also discussed. (I guess they had some difficulties?) 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-83655191008&partnerID=40&md5=79c5e633003169081e869da985f7056b}
}

@InProceedings{Nguyen2011,
  Title                    = {{Online learning from imbalanced data streams}},
  Author                   = {Nguyen, Hien M. and Cooper, Eric W. and Kamei, Katsuari},
  Booktitle                = {2011 International Conference of Soft Computing and Pattern Recognition (SoCPaR)},
  Year                     = {2011},
  Month                    = oct,
  Pages                    = {347--352},
  Publisher                = {IEEE},

  Abstract                 = {Learning from imbalanced data has conventionally been conducted on stationary data sets. Recently, there have been several methods proposed for mining imbalanced data streams, in which training data is read in consecutive data chunks. Each data chunk is considered as a conventional imbalanced data set, making it easy to apply sampling methods to balance data chunks. However, one drawback of chunk-based learning methods is that the update of classification models is delayed until a full data chunk is received. Therefore, this paper proposes a new method for online learning from imbalanced data streams, which uses naive Bayes as the base learner. To deal with the problem of class imbalance, a new training instance from the minority class is always involved in learning, but one from the majority class is only used with a small probability. In effect, this method corresponds to an under-sampling technique on imbalanced data streams. We show the effectiveness of the proposed online learning method on ten UCI data sets of various domains. Problems in the performance of naive Bayes on imbalanced data sets are also discussed.},
  Doi                      = {10.1109/SoCPaR.2011.6089268},
  ISBN                     = {978-1-4577-1196-1},
  Keywords                 = {Accuracy,Bayes methods,Data models,Equations,Learning systems,Mathematical model,Single photon emission computed tomography,Training,UCI,class imbalance,data chunks,data mining,data streams,imbalanced data streams,learning (artificial intelligence),media streaming,naive Bayes method,naive bayes,online learning,sampling methods,stationary data sets,under-sampling},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Nguyen2011a},
  Shorttitle               = {Soft Computing and Pattern Recognition (SoCPaR), 2},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6089268}
}

@Article{Nguyen2004,
  Title                    = {{Grid-based Mobile Phone Fraud Detection System}},
  Author                   = {Nguyen, Tho Manh and Tjoa, A Min},
  Journal                  = {IN PROC. OF PAKM},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {the architecture of Grid-based Mobile Phone Fraud Detection System (GFDS) which enables online-analysis, rule-based decision support and automatic reaction for fraud detection and elimination. The GFDS system is built upon a set of Open Grid Service Infrastructure (OGSI)-based grid services and Globus Toolkit 3 (GT3) allows to conduct the analytical process on continuous data streams (CDRs) and to issue relevant actions automatically depending on the pattern of CDRs streams without using statistical approximation. The requirements of GFDS system, the conceptual architecture and its operation based on service invocation as well as some open issues are the main contribution of the paper.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The requirements of GFDS system, the conceptual architecture and its operation based on service invocation as well as some open issues are the main contribution of the paper. Again no tangible results. 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.94.1584}
}

@Article{Nguyen-Tuong2011,
  Title                    = {Model learning for robot control: A survey},
  Author                   = {Nguyen-Tuong, D. and Peters, J.},
  Journal                  = {Cognitive Processing},
  Year                     = {2011},
  Note                     = {cited By (since 1996)30},
  Number                   = {4},
  Pages                    = {319-340},
  Volume                   = {12},

  Abstract                 = {Models are among the most essential tools in robotics, such as kinematics and dynamics models of the robot's own body and controllable external objects. It is widely believed that intelligent mammals also rely on internal models in order to generate their actions. However, while classical robotics relies on manually generated models that are based on human insights into physics, future autonomous, cognitive robots need to be able to automatically generate models that are based on information which is extracted from the data streams accessible to the robot. In this paper, we survey the progress in model learning with a strong focus on robot control on a kinematic as well as dynamical level. Here, a model describes essential information about the behavior of the environment and the influence of an agent on this environment. In the context of model-based learning control, we view the model from three different perspectives. First, we need to study the different possible model learning architectures for robotics. Second, we discuss what kind of problems these architecture and the domain of robotics imply for the applicable learning methods. From this discussion, we deduce future directions of real-time learning algorithms. Third, we show where these scenarios have been used successfully in several case studies. Ã‚Â© 2011 Marta Olivetti Belardinelli and Springer-Verlag.},
  Affiliation              = {Max-Planck Institute for Biological Cybernetics, Spemannstrasse 38, TÃƒÂ¼bingen 72076, Germany},
  Author_keywords          = {Machine learning; Model learning; Regression; Robot control},
  Document_type            = {Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. It's a survey},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-81255141919&partnerID=40&md5=9ecc0dc41cdda3302c47ecfa33629be1}
}

@Article{Ni2010,
  Title                    = {Online mining closed frequent itemsets in mixed window over data streams},
  Author                   = {Ni, Z.-W.a b and Jiang, M.a b and Wang, C.a b and Dai, Q.-B.a b },
  Journal                  = {Xitong Fangzhen Xuebao / Journal of System Simulation},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Number                   = {9},
  Pages                    = {2110-2114+2119},
  Volume                   = {22},

  Abstract                 = {In data mining, boundary window considers the influence of history pattern to the current mining result, but do not think over mode decaying as time passed. Sliding window can record the latest and most useful patterns, but the best size can not be accurately determined. To aim at data with the characteristics of data flow in some simulation systems, a method for mining the closed frequent patterns in the mixed window of data stream was proposed. The pattern of data stream could be completely recorded by scanning the stream only once. And the pruning method of T-Moment could reduce the space complexity of sliding window tree and the maintenance cost of the closed frequent patterns tree. To differentiate the historical and the latest patterns, a time decaying model was applied. The experimental results show that the algorithm has good efficiency and accuracy.},
  Affiliation              = {School of Management, Hefei University of Technology, Hefei 230009, China; Key Laboratory of Process Optimization and Intelligent Decision-Making, Ministry of Education, Hefei 230009, China},
  Author_keywords          = {Closed frequent pattern; Mixed window; Simulation data; Time decaying},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A method for mining the closed frequent patterns in the mixed window of data stream is proposed. The pattern of data stream could be recorded by scanning the stream once. Uses a time decaying model. Reports good efficiency and accuracy. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77957554117&partnerID=40&md5=0cfffb8364c1dfc108f28a70d907fa9a}
}

@InProceedings{Niennattrakul2009,
  Title                    = {{Accurate subsequence matching on data stream under time warping distance}},
  Author                   = {Niennattrakul, Vit and Wanichsan, Dechawut and Ratanamahatana, Chotirat Ann},
  Booktitle                = {2009 6th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology},
  Year                     = {2009},
  Month                    = may,
  Pages                    = {752--755},
  Publisher                = {IEEE},
  Volume                   = {02},

  Abstract                 = {With ever more increases in both storage and computational power, mining data in real time has become more and more practical and rapidly consumed a large fraction of research works on data streams. Particularly for time series data, subsequence matching under dynamic time warping (DTW) distance has proven to work exceptionally well, but with higher time and space complexities, thus posing a much challenging problem to work on streaming data. Recent work has proposed a solution to this problem with only linear time and space. However, we demonstrate that it may give inaccurate results, and then propose a novel accurate subsequence matching (ASM) algorithm that eliminates this discrepancy. We further demonstrate utilities of our work on a comprehensive set of experiments that guarantees an improvement in accuracy while maintaining the same time and space complexities.},
  Doi                      = {10.1109/ECTICON.2009.5137156},
  ISBN                     = {978-1-4244-3387-2},
  Keywords                 = {Association rules,Data engineering,Data mining,Dynamic programming,Euclidean distance,Pattern matching,Power engineering and energy,Power engineering computing,Springs,Time measurement,accurate subsequence matching,computational complexity,data analysis,data mining,data stream,dynamic time warping distance,linear time complexity,pattern matching,space complexity,time series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a novel accurate subsequence matching (ASM) algorithm to do subsequence matching on time series data. Their algorithm is an improvement on recent work that only uses linear space and time to reduce complexity. Experiments show an improvement in accuracy while maintaining time and space complexity Not sure if the algorithm they improve upon is SotA, so most likely not. I'm not quite sure what Dynamic Time Warping implies either. 1,2,3,4,6},
  Shorttitle               = {Electrical Engineering/Electronics, Computer, Tele},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5137156}
}

@Conference{Nishida2005,
  Title                    = {ACE: Adaptive classifiers-ensemble system for concept-drifting environments},
  Author                   = {Nishida, K. and Yamauchi, K. and Omori, T.},
  Year                     = {2005},
  Note                     = {cited By (since 1996)15},
  Pages                    = {176-185},
  Volume                   = {3541},

  Abstract                 = {Most machine learning algorithms assume stationary environments, require a large number of training examples in advance, and begin the learning from scratch. In contrast, humans learn in changing environments with sequential training examples and leverage prior knowledge in new situations. To deal with real-world problems in changing environments, the ability to make human-like quick responses must be developed in machines. Many researchers have presented learning systems that assume the presence of hidden context and concept drift. In particular, several systems have been proposed that use ensembles of classifiers on sequential chunks of training examples. These systems can respond to gradual changes in large-scale data streams but have problems responding to sudden changes and leveraging prior knowledge of recurring contexts. Moreover, these are not pure online learning systems. We propose an online learning system that uses an ensemble of classifiers suited to recent training examples. We use experiments to show that this system can leverage prior knowledge of recurring contexts and is robust against various noise levels and types of drift. Ã‚Â© Springer-Verlag Berlin Heidelberg 2005.},
  Affiliation              = {Graduate School of Information Science and Technology, Hokkaido University, Kita 14 Nishi 9, Kita, Sapporo, 060-0814, Japan},
  Document_type            = {Conference Paper},
  Journal                  = {Lecture Notes in Computer Science},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We propose an online learning system that uses an ensemble of classifiers suited to recent training examples. We use experiments to show that this system can leverage prior knowledge of recurring contexts and is robust against various noise levels and types of drift These guys seem to imply that their system is better than normal ensemble classifiers, as they state that these do not cope well with sudden changes in large-scale data streams. Very little written about their own system in the abstract though. Most of it is introduction. 1,2,3,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-26444530040&partnerID=40&md5=76ca5cf6d6782e50fc658b4d0198bbd5}
}

@Misc{Noack,
  Title                    = {{Real-Time Monitoring and Long-Term Analysis by Means of Embedded Systems}},

  Author                   = {Noack, Tino and Prof, Supervised and Schmitt, Ingo and Cottbus, Tu},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper sketches an interdisciplinary doctoral research. The main contribution is amongst others the combination of existing approaches for realtime monitoring and long-term analysis. This includes data stream management, event condition action rules, complex event processing as well as data mining technologies. As a practical use case we introduce briefly a scenario related to the failure management system of the International Space Station Columbus Module. Our research is based on three main assumptions and we identify five monitoring requirements. Furthermore, we describe a system model that is known as the state space. Here, the state space represents the knowledge about the monitored target system. Additionally, we present a cyclic monitoring process chain that represents a dynamic and flexible monitoring approach. Our proposed monitoring architecture respects the complexity of system monitoring as well as today’s and future monitoring requirements.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The main contribution is amongst others the combination of existing approaches for realtime monitoring and long-term analysis. This includes data stream management, event condition action rules, complex event processing as well as data mining technologies Accepted under uncertainty. They seem to have only combined existing techniques to make a monitoring/analysis system, which they describe in a real-life scenario. Accepted only because they say data mining technologies. 4v},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.414.9521}
}

@Misc{Nunez2007,
  Title                    = {{Learning in Environments with Unknown Dynamics: Towards more Robust Concept Learners}},

  Author                   = {Núñez , Marlon and Fidalgo, Raúl and Morales, Rafael},
  Year                     = {2007},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In the process of concept learning, target concepts may have portions with short-term changes, other portions may support long-term changes, and yet others may not change at all. For this reason several local windows need to be handled. We suggest facing this problem, which naturally exists in the field of concept learning, by allocating windows which can adapt their size to portions of the target concept. We propose an incremental decision tree that is updated with incoming examples. Each leaf of the decision tree holds a time window and a local performance measure as the main parameter to be controlled. When the performance of a leaf decreases, the size of its local window is reduced. This learning algorithm, called OnlineTree2, automatically adjusts its internal parameters in order to face the current dynamics of the data stream. Results show that it is comparable to other batch algorithms when facing problems with no concept change, and it is better than evaluated methods in its ability to deal with concept drift when dealing with problems in which: concept change occurs at different speeds, noise may be present and, examples may arrive from different areas of the problem domain (virtual drift).},
  Booktitle                = {JOURNAL OF MACHINE LEARNING RESEARCH},
  Owner                    = {Alexander},
  Pages                    = {95 -- 2628},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an incremental decision tree that is updated with incoming examples, called OnlineTree2. It automatically adjusts its internal parameters in order to face the current dynamics of the data stream. Experiments shows it's comparable to other batch algorithms when there's no concept change, and is better than these methods when concept change occurs at different speeds and with noise. Example of incremental learning, could be interesting. 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.122.7482},
  Volume                   = {8}
}

@Article{Oberwinkler2005,
  Title                    = {From real-time data to production optimization},
  Author                   = {Oberwinkler, C. and Stundner, M.},
  Journal                  = {SPE Production and Facilities},
  Year                     = {2005},
  Note                     = {cited By (since 1996)5},
  Number                   = {3},
  Pages                    = {229-239},
  Volume                   = {20},

  Abstract                 = {A new way of reservoir management is dawning on the horizon: intelligent-reservoir management using continuous data from intelligent wells and/or smart fields. Even though there are many different buzz words for this new technology, they all lead to the same thing - managing a reservoir in real time or close to real time. Real time usually means reacting to an event as it happens or within a short time lag. In the petroleum industry, however, real time is different. This short time lag can be hours, days, or even weeks, which highly depends, of course, on the objective of a project. Integrating real-time data in to a reservoir-management workflow, and turning the data into value, is a complicated task. The bottleneck for the data flow, right now, is the transfer of the real-time data, measured with time increments by the second and/or minute and stored on a real-time server, to the engineers' desktops in a clean, timely, and useful fashion. This paper shows ways to provide a continuous (i.e., 24 -hours-a-day/ 7-days-a-week) flow of clean data to the engineers' desktops as a first step in the intelligent-reservoir management. It shows that the implementation of a smart field rises or falls with its ability to provide the data to the information specialist - the petroleum engineer. Because the data are coming into the database very frequently (e.g., at times, every hour or every other day), the engineer is not able to check these data for discrepancies. Therefore, intelligent-reservoir management needs an alarm system that informs the engineers of any underperformance or critical condition of a well or a reservoir. Another important aspect to the intelligent-reservoir management system is the integration of the standard petroleum engineering tools [e.g., decline-curve analysis, material balance, inflow performance relationship (IPR) curves, and reservoir simulation] into this work process. Currently, an IPR curve not only gets data every other month but every other day. This gives the engineer completely new opportunities for closer observation of the workflow (e.g., monitoring the permeability impairment over time). Well tests are usually a snapshot in time, but with continuous surveillance of the reservoir parameters, the development of the skin, for example, can be followed over time and preventative actions can be taken (i.e., predictive maintenance). Neural networks and genetic algorithms are other powerful tools in the real-time environment for handling large amounts of data. A neural network learns from the data gathered and detects underlying relationships - the more data, the better the network can detect these relationships. Once the underlying relationships have been established, the neural networks can be used for predictions (predictive data mining) such as predicting sand production. This approach gives the engineer time to react and prevents the equipment from getting damaged. This work provides a straightforward way of integrating real-time data into a reservoir-management process, and its methodology implies how to gain value from the information provided by a continuous data stream. Copyright Ã‚Â© 2005 Society of Petroleum Engineers.},
  Affiliation              = {Real-Time Production Data Management Systems, Schlumberger Information Solutions},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper deals with problems in oilwell industry, where real-time flow of data is a bottleneck. This work provides a straightforward way of integrating real-time data into a reservoir-management process, and its methodology implies how to gain value from the information provided by a continuous data stream. They use Neural Networks and genetic algorithms to detect underlying relationships in the real-time data flow, and make predictions. Long abstract with lot of info about the oil industry, but not so much about what they have actually made. Could be interesting if the principles can be transferred. 1,2,6,},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-24644467657&partnerID=40&md5=8ed87ecbbb4215bf165ba5810449af26}
}

@Conference{Oberwinkler2004,
  Title                    = {From real time data to production optimization},
  Author                   = {Oberwinkler, C. and Stundner, M.},
  Year                     = {2004},
  Note                     = {cited By (since 1996)0},
  Pages                    = {91-104},

  Abstract                 = {A new way of reservoir management is dawning at the horizon - intelligent reservoir management utilizing continuous data from intelligent wells and/or smart fields. Even though there are many different buzz words for this new technology, they all lead to the same - managing a reservoir in REAL TIME or close to REAL TIME. Real time usually means to react to an event as it happens or within a short time lag. In the petroleum industry real time is for sure different. This "short time lag" can be hours, days or even weeks, which of course depends highly on the objective itself. Integrating real-time data into a reservoir management work flow and turn the data into value is a complex task. The bottle neck for the data flow right now is the transfer of the real time data - measured with a secondly and minutely time increment and stored on real time server - to the engineers' desktops in a clean and timely useful fashion. This paper will show ways how to provide a continuous (24/7) flow of clean data to the engineers' desktop as a first step for the intelligent reservoir management. It will be shown that the implementation of a smart field rises or falls with the ability to provide the data to the knowledge worker - the petroleum engineer. Since the data is coming into the database, let's say every hour or every other day, the engineer is not able to check this data for discrepancies. Therefore, intelligent reservoir management needs an alarm system to inform the engineers about any under performing or critical condition of a well or the reservoir itself. Another important aspect is the integration of the standard petroleum engineering tools, like Decline Curve Analysis, Material Balance, IPR curves, Reservoir Simulation, etc., into this work process. Now an Inflow Performance Relationship Curve does not only get data every other month, but every other day. This gives the engineer completely new opportunities, e.g. monitoring the permeability impairment over time. Well tests are usually a snapshot in time, but with a continuous surveillance of the reservoir parameters, the development of, e.g., the skin can be followed over time and actions can be taken in time - predictive maintenance. Neural Networks and Genetic Algorithms are other powerful tools in the real time environment, handling such a large amount of data. A Neural Network learns on the gathered data and detects their underlying relationships - the more data, the better. Afterwards, the Neural Networks can be used for predictions (predictive data mining) - for instance predicting sand production. This approach gives the engineer time to react, and prevents the equipment from harm. This work and the methodology it implies, provides a straight forward way of integrating real time data into a reservoir management process and how to gain value from the information provided by a continuous data stream.},
  Affiliation              = {Decision Team - Software},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the SPE Asia Pacific Conference on Integrated Modelling for Asset Management},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Oberwinkler2005},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-2942624361&partnerID=40&md5=5963c13fd04d19175bf257151357cb80}
}

@Article{Ogras2006,
  Title                    = {Online summarization of dynamic time series data},
  Author                   = {Ogras, U.Y.a and Ferhatosmanoglu, H.b },
  Journal                  = {VLDB Journal},
  Year                     = {2006},
  Note                     = {cited By (since 1996)10},
  Number                   = {1},
  Pages                    = {84-98},
  Volume                   = {15},

  Abstract                 = {Managing large-scale time series databases has attracted significant attention in the database community recently. Related fundamental problems such as dimensionality reduction, transformation, pattern mining, and similarity search have been studied extensively. Although the time series data are dynamic by nature, as in data streams, current solutions to these fundamental problems have been mostly for the static time series databases. In this paper, we first propose a framework to online summary generation for large-scale and dynamic time series data, such as data streams. Then, we propose online transform-based summarization techniques over data streams that can be updated in constant time and space. We present both the exact and approximate versions of the proposed techniques and provide error bounds for the approximate case. One of our main contributions in this paper is the extensive performance analysis. Our experiments carefully evaluate the quality of the online summaries for point, range, and k-nn queries using real-life dynamic data sets of substantial size.},
  Affiliation              = {Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, United States; Department of Computer Science and Engineering, Ohio State University, Columbus, OH, United States},
  Author_keywords          = {Data streams; Dimensionality reduction; Time-series data; Transformation-based summarization},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. It's about database management},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33745293619&partnerID=40&md5=738479c676a9a2702513ad585cde8ca6}
}

@Article{Ogras2005,
  Title                    = {{Online summarization of dynamic time series data}},
  Author                   = {Ogras, Umit Y. and Ferhatosmanoglu, Hakan},
  Journal                  = {The VLDB Journal},
  Year                     = {2005},

  Month                    = jul,
  Number                   = {1},
  Pages                    = {84--98},
  Volume                   = {15},

  Doi                      = {10.1007/s00778-004-0149-x},
  ISSN                     = {1066-8888},
  Keywords                 = {Data streams,Dimensionality reduction,Time-series data,Transformation-based summarization},
  Owner                    = {alex},
  Publisher                = {Springer-Verlag New York, Inc.},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ogras2006},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1146466.1146470}
}

@InProceedings{Olmezogullari2013,
  Title                    = {{Online Association Rule Mining over Fast Data}},
  Author                   = {Olmezogullari, Erdi and Ari, Ismail},
  Booktitle                = {2013 IEEE International Congress on Big Data},
  Year                     = {2013},
  Month                    = jun,
  Pages                    = {110--117},
  Publisher                = {IEEE},

  Abstract                 = {To extract useful and actionable information in real-time, the information technology (IT) world is coping with big data problems today. In this paper, we present implementation details and performance results of ReCEPtor, our system for "online" Association Rule Mining (ARM) over big and fast data streams. Specifically, we added Apriori and two different FP-Growth algorithms inside Esper Complex Event Processing (CEP) engine and compared their performances using LastFM social music site data. Our most important findings show that online ARM can generate (1) more unique rules, (2) with higher throughput, and (3) much sooner (lower latency) than offline rule mining. In addition, we have found many interesting and realistic musical preference rules such as "George HarrisonaÃŒâ‚¬Beatles". We demonstrate a sustained rate of \~{}15K rows/sec per core. We hope that our findings can shed light on the design and implementation of other fast data analytics systems in the future.},
  Doi                      = {10.1109/BigData.Congress.2013.77},
  ISBN                     = {978-0-7695-5006-0},
  Keywords                 = {ARM,Algorithm design and analysis,Apriori algorithm,Association rules,CEP engine,Engines,Esper complex event processing engine,FP-Growth.,FP-growth algorithms,Fast data,IT world,Information management,Itemsets,LastFM social music site data,ReCEPtor,association rule mining,big data,big data streams,complex event processing,data mining,fast data analytics systems,fast data streams,information technology world,music,musical preference rules,offline rule mining,online association rule mining,social networking (online)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. It's a duplicate publishing of Olmezogullari2013b,},
  Shorttitle               = {Big Data (BigData Congress), 2013 IEEE Internation},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6597126}
}

@Conference{Olmezogullari2013b,
  Title                    = {Online association rule mining over fast data},
  Author                   = {Olmezogullari, E. and Ari, I.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {110-117},

  Abstract                 = {To extract useful and actionable information in real-time, the information technology (IT) world is coping with big data problems today. In this paper, we present implementation details and performance results of ReCEPtor, our system for 'online' Association Rule Mining (ARM) over big and fast data streams. Specifically, we added Apriori and two different FP-Growth algorithms inside Esper Complex Event Processing (CEP) engine and compared their performances using LastFM social music site data. Our most important findings show that online ARM can generate (1) more unique rules, (2) with higher throughput, and (3) much sooner (lower latency) than offline rule mining. In addition, we have found many interesting and realistic musical preference rules such as 'George HarrisonÃƒÂ Beatles'. We demonstrate a sustained rate of ~15K rows/sec per core. We hope that our findings can shed light on the design and implementation of other fast data analytics systems in the future. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Computer Engineering Department, Ãƒâ€“zyegin University, Istanbul, Turkey},
  Art_number               = {6597126},
  Author_keywords          = {association rule mining; big data; complex event processing; Fast data; FP-Growth.},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2013 IEEE International Congress on Big Data, BigData 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper present implementation details and performance results of ReCEPtor, a system for "online" Association Rule Mining (ARM) over big and fast data streams. They've added apriori and two FP-Growth algorithms inside Esper Complex Event Processing (CEP) engine and compared their performances using LastFM social music site data. Our most important findings show that online ARM can generate (1) more unique rules, (2) with higher throughput, and (3) much sooner (lower latency) than offline rule mining. They demonstrate a sustained rate of ~15K rows/sec per core They've only compared itself to the offline version, so I don't know how good it is compared to SotA. Could be interesting principles in there though.
1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84885993411&partnerID=40&md5=25f2a87ac70a13f41b41fa32426854c7}
}

@InProceedings{Olmezogullari2013a,
  Title                    = {{Data stream mining to address big data problems}},
  Author                   = {Olmezogullari, Erdi and Ari, Ismail and Celebi, Omer Faruk and Ergut, Salih},
  Booktitle                = {2013 21st Signal Processing and Communications Applications Conference (SIU)},
  Year                     = {2013},
  Month                    = apr,
  Pages                    = {1--4},
  Publisher                = {IEEE},

  Abstract                 = {Today, the IT world is trying to cope with “big data” problems (data volume, velocity, variety, veracity) on the path to obtaining useful information. In this paper, we present implementation details and performance results of realizing “online” Association Rule Mining (ARM) over big data streams for the first time in the literature. Specifically, we added Apriori and FP-Growth algorithms for stream mining inside an event processing engine, called Esper. Using the system, these two algorithms were compared over LastFM social music site data and by using tumbling windows. The better-performing FP-Growth was selected and used in creation of a real-time rule-based recommendation engine. Our most important findings show that online association rule mining can generate (1) more rules, (2) much faster and more efficiently, and (3) much sooner than offline rule mining. In addition, we have found many interesting and realistic musical preference rules such as “George Harrison=>Beatles”. We hope that our findings can shed light on the design and implementation of other big data analytics systems in the future.},
  Doi                      = {10.1109/SIU.2013.6531483},
  ISBN                     = {978-1-4673-5563-6},
  Keywords                 = {Apriori,Apriori algorithm,Beatles,Data stream mining,Esper,FP-Growth,FP-Growth algorithm,George Harrison,IT world,LastFM social music site data,association rule mining,big data analytics system,big data problem,complex event processing,data analysis,data mining,data stream mining,data variety,data velocity,data veracity,data volume,event processing engine,information retrieval,music,musical preference rules,online ARM,online association rule mining,real-time rule-based recommendation engine,recommender systems,rule generation,social networking (online),tumbling windows},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. It's a duplicate publishing of Olmezogullari2013b, just with a weaker abstract.},
  Shorttitle               = {Signal Processing and Communications Applications },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6531483}
}

@Article{Ordonez2003,
  Title                    = {{Clustering Binary Data Streams with K-means}},
  Author                   = {Ordonez, Carlos},
  Journal                  = {IN 8TH ACM SIGMOD WORKSHOP ON RESEARCH ISSUES IN DATA MINING AND KNOWLEDGE DISCOVERY},
  Year                     = {2003},
  Pages                    = {12 -- 19},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper has been removed for CiteSeer},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.7992}
}

@Article{Orriols-Puig2011,
  Title                    = {Fuzzy knowledge representation study for incremental learning in data streams and classification problems},
  Author                   = {Orriols-Puig, A.a and Casillas, J.b },
  Journal                  = {Soft Computing},
  Year                     = {2011},
  Note                     = {cited By (since 1996)4},
  Number                   = {12},
  Pages                    = {2389-2414},
  Volume                   = {15},

  Abstract                 = {The extraction of models from data streams has become a hot topic in data mining due to the proliferation of problems in which data are made available online. This has led to the design of several systems that create data models online. A novel approach to online learning of data streams can be found in Fuzzy-UCS, a young Michigan-style fuzzy-classifier system that has recently demonstrated to be highly competitive in extracting classification models from complex domains. Despite the promising results reported for Fuzzy-UCS, there still remain some hot issues that need to be analyzed in detail. This paper carefully studies two key aspects in Fuzzy-UCS: the ability of the system to learn models from data streams where concepts change over time and the behavior of different fuzzy representations. Four fuzzy representations that move through the dimensions of flexibility and interpretability are included in the system. The behavior of the different representations on a problem with concept changes is studied and compared to other machine learning techniques prepared to deal with these types of problems. Thereafter, the comparison is extended to a large collection of real-world problems, and a close examination of which problem characteristics benefit or affect the different representations is conducted. The overall results show that Fuzzy-UCS can effectively deal with problems with concept changes and lead to different interesting conclusions on the particular behavior of each representation. Ã‚Â© 2010 Springer-Verlag.v},
  Affiliation              = {Grup de Recerca en Sistemes Intelligents, La Salle-Universitat Ramon Llull, 08022 Barcelona, Spain; Department of Computer Science and Artificial Intelligence, Research Center on Communication and Information Technology (CITIC-UGR), University of Granada, 18071 Granada, Spain},
  Author_keywords          = {Concept drift; Data streams; Fuzzy rule-based representation; Genetic algorithms; Genetic fuzzy systems; Learning classifier systems},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper carefully studies two key aspects in Fuzzy-UCS (A promising approach to online learning) : the ability of the system to learn models from data streams where concepts change over time and the behavior of different fuzzy representations. The overall results show that Fuzzy-UCS can effectively deal with problems with concept changes and lead to different interesting conclusions on the particular behavior of each representation. It seems like this paper only test/analyze a promising algorithm. They compare it to other ML algorithms (possible SotA), and gets good results. 1,2,3,4,(5?),6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-81155154101&partnerID=40&md5=e08389c7c55925f38eb70c1fae05e02b}
}

@InProceedings{Ouyang2008,
  Title                    = {{An Efficient Decision Tree Classification Method Based on Extended Hash Table for Data Streams Mining}},
  Author                   = {Ouyang, Zhenzheng and Wu, Quanyuan and Wang, Tao},
  Booktitle                = {2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery},
  Year                     = {2008},
  Month                    = oct,
  Pages                    = {313--317},
  Publisher                = {IEEE},
  Volume                   = {5},

  Abstract                 = {This paper focuses on continuous attributes handling for mining data stream with concept drift. Data stream is an incremental, online and real time model. Domingos and Hulten have presented a one-pass algorithm. Their system VFDT use Hoeffding inequality to achieve a probabilistic bound on the accuracy of the tree constructed. VFDTpsilas extended version CVFDT handles concept drift efficiently. In this paper, we revisit this problem and implemented a system HashCVFDT on top of CVFDT. It is as fast as hash table when inserting, seeking or deleting attribute value, and it also can sort the attribute value.},
  Doi                      = {10.1109/FSKD.2008.481},
  ISBN                     = {978-0-7695-3305-6},
  Keywords                 = {Classification tree analysis,Continuous Attribute,Data Streams,Data mining,Data processing,Decision trees,Extended Hash Table,Fuzzy systems,Hoeffding inequality,Memory management,Sorting,Statistics,Testing,Time factors,continuous attributes handling,data mining,data streams mining,decision tree classification,decision trees,extended hash table,file organisation,pattern classification},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ouyang2008a},
  Shorttitle               = {Fuzzy Systems and Knowledge Discovery, 2008. FSKD },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4666543}
}

@Conference{Ouyang2008a,
  Title                    = {An efficient decision tree classification method based on extended hash table for data streams mining},
  Author                   = {Ouyang, Z.a and Wu, Q.b and Wang, T.b },
  Year                     = {2008},
  Note                     = {cited By (since 1996)2},
  Pages                    = {313-317},
  Volume                   = {5},

  Abstract                 = {This paper focuses on continuous attributes handling for mining data stream with concept drift. Data stream is an incremental, online and real time model. Domingos and Hulten have presented a one-pass algorithm. Their system VFDT use Hoeffding inequality to achieve a probabilistic bound on the accuracy of the tree constructed. VFDT's extended version CVFDT handles concept drift efficiently. In this paper, we revisit this problem and implemented a system HashCVFDT on top of CVFDT. It is as fast as hash table when inserting, seeking or deleting attribute value, and it also can sort the attribute value. Ã‚Â© 2008 IEEE.},
  Affiliation              = {Science School, National University of Defense Technology, Changsha, 410073, China; Computer School, National University of Defense Technology, Changsha, 410073, China},
  Art_number               = {4666543},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 5th International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2008},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, they revisit a problem (from a paper by Domingos) and implemented a system HashCVFDT on top of CVFDT. It is as fast as hash table when inserting, seeking or deleting attribute value, and it also can sort the attribute value. If the original paper this bases itself upon is interesting, this might be as well. They seem to have made some alterations/improvements. 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-58149134494&partnerID=40&md5=db5b506f7dff58a02415c192ce40a97e}
}

@InProceedings{Ozkan2013,
  Title                    = {{Competitive and online piecewise linear classification}},
  Author                   = {Ozkan, Huseyin and Donmez, Mehmet A. and Pelvan, Ozgun S. and Akman, Arda and Kozat, Suleyman S.},
  Booktitle                = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
  Year                     = {2013},
  Month                    = may,
  Pages                    = {3452--3456},
  Publisher                = {IEEE},

  Abstract                 = {In this paper, we study the binary classification problem in machine learning and introduce a novel classification algorithm based on the Ã¢â‚¬Å“Context Tree Weighting MethodÃ¢â‚¬ï¿½. The introduced algorithm incrementally learns a classification model through sequential updates in the course of a given data stream, i.e., each data point is processed only once and forgotten after the classifier is updated, and asymptotically achieves the performance of the best piecewise linear classifiers defined by the Ã¢â‚¬Å“context treeÃ¢â‚¬ï¿½. Since the computational complexity is only linear in the depth of the context tree, our algorithm is highly scalable and appropriate for real time processing. We present experimental results on several benchmark data sets and demonstrate that our method provides significant computational improvement both in the test (5 \~{} 35Ãƒâ€”) and training phases (40 \~{} 1000Ãƒâ€”), while achieving high classification accuracy in comparison to the SVM with RBF kernel.},
  Doi                      = {10.1109/ICASSP.2013.6638299},
  ISBN                     = {978-1-4799-0356-6},
  ISSN                     = {1520-6149},
  Keywords                 = {Algorithm design and analysis,Approximation algorithms,Classification,Competitive,Context,Context tree,Kernel,LDA,Online,Partitioning algorithms,Piecewise linear,Support vector machines,Training,binary classification problem,competitive piecewise linear classification,computational complexity,context tree weighting method,high classification accuracy,learning (artificial intelligence),machine learning,online piecewise linear classification,piecewise linear techniques,real time processing,sequential updates},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ozkan2013a},
  Shorttitle               = {Acoustics, Speech and Signal Processing (ICASSP), },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6638299}
}

@Conference{Ozkan2013a,
  Title                    = {Competitive and online piecewise linear classification},
  Author                   = {Ozkan, H.a and Donmez, M.A.b and Pelvan, O.S.c and Akman, A.c and Kozat, S.S.a },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {3452-3456},

  Abstract                 = {In this paper, we study the binary classification problem in machine learning and introduce a novel classification algorithm based on the 'Context Tree Weighting Method'. The introduced algorithm incrementally learns a classification model through sequential updates in the course of a given data stream, i.e., each data point is processed only once and forgotten after the classifier is updated, and asymptotically achieves the performance of the best piecewise linear classifiers defined by the 'context tree'. Since the computational complexity is only linear in the depth of the context tree, our algorithm is highly scalable and appropriate for real time processing. We present experimental results on several benchmark data sets and demonstrate that our method provides significant computational improvement both in the test (5 - 35×) and training phases (40 - 1000×) , while achieving high classification accuracy in comparison to the SVM with RBF kernel. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Bilkent University, Electrical and Electronics Engineering Department, Ankara, Turkey; Koc University, Electrical and Electronics Engineering Department, Istanbul, Turkey; Turk Telekom Group R and D, Ankara, Turkey},
  Art_number               = {6638299},
  Author_keywords          = {Classification; Competitive; Context tree; LDA; Online; Piecewise linear},
  Document_type            = {Conference Paper},
  Journal                  = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They study the binary classification problem in machine learning and introduce a novel classification algorithm based on the 'Context Tree Weighting Method'. The introduced algorithm incrementally learns a classification model through sequential updates in the course of a given data stream, i.e., each data point is processed only once and forgotten after the classifier is updated. Experiments on benchmark data sets shows significant computational improvement compared to SVM with RBF kernel (a popular kernel function). Interesting algorithm for binary classification, fast and scalable. Does popular mean SotA? 1,2,3,4,(5?),6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84890463116&partnerID=40&md5=f9e563ad7315dfccd09ef817ec01fbcf}
}

@InProceedings{Paliyawan2014,
  Title                    = {{Prolonged sitting detection for office workers syndrome prevention using kinect}},
  Author                   = {Paliyawan, Pujana and Nukoolkit, Chakarida and Mongkolnam, Pornchai},
  Booktitle                = {2014 11th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)},
  Year                     = {2014},
  Month                    = may,
  Pages                    = {1--6},
  Publisher                = {IEEE},

  Abstract                 = {This research has focused on detection of prolonged sitting of office workers by performing data mining classification on the real-time skeleton data stream captured by a single Kinect camera set up in an office worker's work station area. The system classifies the input stream into sequences of stills or moves. The performance of several classification methods such as decision tree, neural network, naive Bayes, and k-Nearest Neighbors are compared in order to acquire the optimal classifier. The proposed system can effectively monitor the user's postures with 98\% accuracy and give the user real-time feedback based on the three levels of healthy in ergonomics. In addition, the proposed work includes development of an alerting device using a microcontroller, and provision of data visualization for a daily summary report.},
  Doi                      = {10.1109/ECTICon.2014.6839785},
  ISBN                     = {978-1-4799-2993-1},
  Keywords                 = {Cameras,Classification,Ergonomics,Feeds,Health and Medical Informatics,Human Gesture Recognition,Joints,Kinect Camera,Kinect camera,Monitoring,Office Workers Syndrome,Real-time systems,cameras,data mining,data mining classification,data visualisation,data visualization,ergonomics,feedback,health care,office workers syndrome prevention,prolonged sitting detection,real-time feedback,real-time skeleton data stream,real-time systems},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Paliyawan2014a},
  Shorttitle               = {Electrical Engineering/Electronics, Computer, Tele},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6839785}
}

@Conference{Paliyawan2014a,
  Title                    = {Prolonged sitting detection for office workers syndrome prevention using kinect},
  Author                   = {Paliyawan, P. and Nukoolkit, C. and Mongkolnam, P.},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {This research has focused on detection of prolonged sitting of office workers by performing data mining classification on the real-time skeleton data stream captured by a single Kinect camera set up in an office worker's work station area. The system classifies the input stream into sequences of stills or moves. The performance of several classification methods such as decision tree, neural network, naive Bayes, and k-Nearest Neighbors are compared in order to acquire the optimal classifier. The proposed system can effectively monitor the user's postures with 98% accuracy and give the user real-time feedback based on the three levels of healthy in ergonomics. In addition, the proposed work includes development of an alerting device using a microcontroller, and provision of data visualization for a daily summary report. Ã‚Â© 2014 IEEE.},
  Affiliation              = {School of Information Technology, King Mongkut's University of Technology Thonburi, Bangkok, Thailand},
  Art_number               = {6839785},
  Author_keywords          = {Classification; Ergonomics; Health and Medical Informatics; Human Gesture Recognition; Kinect Camera; Office Workers Syndrome},
  Document_type            = {Conference Paper},
  Journal                  = {2014 11th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, ECTI-CON 2014},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Performs mining on data stream on human skeletons, to detect prolonged sitting in workers. Test different ML techniques. They create a health system that gives RT feedback. (Maybe relevant for in-house Telenor, to make sure workers stay healthy?) 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905400896&partnerID=40&md5=2d4617185d275326e6bd585997efe510}
}

@Article{Pandey2004,
  Title                    = {{WIC: a general-purpose algorithm for monitoring web information sources}},
  Author                   = {Pandey, Sandeep and Dhamdhere, Kedar and Olston, Christopher},
  Year                     = {2004},

  Month                    = aug,
  Pages                    = {360--371},

  Abstract                 = {The Web is becoming a universal information dissemination medium, due to a number of factors including its support for content dynamicity. A growing number of Web information providers post near real-time updates in domains such as auctions, stock markets, bulletin boards, news, weather, roadway conditions, sports scores, etc. External parties often wish to capture this information for a wide variety of purposes ranging from online data mining to automated synthesis of information from multiple sources. There has been a great deal of work on the design of systems that can process streams of data from Web sources, but little attention has been paid to how to produce these data streams, given that Web pages generally require "pull-based" access. In this paper we introduce a new general-purpose algorithm for monitoring Web information sources, effectively converting pull-based sources into push-based ones. Our algorithm can be used in conjunction with continuous query systems that assume information is fed into the query engine in a push-based fashion. Ideally, a Web monitoring algorithm for this purpose should achieve two objectives: (1) timeliness and (2) completeness of information captured. However, we demonstrate both analytically and empirically using real-world data that these objectives are fundamentally at odds. When resources available for Web monitoring are limited, and the number of sources to monitor is large, it may be necessary to sacrifice some timeliness to achieve better completeness, or vice versa. To take this fact into account, our algorithm is highly parameterized and targets an application-specified balance between timeliness and completeness. In this paper we formalize the problem of optimizing for a flexible combination of timeliness and completeness, and prove that our parameterized algorithm is a 2- approximation in all cases, and in certain cases is optimal.},
  ISBN                     = {0-12-088469-0},
  Owner                    = {alex},
  Publisher                = {VLDB Endowment},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. This paper describes a general-purpose web monitoring system. Nothing about ML.},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1316689.1316722}
}

@Misc{Panigrahi,
  Title                    = {{Online Selection of Diverse Results}},

  Author                   = {Panigrahi, Debmalya and Das, Atish and Gagan, Sarma and Tomkins, Aggarwal Andrew},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The phenomenal growth in the volume of easily accessible information via various web-based services has made it essential for service providers to provide users with personalized representative summaries of such information. Further, online commercial services including social networking and micro-blogging websites, e-commerce portals, leisure and entertainment websites, etc. recommend interesting content to users that is simultaneously diverse on many different axes such as topic, geographic specificity, etc. The key algorithmic question in all these applications is the generation of a succinct, representative, and relevant summary from a large stream of data coming from a variety of sources. In this paper, we formally model this optimization problem, identify its key structural characteristics, and use these observations to design an extremely scalable and efficient algorithm. We analyze the algorithm using theoretical techniques to show that it always produces a nearly optimal solution. In addition, we perform large-scale experiments on both real-world and synthetically generated datasets, which confirm that our algorithm performs even better than its analytical guarantees in practice, and also outperforms other candidate algorithms for the problem by a wide margin.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. In this paper, we formally model this optimization problem (generate summaries from large streams of data), identify its key structural characteristics, and use these observations to design an extremely scalable and efficient algorithm. Theoretical analysis and experiments show that their algorithm outperforms other candidate algorithms for the problem by a wide margin. The algorithm seems interesting, its goal seems to make personal summaries to each user of f.ex blogging or entertainment websites. Not sure what these candidate algorithms are. 1,2,3,4,(5?),6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.224.2799}
}

@Misc{Parita,
  Title                    = {{A Review on Tree Based Incremental Classification}},

  Author                   = {Parita, Ponkiya and Singh, Purnima},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Data mining has been identical as the technology that offers the possibilities of discovering the hidden knowledge from this large amount of data. Classification is an important wellknown problem in the field of data mining, and has remained an extensive research topic within several research communities. When data stream is continuous or online traditional classification will fail so it’s required to develop classification model which deals with online data. Contiguous growth of data makes previously constructed classification tree outdated. So this problem can be solved by building classification tree incrementally. Incremental decision tree method allows existing tree to be updated as when new data instances arrives without re processing old data instances. Many decision tree methods like C4.5 construct tree using whole dataset. I},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This abstract seems like it's cut in half, as it only offers an introduction and stops mid-sentence. THe title indicates that it's a review, so therefore it's discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.432.8724}
}

@Article{Park2013,
  Title                    = {Adaptive trace of multi-dimensional clusters by monitoring data streams},
  Author                   = {Park, N.H.a and Joo, K.H.b and Han, S.Y.a },
  Journal                  = {International Journal of Multimedia and Ubiquitous Engineering},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {3},
  Pages                    = {351-358},
  Volume                   = {8},

  Abstract                 = {In recent years, clustering data streams has been actively proposed in the field of data mining. In real-life domains, clustering methods for data streams should effectively monitor the continuous change of a data stream with respect to all the dimensions of the data stream. In this paper, a clustering method with frequency prediction of data elements is proposed. The incoming statistics of data elements in the monitoring range are maintained. For the range of elements with high density, the range is partitioned to detect the detailed boundary of clusters. To identifying the recent change of a data stream quickly, the support of elements is carefully monitored and predicted to determine partitioned ranges to become clusters. Considering the change of the data stream, a threshold is adaptively controlled by a prediction mechanism. By predicting the change of supports, the on-going change of a data stream can be reflected in real-time. The proposed method is comparatively analyzed by a series of experiments to identify its various characteristics.},
  Affiliation              = {Dept. of Computer Science, Anyang University, 102 Samsungli, Buleunmyun, Ganghwagun, Incheon 417-833, South Korea; Dept. of Computer Education, Gyeongin National University of Education, San 6-8 Seoksudong Manangu Anyangsi, Gyeonggi 430-040, South Korea},
  Author_keywords          = {Adaptive memory utilization; Clustering; Data mining; Data streams},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, a clustering method with frequency prediction of data elements is proposed. . To identify the recent change of a data stream quickly, the support of elements is carefully monitored and predicted to determine partitioned ranges to become clusters. By predicting the change of supports, the ongoing change of a data stream can be reflected in real-time. The proposed method is comparatively analyzed by a series of experiments to identify its various characteristics. Nothing about the outcome of the experimentation. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84878475965&partnerID=40&md5=44fc9271669aaaab51d748c3bb054ce7}
}

@Misc{Park,
  Title                    = {{Adaptive Trace of Multi-dimensional Clusters by Monitoring Data Streams}},

  Author                   = {Park, Nam Hun and Joo, Kil Hong and Han, Su Young},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In recent years, clustering data streams has been actively proposed in the field of data mining. In real-life domains, clustering methods for data streams should effectively monitor the continuous change of a data stream with respect to all the dimensions of the data stream. In this paper, a clustering method with frequency prediction of data elements is proposed. The incoming statistics of data elements in the monitoring range are maintained. For the range of elements with high density, the range is partitioned to detect the detailed boundary of clusters. To identifying the recent change of a data stream quickly, the support of elements is carefully monitored and predicted to determine partitioned ranges to become clusters. Considering the change of the data stream, a threshold is adaptively controlled by a prediction mechanism. By predicting the change of supports, the on-going change of a data stream can be reflected in real-time. The proposed method is comparatively analyzed by a series of experiments to identify its various characteristics.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Park2013},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.306.8500}
}

@Conference{Parker2013a,
  Title                    = {Rapidly labeling and tracking dynamically evolving concepts in data streams},
  Author                   = {Parker, B.S. and Khan, L.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1161-1164},

  Abstract                 = {Data mining research has produced a significant repertoire of algorithms to predict the classification of data instances with reasonable accuracy. However, data quantity and availability is continuing to rapidly expand such that we no longer have fixed and manageable data sets, but rather continual streams of data. Mining streaming data becomes challenging when using a piece-wise or online approach, however, due to concept drift and feature evolution. As the stream progresses, features may be added, removed, or change in the range of possible values, which is known as feature evolution. The defining concepts for a label or class may also migrate over the span of the data stream. Novel classes that were not known a priori can also appear within the data stream. Traditional algorithms often characterize unknown labels as errors and outliers, but in the dynamic streaming domain, a sufficiently dense cluster of outliers must be analyzed to discover potential emergent classes. In our approach, we aim to adapt to novel classes emergence, feature evolution, and concept drift while labeling data instances and adhering to the constraints of continuous data streams. Our solution consists of an adaptive supervised ensemble for predicting instance labels, and a stream clustering approach to monitor concept defining characteristics and novel class development without regard to label (i.e. unsupervised). We analyze and compare our approach to traditional baseline approaches on benchmark data streams to verify the accuracy and efficiency of the algorithm. Ã‚Â© 2013 IEEE.},
  Affiliation              = {University of Texas at Dallas, 800 W Campbell Rd, Richardson, TX 75083-0688, United States},
  Art_number               = {6754056},
  Author_keywords          = {Concept drift; Concept evolution; Ensemble Methods; Stream Data Mining},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE 13th International Conference on Data Mining Workshops, ICDMW 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They aim to adapt to novel classes emergence, feature evolution, and concept drift while labeling data instances and adhering to the constraints of continuous data streams. The solution consists of an adaptive supervised ensemble for predicting instance labels, and a stream clustering approach to monitor concept defining characteristics and novel class development without regard to label (i.e. unsupervised). They compare their approach to baseline approaches on benchmark data sets. They don't outright state that their approach is efficient, they just say that they verify the accuracy and efficiency. Without reading the whole thing we won't know. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84898047900&partnerID=40&md5=214a95de046299733e67ab71a9fcca72}
}

@InProceedings{Parker2013,
  Title                    = {{Rapidly Labeling and Tracking Dynamically Evolving Concepts in Data Streams}},
  Author                   = {Parker, Brandon S. and Khan, Latifur},
  Booktitle                = {2013 IEEE 13th International Conference on Data Mining Workshops},
  Year                     = {2013},
  Month                    = dec,
  Pages                    = {1161--1164},
  Publisher                = {IEEE},

  Abstract                 = {Data mining research has produced a significant repertoire of algorithms to predict the classification of data instances with reasonable accuracy. However, data quantity and availability is continuing to rapidly expand such that we no longer have fixed and manageable data sets, but rather continual streams of data. Mining streaming data becomes challenging when using a piece-wise or online approach, however, due to concept drift and feature evolution. As the stream progresses, features may be added, removed, or change in the range of possible values, which is known as feature evolution. The defining concepts for a label or class may also migrate over the span of the data stream. Novel classes that were not known a priori can also appear within the data stream. Traditional algorithms often characterize unknown labels as errors and outliers, but in the dynamic streaming domain, a sufficiently dense cluster of outliers must be analyzed to discover potential emergent classes. In our approach, we aim to adapt to novel classes emergence, feature evolution, and concept drift while labeling data instances and adhering to the constraints of continuous data streams. Our solution consists of an adaptive supervised ensemble for predicting instance labels, and a stream clustering approach to monitor concept defining characteristics and novel class development without regard to label (i.e. unsupervised). We analyze and compare our approach to traditional baseline approaches on benchmark data streams to verify the accuracy and efficiency of the algorithm.},
  Doi                      = {10.1109/ICDMW.2013.37},
  ISBN                     = {978-1-4799-3142-2},
  Keywords                 = {Accuracy,Conferences,Data mining,Educational institutions,Ensemble Methods,Heuristic algorithms,Labeling,Prediction algorithms,Stream Data Mining,class development,concept defining characteristics,concept drift,concept evolution,concept rapid labeling,concept tracking,continuous data streams,data availability,data instance classification,data mining,data mining research,data quantity,dynamically evolving concepts,feature evolution,online data mining approach,pattern classification,piece-wise data mining approach,streaming data mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Parker2013a},
  Shorttitle               = {Data Mining Workshops (ICDMW), 2013 IEEE 13th Inte},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6754056}
}

@Article{Patil2012a,
  Title                    = {Concept adapting real-time data stream mining for health care applications},
  Author                   = {Patil, D.D. and Mudkanna, J.G. and Rokade, D. and Wadhai, V.M.},
  Journal                  = {Advances in Intelligent and Soft Computing},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {VOL. 1},
  Pages                    = {341-351},
  Volume                   = {166 AISC},

  Abstract                 = {Developments in sensors, miniaturization of low-power microelectronics, and wireless networks are becoming a significant opportunity for improving the quality of health care services. Vital signals like ECG, EEG, SpO2, BP etc. can be monitor through wireless sensor networks and analyzed with the help of data mining techniques. These real-time signals are continuous in nature and abruptly changing hence there is a need to apply an efficient and concept adapting real-time data stream mining techniques for taking intelligent health care decisions online. Because of the high speed and huge volume data set in data streams, the traditional classification technologies are no longer applicable. The most important criteria are to solve the real-time data streams mining problem with 'concept drift' efficiently. This paper presents the state-of-the art in this field with growing vitality and introduces the methods for detecting concept drift in data stream, then gives a significant summary of existing approaches to the problem of concept drift. The work is focused on applying these real time stream mining algorithms on vital signals of human body in health care environment. Ã‚Â© 2012 Springer-Verlag GmbH.},
  Affiliation              = {MAEER's MIT College of Engineering, Comp. Engg. Dept., Pune, India},
  Author_keywords          = {concept-drift; Health Care; Real-time data stream mining; vital Signal processing},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents the state-of-the art in this field (health care monitoring) with growing vitality and introduces the methods for detecting concept drift in data stream, then gives a significant summary of existing approaches to the problem of concept drift. The work is focused on applying these real time stream mining algorithms on vital signals of human body in health care environment. Seems like they try to adapt SotA ML-techniques to fit into monitoring of health. Could be interesting. Nothing hugely innovative it seems, but could be a primary source. 1,2,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84865192710&partnerID=40&md5=5f6a2f4714ed740b791f33e725b525f0}
}

@Conference{Patil2012b,
  Title                    = {Dynamic data mining approach to WMRHM},
  Author                   = {Patil, D.D.a and Wadhai, V.M.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1978-1983},

  Abstract                 = {Developments in sensors, miniaturization of low-power microelectronics, and wireless networks are becoming a significant opportunity for improving the quality of health care services. Since the population is growing, the need for high quality and efficient healthcare, both at home and in hospital, is becoming more important. This paper presents the innovative wireless sensor network based Mobile Real-time Health care Monitoring (WMRHM) framework which has the capacity of giving health predictions online based on continuously monitored real time vital body signals. Our approach focused towards handling all kinds of vital signals like ECG, EMG, SpO2 etc. which previous work was not supporting. While predictions the framework considers all parameters like patient history, domain expert's rules and continuously monitored real-time signals. Implementation and results of applying clustering algorithms (Graph theoretic, K-means) on patient's historical health data for forming the health rule base are discussed here. The framework has been designed to perform the analysis on the instantaneous and stream (continuous) data over a sliding time window which applies dynamic data mining on the live data. The comparative analysis on vital signals made from various clustering algorithms adds extra dimension to global risk alerts and help doctors to diagnose more accurately. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Dept. Computer Engineering, MAEER's MITCOE, Pune, India; MAEER's MITCOE, Pune, India},
  Art_number               = {6361053},
  Author_keywords          = {Clustering; Dynamic data mining; vital signal Processing; Wireless Sensor Networks},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2012 7th IEEE Conference on Industrial Electronics and Applications, ICIEA 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents the innovative wireless sensor network based Mobile Real-time Health care Monitoring (WMRHM). The framework has been designed to perform the analysis on the instantaneous and stream (continuous) data over a sliding time window which applies dynamic data mining on the live data. Nothing about the quantifiable results. No new algorithms 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84871678162&partnerID=40&md5=02bb0dd2b53465fed3bd13bc39953fe1}
}

@InProceedings{Patil2012,
  Title                    = {{Dynamic data mining approach to WMRHM}},
  Author                   = {Patil, Dipti Durgesh and Wadhai, Vijay M.},
  Booktitle                = {2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA)},
  Year                     = {2012},
  Month                    = jul,
  Pages                    = {1978--1983},
  Publisher                = {IEEE},

  Abstract                 = {Developments in sensors, miniaturization of low-power microelectronics, and wireless networks are becoming a significant opportunity for improving the quality of health care services. Since the population is growing, the need for high quality and efficient healthcare, both at home and in hospital, is becoming more important. This paper presents the innovative wireless sensor network based Mobile Real-time Health care Monitoring (WMRHM) framework which has the capacity of giving health predictions online based on continuously monitored real time vital body signals. Our approach focused towards handling all kinds of vital signals like ECG, EMG, SpO2 etc. which previous work was not supporting. While predictions the framework considers all parameters like patient history, domain expert's rules and continuously monitored real-time signals. Implementation and results of applying clustering algorithms (Graph theoretic, K-means) on patient's historical health data for forming the health rule base are discussed here. The framework has been designed to perform the analysis on the instantaneous and stream (continuous) data over a sliding time window which applies dynamic data mining on the live data. The comparative analysis on vital signals made from various clustering algorithms adds extra dimension to global risk alerts and help doctors to diagnose more accurately.},
  Doi                      = {10.1109/ICIEA.2012.6361053},
  ISBN                     = {978-1-4577-2119-9},
  Keywords                 = {Biomedical monitoring,Clustering,Clustering algorithms,Data mining,Dynamic data mining,Heuristic algorithms,K-means clustering,Medical services,Monitoring,Real-time systems,WMRHM,Wireless Sensor Networks,clustering algorithms,data mining,dynamic data mining approach,graph theory,health care,health care services,low-power microelectronics,medical administrative data processing,mobile real-time health care monitoring,pattern clustering,vital signal Processing,wireless sensor network,wireless sensor networks},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Patil2012b},
  Shorttitle               = {Industrial Electronics and Applications (ICIEA), 2},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6361053}
}

@Conference{Peng2012,
  Title                    = {Real-time analytics processing with MapReduce},
  Author                   = {Peng, C.-Z.a and Jiang, Z.-J.a and Cai, X.-B.b and Zhang, Z.-K.a },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1308-1311},
  Volume                   = {4},

  Abstract                 = {Many real-time analytical applications over massive data streams were performed by usually introducing a specific stream processing core. In general, these SPCs were not popularly applied to enterprises same as MapReduce, even if now real-time analytics applications are taken into attention more and more. For reversing this tide, we developed a new analytics system. Our system modified the stock Hadoop's MapReduce programming model and execution framework, and used Chord model as temporary data, Cassandra as its persistent storage. With our system, we can develop data stream processing application with the familiar MapReduce programming model. Ã‚Â© 2012 IEEE.},
  Affiliation              = {School of Computer Science and Technology, Northwestern Polytechnical University, Xi'an, China; China Aerospace Science and Technology Corporation, China},
  Art_number               = {6359554},
  Author_keywords          = {Cassandra; Data stream processing; JOL; MapReduce; Real-time analytics},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Machine Learning and Cybernetics},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They developed a new analytics system based on stock Hadoop , and used Chord model as temporary data, Cassandra as its persistent storage. With our system, we can develop data stream processing application with the familiar MapReduce programming model. Short abstract, would have liked to know more about the possibilities with this new system. Could be a primary source, as it seems it should be read in its entirety. 1,2,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84871543232&partnerID=40&md5=242871a3896fb0cfd1c688dc7ba708ba}
}

@Article{Percival2014,
  Title                    = {Enabling the integration of clinical event and physiological data for real-time and retrospective analysis},
  Author                   = {Percival, J.a and McGregor, C.a and Percival, N.b and James, A.c d },
  Journal                  = {Information Systems and e-Business Management},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0; Article in Press},
  Pages                    = {1-19},

  Abstract                 = {There is a growing trend of developing advanced clinical decision support systems that analyze physiological data streams for early detection of a variety of clinical diagnoses. This paper presents prototype architecture for both a real-time mobile clinical event data capture application and an Artemis-based replay system for retrospective analysis and validation of physiological data analytics. These two components provide important information for improving the ability of clinical decision support systems and patient monitoring algorithms to detect and adjust for artifacts caused by clinical events. A description of the prototypes, as well as results from initial prototype testing is provided. Although the sample size is small for the initial testing, significant information with respect to design principles and infrastructure needs were uncovered. Future research directions are identified to improve the mobile application through increased security, robustness, further integration into data mining analysis, and future clinical decision support algorithms. Ã‚Â© 2014 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {Faculty of Business and Information Technology, University of Ontario Institute of Technology, 2000 Simcoe Street North, Oshawa, Canada; Faculty of Engineering and Applied Science, University of Ontario Institute of Technology, 2000 Simcoe Street North, Oshawa, Canada; Division of Neonatology, The Hospital for Sick Children, Toronto, Canada; Department of Paediatrics, University of Toronto, 555 University Avenue, Toronto, Canada},
  Author_keywords          = {Algorithm testing; Clinical data integration; Data replay; Intelligent clinical decision support systems; Physiological data streams; Real-time patient monitoring systems},
  Document_type            = {Article in Press},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A prototype that analyze a physiological data stream and aim at developing advanced clinical decision support system. The paper presents prototype architecture for both a real-time mobile clinical event data capture application and an Artemis-based replay system for retrospective analysis and validation of physiological data analytics. Mostly a exploratory study, with very weak focus on data mining. Approved under uncertainty. 1},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84892407457&partnerID=40&md5=8a923fb7d6357e68f2c345e662e09082}
}

@Article{Perrochon1999,
  Title                    = {{Event Mining with Event Processing Networks}},
  Author                   = {Perrochon, Louis and Mann, Walter and Kasriel, Stephane and Luckham, David C.},
  Journal                  = {IN PROCEEDINGS OF THE THIRD PACIFIC-ASIA CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING},
  Year                     = {1999},
  Pages                    = {474 -- 478},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Event Mining discovers information in a stream of data, or events, and delivers knowledge in real-time. Our event processing engine consists of a network of event processing agents (EPAs) running in parallel that interact using a dedicated event processing infrastructure. EPAs can be configured at run-time using a formal pattern language. The underlying infrastructure provides an abstract communication mechanism and thus allows dynamic reconfiguration of the communication topology between agents at run-time and provides transparent, location-independent access to all data. These features support dynamic allocation of EPAs to machines in a local area network at run time.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The paper present an Event Processing Engine to discover information in a stream of data. Very short abstract, no expermimentation, very old. Approved under uncertainty, Seems to only describe their engine. 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.34.1418}
}

@Article{Pfleger2004,
  Title                    = {{On-Line Cumulative Learning of Hierarchical Sparse n-Grams}},
  Author                   = {Pfleger, Karl},
  Journal                  = {PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We present a system for on-line, cumulative learning of hierarchical collections of frequent patterns from unsegmented data streams. Such learning is critical for long-lived intelligent agents in complex worlds. Learned patterns enable prediction of unseen data and serve as building blocks for higher-level knowledge representation. We introduce a novel sparse n-gram model that, unlike pruned n-grams, learns on-line by stochastic search for frequent n-tuple patterns. Adding patterns as data arrives complicates probability calculations. We discuss an EM approach to this problem and introduce hierarchical sparse n-grams, a model that uses a better solution based on a new method for combining information across levels. A second new method for combining information from multiple granularities (n-gram widths) enables these models to more effectively search for frequent patterns (an on-line, stochastic analog of pruning in association rule mining). The result is an example of a rare combination---unsupervised, on-line, cumulative, structure learning. Unlike prediction suffix tree (PST) mixtures, the model learns with no size bound but using less space than the data. It does not repeatedly iterate over data (unlike MaxEnt feature construction). It discovers repeated structure on-line and (unlike PSTs) uses this to learn larger patterns. The type of repeated structure is limited (e.g., compared to hierarchical HMMs) but still useful, and these are important first steps towards learning repeated structure in more expressive representations, which has seen little progress especially in unsupervised, on-line contexts.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present a system for on-line, cumulative learning of hierarchical collections of frequent patterns from unsegmented data streams. First they introduce a novel sparse n-gram model that, unlike pruned n-grams, learns on-line by stochastic search for frequent n-tuple patterns. A second new method for combining information from multiple granularities (n-gram widths) enables these models to more effectively search for frequent patterns. The results is -unsupervised, on-line, cumulative, structure learning It seems they are making progress in uncharted territory, but the paper is 10 years old. Nothing about experimentation, comparisons or results. 1,2,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.2076}
}

@Article{Pham2013,
  Title                    = {Detection of cross-channel anomalies},
  Author                   = {Pham, D.-S.a and Saha, B.b and Phung, D.Q.b and Venkatesh, S.b },
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Number                   = {1},
  Pages                    = {33-59},
  Volume                   = {35},

  Abstract                 = {The data deluge has created a great challenge for data mining applications wherein the rare topics of interest are often buried in the flood of major headlines. We identify and formulate a novel problem: cross-channel anomaly detection from multiple data channels. Cross-channel anomalies are common among the individual channel anomalies and are often portent of significant events. Central to this new problem is a development of theoretical foundation and methodology. Using the spectral approach, we propose a two-stage detection method: anomaly detection at a single-channel level, followed by the detection of cross-channel anomalies from the amalgamation of single-channel anomalies. We also derive the extension of the proposed detection method to an online settings, which automatically adapts to changes in the data over time at low computational complexity using incremental algorithms. Our mathematical analysis shows that our method is likely to reduce the false alarm rate by establishing theoretical results on the reduction of an impurity index. We demonstrate our method in two applications: document understanding with multiple text corpora and detection of repeated anomalies in large-scale video surveillance. The experimental results consistently demonstrate the superior performance of our method compared with related state-of-art methods, including the one-class SVM and principal component pursuit. In addition, our framework can be deployed in a decentralized manner, lending itself for large-scale data stream analysis. Ã‚Â© 2012 Springer-Verlag London Limited.},
  Affiliation              = {Department of Computing, Curtin University, Perth, WA, Australia; Center for Pattern Recognition and Data Analytics (PRaDA), Deakin University, Geelong, VIC, Australia},
  Author_keywords          = {Anomaly detection; Collaborative subspace learning; Data mining; Multiple channels; Residual subspace analysis; Text data analysis; Topic modeling; Video surveillance},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They identify and formulate a novel problem: cross-channel anomaly detection from multiple data channels, and propose a two-stage detection method. It automatically adapts to changes in the data over time at low computational complexity using incremental algorithms. The experimental results consistently demonstrate superior performance compared with related state-of-art methods, including the one-class SVM and principal component pursuit. Could be interesting. Not quite sure what anomalies they detect, but they use real-life applications to test. 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84875448991&partnerID=40&md5=8978a60d9f1d484a0e3f7764baeac3dc}
}

@Article{PhridviRaj2014,
  Title                    = {Clustering Text Data Streams Ã¢â‚¬â€œ A Tree based Approach with Ternary Function and Ternary Feature Vector },
  Author                   = {PhridviRaj and Chintakindi Srinivas and C.V. GuruRao},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2nd International Conference on Information Technology and Quantitative Management, \{ITQM\} 2014 },
  Number                   = {0},
  Pages                    = {976 - 984},
  Volume                   = {31},

  Abstract                 = {Abstract Data is the primary concern in data mining. Data Stream Mining is gaining a lot of practical significance with the huge online data generated from Sensors, Internet Relay Chats, Twitter, Facebook, Online Bank or \{ATM\} Transactions. The primary constraint in finding the frequent patterns in data streams is to perform only one time scan of the data with limited memory and requires less processing time. The concept of dynamically changing data is becoming a key challenge, what we call as data streams. In our present work, the algorithm is based on finding frequent patterns in the data streams using a tree based approach and to continuously cluster the text data streams being generated using a new ternary similarity measure defined.},
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.350},
  ISSN                     = {1877-0509},
  Keywords                 = {similarity},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of PhridviRaj2013, just from another conference.},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914005274}
}

@Conference{PhridviRaj2013,
  Title                    = {Mining top-k rank frequent patterns in data streams a tree based approach with ternary function and ternary feature vector},
  Author                   = {PhridviRaj, M.S.B.a and Guru Rao, C.V.b},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {271-276},

  Abstract                 = {Data is the primary concern in data mining. Data Stream Mining is gaining a lot of practical significance with the huge online data generated from Sensors, Internet Relay Chats, Twitter, Facebook, Online Bank or ATM Transactions. The primary constraint in finding the frequent patterns in data streams is to perform only one time scan of the data with limited memory and requires less processing time. The concept of dynamically changing data is becoming a key challenge, what we call as data streams. In our present work, the algorithm is based on finding frequent patterns in the data streams using a tree based approach. Ã‚Â© 2013 ACM.},
  Affiliation              = {Department of Computer Science and Engineering, Kakatiya Institute of Technology and Science, Warangal, India; Department of Computer Science and Engineering, S.R.Engineering College Hasanparthy, Warangal, India},
  Author_keywords          = {Data streams; Frequent item; Frequent pattern tree; Ternary vector},
  Document_type            = {Conference Paper},
  Journal                  = {ACM International Conference Proceeding Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present an algorithm that is based on finding frequent patterns in the data streams using a tree based approach. Weak and short abstract. It's from a conference called Innovative Computing, so I guess their approach is innovative, but they detail no experimentation nor any details about their algorithm 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84899581103&partnerID=40&md5=3e3adc5f733f550b592b5fad66b35098}
}

@Article{PhridviRaj2014a,
  Title                    = {Data Mining – Past, Present and Future – A Typical Survey on Data Streams},
  Author                   = {M.S.B. PhridviRaj and C.V. GuruRao},
  Journal                  = {Procedia Technology },
  Year                     = {2014},
  Note                     = {The 7th International Conference Interdisciplinarity in Engineering, INTER-ENG 2013, 10-11 October 2013, Petru Maior University of Tirgu Mures, Romania },
  Number                   = {0},
  Pages                    = {255 - 263},
  Volume                   = {12},

  Abstract                 = {Abstract Data Stream Mining is one of the area gaining lot of practical significance and is progressing at a brisk pace with new methods, methodologies and findings in various applications related to medicine, computer science, bioinformatics and stock market prediction, weather forecast, text, audio and video processing to name a few. Data happens to be the key concern in data mining. With the huge online data generated from several sensors, Internet Relay Chats, Twitter, Face book, Online Bank or \{ATM\} Transactions, the concept of dynamically changing data is becoming a key challenge, what we call as data streams. In this paper, we give the algorithm for finding frequent patterns from data streams with a case study and identify the research issues in handling data streams.},
  Doi                      = {http://dx.doi.org/10.1016/j.protcy.2013.12.483},
  ISSN                     = {2212-0173},
  Keywords                 = {Clustering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Shitty english, seems to be the same paper as before. Just a survey on one/more algorithms. Can't tell. Discarded},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2212017313006683}
}

@Conference{PhridviRaj2014b,
  Title                    = {Clustering text data streams - A tree based approach with ternary function and ternary feature vector},
  Author                   = {PhridviRaj, M.S.B.a and Srinivas, C.a and GuruRao, C.V.b },
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {976-984},
  Volume                   = {31},

  Abstract                 = {Data is the primary concern in data mining. Data Stream Mining is gaining a lot of practical significance with the huge online data generated from Sensors, Internet Relay Chats, Twitter, Facebook, Online Bank or ATM Transactions. The primary constraint in finding the frequent patterns in data streams is to perform only one time scan of the data with limited memory and requires less processing time. The concept of dynamically changing data is becoming a key challenge, what we call as data streams. In our present work, the algorithm is based on finding frequent patterns in the data streams using a tree based approach and to continuously cluster the text data streams being generated using a new ternary similarity measure defined. Ã‚Â© 2014 Published by Elsevier B.V.},
  Affiliation              = {Kakatiya Institute of Technology and Science, Warangal, India; Department of CSE, S.R. Engineering College, Warangal, India},
  Author_keywords          = {Cluster; Data stream; Frequent item; Similarity; Ternary vector},
  Document_type            = {Conference Paper},
  Journal                  = {Procedia Computer Science},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of PhridviRaj2013 This guy just seriously changes the name of the paper, and give the exact same abstract.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84902246002&partnerID=40&md5=884d0a7e613819cc5470df9ffca0b7a0}
}

@InProceedings{PhridviRaj2013a,
  Title                    = {{Mining Top-K Rank Frequent Patterns in Data Streams A Tree Based Approach with Ternary Function and Ternary Feature Vector}},
  Author                   = {PhridviRaj, M. S. B. and Rao, C. V. Guru},
  Booktitle                = {Proceedings of the Second International Conference on Innovative Computing and Cloud Computing - ICCC '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = dec,
  Pages                    = {271--276},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/2556871.2556935},
  ISBN                     = {9781450321198},
  Keywords                 = {Data streams,frequent item,frequent pattern tree,ternary vector},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of PhridviRaj2013},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2556871.2556935}
}

@Conference{Phua2008a,
  Title                    = {Utility of real-time decision-making in commercial data stream mining domains},
  Author                   = {Phua, C.a and Lee, V.C.S.b and Smith-Miles, K.c },
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The objective is to measure utility of real-time commercial decision making. It is important due to a higher possibility of mistakes in real-time decisions, problems with recording actual occurrences, and significant costs associated with predictions produced by algorithms. The first contribution is to use overall utility and represent individual utility with a monetary value instead of a prediction. The second is to calculate the benefit from predictions using the utility-based decision threshold. The third is to incorporate cost of predictions. For experiments, overall utility is used to evaluate communal and spike detection, and their adaptive versions. The overall utility results show that with fewer alerts, communal detection is better than spike detection. With more alerts, adaptive communal and spike detection are better than their static versions. To maximise overall utility with all algorithms, only 1% to 4% in the highest predictions should be alerts. Ã‚Â© 2008 IEEE.},
  Affiliation              = {Institute of Infocomm Research (I2R), Singapore, Singapore; Clayton School of Information Technology, Monash University, VIC, Australia; School of Engineering and Information Technology, Deakin University, VIC, Australia},
  Art_number               = {4598518},
  Author_keywords          = {Costs and benefits; Measurement; Real-time decision-making; Utility},
  Document_type            = {Conference Paper},
  Journal                  = {5th International Conference Service Systems and Service Management - Exploring Service Dynamics with Science and Innovative Technology, ICSSSM'08},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-52249088195&partnerID=40&md5=848e2b734b59d9d6012488fa5a86a887}
}

@InProceedings{Phua2008,
  Title                    = {{Utility of real-time decision-making in commercial data stream mining domains}},
  Author                   = {Phua, Clifton and Lee, Vincent C.S. and Smith-Miles, Kate},
  Booktitle                = {2008 International Conference on Service Systems and Service Management},
  Year                     = {2008},
  Month                    = jun,
  Pages                    = {1--6},
  Publisher                = {IEEE},

  Abstract                 = {The objective is to measure utility of real-time commercial decision making. It is important due to a higher possibility of mistakes in real-time decisions, problems with recording actual occurrences, and significant costs associated with predictions produced by algorithms. The first contribution is to use overall utility and represent individual utility with a monetary value instead of a prediction. The second is to calculate the benefit from predictions using the utility-based decision threshold. The third is to incorporate cost of predictions. For experiments, overall utility is used to evaluate communal and spike detection, and their adaptive versions. The overall utility results show that with fewer alerts, communal detection is better than spike detection. With more alerts, adaptive communal and spike detection are better than their static versions. To maximise overall utility with all algorithms, only 1\% to 4\% in the highest predictions should be alerts.},
  Doi                      = {10.1109/ICSSSM.2008.4598518},
  ISBN                     = {978-1-4244-1671-4},
  Keywords                 = {Classification algorithms,Classification tree analysis,Costs,Data mining,Databases,Decision making,Feedback,Information technology,Prediction algorithms,Predictive models,costs and benefits,data mining,data stream mining,measurement,real-time decision-making,utility,utility-based decision},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {The objective is to measure utility of real-time commercial decision making Can't tell the purpose of this paper from the abstract, nor what they have done. It's not clear if they've used any ML at all, so discarded.},
  Shorttitle               = {Service Systems and Service Management, 2008 Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4598518}
}

@InProceedings{Phung2007,
  Title                    = {{Resource-aware Online Data Mining in Wireless Sensor Networks}},
  Author                   = {Phung, Nhan Duc and Gaber, Mohamed Medhat and Rohm, Uwe},
  Booktitle                = {2007 IEEE Symposium on Computational Intelligence and Data Mining},
  Year                     = {2007},
  Pages                    = {139--146},
  Publisher                = {IEEE},

  Abstract                 = {Data processing in wireless sensor networks often relies on high-speed data stream input, but at the same time is inherently constrained by limited resource availability. Thus, energy efficiency and good resource management are vital for in-network processing techniques. We propose enabling resource-awareness for in-network processing algorithms by means of a resource monitoring component and designed a corresponding framework. As proof of concept, we implement an online clustering algorithm, which uses the resource monitor to adapt to resource availability, on the Sun SPOT sensor nodes from Sun Microsystem. We refer to this adaptive clustering algorithm as extended resource-aware cluster (ERA-cluster). Finally, we report on the outcome of several experiments to evaluate the validity of our approach in terms of resource adaptiveness and accuracy of the ERA-cluster. Results show that ERA-cluster can effectively adapt to resource availability while maintaining acceptable level of accuracy.},
  Doi                      = {10.1109/CIDM.2007.368865},
  ISBN                     = {1-4244-0705-2},
  Keywords                 = {Availability,Clustering algorithms,Data mining,Data processing,Energy efficiency,Monitoring,Resource management,Sun,Sun SPOT sensor nodes,Time factors,Wireless sensor networks,adaptive clustering,data mining,data processing,extended resource-aware cluster,high-speed data stream input,in-network processing,online clustering,pattern clustering,resource allocation,resource availability,resource awareness,resource management,resource monitoring component,resource-aware online data mining,supervisory programs,wireless sensor networks},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {they implement an online clustering algorithm, which uses a resource monitor to adapt to resource availability. They report on the outcome of several experiments to evaluate the validity of our approach in terms of resource adaptiveness and accuracy of the ERA-cluster. Results show that ERA-cluster can effectively adapt to resource availability while maintaining acceptable level of accuracy. It seems this focuses more on the resource monitor than actual ML, but they use clustering techniques to make the monitor. 1,3,4,6},
  Shorttitle               = {Computational Intelligence and Data Mining, 2007. },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4221289}
}

@Article{Plimpton2014a,
  Title                    = {Streaming data analytics via message passing with application to graph algorithms},
  Author                   = {Plimpton, S.J. and Shead, T.},
  Journal                  = {Journal of Parallel and Distributed Computing},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {8},
  Pages                    = {2687-2698},
  Volume                   = {74},

  Abstract                 = {The need to process streaming data, which arrives continuously at high-volume in real-time, arises in a variety of contexts including data produced by experiments, collections of environmental or network sensors, and running simulations. Streaming data can also be formulated as queries or transactions which operate on a large dynamic data store, e.g. a distributed database. We describe a lightweight, portable framework named PHISH which provides a communication model enabling a set of independent processes to compute on a stream of data in a distributed-memory parallel manner. Datums are routed between processes in patterns defined by the application. PHISH provides multiple communication backends including MPI and sockets/ZMQ. The former means streaming computations can be run on any parallel machine which supports MPI; the latter allows them to run on a heterogeneous, geographically dispersed network of machines. We illustrate how streaming MapReduce operations can be implemented using the PHISH communication model, and describe streaming versions of three algorithms for large, sparse graph analytics: triangle enumeration, sub-graph isomorphism matching, and connected component finding. We also provide benchmark timings comparing MPI and socket performance for several kernel operations useful in streaming algorithms. Ã‚Â© 2014 Elsevier Inc. All rights reserved.},
  Affiliation              = {Sandia National Laboratories, Albuquerque, NM, United States},
  Author_keywords          = {Graph algorithms; MapReduce; Message passing; MPI; Sockets; Streaming data},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper describes a communication model for stream data. Nothing indicates ML has been used. Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84902250397&partnerID=40&md5=cf4d42f180cb9c21a5459863f9524f66}
}

@Conference{Pramod2012,
  Title                    = {Recent frequent itemsets mining over data streams},
  Author                   = {Pramod, S.a and Vyas, O.P.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {484-489},

  Abstract                 = {The association rule mining and its usages have thrown the lights to the different possibilities for the researchers. The importance of association rule mining is getting increased day by day due to the proliferation of internet as well as the fiercer competition in the business domain. The time required for generating frequent itemsets plays an important role in the online stream mining. Some algorithms are designed as considering only the time factor. The data streams typically arrive continuously in high speed in huge amount and changing distribution. Here in this paper our effort is to improve the performance of the online stream mining algorithm as by developing a new algorithm with a new data structure. The result shows that the new approach improved the performance in the association rule mining in its online environment. The implementation of this algorithm has been tested using the datasets from Frequent Itemset Mining(FIM) dataset repository. Copyright Ã‚Â© 2012 ACM.},
  Affiliation              = {Christian College of Engineering, Bhilai, C.G., India; IIIT, Allahabad, U.P., India},
  Author_keywords          = {Frequent itemset; Frequent itemset mining; Online stream mining; Single order path tree},
  Document_type            = {Conference Paper},
  Journal                  = {ACM International Conference Proceeding Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper want to improve the performance of the online stream mining algorithm by developing a new algorithm with a new data structure. The result shows that the new approach improved the performance in the association rule mining in its online environment Very weak abstract. Few to no details about their solution, experiments and outcome 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870686538&partnerID=40&md5=4a2a123b56b7ff6f6ec36d34162b5f4e}
}

@InProceedings{Pramod2012a,
  Title                    = {{Recent frequent itemsets mining over data streams}},
  Author                   = {Pramod, S. and Vyas, O. P.},
  Booktitle                = {Proceedings of the Second International Conference on Computational Science, Engineering and Information Technology - CCSEIT '12},
  Year                     = {2012},

  Address                  = {New York, New York, USA},
  Month                    = oct,
  Pages                    = {484--489},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/2393216.2393297},
  ISBN                     = {9781450313100},
  Keywords                 = {frequent itemset,frequent itemset mining,online stream mining,single order path tree},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Pramod2012},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2393216.2393297}
}

@Article{Presti2014,
  Title                    = {Streamlining CASTOR to manage the LHC data torrent},
  Author                   = {Presti, G.L. and Curull, X.E. and Cano, E. and Fiorini, B. and Ieri, A. and Murray, S. and Ponce, S. and Sindrilaru, E.},
  Journal                  = {Journal of Physics: Conference Series},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {TRACK 4},
  Volume                   = {513},

  Abstract                 = {This contribution describes the evolution of the main CERN storage system, CASTOR, as it manages the bulk data stream of the LHC and other CERN experiments, achieving over 90 PB of stored data by the end of LHC Run 1. This evolution was marked by the introduction of policies to optimize the tape sub-system throughput, going towards a cold storage system where data placement is managed by the experiments' production managers. More efficient tape migrations and recalls have been implemented and deployed where bulk meta-data operations greatly reduce the overhead due to small files. A repack facility is now integrated in the system and it has been enhanced in order to automate the repacking of several tens of petabytes, required in 2014 in order to prepare for the next LHC run. Finally the scheduling system has been evolved to integrate the internal monitoring. To efficiently manage the service a solid monitoring infrastructure is required, able to analyze the logs produced by the different components (about 1 kHz of log messages). A new system has been developed and deployed, which uses a transport messaging layer provided by the CERN-IT Agile Infrastructure and exploits technologies including Hadoop and HBase. This enables efficient data mining by making use of MapReduce techniques, and real-time data aggregation and visualization. The outlook for the future is also presented. Directions and possible evolution will be discussed in view of the restart of data taking activities. Ã‚Â© Published under licence by IOP Publishing Ltd.},
  Affiliation              = {CERN, 1211 Geneva 23, Switzerland},
  Art_number               = {042031},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper describes a new system to handle the bulk of data from CERN's LHC. IT enables efficient data mining by making use of MapReduce techniques, and real-time data aggregation and visualization. The outlook for the future is also presented Approved under uncertainty. It says it can use data mining on the stream, but no more details. 1,2,},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84903649630&partnerID=40&md5=2d4b450cfa58ab61f2186b2d5ed8ff80}
}

@InProceedings{ProgramChair-Fan2013,
  Title                    = {{Proceedings of the 2nd International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications}},
  Author                   = {{Program Chair-Fan}, Wei and {Program Chair-Bifet}, Albert and {Program Chair-Yang}, Qiang and {Program Chair-Yu}, Philip},
  Booktitle                = {Proceedings of the 2nd International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
  Year                     = {2013},
  Month                    = aug,
  Publisher                = {ACM},

  ISBN                     = {978-1-4503-2324-6},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2501221}
}

@InProceedings{ProgramChair-Fan2012,
  Title                    = {{Proceedings of the 1st International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications}},
  Author                   = {{Program Chair-Fan}, Wei and {Program Chair-Bifet}, Albert and {Program Chair-Yang}, Qiang and {Program Chair-Yu}, Philip},
  Booktitle                = {Proceedings of the 1st International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
  Year                     = {2012},
  Month                    = aug,
  Publisher                = {ACM},

  Abstract                 = {Discarded. Only contains proceedings from SIGKDD workshop on big data},
  ISBN                     = {978-1-4503-1547-0},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2351316}
}

@InProceedings{Qadeer2009,
  Title                    = {{Comparison of Tools for Data Mining and Retrieval in High Volume Data Stream}},
  Author                   = {Qadeer, Mohammed A. and Akhtar, Nadeem and Khan, Faraz},
  Booktitle                = {2009 Second International Workshop on Knowledge Discovery and Data Mining},
  Year                     = {2009},
  Month                    = jan,
  Pages                    = {252--255},
  Publisher                = {IEEE},

  Abstract                 = {Applications querying real time data streams in order to identify trends, patterns, or anomalies can often benefit from comparing the live stream data with archived historical stream data. This is especially true for applications involving live \& unpredictable data like in traffic analysis \& stock markets. However this data mining in DSMSs have turned out to be a costly proposition. In this paper, perform a comparative analysis between various tools available that can handle this historical data \& hence facilitate in the Data Mining. For comparing the tools for data retrieval, we cover inclemently, from using traditional DBMS to the more sophisticated tools that utilize Bit-Map indexing or Hoeffding Algorithm. We will see how these tools can simultaneously analyze (1) live streams with high data rates and maintain (2) a large repository of historical stream data.},
  Doi                      = {10.1109/WKDD.2009.176},
  ISBN                     = {978-0-7695-3543-2},
  Keywords                 = {Bit-Map indexing,Containers,Data analysis,Data engineering,Data mining,Hoeffding Algorithm,Hoeffding algorithm,Indexing,Information retrieval,Knowledge engineering,Performance analysis,Stock markets,TelegraphCQ,Time Machine,User interfaces,bit-map indexing,data mining,data retrieval,high volume data stream,historical stream data,indexing,information retrieval,live stream data,real time data streams,stock markets,traffic analysis},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to only being a comparison of existing tools. No innovation, nor anything about results.},
  Shorttitle               = {Knowledge Discovery and Data Mining, 2009. WKDD 20},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4771925}
}

@Conference{Qadeer2009a,
  Title                    = {Comparison of tools for data mining and retrieval in high volume data stream},
  Author                   = {Qadeer, M.A. and Akhtar, N. and Khan, F.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {252-255},

  Abstract                 = {Applications querying real time data streams in order to identify trends, patterns, or anomalies can often benefit from comparing the live stream data with archived historical stream data. This is especially true for applications involving live & unpredictable data like in traffic analysis & stock markets. However this data mining in DSMSs have turned out to be a costly proposition. In this paper, perform a comparative analysis between various tools available that can handle this historical data & hence facilitate in the Data Mining. For comparing the tools for data retrieval, we cover inclemently, from using traditional DBMS to the more sophisticated tools that utilize Bit-Map indexing or Hoeffding Algorithm. We will see how these tools can simultaneously analyze (1) live streams with high data rates and maintain (2) a large repository of historical stream data. Ã‚Â© 2009 IEEE.},
  Affiliation              = {Department of Computer Engineering, Zakir Hussain College of Engineering and Technology, Aligarh Muslim University, Aligarh 202002, India},
  Art_number               = {4771925},
  Author_keywords          = {Bit-map indexing; Data mining; Hoeffding algorithm; TelegraphCQ; Time machine; Traffic analysis},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2009 2nd International Workshop on Knowledge Discovery and Data Mining, WKKD 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Qadeer2009 (also discarded)},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-66249091943&partnerID=40&md5=858cbbb63936e34c013fb87f20fdfe98}
}

@Article{Qin2005,
  Title                    = {{Adaptively detecting aggregation bursts in data streams}},
  Author                   = {Qin, List Shouke and Qin, Shouke and Qian, Weining and Zhou, Aoying},
  Journal                  = {IN PROC. OF DASFAA},
  Year                     = {2005},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Finding bursts in data streams is attracting much attention in research community due to its broad applications. Existing burst detection methods suffer the problems that 1) the parameters of window size and absolute burst threshold, which are hard to be determined a priori, should be given in advance. 2) Only one side bursts, i.e. either increasing or decreasing bursts, can be detected. 3) Bumps, which are changes of aggregation data caused by noises, are often reported as bursts. The disturbance of bumps causes much effort in subsequent exploration of mining results. In this paper, a general burst model is introduced for overcoming above three problems. We develop an efficient algorithm for detecting adaptive aggregation bursts in a data stream given a burst ratio. With the help of a novel inverted histogram, the statistical summary is compressed to be fit in limited main memory, so that bursts on windows of any length can be detected accurately and efficiently on-line. Theoretical analysis show the space and time complexity bound of this method is relatively good, while experimental results depict the applicability and efficiency of our algorithm in different application settings.},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They explore finding bursts in data streams. Finding bursts in data streams I think this is a duplicate/similar work to Qin2006. The introduction is different, but the method seems to be the same.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.6588}
}

@Misc{Qin,
  Title                    = {{Approximately Processing Multi-granularity Aggregate Queries over Data Streams}},

  Author                   = {Qin, Shouke and Qian, Weining and Zhou, Aoying},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Aggregate monitoring over data streams is attracting more and more attention in research community due to its broad potential applications. Existing methods suffer two problems, 1) The aggregate functions which could be monitored are restricted to be first-order statistic or monotonic with respect to the window size. 2) Only a limited number of granularity and time scales could be monitored over a stream, thus some interesting patterns might be neglected, and users might be misled by the incomplete changing profile about current data streams. These two impede the development of online mining techniques over data streams, and some kind of breakthrough is urged. In this paper, we employed the powerful tool of fractal analysis to enable the monitoring of both monotonic and non-monotonic aggregates on time-changing data streams. The monotony property of aggregate monitoring is revealed and monotonic search space is built to decrease the time overhead for accessing the synopsis from O(m) to O(log m), where m is the number of windows to be monitored. With the help of a novel inverted histogram, the statistical summary is compressed to be fit in limited main memory, so that high aggregates on windows of any length can be detected accurately and efficiently on-line. Theoretical analysis show the space and time complexity bound of this method are relatively low, while experimental results prove the applicability and efficiency of the proposed algorithm in different application settings.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Qin2006},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.6746}
}

@Conference{Qin2006,
  Title                    = {Approximately processing multi-granularity aggregate queries over data streams},
  Author                   = {Qin, S.a and Qian, W.a and Zhou, A.a b },
  Year                     = {2006},
  Note                     = {cited By (since 1996)8},
  Pages                    = {67},
  Volume                   = {2006},

  Abstract                 = {Aggregate monitoring over data streams is attracting more and more attention in research community due to its broad potential applications. Existing methods suffer two problems, 1) The aggregate functions which could be monitored are restricted to be first-order statistic or monotonic with respect to the window size. 2) Only a limited number of granularity and time scales could be monitored over a stream, thus some interesting patterns might be neglected, and users might be misled by the incomplete changing profile about current data streams. These two impede the development of online mining techniques over data streams, and some kind of breakthrough is urged. In this paper, we employed the powerful tool of fractal analysis to enable the monitoring of both monotonic and non-monotonic aggregates on time-changing data streams. The monotony property of aggregate monitoring is revealed and monotonic search space is built to decrease the time overhead for accessing the synopsis from O(m) to O(log m), where m is the number of windows to be monitored. With the help of a novel inverted histogram, the statistical summary is compressed to befit in limited main memory, so that high aggregates on windows of any length can be detected accurately and efficiently on-line. Theoretical analysis show the space and time complexity bound of this method are relatively low, while experimental results prove the applicability and efficiency of the proposed algorithm in different application settings. Ã‚Â© 2006 IEEE.},
  Affiliation              = {Department of Computer Science and Engineering, Fudan University, Shanghai 200433, China; Computer Science Division, University of California, Berkeley, United States},
  Art_number               = {1617435},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They explore aggregate monitoring over data streams, using fractal analysis to monitor both monotonic and non-monotonic aggregates on time-changing data streams. With the help of a novel inverted histogram, the statistical summary is compressed to be fit in limited main memory, so that high aggregates on windows of any length can be detected accurately and efficiently on-line. experimental results prove the applicability and efficiency of the proposed algorithm. I guess the algorithm is histogram-based. Difficult to understand from the abstract what they had actually done. 2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33749625585&partnerID=40&md5=7091692a4fa848a4ef3275b7a1cf9ec4}
}

@InProceedings{QHLZZ2005,
  Title                    = {{A real-time architecture for NIDS based on sequence analysis}},
  Author                   = {{Qing-Hua Liu} and {Feng Zhaoi} and {Feng Zhao}},
  Booktitle                = {2005 International Conference on Machine Learning and Cybernetics},
  Year                     = {2005},
  Pages                    = {1893--1896 Vol. 3},
  Publisher                = {IEEE},
  Volume                   = {3},

  Abstract                 = {Due to customers' demands, network intrusion detection systems (NIDS) are required more real time. Since traditional intelligent NIDS are constructed on the basis of historical network data and system logs, they are expensive and not real time in a network stream environment. This paper presents an improved real time model that based on sequence mining to accelerate the accuracy and efficiency. In this paper, multidimensional item set is used to describes network events, sliding window is used to gather network data stream, and sequence mining algorithms are applied to discover intrusions from normal network stream. Analysis and study on this model indicate that it provide a more accurate and efficient way to building real-time NIDS.},
  Doi                      = {10.1109/ICMLC.2005.1527254},
  ISBN                     = {0-7803-9091-1},
  Keywords                 = {Data engineering,Data mining,Data security,Databases,Decision support systems,IDS,Intrusion detection,Multidimensional systems,Performance analysis,Real time systems,Windows,computer networks,customer demands,data mining,historical network data,intelligent network intrusion detection systems,intrusion,intrusion discovery,knowledge based systems,multidimensional item set,network data stream gathering,network events,network stream environment,real time,real-time architecture,real-time systems,security of data,sequence,sequence analysis,sequence mining,sliding window,system logs},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents an improved real time Network Intrusion Detection model that based on sequence mining. A multidimensional item set is used to describes network events, sliding window is used to gather network data stream, and sequence mining algorithms are applied to discover intrusions from normal network stream. Analysis and study on this model indicate that it provide a more accurate and efficient way to building real-time NIDS Short abstract, but to the point. Little details about the results of experimentation. 1,2,3,4,6},
  Shorttitle               = {Machine Learning and Cybernetics, 2005. Proceeding},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1527254}
}

@Misc{Quan2011,
  Title                    = {{Grid-based Data Stream Clustering for Intrusion Detection}},

  Author                   = {Quan, Qian and Xiao, Chao-jie and Zhang, Rui},
  Year                     = {2011},

  __markedentry            = {[Alexander:]},
  Abstract                 = {As a kind of stream data mining method, stream clustering has great potentiality in areas such as network traffic analysis, intrusion detection, etc. This paper proposes a novel grid-based clustering algorithm for stream data, which has both advantages of grid mapping and DBSCAN algorithm. The algorithm adopts the two-phase model and in the online phase, it maps stream data into a grid and the geometric center of all the data in the grid is used to represent the characteristic of entire data in the grid approximately. In the offline phase, grid-based DBSCAN clustering algorithm is used to cluster all grids in the space based on density. Meanwhile, extension of the algorithm to an incremental one is also presented in detail in the paper. The algorithm proposed in the paper can solve the problem that it is difficult to find neighbor grids in DStream algorithm and also solve the incompetency of DBSCAN in data compression, which makes it capable for DBSCAN to be used for stream data. Experimental results on KDDCUP99 intrusion detection dataset show that the algorithm can achieve a good clustering quality and efficiency. The average accuracy is above 92 % and the highest order of magnitude of SSQ is 104 and the average processing time of 10,000 sessions is about 3 seconds.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes a novel grid-based clustering algorithm for stream data, which has both advantages of grid mapping and DBSCAN algorithm. The algorithm adopts the two-phase model and in the online phase, it maps stream data into a grid. In the offline phase, grid-based DBSCAN clustering algorithm is used to cluster all grids in the space based on density. Experimental results on KDDCUP99 intrusion detection dataset show that the algorithm can achieve a good clustering quality and efficiency Both online and offline-phase seems to imply that it won't work as well on real-time data. 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.377.3947}
}

@Article{Rakthanmanon2012b,
  Title                    = {{Searching and mining trillions of time series subsequences under dynamic time warping}},
  Author                   = {Rakthanmanon, Thanawin and Campana, Bilson and Mueen, Abdullah and Batista, Gustavo and Westover, Brandon},
  Journal                  = {IN SIGKDD},
  Year                     = {2012},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Rakthanmanon2012},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.261.3283}
}

@Article{Rakthanmanon2013,
  Title                    = {Addressing big data time series: Mining trillions of time series subsequences under dynamic time warping},
  Author                   = {Rakthanmanon, T.a and Campana, B.b and Mueen, A.b and Batista, G.c and Westover, B.d and Zhu, Q.b and Zakaria, J.b and Keogh, E.b },
  Journal                  = {ACM Transactions on Knowledge Discovery from Data},
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Number                   = {3},
  Volume                   = {7},

  Abstract                 = {Most time series data mining algorithms use similarity search as a core subroutine, and thus the time taken for similarity search is the bottleneck for virtually all time series data mining algorithms, including classification, clustering, motif discovery, anomaly detection, and so on. The difficulty of scaling a search to large datasets explains to a great extent why most academic work on time series data mining has plateaued at considering a few millions of time series objects, while much of industry and science sits on billions of time series objects waiting to be explored. In this work we show that by using a combination of four novel ideas we can search and mine massive time series for the first time. We demonstrate the following unintuitive fact: in large datasets we can exactly search under Dynamic Time Warping (DTW) much more quickly than the current state-of-the-art Euclidean distance search algorithms. We demonstrate our work on the largest set of time series experiments ever attempted. In particular, the largest dataset we consider is larger than the combined size of all of the time series datasets considered in all data mining papers ever published. We explain how our ideas allow us to solve higher-level time series data mining problems such as motif discovery and clustering at scales that would otherwise be untenable. Moreover, we show how our ideas allow us to efficiently support the uniform scaling distance measure, a measure whose utility seems to be underappreciated, but which we demonstrate here. In addition to mining massive datasets with up to one trillion data points, we will show that our ideas also have implications for real-time monitoring of data streams, allowing us to handle much faster arrival rates and/or use cheaper and lower powered devices than are currently possible. Ã‚Â© 2013 ACM.},
  Affiliation              = {Department of Computer Engineering, University of California Riverside, United States; Department of Computer Science and Engineering, University of California Riverside, United States; Instituto de CiÃƒÂªncias MatemÃƒÂ¡ticas E de ComputaÃƒÂ§ÃƒÂ£, University of SÃƒÂ£o Paulo, Brazil; Brigham and Women's Hospital, United States},
  Art_number               = {10},
  Author_keywords          = {Lower bounds; Similarity search; Time series},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this work they show that by using a combination of four novel ideas we can search and mine massive time series for the first time. They demonstrate their work on the largest set of time series experiments ever attempted, and are able to do higher-level time series mining problems. THey show that their ideas also have implications for real-time monitoring of data streams, allowing us to handle much faster arrival rates and/or use cheaper and lower powered devices than are currently possible Seems like an potential primary source. Been indexed in three databases, been on several conferences. Says it's better than current SotA, and that it has new and better ideas. Lacking a little info on experimental results. 1,2,3,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84884994717&partnerID=40&md5=8e59bf9524f74af99f509f35547acb4a}
}

@Conference{Rakthanmanon2012,
  Title                    = {Searching and mining trillions of time series subsequences under dynamic time warping},
  Author                   = {Rakthanmanon, T.a and Campana, B.a and Mueen, A.a and Batista, G.c and Westover, B.b and Zhu, Q.a and Zakaria, J.a and Keogh, E.a },
  Year                     = {2012},
  Note                     = {cited By (since 1996)32},
  Pages                    = {262-270},

  Abstract                 = {Most time series data mining algorithms use similarity search as a core subroutine, and thus the time taken for similarity search is the bottleneck for virtually all time series data mining algorithms. The difficulty of scaling search to large datasets largely explains why most academic work on time series data mining has plateaued at considering a few millions of time series objects, while much of industry and science sits on billions of time series objects waiting to be explored. In this work we show that by using a combination of four novel ideas we can search and mine truly massive time series for the first time. We demonstrate the following extremely unintuitive fact; in large datasets we can exactly search under DTW much more quickly than the current state-of-the-art Euclidean distance search algorithms. We demonstrate our work on the largest set of time series experiments ever attempted. In particular, the largest dataset we consider is larger than the combined size of all of the time series datasets considered in all data mining papers ever published. We show that our ideas allow us to solve higher-level time series data mining problem such as motif discovery and clustering at scales that would otherwise be untenable. In addition to mining massive datasets, we will show that our ideas also have implications for real-time monitoring of data streams, allowing us to handle much faster arrival rates and/or use cheaper and lower powered devices than are currently possible. Ã‚Â© 2012 ACM.},
  Affiliation              = {UC Riverside, United States; Brigham and Women's Hospital, United States; University of SÃƒÂ£o Paulo, Brazil},
  Author_keywords          = {lower bounds; similarity search; time series},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Newer version in Rakthanmanon2013},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84866037385&partnerID=40&md5=e3630b8f457e3d7607f560900696caa9}
}

@InProceedings{Rakthanmanon2012a,
  Title                    = {{Searching and mining trillions of time series subsequences under dynamic time warping}},
  Author                   = {Rakthanmanon, Thanawin and Campana, Bilson and Mueen, Abdullah and Batista, Gustavo and Westover, Brandon and Zhu, Qiang and Zakaria, Jesin and Keogh, Eamonn},
  Booktitle                = {Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '12},
  Year                     = {2012},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {262},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/2339530.2339576},
  ISBN                     = {9781450314626},
  Keywords                 = {lower bounds,similarity search,time series},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Rakthanmanon2012},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2339530.2339576}
}

@Article{Ramachandran2006,
  Title                    = {Bird's-eye view of data mining in geosciences},
  Author                   = {Ramachandran, R.a and Rushing, J.a and Li, X.a and Kamath, C.b and Conover, H.a and Graves, S.a },
  Journal                  = {Special Paper of the Geological Society of America},
  Year                     = {2006},
  Note                     = {cited By (since 1996)0},
  Pages                    = {235-247},
  Volume                   = {397},

  Abstract                 = {Data mining is presented in this paper as an example of geoinformatics, to illustrate how a collaborative effort between data-mining experts and geoscientists is essential for analyzing large volumes of data to extract knowledge. There is a wide variety of mining algorithms and tools available for both predictive and descriptive data mining that have been applied on a variety of geoscience problems. This paper provides a high-level overview of the data-mining process, several mining algorithms and tools, and their application to the geosciences. It also describes the geoscience data characteristics that make mining these data a challenge, and details some of the common data preparation operations that are required to make the geoscience data ready for mining. Three data-mining applications are presented in detail in this paper to demonstrate the usefulness of data mining to solve specific geoscience problems. Issues relevant in determining a successful data-mining application in geoscience are presented as lessons learned. Finally, the paper looks at challenges ahead by focusing on two relevant research areas for data mining and geosciences: mining streaming data in real time and exploiting the emerging cyberinfrastructure for mining. Ã‚Â© 2006 Geological Society of America. All rights reserved.},
  Affiliation              = {Information Technology and Systems Center, University of Alabama in Huntsville, 301 Sparkman Drive, Huntsville, AL 35899, United States; Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, 7000 East Avenue, Livermore, CA 94551, United States},
  Author_keywords          = {Cyberinfrastructure; Data mining; Geospatial data; Mining algorithms; Mining applications},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper provides a high-level overview of the data-mining process, several mining algorithms and tools, and their application to the geoscience Discarded due to only being an overview, no new approach. Maybe a side source.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-73849083560&partnerID=40&md5=51c2061ff3b6a2a120dc5a8d421fdc5d}
}

@Misc{Rangaswami,
  Title                    = {{Building MEMS-Based Storage Systems for Streaming Media}},

  Author                   = {Rangaswami, Raju and Dimitrijevi\'{c}, Zoran and Chang, Edward and Inc, Google and Schauser, Klaus},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The performance of streaming media servers has been limited by the dual requirements of high disk throughput (to service more clients simultaneously) and low memory use (to decrease system cost). To achieve high disk throughput, disk drives must be accessed with large IOs to amortize disk access overhead. Large IOs imply an increased requirement of expensive DRAM, and, consequently, greater overall system cost. MEMS-based storage, an emerging storage technology, is predicted to offer a price-performance point between those of DRAM and disk drives. In this study, we propose storage architectures that use the relatively inexpensive MEMS-based storage devices as an intermediate layer (between DRAM and disk drives) for temporarily staging large disk IOs at a significantly lower cost. We present data layout mechanisms and synchronized IO scheduling algorithms for the real-time storage and retrieval of streaming data within such an augmented storage system. Analytical evaluation suggests that MEMS-augmented storage hierarchies can reduce the cost and improve the throughput of streaming servers significantly.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. This is about database storage, not about ML},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.120.2679}
}

@Article{RasheedaShameem2013,
  Title                    = {A dynamic approach for mining generalised sequential patterns in time series clinical data sets},
  Author                   = {Rasheeda Shameem, M.a and Razia Naseem, M.a and Subanivedhi, N.K.a and Sethukkarasi, R.b },
  Journal                  = {Advances in Intelligent Systems and Computing},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {VOL. 2},
  Pages                    = {667-674},
  Volume                   = {177 AISC},

  Abstract                 = {Similarity based stream time series is gaining ever-increasing attention due to its importance in many applications such as financial data processing, network monitoring, Web click-stream analysis, sensor data mining, and anomaly detection. These applications require managing data streams, i.e., data composed of continuous, real-time sequence of items. We propose a technique for pattern matching within static patterns and stream time series clinical data sets. The main objective of our project is to ascertain hidden patterns between incoming time series clinical data sets and the set of predetermined clinical patterns. By considering the incoming image data at a particular timestamp, we construct a MultiScale Median model at multiple levels to adapt to the stream time series, characterized by frequent updates. Further, we employ a pruning algorithm, Segment Median Pruning on clinical Image data for pruning all candidate patterns. Experiments have been carried out on retinal disease data set known as Age Related Macula Degeneration (ARMD) and simulation results show that the system is efficient in processing image data sets for making efficient and accurate decision. Ã‚Â© 2013 Springer-Verlag.},
  Affiliation              = {Department of Computer Science and Engineering, R.M.K Engineering College, Kavaraipettai, Tamil Nadu, India; Department of Information Science and Technology, Anna University, Chennai, Tamil Nadu, India},
  Author_keywords          = {MultiScale Median; Pattern match; stream time series},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a technique for pattern matching within static patterns and stream time series clinical data sets. The main objective of the project is to ascertain hidden patterns between incoming time series clinical data sets and the set of predetermined clinical patterns. Not sure about the real-time applicability of this one. It mentions other uses of similarity based stream time series, so the principles might be transferred. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84868318339&partnerID=40&md5=ae21865fb78878284cd2bf01e3ea6071}
}

@Conference{Rashid2013,
  Title                    = {Mining associated sensor patterns for data stream of wireless sensor networks},
  Author                   = {Rashid, Md.M. and Gondal, I. and Kamruzzaman, J.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {91-98},

  Abstract                 = {WSNs generate a large amount of data in the form of data stream; and mining these streams to extract useful knowledge is a highly challenging task. Existing works proposed in literature use sensor association rules measured in terms of occurrence frequency of patterns. However, these rules often generate a huge number of rules, most of which are non-informative or fail to reflect the true correlation among data objects. Additionally mining associated sensor patterns from sensor stream data, which is vital for real-time applications, has not been addressed yet in literature. In this paper, we address these problems and propose a new type of sensor behavioral pattern called associated sensor patterns which capture simultaneously association-like co-occurrence as well as substantial temporal correlations implied by such co-occurrences in sensor data. We propose a novel tree structure, called associated sensor pattern stream tree (ASPS-tree) and a new technique, called associated sensor pattern mining of data stream (ASPMS), using sliding window-based associated sensor pattern mining for WSNs. By capturing the useful knowledge of the data stream into an ASPS-tree, our ASPMS algorithm can mine associated sensor patterns in the current window with frequent pattern (FP)-growth like pattern-growth method. Extensive experimental analyses show that our technique is very efficient in discovering associated sensor patterns over sensor data stream. Ã‚Â© 2013 ACM.},
  Affiliation              = {Faculty of Information Technology, Monash University, Melbourne, VIC, Australia},
  Author_keywords          = {behavioral patterns; data mining; knowledge discovery; sensor data stream; wireless sensor networks},
  Document_type            = {Conference Paper},
  Journal                  = {PM2HW2N 2013 - Proceedings of the 8th ACM Workshop on Performance Monitoring and Measurement of Heterogeneous Wireless and Wired Networks, Co-located with ACM MSWiM 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a novel tree structure, called associated sensor pattern stream tree (ASPS-tree) and a new technique, called associated sensor pattern mining of data stream (ASPMS), using sliding window-based associated sensor pattern mining for WSNs (Wireless sensor networks). Experimental analyses show that their technique is very efficient in discovering associated sensor patterns over sensor data stream, by using frequent pattern (FP)-growth on the current window. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84889797013&partnerID=40&md5=224bc6955eddc68ae892d91bc287fe8d}
}

@InProceedings{Rashid2013a,
  Title                    = {{Mining associated sensor patterns for data stream of wireless sensor networks}},
  Author                   = {Rashid, Md. Mamunur and Gondal, Iqbal and Kamruzzaman, Joarder},
  Booktitle                = {Proceedings of the 8th ACM workshop on Performance monitoring and measurement of heterogeneous wireless and wired networks - PM2HW2N '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = nov,
  Pages                    = {91--98},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/2512840.2512853},
  ISBN                     = {9781450323710},
  Keywords                 = {behavioral patterns,data mining,knowledge discovery,sensor data stream,wireless sensor networks},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Rashid2013},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2512840.2512853}
}

@Article{Rassi2008,
  Title                    = {Mining multidimensional sequential patterns over data streams},
  Author                   = {Rassi, C. and Plantevit, M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Pages                    = {263-272},
  Volume                   = {5182 LNCS},

  Abstract                 = {Sequential pattern mining is an active field in the domain of knowledge discovery and has been widely studied for over a decade by data mining researchers. More and more, with the constant progress in hardware and software technologies, real-world applications like network monitoring systems or sensor grids generate huge amount of streaming data. This new data model, seen as a potentially infinite and unbounded flow, calls for new real-time sequence mining algorithms that can handle large volume of information with minimal scans. However, current sequence mining approaches fail to take into account the inherent multidimensionality of the streams and all algorithms merely mine correlations between events among only one dimension. Therefore, in this paper, we propose to take multidimensional framework into account in order to detect high-level changes like trends. We show that multidimensional sequential pattern mining over data streams can help detecting interesting high-level variations. We demonstrate with empirical results that our approach is able to extract multidimensional sequential patterns with an approximate support guarantee over data streams. Ã‚Â© 2008 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {LIRMM, University of Montpellier, France},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose to take multidimensional framework into account in order to detect high-level changes like trends. We show that multidimensional sequential pattern mining over data streams can help detecting interesting high-level variations. Empirical results show that their approach is able to extract multidimensional sequential patterns with an approximate support guarantee over data streams. Could be interesting},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-52949086480&partnerID=40&md5=3179301a53b8a59bb651fe9a70a9b174}
}

@InProceedings{Ratner2008,
  Title                    = {{Mining Unstructured Text at Gigabyte per Second Speeds}},
  Author                   = {Ratner, Alan},
  Booktitle                = {2008 IEEE International Conference on Data Mining Workshops},
  Year                     = {2008},
  Month                    = dec,
  Pages                    = {468--476},
  Publisher                = {IEEE},

  Abstract                 = {Humans communicate with text in thousands of languages, in dozens of scripts, in a variety of binary codes, on millions of topics. There is a need, for both government and commercial applications, to identify these text characteristics to enable follow-on processing such as transcoding, translation, transliteration, routing and prioritization. This paper deals with the implementation of real-time mining of unstructured text on high-speed hardware capable of processing network data streams at gigabyte per second speeds.},
  Doi                      = {10.1109/ICDMW.2008.9},
  Keywords                 = {Binary codes,Conferences,Data mining,Encoding,Government,Humans,Language,National security,Natural,Natural languages,Processing,Transcoding,USA Councils,data mining,gigabyte per second speed,network data streams,real-time mining,text analysis,unstructured text mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Ratner2008a},
  Shorttitle               = {Data Mining Workshops, 2008. ICDMW '08. IEEE Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4733970}
}

@Conference{Ratner2008a,
  Title                    = {Mining unstructured text at gigabyte per second speeds},
  Author                   = {Ratner, A.},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Pages                    = {468-476},

  Abstract                 = {Humans communicate with text in thousands of languages, in dozens of scripts, in a variety of binary codes, on millions of topics. There is a need, for both government and commercial applications, to identify these text characteristics to enable follow-on processing such as transcoding, translation, transliteration, routing and prioritization. This paper deals with the implementation of real-time mining of unstructured text on high-speed hardware capable of processing network data streams at gigabyte per second speeds.},
  Affiliation              = {National Security Agency, Fort Meade, MD, United States},
  Art_number               = {4733970},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining Workshops, ICDM Workshops 2008},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper deals with the implementation of real-time mining of unstructured text on high-speed hardware capable of processing network data streams at gigabyte per second speeds. Weak abstract, no experiment or results described, 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-62449254091&partnerID=40&md5=eaee3313b594a160e1a144d764de2bc1}
}

@Conference{Rautio2009,
  Title                    = {Component-based framework for mobile data mining with support for real-time sensors},
  Author                   = {Rautio, T. and Laurinen, P. and RÃƒÂ¶ning, J.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {208-213},

  Abstract                 = {The increasing use of various mobile devices has shown that there is a need for mobile data mining applications. While many existing data mining frameworks can be modified to handle data streams generated in real time, they are usually too complex and inflexible to be used in mobile devices. This paper presents Mobile Smart Archive, a component-based framework for data stream mining in mobile devices. The framework takes care of generic data mining operations, allowing the application developer to concentrate on implementing only application-specific functionalities. This reduces implementation time and generates fewer errors, since the underlying framework of the application is tested and robust. The presented framework is written in C++ and it extends the existing Smart Archive framework with support for mobile systems and real-time sensors. The benefits of framework-based applications in the mobile world are presented by building and testing a demonstration program in different computer architectures. In this paper we show that the MSA framework is suitable for building data stream mining applications for the hardware-oriented mobile environment.},
  Affiliation              = {Intelligent Systems Group, Department of Electrical and Information Engineering, University of Oulu, FI-900014, Finland},
  Author_keywords          = {Component-based framework; Mobile data mining},
  Document_type            = {Conference Paper},
  Journal                  = {ICAART 2009 - Proceedings of the 1st International Conference on Agents and Artificial Intelligence},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents Mobile Smart Archive, a component-based framework for data stream mining in mobile devices. The framework takes care of generic data mining operations, allowing the application developer to concentrate on implementing only application-specific functionalities. Not hugely innovative, uses generic ML algorithms. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70349473223&partnerID=40&md5=db3b9862c483cdc4207fd523484edb33}
}

@Misc{Reddy,
  Title                    = {{Knowledge Discovery from Static Datasets to Evolving Data Streams and Challenges}},

  Author                   = {Reddy, V. Sidda and Narendra, M. and Helini, K.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Mining data streams has recently become an important active research work and more widespread in several fields of computer science and engineering. It has proven successfully in many domains such as wireless sensor networks, ATM transactions, search engines, web analysis and weather monitoring. Data steams can be considered a subfield of machine learning, data mining and knowledge discovery. Data Mining is a step in the process of knowledge discovery from large amount of data. Traditional data mining techniques can not be easily applied to the data stream mining due to unique characteristics of data streams. In this research work, we will survey the main techniques and applications of data mining and data stream mining. We then study, the computational and miming challenges in particular, on-line mining of continuous, high-speed massive data streams.},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {In this research work, we will survey the main techniques and applications of data mining and data stream mining. We then study, the computational and miming challenges in particular, on-line mining of continuous, high-speed massive data streams. Discarded due to being a survey. set aside as similar study},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.428.8322}
}

@InCollection{Reeve2013,
  Title                    = {Chapter 21 - Big Data Integration },
  Author                   = {April Reeve},
  Booktitle                = {Managing Data in Motion },
  Publisher                = {Morgan Kaufmann},
  Year                     = {2013},

  Address                  = {Boston},
  Editor                   = {Reeve, April },
  Pages                    = {141 - 156},
  Series                   = {MK Series on Business Intelligence},

  Abstract                 = {Ã¢â‚¬Å“Big dataÃ¢â‚¬ï¿½ implies not only large volumes of data but a wide variety of data types and a high velocity of data streams, with data needed to be integrated from locally within the organization as well as from external sources and distributed locations. New technologies such as Hadoop have been introduced from social media companies to handle vast amounts of unstructured data for analysis. The power of big data comes from using the results of the analysis of the large volumes of unstructured data to make faster and better real-time decisions. Big data architecture includes data integration engines (ETL, ESB, data virtualization), data hubs (master data, data warehouse, document management, Hadoop file system), and metadata support tools (metadata repository, data discovery, data profiling, data modeling). Business intelligence tools and an analytic sandbox are needed to analyze the vast and various structured and unstructured data, and a complex event-processing system is necessary to integrate real-time events with the analysis results to trigger real-time risk and opportunity responses. Keywords big data, relational database management system, data volume, data variety, data velocity, massive parallel processing, moving process to data, Hadoop, MapReduce, external data, persistent data, transient data, visualization, tag, unstructured data, sensor data, streaming data, social media data, real-time decision support, triggering action, data in memory, patterns, risks, opportunities, data scientist, data analyst, business intelligence, search, risk response system, complex event processing},
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-397167-8.00021-2},
  ISBN                     = {978-0-12-397167-8},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. It's a book chapter.},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780123971678000212}
}

@Article{Rehman2012,
  Title                    = {Anomalous pattern detection using context aware ubiquitous data mining},
  Author                   = {ur Rehman, Z.a and Shahbaz, M.a and Shaheen, M.a and Mehmood, S.a and Masood, S.A.b },
  Journal                  = {Life Science Journal},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {3},
  Pages                    = {6-12},
  Volume                   = {9},

  Abstract                 = {Due to the developments in technology number of applications emerged that produce huge amount of data in the form of streams. Dealing with this and extracting useful information from that data is a real challenge. In this paper, we have developed an architecture that can be used to manage data streaming applications and can extract useful information from that data in online fashion. To achieve mining results online, different phases in our model are parallelized. In this model we have also introduced the concept of context-awareness to improve performance of the proposed architectural model. In this model information from heterogeneous sources is gathered, fuse that information, and generate real-time results. These real-time results can be beneficial in different application area like web usage mining, online monitoring, fraud detection, network security, telecommunication calls monitoring, network monitoring and security, etc. To fulfill the objectives of this research, we incorporate lightweight online mining algorithms to extract useful but hidden information from the data gathered. Contextual information is exploited to detect anomalous behaviors. In this paper we have designed an architectural model to extract frequent patterns in the streaming data.},
  Affiliation              = {Department of Computer Science and Engineering, University of Engineering and Technology, Lahore-54890, Pakistan; Department of Engineering Management, NUST, College of E and ME, Rawalpindi, Pakistan},
  Author_keywords          = {Anomalous pattern mining; Context-aware; Stream mining; Ubiquitous data mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They have developed an architecture that can be used to manage data streaming applications and can extract useful information from that data in online fashion. To achieve mining results online, different phases in our model are parallelized. Contextual information is exploited to detect anomalous behaviors. In this paper we have designed an architectural model to extract frequent patterns in the streaming data. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84874877721&partnerID=40&md5=e381727dc884ffc135c132b51892cf81}
}

@Conference{Ren2011b,
  Title                    = {Density-based data streams subspace clustering over weighted sliding windows},
  Author                   = {Ren, J.a and Cao, S.a and Hu, C.b },
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {212-216},

  Abstract                 = {Most real-world data sets are characterized by a high dimensinal, inherely sparse data space. In this paper, we present a novel density-based approach to the subspace clustering problem. A new framework for data stream mining is introduced, called the weighted sliding window. In the online component, the structure of Exponential Histogram of Cluster Feature(EHCF) is improved to maintain the micro-clusters. The concepts of potential core-micro-cluster and outlier micro-cluster are applied to distinguish the potential clusters and outliers. A novel pruning strategy is proposed to decrease the number of micro-clusters. In the offline component, the final clusters are generated by SUBCLU algorithm. Our performance study demonstrates the effectiveness and efficiency of our algorithm. Ã‚Â© 2010 IEEE.},
  Affiliation              = {College of Information Science and Engineering, Yanshan University, Qinhuangdao City, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing City, China},
  Art_number               = {5759375},
  Author_keywords          = {Data stream; Density-based; Subspace clustering; Weighted sliding windows},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2010 1st ACIS International Symposium on Cryptography, and Network Security, Data Mining and Knowledge Discovery, E-Commerce and Its Applications, and Embedded Systems, CDEE 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present a novel density-based approach to the subspace clustering problem. A new framework for data stream mining is introduced, called the weighted sliding window. A novel pruning strategy is proposed to decrease the number of micro-clusters A performance study demonstrates the effectiveness and efficiency of our algorithm. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79959189025&partnerID=40&md5=53f29640320801f4bfa86e0e85fb5ac2}
}

@InProceedings{Ren2010,
  Title                    = {{Density-Based Data Streams Subspace Clustering over Weighted Sliding Windows}},
  Author                   = {Ren, Jiadong and Cao, Shiyuan and Hu, Changzhen},
  Booktitle                = {2010 First ACIS International Symposium on Cryptography, and Network Security, Data Mining and Knowledge Discovery, E-Commerce and Its Applications, and Embedded Systems},
  Year                     = {2010},
  Month                    = oct,
  Pages                    = {212--216},
  Publisher                = {IEEE},

  Abstract                 = {Most real-world data sets are characterized by a high dimensinal, inherely sparse data space. In this paper, we present a novel density-based approach to the subspace clustering problem. A new framework for data stream mining is introduced, called the weighted sliding window. In the online component, the structure of Exponential Histogram of Cluster Feature(EHCF) is improved to maintain the micro-clusters. The concepts of potential core-micro-cluster and outlier micro-cluster are applied to distinguish the potential clusters and outliers. A novel pruning strategy is proposed to decrease the number of micro-clusters. In the offline component, the final clusters are generated by SUBCLU algorithm. Our performance study demonstrates the effectiveness and efficiency of our algorithm.},
  Doi                      = {10.1109/CDEE.2010.48},
  ISBN                     = {978-1-4244-9595-5},
  Keywords                 = {Algorithm design and analysis,Clustering algorithms,Data mining,Data models,Finite element methods,Histograms,Knowledge engineering,SUBCLU algorithm,core-microclusters,data mining,data stream,data stream mining,density-based,density-based data streams subspace clustering,exponential histogram of cluster feature,outlier microcluster,pattern clustering,pruning strategy,sparse data space,subspace clustering,weighted sliding windows},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose SDStream, a new method for performing density-based data streams clustering over sliding windows, based on CluStream. Has an online and offline component. Experimental results show that SDStream which can generate clusters of arbitrary shape has a much higher clustering quality than CluStream which generates spherical clusters 1,2,3,4,6},
  Shorttitle               = {Cryptography and Network Security, Data Mining and},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5759375}
}

@Article{Ren2008,
  Title                    = {Online mining frequent path traversal patterns in web click streams},
  Author                   = {Ren, J. and Feng, J.},
  Journal                  = {Journal of Computational Information Systems},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Number                   = {3},
  Pages                    = {1009-1016},
  Volume                   = {4},

  Abstract                 = {Mining frequent path traversal patterns in Web click streams is an important application for mining data streams. However, it is also a new challenge for data mining since streaming data are of infinite length and fast changing with time. In this paper, we propose an algorithm BCTM (Binary Code Table Mining) to online mine frequent path traversal patterns in the novel BCT (Binary Code Table) summary data structure. BCT builds a binary code for each maximal forward reference first, then algorithm BCTM performs logical AND operation to mine all the frequent path traversal patterns in BCT with a single-pass scan of the incoming data. Experiment shows that BCTM algorithm is more efficient and scalable than algorithm DSM-PLW in memory usage and CPU runtime.},
  Affiliation              = {College of Information Science and Engineering, Yanshan University, Qinhuangdao 066000, China},
  Author_keywords          = {Data mining; Data streams; Path traversal pattern; Web click streams},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an algorithm BCTM (Binary Code Table Mining) to online mine frequent path traversal patterns in the novel BCT (Binary Code Table) summary data structure. Experiment shows that BCTM algorithm is more efficient and scalable than algorithm DSM-PLW in memory usage and CPU runtime. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-48549086047&partnerID=40&md5=5aac8ad5af8d142685e89459443a3d61}
}

@InProceedings{Ren2009,
  Title                    = {{Density-Based Data Streams Clustering over Sliding Windows}},
  Author                   = {Ren, Jiadong and Ma, Ruiqing},
  Booktitle                = {2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery},
  Year                     = {2009},
  Pages                    = {248--252},
  Publisher                = {IEEE},
  Volume                   = {5},

  Abstract                 = {Data stream clustering is an important task in data stream mining. In this paper, we propose SDStream, a new method for performing density-based data streams clustering over sliding windows. SDStream adopts CluStream clustering framework. In the online component, the potential core-micro-cluster and outlier micro-cluster structures are introduced to maintain the potential clusters and outliers. They are stored in the form of exponential histogram of cluster feature (EHCF) in main memory and are maintained by the maintenance of EHCFs. Outdated micro-clusters which need to be deleted are found by the value of t in temporal cluster feature (TCF). In the offline component, the final clusters of arbitrary shape are generated according to all the potential core-micro-clusters maintained online by DBSCAN algorithm. Experimental results show that SDStream which can generate clusters of arbitrary shape has a much higher clustering quality than CluStream which generates spherical clusters.},
  Doi                      = {10.1109/FSKD.2009.553},
  ISBN                     = {978-0-7695-3735-1},
  Keywords                 = {Cities and towns,CluStream clustering,Clustering algorithms,DBSCAN algorithm,Data mining,Data structures,Educational institutions,Electronic mail,Fuzzy systems,Histograms,Partitioning algorithms,SDStream,Shape,core-microcluster structure,data mining,data stream,data stream mining,density-based clustering,density-based data stream clustering,exponential histogram of cluster feature,outlier microcluster structure,pattern clustering,sliding window,sliding windows,temporal cluster feature},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Ren2009a},
  Shorttitle               = {Fuzzy Systems and Knowledge Discovery, 2009. FSKD },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5360620}
}

@Article{Ren2011,
  Title                    = {An algorithm based on prime-block encoding for mining frequent patterns in data streams},
  Author                   = {Ren, J.a and Wang, Q.a and Wang, M.b },
  Journal                  = {ICIC Express Letters},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Number                   = {8 A},
  Pages                    = {2511-2516},
  Volume                   = {5},

  Abstract                 = {When mining frequent patterns from large-scale data streams, to record the information of data streams accurately often leads to mass data storage. In this paper, we present an algorithm PEMF, which is based on primal block encoding for mining frequent patterns in data streams. In online phase, it converts items contained in each transaction into bit vectors according to the prime encoding generator and divides the bit vectors into blocks according to the size of the generator. Only the multiplication of the integers in each block needs to be stored, which greatly reduces the mass data storage and simplifies the mining process. In offline phase, we first compute the item (itemset) support which is the number of transaction encodings that can be divisible by the encoding of the item (itemsets), and then obtain all the frequent patterns according to the prime unique factorization and user-defined threshold. PEMF can also quickly mine maximal frequent patterns and closed frequent patterns by simple calculations. Experimental results show that PEMF has high implementation efficiency.},
  Affiliation              = {College of Information Science and Engineering, Yanshan University, No. 438, Hebei Ave, Qinhuangdao 066004, China; College of Physics and Electronic Engineering, TaiShan University, Yingbin Ave, Taian 271021, China},
  Author_keywords          = {Data stream; Frequent pattern; Prime-block encoding},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present an algorithm PEMF, which is based on primal block encoding for mining frequent patterns in data streams. Online and offline phase. Experimental results show that PEMF has high implementation efficiency. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79960779051&partnerID=40&md5=862032b7453633fa59e06994e2082930}
}

@Article{Ren2011a,
  Title                    = {An algorithm based on equal - length bit table for mining frequent patterns in data streams},
  Author                   = {Ren, J.a and Wang, Q.a and Wang, M.b and Feng, S.a },
  Journal                  = {Advances in Information Sciences and Service Sciences},
  Year                     = {2011},
  Note                     = {cited By (since 1996)8},
  Number                   = {7},
  Pages                    = {244-250},
  Volume                   = {3},

  Abstract                 = {Algorithms based on bit vectors always generate a large number of candidate itemsets and repeatedly scan all the bit vectors transformed by the transaction database, this increases time and space cost. In this paper, an algorithm based on Equal-length Bit Table (EBT) for mining Frequent Patterns in data Streams, EBTFPS, is proposed. In online phase, each transaction is converted into a bit vector and the vector is inserted to different EBTs according to the tail item of the transaction, row count for the same bit vector and column count for the bit value 1 are recorded in each EBT. In offline phase, from the longest EBT to shortest EBT, a minimum support is given for pruning strategy and candidate itemsets generation. After an EBT is mined by And-operation, it is merged into other shorter EBTs, and all the frequent patterns are obtained until the shortest EBT is mined. Experiment results show that EBTFPS is very effective and scalable, theory analysis is also illustrated the small storage cost.},
  Affiliation              = {College of Information Science and Engineering, Yanshan University, Qinhuangdao, Hebei P.R. 066004, China; College of Physics and Electronic Engineering, TaiShan University, Taian, Shandong, P.R. 271021, China},
  Author_keywords          = {Bit vector; Data stream; EBT; Frequent pattern},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {An algorithm based on Equal-length Bit Table (EBT) for mining Frequent Patterns in data Streams, EBTFPS, is proposed. Online and offline phase. Results show that EBTFPS is very effective and scalable, theory analysis is also illustrated the small storage cost. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052569994&partnerID=40&md5=18eef0d621b101223d11025ae9cf18cf}
}

@Conference{Ren2009a,
  Title                    = {Density-based data streams clustering over sliding windows},
  Author                   = {Ren, J.a b and Ma, R.a },
  Year                     = {2009},
  Note                     = {cited By (since 1996)7},
  Pages                    = {248-252},
  Volume                   = {5},

  Abstract                 = {Data stream clustering is an important task in data stream mining. In this paper, we propose SDStream, a new method for performing density-based data streams clustering over sliding windows. SDStream adopts CluStream clustering framework. In the online component, the potential core-micro-cluster and outlier micro-cluster structures are introduced to maintain the potential clusters and outliers. They are stored in the form of Exponential Histogram of Cluster Feature (EHCF) in main memory and are maintained by the maintenance of EHCFs. Outdated micro-clusters which need to be deleted are found by the value of t in Temporal Cluster Feature (TCF). In the offline component, the final clusters of arbitrary shape are generated according to all the potential core-micro-clusters maintained online by DBSCAN algorithm. Experimental results show that SDStream which can generate clusters of arbitrary shape has a much higher clustering quality than CluStream which generates spherical clusters. Ã‚Â© 2009 IEEE.},
  Affiliation              = {College of Information Science and Engineering, Yanshan University, Qinhuangdao City, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing City, China},
  Art_number               = {5360620},
  Author_keywords          = {Data stream; Density-based clustering; Sliding windows},
  Document_type            = {Conference Paper},
  Journal                  = {6th International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-76549115319&partnerID=40&md5=a1c6412730f36f9ee2f7c93f767e592c}
}

@Conference{Ren2008a,
  Title                    = {Online data stream mining of recent frequent itemsets based on sliding window model},
  Author                   = {Ren, J.-D. and Li, K.},
  Year                     = {2008},
  Note                     = {cited By (since 1996)1},
  Pages                    = {293-298},
  Volume                   = {1},

  Abstract                 = {Online data stream mining is one of the most important issues in data mining. Identifying the recent knowledge can provide valuable information for the analysis of the data stream. In this paper, we proposed an one-pass data stream mining algorithm to mine the recent frequent itemsets in data streams with a sliding window basing on transactions. To reduce the cost of time and memory needed to slide the windows, each items is denoted a bit-sequence representations. Basing on Apriori property, this kind of representations can find frequent items in data streams efficiently. We named this method MRFI-SW (Mining Recent Frequent Itemsets by Sliding Window) algorithm. Experiment results show that the proposed algorithm not only attains highly accurate mining result, but also consumes less memory than existing algorithms for mining frequent itemsets over recent data streams. Ã‚Â© 2008 IEEE.},
  Affiliation              = {College of Information Science, Engineering YanShan University, Qinhuangdao 066004, China},
  Art_number               = {4620420},
  Author_keywords          = {Data mining; Online data stream; Sliding windows},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 7th International Conference on Machine Learning and Cybernetics, ICMLC},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an one-pass data stream mining algorithm to mine the recent frequent itemsets in data streams with a sliding window basing on transactions. To reduce the cost of time and memory needed to slide the windows, each items is denoted a bit-sequence representations. It's called MRFI-SW (Mining Recent Frequent Itemsets by Sliding Window). Experiment results show that the proposed algorithm not only attains highly accurate mining result, but also consumes less memory than existing algorithms 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57849094489&partnerID=40&md5=9852aef49c3c80231f9d2883e61ac12e}
}

@Misc{Repoff,
  Title                    = {{Joint Statistical Meetings- Statistical Computing Section Real-Time Data Mining of Complex Spaces}},

  Author                   = {Repoff, Thomas},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.380.410}
}

@Conference{Roach2006,
  Title                    = {An IP-based recording system},
  Author                   = {Roach, J. and Hildin, J.},
  Year                     = {2006},
  Note                     = {cited By (since 1996)0},
  Volume                   = {42},

  Abstract                 = {Traditionally, acquired instrumentation data on a non-destructive test article is recorded to a nonvolatile memory recorder. The data acquisition system usually samples and formats its inputs before transmitting the data to the recorder (also known in this paper as a data sink) via a PCM serial data stream (i.e., clock and data). In a network-based data acquisition architecture, the inclusion of an IP-based recorder adds a new dimension to the data acquisition process. Any IP network inherently allows for the bi-directional exchange of data. In this environment, the IPbased recorder can be treated as both a data sink for parameter recording and a data source for parameter extraction, data rate statistics, and recorder status reporting. The network model recasts the data recorder's function as a file server to which multiple clients could be simultaneously requesting services. Those clients that represent the data acquisition nodes are requesting storage of their acquired parameters. Clients, such as transmitters or test engineers, are requesting access to archived data or status information for further processing. This paper presents the advantages of using an IP-based recorder in a network-based data acquisition system. The availability of an IP interface along with the intelligence built into the recorder expands its capabilities beyond that of a conventional PCM recorder. These capabilities include real-time health monitoring, support for the Simple Network Management Protocol (SNMP), data mining, reporting of real-time performance and network statistics. Ã‚Â© International Foundation for Telemetering, 2006.},
  Affiliation              = {Teletronics Technology Corporation, Newtown, PA, United States},
  Author_keywords          = {Data acquisition; Data mining; IP-based Recorder; Network; SNMP},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the International Telemetering Conference},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. About networks, not ML},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84877894919&partnerID=40&md5=4a77c02ef9ea45a29165597d8533c543}
}

@Article{Robinson2012,
  Title                    = {{Discovery and diagnosis of behavioral transitions in patient event streams}},
  Author                   = {Robinson, William N. and Akhlaghi, Arash and Deng, Tianjie and Syed, Ali Raza},
  Journal                  = {ACM Transactions on Management Information Systems},
  Year                     = {2012},

  Month                    = apr,
  Number                   = {1},
  Pages                    = {1--28},
  Volume                   = {3},

  Abstract                 = {Users with cognitive impairments use assistive technology (AT) as part of a clinical treatment plan. As the AT interface is manipulated, data stream mining techniques are used to monitor user goals. In this context, real-time data mining aids clinicians in tracking user behaviors as they attempt to achieve their goals. Quality metrics over stream-mined models identify potential changes in user goal attainment, as the user learns his or her personalized emailing system. When the quality of some data-mined models varies significantly from nearby models—as defined by quality metrics—the user's behavior is then flagged as a significant behavioral change. The specific changes in user behavior are then characterized by differencing the data-mined decision tree models. This article describes how model quality monitoring and decision tree differencing can aid in recognition and diagnoses of behavioral changes in a case study of cognitive rehabilitation via emailing. The technique may be more widely applicable to other real-time data-intensive analysis problems.},
  Doi                      = {10.1145/2151163.2151167},
  ISSN                     = {2158656X},
  Keywords                 = {Patient monitoring,behavioral rehabilitation,clinical treatment plans,decision trees,real-time data mining,stream mining},
  Owner                    = {alex},
  Publisher                = {ACM},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This article describes how model quality monitoring and decision tree differencing can aid in recognition and diagnoses of behavioral changes in a case study of cognitive rehabilitation via emailing Data mining on stream data from AT, using Dec Trees. Weak abstract. 6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2151163.2151167}
}

@InProceedings{Rojas2009,
  Title                    = {{Online Evaluation of Patterns from Evolving Web Data Streams}},
  Author                   = {Rojas, Carlos and Nasraoui, Olfa},
  Booktitle                = {2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology},
  Year                     = {2009},
  Pages                    = {315--318},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {We present a generic framework to evaluate patterns obtained from transactional web data streams whose underlying distribution changes with time. The evolving nature of the data makes it very difficult to determine whether there is structure in the data stream, and whether this structure is being learned. This challenge arises in applications such as mining online store transactions, summarizing dynamic document collections, and profiling web traffic. We propose to evaluate this hard instance of unsupervised learning using a continuous assessment of the predictive power of the learned patterns, with specific examples that borrow concepts from supervised learning. We present results from experiments with synthetic data, the 20 Newsgroups dataset, web clickstream data, and a custom collection of RSS News feeds.},
  Doi                      = {10.1109/WI-IAT.2009.56},
  ISBN                     = {978-0-7695-3801-3},
  Keywords                 = {Clustering algorithms,Computer science,Conferences,Data engineering,Distributed computing,Intelligent agent,Supervised learning,Testing,USA Councils,Unsupervised learning},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Rojas2009a},
  Shorttitle               = {Web Intelligence and Intelligent Agent Technologie},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5286055}
}

@Conference{Rojas2009a,
  Title                    = {Online evaluation of patterns from evolving web data streams},
  Author                   = {Rojas, C. and Nasraoui, O.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {315-318},
  Volume                   = {1},

  Abstract                 = {We present a generic framework to evaluate patterns obtained from transactional web data streams whose underlying distribution changes with time. The evolving nature of the data makes it very difficult to determine whether there is structure in the data stream, and whether this structure is being learned. This challenge arises in applications such as mining online store transactions, summarizing dynamic document collections, and profiling web traffic. We propose to evaluate this hard instance of unsupervised learning using a continuous assessment of the predictive power of the learned patterns, with specific examples that borrow concepts from supervised learning. We present results from experiments with synthetic data, the 20 Newsgroups dataset, web clickstream data, and a custom collection of RSS News feeds. Ã‚Â© 2009 IEEE.},
  Affiliation              = {Department of Computer Engineering and Computer Science, University of Louisville, Louisville, KY, United States},
  Art_number               = {5286055},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2009 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We present a generic framework to evaluate patterns obtained from transactional web data streams whose underlying distribution changes with time. We present results from experiments with synthetic data, the 20 Newsgroups dataset, web clickstream data, and a custom collection of RSS News feed. Unsupervised learning, using concepts from supervised learning 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84856903614&partnerID=40&md5=42662615817993dff9ab97108cc0088e}
}

@Conference{Rusitschka2013,
  Title                    = {Adaptive middleware for real-time prescriptive analytics in large scale power systems},
  Author                   = {Rusitschka, S.a and Doblander, C.b and Goebel, C.b and Jacobsen, H.-A.b },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The increased digitalization of power systems poses both opportunities and challenges for system operators. GPS time-synchronized high-resolution data streams emanating from measurement devices distributed over a wide area enable the detection of disturbances and the real-time monitoring of consequences as they are evolving, such as undamped oscillations. Processing these data streams is not possible with state-of-the-art SCADA systems that poll data asynchronously at much lower time intervals. Moreover, real-time analysis on fresh streaming data at the enterprise level is an unresolved challenge. In this paper we propose an adaptive middleware concept that can make better use of available data processing resources by enabling distributed computation both on the enterprise and on the field level. We apply the concept of linked data to provide a map for moving the computation to the data it requires for analysis. If based on the IEC 61850 standard semantic data model, the linked data concept additionally yields location and domain awareness that can be leveraged for real-time prescriptive analytics in the field. Another advantage of the proposed adaptive middleware is the abstraction of computational resources: Analytical programs can be written once and then be used to process historical data residing on servers on the enterprise level as well on the distributed devices that originated the data to enable fast analysis of events as they are unfolding. Ã‚Â© 2013 ACM.},
  Affiliation              = {Siemens AG Corporate Technology, Otto-Hahn-Ring 6, D-81739 Munich, Germany; Application and Middleware Systems Research Group, Technische UniversitÃƒÂ¤t MÃƒÂ¼nchen, Germany},
  Author_keywords          = {data analytics; distributed computing; IEC 61850; middleware; power system automation},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the Industrial Track of the 13th ACM/IFIP/USENIX International Middleware Conference, Middleware Industry 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper propose an adaptive middleware concept that can make better use of available data processing resources by enabling distributed computation. They apply the concept of linked data to provide a map for moving the computation to the data it requires for analysis. Uses abstraction to hide computational resources Approved under uncertainty. Can be used for RT prescriptive analytics. Nothing about the experiments or process of creating the middleware. 1,,5},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84897369253&partnerID=40&md5=5ca5a41d4ae05cbd9431e387c5a3ba90}
}

@InProceedings{Rusitschka2013a,
  Title                    = {{Adaptive middleware for real-time prescriptive analytics in large scale power systems}},
  Author                   = {Rusitschka, Sebnem and Doblander, Christoph and Goebel, Christoph and Jacobsen, Hans-Arno},
  Booktitle                = {Proceedings of the Industrial Track of the 13th ACM/IFIP/USENIX International Middleware Conference on - Middleware Industry '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = dec,
  Pages                    = {1--6},
  Publisher                = {ACM Press},

  Abstract                 = {The increased digitalization of power systems poses both opportunities and challenges for system operators. GPS time-synchronized high-resolution data streams emanating from measurement devices distributed over a wide area enable the detection of disturbances and the real-time monitoring of consequences as they are evolving, such as undamped oscillations. Processing these data streams is not possible with state-of-the-art SCADA systems that poll data asynchronously at much lower time intervals. Moreover, real-time analysis on fresh streaming data at the enterprise level is an unresolved challenge. In this paper we propose an adaptive middleware concept that can make better use of available data processing resources by enabling distributed computation both on the enterprise and on the field level. We apply the concept of linked data to provide a map for moving the computation to the data it requires for analysis. If based on the IEC 61850 standard semantic data model, the linked data concept additionally yields location and domain awareness that can be leveraged for real-time prescriptive analytics in the field. Another advantage of the proposed adaptive middleware is the abstraction of computational resources: Analytical programs can be written once and then be used to process historical data residing on servers on the enterprise level as well on the distributed devices that originated the data to enable fast analysis of events as they are unfolding.},
  Doi                      = {10.1145/2541596.2541601},
  ISBN                     = {9781450325509},
  Keywords                 = {IEC 61850,data analytics,distributed computing,middleware,power system automation},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Rusitschka2013},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2541596.2541601}
}

@Misc{S,
  Title                    = {{Frequent Itemset mining over transactional data streams using Item-Order-Tree}},

  Author                   = {S, Pramod and Vyas, O. P.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The association rule mining is one of the important area for research in data mining. In association rule mining online association rule mining is one of the hottest area due to the reason that the knowledge embedded in the data stream is more likely to be changed as time goes by. This paper proposes an algorithm as well as a data structure for online data mining. In this method the pruning in the data structure as well as the frequent itemset generation will be based on the request. The data structure which we introducing will have the capability to maintain the transactions in the sorted order. Every transaction can be extracted from the item-Order-Tree as by doing the traversal in depth. Frequent itemset can be generated as by do the traversal from the parent node that the user requested for. This ItemOrder-Tree improves the performance of the online association rule mining.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes an algorithm as well as a data structure for online data mining. In this method the pruning in the data structure as well as the frequent itemset generation will be based on the request. This ItemOrder-Tree improves the performance of the online association rule mining. 1,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.301.1022}
}

@Article{Sancho-Asensio2014,
  Title                    = {Improving data partition schemes in Smart Grids via clustering data streams },
  Author                   = {Andreu Sancho-Asensio and Joan Navarro and Itziar Arrieta-Salinas and JosÃƒÂ© Enrique ArmendÃƒÂ¡riz-Ãƒï¿½ÃƒÂ±igo and Virginia JimÃƒÂ©nez-Ruano and AgustÃƒÂ­n Zaballos and Elisabet Golobardes},
  Journal                  = {Expert Systems with Applications },
  Year                     = {2014},
  Number                   = {13},
  Pages                    = {5832 - 5842},
  Volume                   = {41},

  Abstract                 = {Data mining techniques are traditionally divided into two distinct disciplines depending on the task to be performed by the algorithm: supervised learning and unsupervised learning. While the former aims at making accurate predictions after deeming an underlying structure in data—which requires the presence of a teacher during the learning phase—the latter aims at discovering regular-occurring patterns beneath the data without making any a priori assumptions concerning their underlying structure. The pure supervised model can construct a very accurate predictive model from data streams. However, in many real-world problems this paradigm may be ill-suited due to (1) the dearth of training examples and (2) the costs of labeling the required information to train the system. A sound use case of this concern is found when defining data replication and partitioning policies to store data emerged in the Smart Grids domain in order to adapt electric networks to current application demands (e.g., real time consumption, network self adapting). As opposed to classic electrical architectures, Smart Grids encompass a fully distributed scheme with several diverse data generation sources. Current data storage and replication systems fail at both coping with such overwhelming amount of heterogeneous data and at satisfying the stringent requirements posed by this technology (i.e., dynamic nature of the physical resources, continuous flow of information and autonomous behavior demands). The purpose of this paper is to apply unsupervised learning techniques to enhance the performance of data storage in Smart Grids. More specifically we have improved the eXtended Classifier System for Clustering (XCSc) algorithm to present a hybrid system that mixes data replication and partitioning policies by means of an online clustering approach. Conducted experiments show that the proposed system outperforms previous proposals and truly fits with the Smart Grid premises.},
  Doi                      = {http://dx.doi.org/10.1016/j.eswa.2014.03.035},
  ISSN                     = {0957-4174},
  Keywords                 = {Smart Grids},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The purpose of this paper is to apply unsupervised learning techniques to enhance the performance of data storage in Smart Grids. They have improved the eXtended Classifier System for Clustering (XCSc) algorithm to present a hybrid system that mixes data replication and partitioning policies by means of an online clustering approach. experiments show that the proposed system outperforms previous proposals 1,2,3,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0957417414001729}
}

@Conference{Saravanan2013a,
  Title                    = {Probing of geospatial stream data to report disorientation},
  Author                   = {Saravanan, M. and Sundar, D. and Kumaresh, V.S.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {227-232},

  Abstract                 = {Probing of data streams in a distributed environment for observation is considered to be one of the prime activities of Big Data Handlers. The notion of big data is efficiently leveraged through popular social networking sites such as Facebook, Twitter, LinkedIn, etc. Twitter is a most popular micro-blogging website enriched with many research issues. The users are allowed to put their ideas and thoughts in the form of messages called 'Tweets' in twitter. In this study, the purpose of gathering the location specific tweets is to understand and surface the insights which are related to human dynamics. We have employed the data stream mining approach to process geo-spatial time invariant tweets in a distributed real-time environment to gain more useful information. Topic models were explored for identifying a particular topic of interest or to extract prudent information from the stream data. Our concentration is on the evolution of different topics at different places, a location-topic matrix is formed for the set of topics observed as most predominant for the specific locations. Then a user graph is generated for the volatile topics that help in analyzing the users who have tweeted or has been re-tweeted on a specific topic the most. From the properties of the generated graph, the disorientation of the topics is reported in the given locations by the use of a sentimental analysis that deems the topic discussed as positive or negative. These analyzes have shown that there is a possibility to outwit the useless and most rampant negative issues spread mutely on a specific location which later creates unnecessary panic to the society. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Ericsson Research India, Ericsson India Global Services Pvt. Ltd, Chennai, Tamil Nadu, India},
  Art_number               = {6745478},
  Author_keywords          = {Big Data Analytics; Stream data processing; Topic models; Twitter streams; User graph},
  Document_type            = {Conference Paper},
  Journal                  = {2013 IEEE Recent Advances in Intelligent Computational Systems, RAICS 2013},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We have employed the data stream mining approach to process geo-spatial time invariant tweets in a distributed real-time environment to gain more useful information They have used ML techniques, but nothing seem innovative. Seems more like a social experiment. Approved under uncertainty 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84896746960&partnerID=40&md5=6af2da1f45ac433429f3833e8b385bb2}
}

@InProceedings{Saravanan2013,
  Title                    = {{Probing of geospatial stream data to report disorientation}},
  Author                   = {Saravanan, M and Sundar, Divya and Kumaresh, V S},
  Booktitle                = {2013 IEEE Recent Advances in Intelligent Computational Systems (RAICS)},
  Year                     = {2013},
  Month                    = dec,
  Pages                    = {227--232},
  Publisher                = {IEEE},

  Abstract                 = {Probing of data streams in a distributed environment for observation is considered to be one of the prime activities of Big Data Handlers. The notion of big data is efficiently leveraged through popular social networking sites such as Facebook, Twitter, LinkedIn, etc. Twitter is a most popular micro-blogging website enriched with many research issues. The users are allowed to put their ideas and thoughts in the form of messages called Ã¢â‚¬Å“TweetsÃ¢â‚¬ï¿½ in twitter. In this study, the purpose of gathering the location specific tweets is to understand and surface the insights which are related to human dynamics. We have employed the data stream mining approach to process geo-spatial time invariant tweets in a distributed real-time environment to gain more useful information. Topic models were explored for identifying a particular topic of interest or to extract prudent information from the stream data. Our concentration is on the evolution of different topics at different places, a location-topic matrix is formed for the set of topics observed as most predominant for the specific locations. Then a user graph is generated for the volatile topics that help in analyzing the users who have tweeted or has been re-tweeted on a specific topic the most. From the properties of the generated graph, the disorientation of the topics is reported in the given locations by the use of a sentimental analysis that deems the topic discussed as positive or negative. These analyzes have shown that there is a possibility to outwit the useless and most rampant negative issues spread mutely on a specific location which later creates unnecessary panic to the society.},
  Doi                      = {10.1109/RAICS.2013.6745478},
  ISBN                     = {978-1-4799-2178-2},
  Keywords                 = {Big Data,Big Data Analytics,Data models,Distributed databases,Facebook,Fasteners,LinkedIn,Real-time systems,Storms,Stream data processing,Topic models,Twitter,Twitter streams,User graph,big data handlers,data mining,data stream mining,data streams,distributed environment,distributed processing,distributed real-time environment,geospatial stream data,geospatial time invariant tweets,human dynamics,location specific tweets,location-topic matrix,microblogging Web site,prudent information,sentimental analysis,social networking (online),social networking sites},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Saravanan2013a},
  Shorttitle               = {Intelligent Computational Systems (RAICS), 2013 IE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6745478}
}

@Misc{Satzger,
  Title                    = {{2011 IEEE 4th International Conference on Cloud Computing Esc: Towards an Elastic Stream Computing Platform for the Cloud}},

  Author                   = {Satzger, Benjamin and Hummer, Waldemar and Dustdar, Schahram},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Today, most tools for processing big data are batch-oriented. However, many scenarios require continuous, online processing of data streams and events. We present ESC, a new stream computing engine. It is designed for computations with real-time demands, such as online data mining. It offers a simple programming model in which programs are specified by directed acyclic graphs (DAGs). The DAG defines the data flow of a program, vertices represent operations applied to the data. The data which are streaming through the graph are expressed as key/value pairs. ESC allows programmers to focus on the problem at hand and deals with distribution and fault tolerance. Furthermore, it is able to adapt to changing computational demands. In the cloud, ESC can dynamically attach and release machines to adjust the computational capacities to the current needs. This is crucial for stream computing since the amount of data fed into the system is not under the platform’s control. We substantiate the concepts we propose in this paper with an evaluation based on a highfrequency trading scenario. Keywords-stream computing; event processing; adaptability I.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Satzger2011a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.228.1498}
}

@InProceedings{Satzger2011,
  Title                    = {{Esc: Towards an Elastic Stream Computing Platform for the Cloud}},
  Author                   = {Satzger, Benjamin and Hummer, Waldemar and Leitner, Philipp and Dustdar, Schahram},
  Booktitle                = {2011 IEEE 4th International Conference on Cloud Computing},
  Year                     = {2011},
  Month                    = jul,
  Pages                    = {348--355},
  Publisher                = {IEEE},

  Abstract                 = {Today, most tools for processing big data are batch-oriented. However, many scenarios require continuous, online processing of data streams and events. We present ESC, a new stream computing engine. It is designed for computations with real-time demands, such as online data mining. It offers a simple programming model in which programs are specified by directed acyclic graphs (DAGs). The DAG defines the data flow of a program, vertices represent operations applied to the data. The data which are streaming through the graph are expressed as key/value pairs. ESC allows programmers to focus on the problem at hand and deals with distribution and fault tolerance. Furthermore, it is able to adapt to changing computational demands. In the cloud, ESC can dynamically attach and release machines to adjust the computational capacities to the current needs. This is crucial for stream computing since the amount of data fed into the system is not under the platform's control. We substantiate the concepts we propose in this paper with an evaluation based on a high-frequency trading scenario.},
  Doi                      = {10.1109/CLOUD.2011.27},
  ISBN                     = {978-1-4577-0836-7},
  ISSN                     = {2159-6182},
  Keywords                 = {Biomedical monitoring,Context,Correlation,Esc,Fault tolerance,Fault tolerant systems,Heart beat,Monitoring,adaptability,batch oriented processing,batch processing (computers),cloud computing,computational capacities,computational demands,data flow,data flow computing,directed acyclic graphs,directed graphs,elastic stream computing platform,event processing,fault tolerance,fault tolerant computing,online data stream processing,programming model,stream computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Satzger2011a},
  Shorttitle               = {Cloud Computing (CLOUD), 2011 IEEE International C},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6008729}
}

@Conference{Satzger2011a,
  Title                    = {Esc: Towards an elastic stream computing platform for the cloud},
  Author                   = {Satzger, B. and Hummer, W. and Leitner, P. and Dustdar, S.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)3},
  Pages                    = {348-355},

  Abstract                 = {Today, most tools for processing big data are batch-oriented. However, many scenarios require continuous, online processing of data streams and events. We present ESC, a new stream computing engine. It is designed for computations with real-time demands, such as online data mining. It offers a simple programming model in which programs are specified by directed acyclic graphs (DAGs). The DAG defines the data flow of a program, vertices represent operations applied to the data. The data which are streaming through the graph are expressed as key/value pairs. ESC allows programmers to focus on the problem at hand and deals with distribution and fault tolerance. Furthermore, it is able to adapt to changing computational demands. In the cloud, ESC can dynamically attach and release machines to adjust the computational capacities to the current needs. This is crucial for stream computing since the amount of data fed into the system is not under the platform's control. We substantiate the concepts we propose in this paper with an evaluation based on a high-frequency trading scenario. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Distributed Systems Group, Vienna University of Technology, Argentinierstr. 8/184-1, A-1040 Vienna, Austria},
  Art_number               = {6008729},
  Author_keywords          = {Adaptability; Event processing; Stream computing},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2011 IEEE 4th International Conference on Cloud Computing, CLOUD 2011},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We present ESC, a new stream computing engine, in which programs are specified by directed acyclic graphs (DAGs). The DAG defines the data flow of a program, vertices represent operations applied to the data. Approved under uncertainty. It's a platform for solving continous, online processing of stream data. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053134516&partnerID=40&md5=8e8dd413b9f55c1d806d7b8a25c68da3}
}

@Article{Sayed2014,
  Title                    = {Adaptation, learning, and optimization over networks},
  Author                   = {Sayed, A.H.},
  Journal                  = {Foundations and Trends in Machine Learning},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {4-5},
  Pages                    = {311-801},
  Volume                   = {7},

  Abstract                 = {This work deals with the topic of information processing over graphs. The presentation is largely self-contained and covers results that relate to the analysis and design of multi-agent networks for the distributed solution of optimization, adaptation, and learning problems from streaming data through localized interactions among agents. The results derived in this work are useful in comparing network topologies against each other, and in comparing networked solutions against centralized or batch implementations. There are many good reasons for the peaked interest in distributed implementations, especially in this day and age when the word "network" has become commonplace whether one is referring to social networks, power networks, transportation networks, biological networks, or other types of networks. Some of these reasons have to do with the benefits of cooperation in terms of improved performance and improved resilience to failure. Other reasons deal with privacy and secrecy considerations where agents may not be comfortable sharing their data with remote fusion centers. In other situations, the data may already be available in dispersed locations, as happens with cloud computing. One may also be interested in learning through data mining from big data sets. Motivated by these considerations, this work examines the limits of performance of distributed stochastic-gradient solutions and discusses procedures that help bring forth their potential more fully. The presentation adopts a useful statistical framework and derives performance results that elucidate the mean-square stability, convergence, and steady-state behavior of the learning networks. The work also illustrates how distributed processing over graphs gives rise to some revealing phenomena due to the coupling effect among the agents. These phenomena are discussed in the context of adaptive networks, along with examples from a variety of areas including distributed sensing, intrusion detection, distributed estimation, online adaptation, network system theory, and machine learning. Ã‚Â© 2014 A. H. Sayed.},
  Affiliation              = {University of California, Los Angeles, United States},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {, this work examines the limits of performance of distributed stochastic-gradient solutions and discusses procedures that help bring forth their potential more fully. The presentation adopts a useful statistical framework and derives performance results that elucidate the mean-square stability, convergence, and steady-state behavior of the learning networks. These phenomena are discussed in the context of adaptive networks, along with examples from a variety of areas including distributed sensing, intrusion detection, distributed estimation, online adaptation, network system theory, and machine learning. Approved under uncertainty. not sure about results or innovative. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905009821&partnerID=40&md5=c837a8c590fa077debc414ef07e89ea3}
}

@Conference{Schwaighofer2009,
  Title                    = {Scalable clustering and keyword suggestion for online advertisements},
  Author                   = {Schwaighofer, A. and Candela, J.Q. and Borchert, T. and Graepel, T. and Herbrich, R.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)2},
  Pages                    = {27-36},

  Abstract                 = {We present an efficient Bayesian online learning algorithm for clustering vectors of binary values based on a well known model, the mixture of Bernoulli profiles. The model includes conjugate Beta priors over the success probabilities and maintains discrete probability distributions for cluster assignments. Clustering is then formulated as inference in a factor graph which is solved efficiently using online approximate message passing. The resulting algorithm has three key features: a) it requires only a single pass across the data and can hence be used on data streams, b) it maintains the uncertainty of parameters and cluster assignments, and c) it implements an automatic step size adaptation based on the current model uncertainty. The model is tested on an artificially generated toy dataset and applied to a large scale real-world data set from online advertising, the data being online ads characterized by the set of keywords to which they have been subscribed. The proposed approach scales well for large datasets, and compares favorably to other clustering algorithms on the ads dataset. As a concrete application to online advertising we show how the learnt model can be used to recommend new keywords for given ads. Copyright 2009 ACM.},
  Affiliation              = {Microsoft Research, 7 JJ Thomson Ave, Cambridge CB3 OFB, United Kingdom},
  Art_number               = {1592753},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 3rd International Workshop on Data Mining and Audience Intelligence for Advertising, ADKDD 2009 in Conjunction with SIGKDD'09},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present an efficient Bayesian online learning algorithm for clustering vectors of binary values based on a well known model, the mixture of Bernoulli profiles. The algorithm has three key features: a) it requires only a single pass across the data and can hence be used on data streams, b) it maintains the uncertainty of parameters and cluster assignments, and c) it implements an automatic step size adaptation based on the current model uncertainty. Test on synthetic and real-world dataset. The proposed approach scales well for large datasets, and compares favorably to other clustering algorithms on the ads dataset. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70449640481&partnerID=40&md5=32fe3a82d3b67c09a732c6a6c83f9676}
}

@InProceedings{Schwaighofer2009a,
  Title                    = {{Scalable clustering and keyword suggestion for online advertisements}},
  Author                   = {Schwaighofer, Anton and Candela, Joaquin Qui\~{n}onero and Borchert, Thomas and Graepel, Thore and Herbrich, Ralf},
  Booktitle                = {Proceedings of the Third International Workshop on Data Mining and Audience Intelligence for Advertising - ADKDD '09},
  Year                     = {2009},

  Address                  = {New York, New York, USA},
  Month                    = jun,
  Pages                    = {27--36},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/1592748.1592753},
  ISBN                     = {9781605586717},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Schwaighofer2009},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1592748.1592753}
}

@Misc{Schweller,
  Title                    = {{1 Reversible Sketches: Enabling Monitoring and Analysis over High-speed Data Streams}},

  Author                   = {Schweller, Robert and Li, Zhichun and Chen, Yan and Gao, Yan and Gupta, Ashish and Parsons, Elliot and Zhang, Yin and Dinda, Peter and Kao, Ming-yang and Memik, Gokhan},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A key function for network traffic monitoring and analysis is the ability to perform aggregate queries over multiple data streams. Change detection is an important primitive which can be extended to construct many aggregate queries. The recently proposed sketches [1] are among the very few that can detect heavy changes online for high speed links, and thus support various aggregate queries in both temporal and spatial domains. However, it does not preserve the keys (e.g., source IP address) of flows, making it difficult to reconstruct the desired set of anomalous keys. To address this challenge, we propose the reversible sketch data structure along with reverse hashing algorithms to infer the keys of culprit flows. There are two phases. The first operates online, recording the packet stream in a compact representation with negligible extra memory and few extra memory accesses. Our prototype single FPGA board implementation can achieve a throughput of over 16 Gbps for 40-byte-packet streams (the worst case). The second phase identifies heavy changes and their keys from the representation in nearly real time. We evaluate our scheme using traces from large edge routers with OC-12 or higher links. Both the analytical and experimental results show that we are able to achieve online traffic monitoring and accurate change/intrusion detection over massive data streams on high speed links, all in a manner that scales to large key space size. To the best of our knowledge, our system is the first to achieve these properties simultaneously.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Schweller2004},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.422.585}
}

@Misc{Schwellera,
  Title                    = {{Reversible Sketches: Enabling Monitoring and Analysis over High-speed Data Streams}},

  Author                   = {Schweller, Robert and Li, Zhichun and Chen, Yan and Gao, Yan and Gupta, Ashish and Parsons, Elliot and Zhang, Yin and Dinda, Peter and Kao, Ming-yang and Memik, Gokhan},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A key function for network traffic monitoring and analysis is the ability to perform aggregate queries over multiple data streams. Change detection is an important primitive which can be extended to construct many aggregate queries. The recently proposed sketches [1] are among the very few that can detect heavy changes online for high speed links, and thus support various aggregate queries in both temporal and spatial domains. However, it does not preserve the keys (e.g., source IP address) of flows, making it difficult to reconstruct the desired set of anomalous keys. To address this challenge, we propose the reversible sketch data structure along with reverse hashing algorithms to infer the keys of culprit flows. There are two phases. The first operates online, recording the packet stream in a compact representation with negligible extra memory and few extra memory accesses. Our prototype single FPGA board implementation can achieve a throughput of over 16 Gbps for 40-byte-packet streams (the worst case). The second phase identifies heavy changes and their keys from the representation in nearly real time. We evaluate our scheme using traces from large edge routers with OC-12 or higher links. Both the analytical and experimental results show that we are able to achieve online traffic monitoring and accurate change/intrusion detection over massive data streams on high speed links, all in a manner that scales to large key space size. To the best of our knowledge, our system is the first to achieve these properties simultaneously.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Schweller2004},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.86.5473}
}

@Misc{Schwellerb,
  Title                    = {{Monitoring Flow-level High-speed Data Streams with Reversible Sketches}},

  Author                   = {Schweller, Robert and Li, Zhichun and Chen, Yan and Gao, Yan and Gupta, Ashish and Zhang, Yin and Dinda, Peter and Kao, Ming-yang and Memik, Gokhan},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A key function for network traffic monitoring and analysis is the ability to perform aggregate queries over multiple data streams. Change detection is an important primitive which can be extended to construct many aggregate queries. The recently proposed sketches [1] are among the very few that can detect heavy changes online for high speed links, and thus support various aggregate queries in both temporal and spatial domains. However, it does not preserve the keys (e.g., source IP address) of flows, making it difficult to reconstruct the desired set of anomalous keys. In an earlier abstract we proposed a framework for a reversible sketch data structure that offers hope for efficient extraction of keys [2]. However, this scheme is only able to detect a single heavy change key and places restrictions on the statistical properties of the key space. To address these challenges, we propose an efficient reverse hashing scheme to infer the keys of culprit flows from reversible sketches. There are two phases. The first operates online, recording the packet stream in a compact representation with negligible extra memory and few extra memory accesses. Our prototype single FPGA board implementation can achieve a throughput of over 16 Gbps for 40-byte-packet streams (the worst case). The second phase identifies heavy changes and their keys from the representation in nearly real time. We evaluate our scheme using traces from large edge routers with OC-12 or higher links. Both the analytical and experimental results show that we are able to achieve online traffic monitoring and accurate change/intrusion detection over massive data streams on high speed links, all in a manner that scales to large key space size. To the best of our knowledge, our system is the first to achieve these properties simultaneously.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Schweller2004},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.122.3340}
}

@Article{Schweller2004,
  Title                    = {{Reverse hashing for high-speed network monitoring: Algorithms, evaluation, and applications}},
  Author                   = {Schweller, Robert and Li, Zhichun and Chen, Yan and Gao, Yan and Gupta, Ashish and Zhang, Yin and Dinda, Peter and Kao, Ming-yang and Memik, Gokhan},
  Journal                  = {IN IEEE INFOCOM},
  Year                     = {2004},
  Pages                    = {1 -- 12},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A key function for network traffic monitoring and analysis is the ability to perform aggregate queries over multiple data streams. Change detection is an important primitive which can be extended to construct many aggregate queries. The recently proposed sketches [1] are among the very few that can detect heavy changes online for high speed links, and thus support various aggregate queries in both temporal and spatial domains. However, it does not preserve the keys (e.g., source IP address) of flows, making it difficult to reconstruct the desired set of anomalous keys. In an earlier abstract we proposed a framework for a reversible sketch data structure that offers hope for efficient extraction of keys [2]. However, this scheme is only able to detect a single heavy change key and places restrictions on the statistical properties of the key space. To address these challenges, we propose an efficient reverse hashing scheme to infer the keys of culprit flows from reversible sketches. There are two phases. The first operates online, recording the packet stream in a compact representation with negligible extra memory and few extra memory accesses. Our prototype single FPGA board implementation can achieve a throughput of over 16 Gbps for 40-byte-packet streams (the worst case). The second phase identifies heavy changes and their keys from the representation in nearly real time. We evaluate our scheme using traces from large edge routers with OC-12 or higher links. Both the analytical and experimental results show that we are able to achieve online traffic monitoring and accurate change/intrusion detection over massive data streams on high speed links, all in a manner that scales to large key space size. To the best of our knowledge, our system is the first to achieve these properties simultaneously.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Theypropose an efficient reverse hashing scheme to infer the keys of culprit flows from reversible sketches. Online and Offline phase. Used for network traffic monitoring and change detection. They say their system is the first to be able to achieve online traffic monitoring and accurate change/intrusion detection over massive data streams on high speed links, all in a manner that scales to large key space size. 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.134.2722}
}

@Conference{Seemann2013,
  Title                    = {Improving resevoir management through big data technologies},
  Author                   = {Seemann, D. and Williamson, M. and Hasan, S.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {837-847},

  Abstract                 = {It's time to set a realistic and pragmatic plan for implementing Big Data Technologies so we can revive our vision of Real Time Fields and fully capitalize on them the way we planned all along. With the introduction of real time streaming data and the resulting data overload, the petroleum industry has effectively entered into the world of "technical" big data. Using traditional data management techniquess on real time data has resulted in data abbiguity and handicaped our ability to understand the information as it flowes through our hands, we are processing more data but less thoughtfully. Harnessing the power of big data can return us to the concept of diagnose and forecast, enhancing performance, organizations that master this will be capable of responding more rapidly to evolving situations, but success will depend acquiring the expertise. Introduction - Replacing gut instinct with data-driven decision-making The term big data is abstract at best, so what's behind all the hype? Big data technologies are more than simply analyzing large amounts of data, fundamentally big data is about extracting knowledge simaltaniously from a varaity of different sources. The term "Big Data" gets used when collectively these sources of data grow beyond the ability of traditional data management tools to process the data within a reasonable amount of time. Traditional data extraction techniques function on the philosophy that the user knows what data is required and pulls the most recent information on a routine basis. Data mining techniques use descriptive statistics to detect trends within the data by continuously searching for relevant patterns to known business process, while simaltaniously seeking patterns where none are preceved to exist and raising alerts to potential new trends. Big data techniques are geared towards generating actionable business Intelligence, they do this by applying inductive statistics based on business rules, which in turn give us (within the limits of inference reasoning) predictive capabilities. With the introduction of real time streaming data and the resulting data overload, the petroleum industry has effectively entered into the world of "technical" big data. The reality of the petroleum industry is we not only subject to internal decisions, but also to decisions made external to the organization and possibly external to the industry itself, such as market forces, weather, transportation, as well as technology and service providers. Since these decisions can have a huge impact on the how we manage our reservoirs we need to make the most educated and beneficial decision possible by adopting more data-driven decision making process. Copyright 2013, Society of Petroleum Engineers.},
  Affiliation              = {SPE, Saudi Aramco, Saudi Arabia},
  Document_type            = {Conference Paper},
  Journal                  = {Society of Petroleum Engineers - SPE Intelligent Energy International 2013: Realising the Full Asset Value},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This abstract seems to be a sales pitch that the oil industry must start using Big Data.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84899421857&partnerID=40&md5=6a98981eb3e1fd78a89552653e7329c7}
}

@InProceedings{Shaeib2010,
  Title                    = {{A framework for real-time context provision in ubiquitous sensing environments}},
  Author                   = {Shaeib, Adel and Cappellari, Paolo and Roantree, Mark},
  Booktitle                = {The IEEE symposium on Computers and Communications},
  Year                     = {2010},
  Month                    = jun,
  Pages                    = {1083--1085},
  Publisher                = {IEEE},

  Abstract                 = {In many ubiquitous computing environments, where applications and systems are required to determine the location of individuals, context information is necessary to support decision making. In practical terms, this requires a hybrid query interface where the user can query live streaming data (to confirm their location) while also using more traditional database expressions to query or mine context repositories. The research presented in this paper describes our approach to developing a framework to support this form of hybrid query application. Our industry collaborator provides a real-world application in which spaces that are equipped with ubiquitous sensing environments are prone to frequent change, requiring a flexible approach to the management of context information.},
  Doi                      = {10.1109/ISCC.2010.5546645},
  ISBN                     = {978-1-4244-7754-8},
  ISSN                     = {1530-1346},
  Keywords                 = {Query,Resource management,Semantics,Sensors,Streaming,Ubiquitous Computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This is about ubi comp and databases, not ML},
  Shorttitle               = {Computers and Communications (ISCC), 2010 IEEE Sym},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5546645}
}

@Article{Shahparast2014,
  Title                    = {A Novel Weight Adjustment Method for Handling Concept-Drift in Data Stream Classification},
  Author                   = {Shahparast, H. and Jahromi, M.Z. and Taheri, M. and Hamzeloo, S.},
  Journal                  = {Arabian Journal for Science and Engineering},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {2},
  Pages                    = {799-807},
  Volume                   = {39},

  Abstract                 = {Evolving fuzzy rule-based systems are very powerful methods for online classification of data streams. In these systems, the classifier is updated by generating, removing and modifying fuzzy classification rules. One of the simplest but efficient algorithms of this type is evolving classifier (eClass) that generates fuzzy classification rules without any prior knowledge. However, this algorithm cannot cope properly with drift and shift in the concept of data. In order to improve the performance of this algorithm, in this paper, we propose a scheme that assigns a weight to each fuzzy rule and propose a new efficient online method to adjust the weight of fuzzy classification rules. Using the proposed rule-weighting algorithm, the classifier can quickly cope with drift and shift in the concept of data. Our algorithm is in fact the modified version of a batch mode rule-weight learning algorithm proposed in the past to be consistent with characteristics of data streams. We use some real life and some synthetic datasets to assess the performance of our algorithm in comparison with eClass and some other methods proposed in the past for handling data streams. The results of experiments show that our proposed algorithm performs significantly better than eClass and other methods proposed in the past for classification of data streams. Ã‚Â© 2013 King Fahd University of Petroleum and Minerals.},
  Affiliation              = {Department of Computer Science, Engineering and IT, Shiraz University, Shiraz, Iran},
  Author_keywords          = {Data stream classification; Evolving fuzzy systems; Fuzzy classification systems; Rule-weight learning},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. In order to improve the performance of the evolving Classifier (eClass) ,this paper propose a scheme that assigns a weight to each fuzzy rule and propose a new efficient online method to adjust the weight of fuzzy classification rules. Using the proposed rule-weighting algorithm, the classifier can quickly cope with drift and shift in the concept of data. Experiments show that the proposed algorithm performs significantly better than eClass and other methods proposed in the past for classification of data streams. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893049891&partnerID=40&md5=44d3e5bd615400020e71a1fe253c2acb}
}

@Misc{Shaik,
  Title                    = {{A SURVEY OF TIME SERIES DATA PREDICTION ON SHOPPING MALL}},

  Author                   = {Shaik, Mohammed Ali and Rahim, Abdul},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Tremendous amount of data streams are often generated by dynamic environments such as stock’s and bond’s price indices, telecommunications data, audio and video data, Network traffic and data related to various Shopping malls. Mining regular patterns is one of the most important task in data mining. A time series database consists of various sequences of values that are obtained over a stipulated period of time. The values are typically measured at equal time stamps (eg., hourly, daily, weekly) which are sequence of ordered events, with or without concrete notations of time. The function is to mine all the transactional data which describes the behavior of various transactions. In an online business or in a shopping mall, the customers can purchase more than one item at a time. Frequent patterns are those that appear most often in a data set as a collection of various item sets or its subsequences. The algorithms like Apriori and FP Growth are used to mine the frequent patterns of a item set. The Apriori algorithm generates candidate set during its each iteration. It reduces the dataset by removing all the irregular itemsets which does not meet the minimum threshold values from the candidate sets. The most expensive phase of FP Growth algorithm is to generate a candidate set and to mine the database},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {No new approach or problem here. Only a survey},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.375.3628}
}

@InProceedings{Shcherbakov2013,
  Title                    = {{An On-Line and Off-Line Pipeline-Based Architecture of the System for Gaps and Outlier Detection in Energy Data Stream}},
  Author                   = {Shcherbakov, Maxim and Timofeev, Yuri and Saprykin, Alexander and Trushin, Vyacheslav and Tyukov, Anton and Shcherbakova, Nataliya and Kamaev, Valeriy and Brebels, Adriaan},
  Booktitle                = {2013 3rd Eastern European Regional Conference on the Engineering of Computer Based Systems},
  Year                     = {2013},
  Month                    = aug,
  Pages                    = {1--7},
  Publisher                = {IEEE},

  Abstract                 = {The quality of energy data (e.g. electric energy consumption, gas consumption data, energy production data) is very crucial issue in the energy domain. Low quality data is expressed in terms of large number of gaps and outliers in the data stream. These drawbacks can be caused by different reasons (e.g. devices faults, loss connections) but just-in-time detection of these cases is the mandatory step for further data handling. This paper describes an on-line and off-line pipeline-based architecture of a system for gaps and outlier detection in energy data streams. As decision making process is limited by time, it is proposed to split the data mining mechanism for gaps and outlier detection in real-time mode(on-line pipeline) from the adjustment mechanism of on-line pipeline's parameters (off-line pipeline). Each pipeline contains the sequence of filters for data handling. Filters in the on-line pipeline use only last input fraction of data. In contrast, filters in the off-line pipeline use all data stored in the data base. The results indicate that the proposed architecture allows to perform real-time gaps and outlier detection with the desired quality and constant latency despite increasing volume of data.},
  Doi                      = {10.1109/ECBS-EERC.2013.9},
  ISBN                     = {978-0-7695-5064-0},
  Keywords                 = {Buildings,Computer architecture,Databases,Delays,Energy consumption,Pipelines,Predictive models,building energy management system,building management systems,computer architecture,connection loss,constant latency,data handling,data mining,data mining mechanism,data stream mining,decision making,decision making process,devices faults,electric energy consumption,energy consumption,energy data,energy data quality,energy data stream,energy domain,energy management systems,energy production data,filter sequence,gaps detection,gas consumption data,just-in-time detection,offline pipeline-based architecture,on-line pipeline parameter adjustment,online pipeline-based architecture,outlier detection,pipeline processing,pipeline-based architecture,power engineering computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Shcherbakov2013a},
  Shorttitle               = {Engineering of Computer Based Systems (ECBS-EERC),},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6664503}
}

@Conference{Shcherbakov2013a,
  Title                    = {An on-line and off-line pipeline-based architecture of the system for gaps and outlier detection in energy data stream},
  Author                   = {Shcherbakov, M.a and Timofeev, Y.a and Saprykin, A.a and Trushin, V.a and Tyukov, A.a and Shcherbakova, N.a and Kamaev, V.a and Brebels, A.b },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1-7},

  Abstract                 = {The quality of energy data (e.g. electric energy consumption, gas consumption data, energy production data) is very crucial issue in the energy domain. Low quality data is expressed in terms of large number of gaps and outliers in the data stream. These drawbacks can be caused by different reasons (e.g. devices faults, loss connections) but just-in-time detection of these cases is the mandatory step for further data handling. This paper describes an on-line and off-line pipeline-based architecture of a system for gaps and outlier detection in energy data streams. As decision making process is limited by time, it is proposed to split the data mining mechanism for gaps and outlier detection in real-time mode(on-line pipeline) from the adjustment mechanism of on-line pipeline's parameters (off-line pipeline). Each pipeline contains the sequence of filters for data handling. Filters in the on-line pipeline use only last input fraction of data. In contrast, filters in the off-line pipeline use all data stored in the data base. The results indicate that the proposed architecture allows to perform real-time gaps and outlier detection with the desired quality and constant latency despite increasing volume of data. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Computer Adied Design, Volgograd State Technical University, Russian Federation; Hogeschool Thomas More, Geel, Belgium},
  Art_number               = {6664503},
  Author_keywords          = {data stream mining; energy data; gaps detection; outlier detection; pipeline-based architecture},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2013 IEEE 3rd Eastern European Regional Conference on the Engineering of Computer Based Systems, ECBS-EERC 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper describes an on-line and off-line pipeline-based architecture of a system for gaps and outlier detection in energy data streams. The results indicate that the proposed architecture allows to perform real-time gaps and outlier detection with the desired quality and constant latency despite increasing volume of data 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84892538332&partnerID=40&md5=a44f1eba8c16e0b63f8bbdbc83597044}
}

@Conference{Sherchan2012a,
  Title                    = {Using on-the-move mining for mobile crowdsensing},
  Author                   = {Sherchan, W.a and Jayaraman, P.P.a and Krishnaswamy, S.a b and Zaslavsky, A.c and Loke, S.d and Sinha, A.a },
  Year                     = {2012},
  Note                     = {cited By (since 1996)11},
  Pages                    = {115-124},

  Abstract                 = {In this paper, we propose and develop a platform to support data collection for mobile crowdsensing from mobile device sensors that is under-pinned by real-time mobile data stream mining. We experimentally show that mobile data mining provides an efficient and scalable approach for data collection for mobile crowdsensing. Our approach results in reducing the amount of data sent, as well as the energy usage on the mobile phone, while providing comparable levels of accuracy to traditional models of intermittent/continuous sensing and sending. We have implemented our Context-Aware Real-time Open Mobile Miner (CAROMM) to facilitate data collection from mobile users for crowdsensing applications. CAROMM also collects and correlates this real-time sensory information with social media data from both Twitter and Facebook. CAROMM supports delivering real-time information to mobile users for queries that pertain to specific locations of interest. We have evaluated our framework by collecting real-time data over a period of days from mobile users and experimentally demonstrated that mobile data mining is an effective and efficient strategy for mobile crowdsensing. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Faculty of Information Technology, Monash University, Australia; Institute for Infocomm Research (I2R), Singapore, Singapore; CSIRO ICT Centre, Australia; Department of Comp. Sc. and Comp. Eng., La Trobe University, Australia},
  Art_number               = {6341381},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2012 IEEE 13th International Conference on Mobile Data Management, MDM 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose and develop a platform to support data collection for mobile crowdsensing from mobile device sensors that is under-pinned by real-time mobile data stream mining. CAROMM supports delivering real-time information to mobile users for queries that pertain to specific locations of interest. We have evaluated our framework by collecting real-time data over a period of days from mobile users and experimentally demonstrated that mobile data mining is an effective and efficient strategy for mobile crowdsensing. Could be interesting to Telenor, mobile data mining to deliver information to users. 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870766233&partnerID=40&md5=4e39a936df53fc5d7a9ee04630e1807b}
}

@InProceedings{Sherchan2012,
  Title                    = {{Using On-the-Move Mining for Mobile Crowdsensing}},
  Author                   = {Sherchan, Wanita and Jayaraman, Prem P. and Krishnaswamy, Shonali and Zaslavsky, Arkady and Loke, Seng and Sinha, Abhijat},
  Booktitle                = {2012 IEEE 13th International Conference on Mobile Data Management},
  Year                     = {2012},
  Month                    = jul,
  Pages                    = {115--124},
  Publisher                = {IEEE},

  Abstract                 = {In this paper, we propose and develop a platform to support data collection for mobile crowdsensing from mobile device sensors that is under-pinned by real-time mobile data stream mining. We experimentally show that mobile data mining provides an efficient and scalable approach for data collection for mobile crowdsensing. Our approach results in reducing the amount of data sent, as well as the energy usage on the mobile phone, while providing comparable levels of accuracy to traditional models of intermittent/continuous sensing and sending. We have implemented our Context-Aware Real-time Open Mobile Miner (CAROMM) to facilitate data collection from mobile users for crowdsensing applications. CAROMM also collects and correlates this real-time sensory information with social media data from both Twitter and Facebook. CAROMM supports delivering real-time information to mobile users for queries that pertain to specific locations of interest. We have evaluated our framework by collecting real-time data over a period of days from mobile users and experimentally demonstrated that mobile data mining is an effective and efficient strategy for mobile crowdsensing.},
  Doi                      = {10.1109/MDM.2012.58},
  ISBN                     = {978-1-4673-1796-2},
  Keywords                 = {CAROMM,Data mining,Data models,Facebook,Mobile communication,Mobile handsets,Real-time systems,Sensors,Twitter,context-aware real-time open mobile miner,continuous sensing,data collection,data mining,energy usage,intermittent sensing,mobile computing,mobile crowdsensing,mobile device sensor,mobile phone,mobile radio,mobile user,on-the-move mining,query,query processing,real-time information delivery,real-time mobile data stream mining,real-time sensory information,real-time systems,sending,social media data,social networking (online)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Sherchan2012a},
  Shorttitle               = {Mobile Data Management (MDM), 2012 IEEE 13th Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6341381}
}

@InProceedings{Shetty2011,
  Title                    = {{An integrated machine learning and control theoretic model for mining concept-drifting data streams}},
  Author                   = {Shetty, Sachin and Mukkavilli, Sai Kiran and Keel, L. H.},
  Booktitle                = {2011 IEEE International Conference on Technologies for Homeland Security (HST)},
  Year                     = {2011},
  Month                    = nov,
  Pages                    = {75--80},
  Publisher                = {IEEE},

  Abstract                 = {Anomaly-based network Intrusion Detection Systems (IDS) model patterns of normal activity and detect novel network attacks. However, these systems depend on the availability of the systems normal traffic pattern profile. But the statistical fingerprint of the normal traffic pattern can change and shift over a period of time due to changes in operational or user activity at the networked site or even system updates. The changes in normal traffic patterns over time lead to concept drift. Some changes can be temporal, cyclical and can be short-lived or they can last for longer periods of time. Depending on a number of factors the speed at which the change in traffic patterns occurs can also be variable, ranging from near instantaneous to the change occurring over the span of numerous months. These changes in traffic patterns are a cause of concern for IDSs as they can lead to a significant increase in false positive rates, thereby reducing the overall system performance. In order to improve the reliability of the IDS, there is a need for an automated mechanism to detect valid traffic changes and avoid inappropriate ad hoc responses. ROC curves have historically been used to evaluate the accuracy of IDSs. ROC curves generated using fixed, time-invariant classification thresholds do not characterize the best accuracy that an IDS can achieve in presence of concept-drifting network traffic. In this paper, we present a integrated supervised machine learning and control theoretic model for detecting concept drift in network traffic patterns. The model comprises of a online support vector machine based classifier(incremental anomaly based detection), a Kullback - Leibler divergence based relative entropy measurement scheme(quantifying concept drift) and feedback control engine(adapting ROC thresholding). In our proposed system, any intrusion activity will cause significant variations, thereby causing a large error, while a minor aberration in the variations (concept drift) w- ll not be immediately reported as alert.},
  Doi                      = {10.1109/THS.2011.6107850},
  ISBN                     = {978-1-4577-1376-7},
  Keywords                 = {Accuracy,Adaptation models,Anomaly Based Intrusion Detection Systems,Concept Drift,Engines,Entropy,Feedback control,Kullback-Leibler divergence,ROC curve,Support Vector Machine,Support vector machines,Training,adapting ROC thresholding,anomaly-based network intrusion detection systems,concept drift detection,concept-drifting data stream mining,control theoretic model,data mining,entropy measurement scheme,feedback,feedback control engine,incremental anomaly based detection,learning (artificial intelligence),network attack,normal traffic pattern profile,pattern classification,receiver operating characteristic curve,security of data,supervised machine learning,support vector machine based classifier,support vector machines,user activity},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present a integrated supervised machine learning and control theoretic model for detecting concept drift in network traffic patterns, to solve Anomaly-based network Intrusion Detection Systems (IDS). The model comprises of a online support vector machine based classifier. In the proposed system, any intrusion activity will cause significant variations, thereby causing a large error, while a minor aberration in the variations (concept drift) will not be immediately reported as alert. 1,2,(5?),6},
  Shorttitle               = {Technologies for Homeland Security (HST), 2011 IEE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6107850}
}

@Conference{Shie2010,
  Title                    = {Online mining of temporal maximal utility itemsets from data streams},
  Author                   = {Shie, B.-E.a and Tseng, V.S.a and Yu, P.S.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)4},
  Pages                    = {1622-1626},

  Abstract                 = {Data stream mining has become an emerging research topic in the data mining field, and finding frequent itemsets is an important task in data stream mining with wide applications. Recently, utility mining is receiving extensive attentions with two issues reconsidered: First, the utility (e.g., profit) of each item may be different in real applications; second, the frequent itemsets might not produce the highest utility. In this paper, we propose a novel algorithm named GUIDE (Generation of temporal maximal Utility Itemsets from Data strEams) which can find temporal maximal utility itemsets from data streams. A novel data structure, namely, TMUI-tree (Temporal Maximal Utility Itemset tree), is also proposed for efficiently capturing the utility of each itemset with one-time scanning. The main contributions of this paper are as follows: 1) GUIDE is the first one-pass utility-based algorithm for mining temporal maximal utility itemsets from data streams, and 2) TMUI-tree is efficient and easy to maintain. The experimental results show that our approach outperforms other existing utility mining algorithms like Two-Phase algorithm under the data stream environments. Ã‚Â© 2010 ACM.},
  Affiliation              = {Dept. of Computer Science and Information Engineering, National Cheng Kung University, Taiwan; Dept. of Computer Science, University of Illinois at Chicago, Chicago, IL, United States},
  Author_keywords          = {data stream mining; maximal itemsets; temporal high utility itemsets; utility mining},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM Symposium on Applied Computing},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Newer version in Shie2012},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954704076&partnerID=40&md5=529395c8b9527e2d99c23bd86749cb1b}
}

@InProceedings{Shie2010a,
  Title                    = {{Online mining of temporal maximal utility itemsets from data streams}},
  Author                   = {Shie, Bai-En and Tseng, Vincent S. and Yu, Philip S.},
  Booktitle                = {Proceedings of the 2010 ACM Symposium on Applied Computing - SAC '10},
  Year                     = {2010},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {1622},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/1774088.1774436},
  ISBN                     = {9781605586397},
  Keywords                 = {data stream mining,maximal itemsets,temporal high utility itemsets,utility mining},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Shie2010},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1774088.1774436}
}

@Article{Shie2012,
  Title                    = {Efficient algorithms for mining maximal high utility itemsets from data streams with different models },
  Author                   = {Bai-En Shie and Philip S. Yu and Vincent S. Tseng},
  Journal                  = {Expert Systems with Applications },
  Year                     = {2012},
  Number                   = {17},
  Pages                    = {12947 - 12960},
  Volume                   = {39},

  Abstract                 = {Data stream mining is an emerging research topic in the data mining field. Finding frequent itemsets is one of the most important tasks in data stream mining with wide applications like online e-business and web click-stream analysis. However, two main problems existed in relevant studies: (1) The utilities (e.g., importance or profits) of items are not considered. Actual utilities of patterns cannot be reflected in frequent itemsets. (2) Existing utility mining methods produce too many patterns and this makes it difficult for the users to filter useful patterns among the huge set of patterns. In view of this, in this paper we propose a novel framework, named \{GUIDE\} (Generation of maximal high Utility Itemsets from Data strEams), to find maximal high utility itemsets from data streams with different models, i.e., landmark, sliding window and time fading models. The proposed structure, named MUI-Tree (Maximal high Utility Itemset Tree), maintains essential information for the mining processes and the proposed strategies further facilitates the performance of GUIDE. Main contributions of this paper are as follows: (1) To the best of our knowledge, this is the first work on mining the compact form of high utility patterns from data streams; (2) \{GUIDE\} is an effective one-pass framework which meets the requirements of data stream mining; (3) \{GUIDE\} generates novel patterns which are not only high utility but also maximal, which provide compact and insightful hidden information in the data streams. Experimental results show that our approach outperforms the state-of-the-art algorithms under various conditions in data stream environments on different models.},
  Doi                      = {http://dx.doi.org/10.1016/j.eswa.2012.05.035},
  ISSN                     = {0957-4174},
  Keywords                 = {High utility itemset},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a novel framework, named \{GUIDE\} (Generation of maximal high Utility Itemsets from Data strEams), to find maximal high utility itemsets from data streams with different models, i.e., landmark, sliding window and time fading models. this is the first work on mining the compact form of high utility patterns from data streams. It is an effective one-pass framework. Experimental results show that their approach outperforms the state-of-the-art algorithms. 1,2,3,4,5,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S095741741200749X}
}

@Article{Shin2014a,
  Title                    = {CP-tree: An adaptive synopsis structure for compressing frequent itemsets over online data streams},
  Author                   = {Shin, S.J. and Lee, D.S. and Lee, W.S.},
  Journal                  = {Information Sciences},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {559-576},
  Volume                   = {278},

  Abstract                 = {Due to the characteristics of a data stream, it is very important to confine the memory usage of a data mining process. This paper proposes a CP-tree (Compressible-prefix tree) that can be effectively employed in finding frequent itemsets over an online data stream. Unlike a prefix tree, a node of a CP-tree can maintain a concise synopsis that can be used to trace the supports of several itemsets together. As the number of itemsets that are traced by a node of a CP-tree is increased, the size of a CP-tree becomes smaller. However, the result of a CP-tree becomes less accurate since the estimated supports of those itemsets that are traced together by a node of a CP-tree may contain possible false positive or negative errors. Based on this characteristic, the size of a CP-tree can be controlled by merging or splitting the nodes of a CP-tree, which allows the utilization of a confined memory space as much as possible. Therefore, the accuracy of a CP-tree is maximized at all times for a confined memory space. Furthermore, a CP-tree can trace a concise set of representative frequent itemsets that can collectively represent the set of original frequent itemsets. Ã‚Â© 2014 Elsevier Inc. All rights reserved.},
  Affiliation              = {Department of Computer Science, Yonsei University, 134 Shinchon-dong, Seodaemun-gu, Seoul 120-749, South Korea},
  Author_keywords          = {Data mining; Data stream; Frequent itemset; Frequent itemset compression; Stream data mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Introduces an algorithm for finding freq itemsets on a data stream. Approved, but abstract is a little weak. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84901833382&partnerID=40&md5=7dec99902bde95e06cc9e0fc704f81fa}
}

@InProceedings{SQQZ2006,
  Title                    = {{Approximately Processing Multi-granularity Aggregate Queries over Data Streams}},
  Author                   = {{Shouke Qin} and {Weining Qian} and {Aoying Zhou}},
  Booktitle                = {22nd International Conference on Data Engineering (ICDE'06)},
  Year                     = {2006},
  Pages                    = {67--67},
  Publisher                = {IEEE},

  Abstract                 = {Aggregate monitoring over data streams is attracting more and more attention in research community due to its broad potential applications. Existing methods suffer two problems, 1) The aggregate functions which could be monitored are restricted to be first-order statistic or monotonic with respect to the window size. 2) Only a limited number of granularity and time scales could be monitored over a stream, thus some interesting patterns might be neglected, and users might be misled by the incomplete changing profile about current data streams. These two impede the development of online mining techniques over data streams, and some kind of breakthrough is urged. In this paper, we employed the powerful tool of fractal analysis to enable the monitoring of both monotonic and non-monotonic aggregates on time-changing data streams. The monotony property of aggregate monitoring is revealed and monotonic search space is built to decrease the time overhead for accessing the synopsis from O(m) to O(logm), where m is the number of windows to be monitored. With the help of a novel inverted histogram, the statistical summary is compressed to be fit in limited main memory, so that high aggregates on windows of any length can be detected accurately and efficiently on-line. Theoretical analysis show the space and time complexity bound of this method are relatively low, while experimental results prove the applicability and efficiency of the proposed algorithm in different application settings.},
  Doi                      = {10.1109/ICDE.2006.22},
  ISBN                     = {0-7695-2570-9},
  Keywords                 = {Aggregates,Application software,Computer science,Computerized monitoring,Data engineering,Data mining,Databases,Fractals,Impedance,Statistics},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Qin2006},
  Shorttitle               = {Data Engineering, 2006. ICDE '06. Proceedings of t},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1617435}
}

@Article{Silva2013a,
  Title                    = {{Data stream clustering}},
  Author                   = {Silva, Jonathan A. and Faria, Elaine R. and Barros, Rodrigo C. and Hruschka, Eduardo R. and de Carvalho, Andr\'{e} C. P. L. F. and Gama, Jo\~{a}o},
  Journal                  = {ACM Computing Surveys},
  Year                     = {2013},

  Month                    = oct,
  Number                   = {1},
  Pages                    = {1--31},
  Volume                   = {46},

  Abstract                 = {Data stream mining is an active research area that has recently emerged to discover knowledge from large amounts of continuously generated data. In this context, several data stream clustering algorithms have been proposed to perform unsupervised learning. Nevertheless, data stream clustering imposes several challenges to be addressed, such as dealing with nonstationary, unbounded data that arrive in an online fashion. The intrinsic nature of stream data requires the development of algorithms capable of performing fast and incremental processing of data objects, suitably addressing time and memory limitations. In this article, we present a survey of data stream clustering algorithms, providing a thorough discussion of the main design components of state-of-the-art algorithms. In addition, this work addresses the temporal aspects involved in data stream clustering, and presents an overview of the usually employed experimental methodologies. A number of references are provided that describe applications of data stream clustering in different domains, such as network intrusion detection, sensor networks, and stock market analysis. Information regarding software packages and data repositories are also available for helping researchers and practitioners. Finally, some important issues and open questions that can be subject of future research are discussed.},
  Doi                      = {10.1145/2522968.2522981},
  ISSN                     = {03600300},
  Keywords                 = {Data stream clustering,online clustering},
  Owner                    = {alex},
  Publisher                = {ACM},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Silva2013},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2522968.2522981}
}

@Article{Silva2013,
  Title                    = {Data stream clustering: A survey},
  Author                   = {Silva, J.A.a and Faria, E.R.b and Barros, R.C.a and Hruschka, E.R.a and De Carvalho, A.C.P.L.F.a and Gama, J.c },
  Journal                  = {ACM Computing Surveys},
  Year                     = {2013},
  Note                     = {cited By (since 1996)2},
  Number                   = {1},
  Volume                   = {46},

  Abstract                 = {Data stream mining is an active research area that has recently emerged to discover knowledge from large amounts of continuously generated data. In this context, several data stream clustering algorithms have been proposed to perform unsupervised learning. Nevertheless, data stream clustering imposes several challenges to be addressed, such as dealing with nonstationary, unbounded data that arrive in an online fashion. The intrinsic nature of stream data requires the development of algorithms capable of performing fast and incremental processing of data objects, suitably addressing time and memory limitations. In this article, we present a survey of data stream clustering algorithms, providing a thorough discussion of the main design components of state-of-the-art algorithms. In addition, this work addresses the temporal aspects involved in data stream clustering, and presents an overview of the usually employed experimental methodologies. A number of references are provided that describe applications of data stream clustering in different domains, such as network intrusion detection, sensor networks, and stock market analysis. Information regarding software packages and data repositories are also available for helping researchers and practitioners. Finally, some important issues and open questions that can be subject of future research are discussed. Ã‚Â© 2013 ACM.},
  Affiliation              = {Institure of Mathematics and Computer Science (ICMC), University of SÃƒÂ£o Paulo, SÃƒÂ£o Paulo, Brazil; University of SÃƒÂ£o Paulo, School of Computer, Federal University of Uberlandia, Uberlandia, Brazil; Laboratory of Artificial Intelligence and Decision Support (LIAAD-INESC TEC) and FEP, University of Porto, Portugal},
  Art_number               = {13},
  Author_keywords          = {Data stream clustering; Online clustering},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {, we present a survey of data stream clustering algorithms, providing a thorough discussion of the main design components of state-of-the-art algorithms. Set aside as similar study},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84887425296&partnerID=40&md5=44ce718c5a787fab216cd6f416ce91bd}
}

@Misc{Silveira,
  Title                    = {{Adaptive forward error correction for interactive streaming over the Internet}},

  Author                   = {Silveira, Fernando and Edson, Filho and Watanabe, H. and Silva, Edmundo Souza},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Despite the emergence of voice over IP and videoconferencing services, recent studies have shown that the Internet still may not provide acceptable quality for interactive streaming applications. Among the major parameters that affect quality of service are packet loss rates and loss burst sizes. To mitigate the negative impact of losses, forward error correction (FEC) techniques can be employed. These work by adding extra information to the data stream. So, while FEC can potentially reduce the perceived effects of packet losses, it increases bandwidth requirements which in turn may increase the loss rate. Therefore, it is important to choose, in real time, the proper FEC scheme to provide the best performance to the application. We evaluate the performance of parity-based FEC schemes using an analytical loss model. Then, we develop an adaptive mechanism for FEC selection using a predictive model. We present the results of simulation experiments using real Internet measurements.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. it's about telecommunication.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.2937}
}

@InProceedings{Simeone2012,
  Title                    = {{DIY GIS: A Constructionist, Educational Toolkit for Architecture Students}},
  Author                   = {Simeone, Luca and Lupi, Giorgia and Patelli, Paolo and Iaconesi, Salvatore and Persico, Oriana},
  Booktitle                = {2012 IEEE 12th International Conference on Advanced Learning Technologies},
  Year                     = {2012},
  Month                    = jul,
  Pages                    = {253--257},
  Publisher                = {IEEE},

  Abstract                 = {This paper presents a prototype for an educational toolkit (DIY GIS) to learn and teach some important elements of urban design, planning and management. The project aimed at developing a platform that addresses geographic mapping as a process that is subjective (of a projection of the user-inhabitant's imagination) as well as objective (of the territory as a concrete structure). The platform applies text mining and conversation analysis to geolocalized user generated content (real-time data coming from Twitter, Facebook, FourSquareFoursquare, Flickr) in order to return meaningful visual images and maps about citizens' perception of public services, urban public spaces, and of the city as a whole. This platform has been developed and tested in some workshops with students in the field of architecture. From an educational point of view the platform itself can be considered a sort of toolkit that allows students to harvest, connect, analyze and interpret real-time data streams and to visually represent them in a personalized way. The students have to actively configure this toolkit in order to perform queries and design maps that are meaningful for the specific place under analysis and for their objectives. The paper focuses on both the design process of the toolkit and the first observations of the platform in use during some workshops carried out in the last months of 2011 in order to assess its education potential.},
  Doi                      = {10.1109/ICALT.2012.47},
  ISBN                     = {978-1-4673-1642-2},
  Keywords                 = {Cities and towns,Conferences,DIY GIS,Data mining,Engines,Facebook,Flickr,FourSquareFoursquare,Geographic information systems,Planning,Real time systems,Twitter,architecture,architecture students,cartography,citizen perception,computer aided instruction,concrete structure territory,constructionism,constructionist,conversation analysis,data mining,do it yourself geographic information system,educational toolkit,enhanced learning,geographic information systems,geographic mapping,geolocalized user generated content,infosthetics,mathetics,public services,real-time data stream analysis,real-time data stream harvesting,real-time data stream interpretation,social networking (online),teaching,text analysis,text mining,town and country planning,urban design,urban management,urban planning,urban public spaces,visual images,visual maps},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Simeone2012a},
  Shorttitle               = {Advanced Learning Technologies (ICALT), 2012 IEEE },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6268091}
}

@Conference{Simeone2012a,
  Title                    = {DIY GIS: A constructionist, educational toolkit for architecture students},
  Author                   = {Simeone, L.a b and Lupi, G.c and Patelli, P.c and Iaconesi, S.b and Persico, O.b},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {253-257},

  Abstract                 = {This paper presents a prototype for an educational toolkit (DIY GIS) to learn and teach some important elements of urban design, planning and management. The project aimed at developing a platform that addresses geographic mapping as a process that is subjective (of a projection of the user-inhabitant's imagination) as well as objective (of the territory as a concrete structure). The platform applies text mining and conversation analysis to geolocalized user generated content (real-time data coming from Twitter, Facebook, FourSquareFoursquare, Flickr) in order to return meaningful visual images and maps about citizens' perception of public services, urban public spaces, and of the city as a whole. This platform has been developed and tested in some workshops with students in the field of architecture. From an educational point of view the platform itself can be considered a sort of toolkit that allows students to harvest, connect, analyze and interpret real-time data streams and to visually represent them in a personalized way. The students have to actively configure this toolkit in order to perform queries and design maps that are meaningful for the specific place under analysis and for their objectives. The paper focuses on both the design process of the toolkit and the first observations of the platform in use during some workshops carried out in the last months of 2011 in order to assess its education potential. Ã‚Â© 2012 IEEE.},
  Affiliation              = {MalmÃƒÂ¶ University, MalmÃƒÂ¶, Sweden; FakePress, Rome, Italy; Politecnico, Milan, Italy},
  Art_number               = {6268091},
  Author_keywords          = {constructionism; enhanced learning; infosthetics; mathetics},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 12th IEEE International Conference on Advanced Learning Technologies, ICALT 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents a prototype for an educational toolkit (DIY GIS) to learn and teach some important elements of urban design, planning and management. Approved under uncertainty. Their prototype seems to use ML techniques (text mining and conversation analysis), but not sure about innovative. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867002596&partnerID=40&md5=5857e3950905ea16062c1bd2bc515604}
}

@InProceedings{Simmonds2014,
  Title                    = {{A Platform for Analysing Stream and Historic Data with Efficient and Scalable Design Patterns}},
  Author                   = {Simmonds, R.M. and Watson, P. and Halliday, J. and Missier, P.},
  Booktitle                = {2014 IEEE World Congress on Services},
  Year                     = {2014},
  Month                    = jun,
  Pages                    = {174--181},
  Publisher                = {IEEE},

  Abstract                 = {Social media is an increasingly popular method for people to share information and interact with each other. Analysis of social media data has the potential to provide useful insights in a wide range of domains including social science, advertising and policing. Social media information is produced in real-time, and so analysis that can give insights into events as they occur can be particularly valuable. Similarly, analytics platforms providing low latency query responses can improve the user experience for ad-hoc data exploration on historic data sets. However, the rate at which new data is generated makes it a real challenge to design a system that can meet both of these challenges. This paper describes the deisgn and evaluation of such a system. Firstly, it describes how a meta-analysis of the types of questions that were being asked of Twitter data led to the identification of a small set of queries that could be used to answer the majority of them. Secondly, it describes the design of a scalable platform for answering these and other queries. The architecture is described: it is cloud-based, and combines both continuous query, and noSQL database technology. Evaluation results are presented which show that the system can scale to process queries on streaming data arriving at the rate of the full Twitter firehose. Experiments show that queries on large repositories of stored historic data can also be answered with low latency. Finally, we present the results of queries that combine both streaming and historic data.},
  Doi                      = {10.1109/SERVICES.2014.40},
  ISBN                     = {978-1-4799-5069-0},
  Keywords                 = {Complex event processing,Databases,Distributed database,Educational institutions,Market research,Media,NoSQL,Radiation detectors,Scalability,Scalability and Social Media,Twitter},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Nothing in this paper indicates that machine learning will be used for analytics. only talks about cloud and noSQL.},
  Shorttitle               = {Services (SERVICES), 2014 IEEE World Congress on},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6903262}
}

@Misc{Singh,
  Title                    = {{Exploring the Big Data Spectrum}},

  Author                   = {Singh, Jaya and Rana, Ajay},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Today, enterprises are flooded with data – terabytes and petabytes of it. Exabytes, zettabytes and yottabytes are definitely on the way. This tsunami of data, as some experts call it, which is growing exponentially, at a very high velocity from different sources in diverse formats, is being termed as Big Data. Big Data is the data pouring globally from transactional systems like SCM, CRM, ERP and non-transactional sources such as sensors, mobile communications, RFID, Social Media, satellites, web logs, clickstreams and emails and is structured, semi-structured or unstructured in schema. Big Data is a source of big opportunities, which need to be extracted by applying advanced analytics on it. However, there are several challenges posed by Big Data to the enterprises. Since most of the Big Data is unstructured, new approaches must be adopted by the enterprises to ingest, store, analyze, manage, distribute and process this streaming data and gain insights for innovation and competition in the business process. New infrastructure is needed to handle the explosive volume, velocity, variety and complexity of Big Data. Core competence is required to analyze in real time, the full spectrum of data and discover the patterns, trends and relationships in Big Data, which are the sources of innovation and business transformation. The highlights of this research paper are to define Big Data, explain the significance of Big Data, discuss the approaches to leverage the benefits of Big Data in the Enterprises and look at the future state of Big Data},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {The highlights of this research paper are to define Big Data, explain the significance of Big Data, discuss the approaches to leverage the benefits of Big Data in the Enterprises and look at the future state of Big Data Discarded. Nothing about ML techniques. Maybe a background source.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.413.2969}
}

@Article{Slavakis2014,
  Title                    = {{Modeling and Optimization for Big Data Analytics: (Statistical) learning tools for our era of data deluge}},
  Author                   = {Slavakis, Konstantinos and Giannakis, Georgios B. and Mateos, Gonzalo},
  Journal                  = {IEEE Signal Processing Magazine},
  Year                     = {2014},

  Month                    = sep,
  Number                   = {5},
  Pages                    = {18--31},
  Volume                   = {31},

  Abstract                 = {With pervasive sensors continuously collecting and storing massive amounts of information, there is no doubt this is an era of data deluge. Learning from these large volumes of data is expected to bring significant science and engineering advances along with improvements in quality of life. However, with such a big blessing come big challenges. Running analytics on voluminous data sets by central processors and storage units seems infeasible, and with the advent of streaming data sources, learning must often be performed in real time, typically without a chance to revisit past entries. Workhorse signal processing (SP) and statistical learning tools have to be re-examined in todays high-dimensional data regimes. This article contributes to the ongoing cross-disciplinary efforts in data science by putting forth encompassing models capturing a wide range of SP-relevant data analytic tasks, such as principal component analysis (PCA), dictionary learning (DL), compressive sampling (CS), and subspace clustering. It offers scalable architectures and optimization algorithms for decentralized and online learning problems, while revealing fundamental insights into the various analytic and implementation tradeoffs involved. Extensions of the encompassing models to timely data-sketching, tensor- and kernel-based learning tasks are also provided. Finally, the close connections of the presented framework with several big data tasks, such as network visualization, decentralized and dynamic estimation, prediction, and imputation of network link load traffic, as well as imputation in tensor-based medical imaging are highlighted.},
  Doi                      = {10.1109/MSP.2014.2327238},
  ISSN                     = {1053-5888},
  Keywords                 = {Big Data,Big Data analytics,Big data,CS,DL,Data models,Data storage,Information technology,PCA,SP-relevant data analytic tasks,Signal processing algorithms,Sparse matrices,Statistical analysis,Storage automation,big data tasks,central processors,compressed sensing,compressive sampling,data analysis,data deluge era,data science,data-sketching,decentralized estimation,decentralized learning problems,dictionary learning,dynamic estimation,kernel-based learning tasks,large data volumes,learning (artificial intelligence),modeling,network link load traffic,network visualization,online learning problems,optimisation,optimization algorithms,pervasive sensors,principal component analysis,quality of life,scalable architectures,signal processing,signal sampling,statistical learning tools,storage units,subspace clustering,tensor-based learning tasks,tensor-based medical imaging,voluminous data sets},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This article contributes to the ongoing cross-disciplinary efforts in data science by putting forth encompassing models capturing a wide range of SP-relevant data analytic tasks, such as principal component analysis (PCA), dictionary learning (DL), compressive sampling (CS), and subspace clustering. It offers scalable architectures and optimization algorithms for decentralized and online learning problems This article seems like a discussion piece, so not sure if their contributions are innovative. 1,2,6},
  Shorttitle               = {Signal Processing Magazine, IEEE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6879577}
}

@Article{Song2009,
  Title                    = {Process neural network modeling for real time short-term traffic flow prediction},
  Author                   = {Song, G.-J.a and Hu, C.a and Xie, K.-Q.a and Peng, R.b },
  Journal                  = {Journal of Traffic and Transportation Engineering},
  Year                     = {2009},
  Note                     = {cited By (since 1996)6},
  Number                   = {5},
  Pages                    = {73-77},
  Volume                   = {9},

  Abstract                 = {In order to fully utilize the spatio-temporal process characteristic of traffic flow and predict traffic flow in real time, both process neural network and the online learning technology of data stream were imported into short-term traffic prediction. Considering the inherent traffic features of daily-periodicity and weekly-periodicity, process neural network and wavelet transform were combined to deal with the multi-scale process characteristic of historical data. A road network prediction model was constructed, and was optimized by adopting principal component analysis and utilizing the influence of traffic flow space similarity. An online learning algorithm was proposed based on Harr wavelet technology, which has the characteristics of self-adaptability and real-time prediction. Experimental result shows that the forecasting accuracy of the model is better than ordinary neural networks, its relative error of mean percentage reduces by 6% Ã¢Ë†Â¼ 8%, and its prediction time reduces by 67% at least, so the model has good performance and can meet the demand of real-time prediction of short-term traffic flow.},
  Affiliation              = {Key Laboratory of Machine Perception, Ministry of Education, Peking University, Beijing 100871, China; TECH Traffic Engineering Co., Ltd., Beijing 100083, China},
  Author_keywords          = {Process neural network; Short-time traffic flow; Traffic prediction; Wavelet transform},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A road network prediction model was constructed, and was optimized by adopting principal component analysis and utilizing the influence of traffic flow space similarity. An online learning algorithm was proposed based on Harr wavelet technology, which has the characteristics of self-adaptability and real-time prediction. Experimental result shows that the forecasting accuracy of the model is better than ordinary neural networks. 2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-74549124286&partnerID=40&md5=fa3d570e51fe327f5beef6150ac077da}
}

@Article{Song2004,
  Title                    = {Estimation and maintenance of frequent pattern on data streams},
  Author                   = {Song, G.-J. and Tang, S.-W. and Yang, D.-Q. and Wang, T.-J.},
  Journal                  = {Ruan Jian Xue Bao/Journal of Software},
  Year                     = {2004},
  Note                     = {cited By (since 1996)0},
  Number                   = {SUPPL.},
  Pages                    = {20-27},
  Volume                   = {15},

  Abstract                 = {In this paper, the methods are investigate for online, frequent pattern mining of stream data, with the following contributions: (1) based on heuristic methodology and sample theory, step-by-step data stream mining method is used to estimate potential pattern set; (2) will find any length pattern not only single item pattern; (3) to find more appropriate length of each segment satisfying accuracy requirement, Hoeffding bound theory was introduced and revised to make it more suit for pattern mining; (4) a maintenance approach for estimating frequent patterns is developed for on-line analysis. Based on this design, estimation and maintenance algorithms are proposed for efficient analysis of data streams. This performance study compares the proposed algorithms and identifies the most accuracy-, memory- and time- efficient algorithms for stream data analysis.},
  Affiliation              = {Sch. of Electron. Eng., Peking Univ., Beijing 100871, China},
  Author_keywords          = {Data stream mining; Frequent pattern; Heuristic method; Hoeffding bounds; Sample},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, the methods are investigate for online, frequent pattern mining of stream data. This performance study compares the proposed algorithms and identifies the most accuracy-, memory- and time- efficient algorithms for stream data analysis. SHitty english, but could be interesting. 10 years old though. 3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-10644252924&partnerID=40&md5=aceb7a3782debcd4c7241d015594aae8}
}

@Misc{Soundararaj,
  Title                    = {{Vision-Controlled Autonomous Indoor Helicopter}},

  Author                   = {Soundararaj, Sai Prashanth and Sujeeth, Arvind},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Indoor navigation of aerial vehicles poses several challenges in sustaining hover flights. The key challenges are the high presence of obstacles in constrained environments, frugal payload budget and the need for real-time control response. In this paper, we describe a successful application of computer vision and machine learning techniques for autonomous panning of RC helicopters in fixed indoor settings. Our framework uses images of the environment to ‘learn ’ its surrounding and perform attitude estimation on live-streaming data from an onboard wireless camera using the learned model. We then detail the design of our controller, capable of hovering the helicopter in place, sustaining orientation with respect to reference points and following panning trajectories. Finally, we present test results based on simulations and actual autonomous test flights.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. about controlling hover flights.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.217.3033}
}

@Conference{Sow2010a,
  Title                    = {Body sensor data processing using stream computing},
  Author                   = {Sow, D. and Biem, A. and Blount, M. and Ebling, M. and Verscheure, O.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)2},
  Pages                    = {449-457},

  Abstract                 = {Advances in sensor technologies have accelerated the instrumentation of medical institutions. Today, modern intensive care units use sophisticated patient monitoring systems able to produce massive amounts of physiological streaming data. While these monitoring systems aim at improving patient care and staff productivity, they have the potential of introducing a data explosion problem. We address this problem by developing an open infrastructure upon which healthcare analytics can be built, managed, and deployed to analyze in real time physiological streaming data and turn this data into meaningful information for medical professionals. This infrastructure incorporates feature extraction and data mining functionalities for the discovery of clinical rules capable of identifying medically significant events. The system is based on a state of the art stream computing middleware. This paper presents this infrastructure from a programming model perspective. An exemplar application for arrhythmia detection is also described to illustrate its capabilities. Copyright 2010 ACM.},
  Affiliation              = {IBM T. J. Watson Research Center, 19 Skyline Drive, Hawthorne, NY 10532, United States},
  Author_keywords          = {Distributed computing; Healthcare; Patient monitoring; Stream computing},
  Document_type            = {Conference Paper},
  Journal                  = {MIR 2010 - Proceedings of the 2010 ACM SIGMM International Conference on Multimedia Information Retrieval},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They developed an open infrastructure upon which healthcare analytics can be built, managed, and deployed to analyze in real time physiological streaming data and turn this data into meaningful information. This infrastructure incorporates feature extraction and data mining functionalities for the discovery of clinical rules capable of identifying medically significant events 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77952377169&partnerID=40&md5=7d367f36728490ca2aa92e6c22befe61}
}

@Article{Sow2010,
  Title                    = {{Real-time prognosis of ICU physiological data streams.}},
  Author                   = {Sow, Daby and Biem, Alain and Sun, Jimeng and Hu, Jianying and Ebadollahi, Shahram},
  Journal                  = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference},
  Year                     = {2010},

  Month                    = jan,
  Pages                    = {6785--8},
  Volume                   = {2010},

  Abstract                 = {This paper presents a system capable of predicting in real-time the evolution of Intensive Care Unit (ICU) physiological patient data streams. It leverages a state of the art stream computing platform to host analytics capable of making such prognosis in real time. The focus is on online algorithms that do not require a training phase. We use Fading-Memory Polynomial filters [8] on the frequency domain to predict windows of ICU data streams. We report on both the system and the performance of this approach when applied to traces of more than 1500 ICU patients obtained from the MIMIC-II database [1].},
  Doi                      = {10.1109/IEMBS.2010.5625983},
  ISSN                     = {1557-170X},
  Keywords                 = {Algorithms,Databases, Factual,Humans,Intensive Care Units},
  Owner                    = {Alexander},
  Pmid                     = {21095840},
  Qualityassured           = {qualityAssured},
  Review                   = {Sow2010c},
  Shorttitle               = {Engineering in Medicine and Biology Society (EMBC)},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/21095840}
}

@Conference{Sow2010b,
  Title                    = {Real-time prognosis of ICU physiological data streams},
  Author                   = {Sow, D. and Biem, A. and Sun, J. and Hu, J. and Ebadollahi, S.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)1},
  Pages                    = {6785-6788},

  Abstract                 = {This paper presents a system capable of predicting in real-time the evolution of Intensive Care Unit (ICU) physiological patient data streams. It leverages a state of the art stream computing platform to host analytics capable of making such prognosis in real time. The focus is on online algorithms that do not require a training phase. We use Fading- Memory Polynomial filters [8] on the frequency domain to predict windows of ICU data streams. We report on both the system and the performance of this approach when applied to traces of more than 1500 ICU patients obtained from the MIMIC-II database [1]. Ã‚Â© 2010 IEEE.},
  Affiliation              = {IBM T.J. Watson Research Center, New York, United States},
  Art_number               = {5625983},
  Document_type            = {Conference Paper},
  Journal                  = {2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Sow2010c},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650812288&partnerID=40&md5=c1db94f473bd123c7552713f473893e5}
}

@Article{Sow2010c,
  Title                    = {Real-time prognosis of ICU physiological data streams.},
  Author                   = {Sow, D. and Biem, A. and Sun, J. and Hu, J. and Ebadollahi, S.},
  Journal                  = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Pages                    = {6785-6788},

  Abstract                 = {This paper presents a system capable of predicting in real-time the evolution of Intensive Care Unit (ICU) physiological patient data streams. It leverages a state of the art stream computing platform to host analytics capable of making such prognosis in real time. The focus is on online algorithms that do not require a training phase. We use Fading-Memory Polynomial filters [8] on the frequency domain to predict windows of ICU data streams. We report on both the system and the performance of this approach when applied to traces of more than 1500 ICU patients obtained from the MIMIC-II database [1].},
  Affiliation              = {IBM T.J. Watson Research Center, New York, NY, USA.},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents a system capable of predicting in real-time the evolution of Intensive Care Unit (ICU) physiological patient data streams. The focus is on online algorithms that do not require a training phase. They say they based it on a SotA platform. 1,3,(5?)6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84903873677&partnerID=40&md5=18ca7015cfdd39cfc5bcfe3933b4c57e}
}

@Misc{Sridevi,
  Title                    = {{Signature Analysis of UDP Streams for Intrusion Detection using Data Mining Algorithms}},

  Author                   = {Sridevi, R.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {with the increased use of internet for a wide range of activity from simple data search to online commercial transactions, securing the network is extremely important for any organization. Intrusion detection becomes extremely important to secure the network. Conventional techniques for intrusion detection have been successfully deployed, but predictive action can help in protecting the system in the long run. Data mining techniques are being increasingly used to study the data streams and good results have been achieved over time. In this paper we propose to extract unique signatures from UDP data stream, apply existing mining techniques and compare results. We have used the KDD cup 1999 dataset which contains a wide variety of intrusion attacks simulated in a military environment.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {In this paper we propose to extract unique signatures from UDP data stream, apply existing mining techniques and compare results About intrusion detection, but they don't make any new techniques, only compare. approved under uncertainty 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.301.6084}
}

@Article{Stacey2007a,
  Title                    = {Temporal abstraction in intelligent clinical data analysis: A survey},
  Author                   = {Stacey, M. and McGregor, C.},
  Journal                  = {Artificial Intelligence in Medicine},
  Year                     = {2007},
  Note                     = {cited By (since 1996)62},
  Number                   = {1},
  Pages                    = {1-24},
  Volume                   = {39},

  Abstract                 = {Objective: Intelligent clinical data analysis systems require precise qualitative descriptions of data to enable effective and context sensitive interpretation to take place. Temporal abstraction (TA) provides the means to achieve such descriptions, which can then be used as input to a reasoning engine where they are evaluated against a knowledge base to arrive at possible clinical hypotheses. This paper surveys previous research into the development of intelligent clinical data analysis systems that incorporate TA mechanisms and presents research synergies and trends across the research reviewed, especially those associated with the multi-dimensional nature of real-time patient data streams. The motivation for this survey is case study based research into the development of an intelligent real-time, high-frequency patient monitoring system to provide detection of temporal patterns within multiple patient data streams. Results: The survey was based on factors that are of importance to broaden research into temporal abstraction and on characteristics we believe will assume an increasing level of importance for future clinical IDA systems. These factors were: aspects of the data that is abstracted such as source domain and sample frequency, complexity available within abstracted patterns, dimensionality of the TA and data environment and the knowledge and reasoning underpinning TA processes. Conclusion: It is evident from the review that for intelligent clinical data analysis systems to progress into the future where clinical environments are becoming increasingly data-intensive, the ability for managing multi-dimensional aspects of data at high observation and sample frequencies must be provided. Also, the detection of complex patterns within patient data requires higher levels of TA than are presently available. The conflicting matters of computational tractability and temporal reasoning within a real-time environment present a non-trivial problem for investigation in regard to these matters. Finally, to be able to fully exploit the value of learning new knowledge from stored clinical data through data mining and enable its application to data abstraction, the fusion of data mining and TA processes becomes a necessity. Ã‚Â© 2006 Elsevier B.V. All rights reserved.},
  Affiliation              = {Health Informatics Research Group (HIR), School of Computing and Mathematics, University of Western Sydney, Locked Bag 1797, Penrith South DC, 1797 NSW, Australia},
  Author_keywords          = {Decision support systems; Intelligent data analysis; Intensive care; Patient monitoring; Temporal abstraction; Temporal reasoning},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper surveys previous research into the development of intelligent clinical data analysis systems that incorporate TA mechanisms and presents research synergies and trends across the research reviewed, especially those associated with the multi-dimensional nature of real-time patient data streams Discarded, it's a survey of existing papers in medical data analysis.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33845455091&partnerID=40&md5=8c43af3800626c9cdb57f44336f8f5ff}
}

@Conference{Stahl2012,
  Title                    = {ERules: A modular adaptive classification rule learning algorithm for data streams},
  Author                   = {Stahl, F.a and Gaber, M.M.b and Salvador, M.M.a },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {65-78},

  Abstract                 = {Advances in hardware and software in the past decade allow to capture, record and process fast data streams at a large scale. The research area of data stream mining has emerged as a consequence from these advances in order to cope with the real time analysis of potentially large and changing data streams. Examples of data streams include Google searches, credit card transactions, telemetric data and data of continuous chemical production processes. In some cases the data can be processed in batches by traditional data mining approaches. However, in some applications it is required to analyse the data in real time as soon as it is being captured. Such cases are for example if the data stream is infinite, fast changing, or simply too large in size to be stored. One of the most important data mining techniques on data streams is classification. This involves training the classifier on the data stream in real time and adapting it to concept drifts. Most data stream classifiers are based on decision trees. However, it is well known in the data mining community that there is no single optimal algorithm. An algorithm may work well on one or several datasets but badly on others. This paper introduces eRules, a new rule based adaptive classifier for data streams, based on an evolving set of Rules. eRules induces a set of rules that is constantly evaluated and adapted to changes in the data stream by adding new and removing old rules. It is different from the more popular decision tree based classifiers as it tends to leave data instances rather unclassified than forcing a classification that could be wrong. The ongoing development of eRules aims to improve its accuracy further through dynamic parameter setting which will also address the problem of changing feature domain values Ã‚Â© Springer-Verlag London 2012.},
  Affiliation              = {Bournemouth University, School of Design, Engineering and Computing, Talbot Campus, BH12 5BB Poole, United Kingdom; University of Portsmouth, School of Computing, Buckingham Building, Lion Terrace, PO1 3HE, United Kingdom},
  Document_type            = {Conference Paper},
  Journal                  = {Res. and Dev. in Intelligent Syst. XXIX: Incorporating Applications and Innovations in Intel. Sys. XX - AI 2012, 32nd SGAI Int. Conf. on Innovative Techniques and Applications of Artificial Intel.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper introduces eRules, a new rule based adaptive classifier for data streams, based on an evolving set of Rules. It is different from the more popular decision tree based classifiers as it tends to leave data instances rather unclassified than forcing a classification that could be wrong 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84881518277&partnerID=40&md5=7ff3e06545ba456e1fab6af5ddeec04d}
}

@Article{Su2008,
  Title                    = {Adaptive mining of sparse skyline over data stream},
  Author                   = {Su, L. and Zou, P. and Jia, Y.},
  Journal                  = {Zidonghua Xuebao/Acta Automatica Sinica},
  Year                     = {2008},
  Note                     = {cited By (since 1996)1},
  Number                   = {3},
  Pages                    = {360-366},
  Volume                   = {34},

  Abstract                 = {Skyline query set includes the objects that are not 'dominated' by other objects in the dataset. In recent years, skyline query has been becoming a hot research topic due to its potential applications in online services, decision making and real-time monitoring fields. Usually, people care about obtaining the skyline set quickly and progressively in real applications, however, because of the continuity, large-volume, and high-dimension of stream data, mining the sparse skyline set over data stream under control of losing quality is a more meaningful and challenging problem. In this paper, firstly, we propose a novel concept, called sparse-skyline, which uses a skyline object that represents its nearby skyline neighbors within ÃŽÂµ-distance (acceptable difference). Then, two algorithms are developed which adopt correlation coefficient to adjust adaptively the quality of the sparse skyline query. Furthermore, theoretical analysis and experimental results show that the proposed methods are more efficient and effective compared with the existing skyline computing algorithm, and are suitable for data stream applications.},
  Affiliation              = {School of Computer Science, National University of Defense Technology, Changsha 410073, China},
  Author_keywords          = {Adaptive algorithm; Data mining; Data stream; Sparse skyline},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a novel concept, called sparse-skyline, which uses a skyline object that represents its nearby skyline neighbors within µ-distance (acceptable difference). Then, two algorithms are developed which adopt correlation coefficient to adjust adaptively the quality of the sparse skyline query. Furthermore, theoretical analysis and experimental results show that the proposed methods are more efficient and effective compared with the existing skyline computing algorithm, and are suitable for data stream applications. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-42449110037&partnerID=40&md5=b028888cc09e33961f3c98095bde58bf}
}

@Article{Sukhov2004,
  Title                    = {{Network requirements for high-speed real-time multimedia application}},
  Author                   = {Sukhov, Andrei and Calyam, Prasad and Daly, Warren and Iliin, Er},
  Journal                  = {III IPV6 GLOBAL SUMMIT (INTERNET. NEW GENERATION -IPV6},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {High-speed real-time multimedia applications such as Videoconferencing and HDTV have already become popular in many end-user communities. Developing better network protocols and systems that support such applications requires a sound understanding of the voice and video traffic characteristics and factors that ultimately affect end-user perception of audiovisual quality. In this paper we attempt to propose an analytical model for the various network factors whose interdependencies need to be modeled for characterizing enduser perception of audiovisual quality for high-speed real-time multimedia data streams. Towards validating our theory presented in this paper, we describe our initial results and future plans that consist of conducting a series of experiments and potential modifications to our proposed model. As the portion of middle and high-speed RTP (Real-Time Protocols) applications in the total communication over the Internet grows, it is important to understand the behavior of such traffic over the TCP/IP networks. The impetuous growth of traffic volumes and the rapid advances in the technologies of new-generation networks like IPv6 have made it possible for use of such high-speed applications, but with new demands on the network to deliver superior Quality of Service (QoS) to these applications. Our research focuses on the area of quality criteria for middle and high-speed network applications like},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. About networks},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.120.6821}
}

@Misc{Sun,
  Title                    = {{An FPGA Based Adaptive Computing Implementation of Chirp Signal Detection}},

  Author                   = {Sun, Zaino Bassett and Zaino, J. C. and Bassett, R. L. and Sun, T. S. and Smith, J. M. and Pauer, E. K. and Kintigh, S. and Tufts, D. W.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {A technique for linear FM chirp signal detection on a COTS Field Programmable Gate Array (FPGA) based reconfigurable computing testbed has been implemented. The scheme used for signal detection was based on a semi-coherent method originated by Lank, et al[1]. The scheme developed addresses, in an adaptive computing environment, the detection of a family of signals that can be hard to detect at reasonable false alarm rates. The techniques we have demonstrated make it possible to enhance the detection and measurement SNR by 10 to 20 dB (depending on signal pulse widths and excursions) and to process incoming data through hardware at real time rates in excess of 30 Million samples per second. The semi-coherent technique for signal detection was one of three signal processing schemes studied using analytical models as well as Monte-Carlo type simulations. We have illustrated the performance potential of Adaptive Computing technology in high bandwidth data streaming applications. The result...},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. About signal processing},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.5656}
}

@Article{Susnjak2012,
  Title                    = {Adaptive cascade of boosted ensembles for face detection in concept drift},
  Author                   = {Susnjak, T. and Barczak, A.L.C. and Hawick, K.A.},
  Journal                  = {Neural Computing and Applications},
  Year                     = {2012},
  Note                     = {cited By (since 1996)1},
  Number                   = {4},
  Pages                    = {671-682},
  Volume                   = {21},

  Abstract                 = {We propose an adaptive learning algorithm for cascades of boosted ensembles that is designed to handle the problem of concept drift in nonstationary environments. The goal was to create a real-time adaptive algorithm for dynamic environments that exhibit varying degrees of drift in high-volume streaming data. This we achieved using a hybrid of detect-and-retrain and constant-update approaches. The uniqueness of our method is found in two aspects of our framework. The first is the manner in which individual weak classifiers within each cascade layer of an ensemble are clustered during training and assigned a competence value. Secondly, the idea of learning optimal cascade-layer thresholds during runtime, which enables rapid adaptation to dynamic environments. The proposed adaptive learning method was applied to a binary-class problem with rare-event detection characteristics. For this, we chose the domain of face detection and demonstrate experimentally the ability of our algorithm to achieve an effective trade-off between accuracy and speed of adaptations in dense data streams with unknown rates of change. Ã‚Â© 2011 Springer-Verlag London Limited.},
  Affiliation              = {Massey University, Albany, New Zealand},
  Author_keywords          = {AdaBoost; Adaptive learning; Boosting; Cascades; Concept drift; Ensemble-based learning; Face detection; Nonstationary environments},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an adaptive learning algorithm for cascades of boosted ensembles that is designed to handle the problem of concept drift in nonstationary environment. achieved using a hybrid of detect-and-retrain and constant-update approaches. Tested on face detection and the algorithm achieve an effective trade-off between accuracy and speed of adaptations in dense data streams with unknown rates of change. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861192533&partnerID=40&md5=d88db40b802bb4f4455e0fd223df0220}
}

@Conference{Tabatabaei2013a,
  Title                    = {Adaptive budget for online learning},
  Author                   = {Tabatabaei, T.S. and Karray, F. and Kamel, M.S.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {577-583},

  Abstract                 = {Although the perceptron algorithm has been considered a simple supervised learning algorithm, it has the advantage of learning from the training data set one at a time. This makes it more suitable for online learning tasks and new families of kernelized perceptrons have been shown to be effective in handling streaming data. However, the amount of memory required for storing the online model which grows without any limits and the consequent excessive computation and time complexity makes this framework infeasible in real problems. A common solution to this restriction is to limit the allowed budget size and discard some of the examples in the memory when the budget size is exceeded. In this paper we present a framework for choosing a proper adaptive budget size based on underlying properties of data streams. The experimental results on several synthetic and real data sets show the efficiency of our proposed system compared to other algorithms. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Centre for Pattern Analysis and Machine Intelligence, University of Waterloo, Waterloo, ON, Canada},
  Art_number               = {6753972},
  Author_keywords          = {Concept drift; Incremental learning; Online learning},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE 13th International Conference on Data Mining Workshops, ICDMW 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper we present a framework for choosing a proper adaptive budget size based on underlying properties of data streams. The experimental results on several synthetic and real data sets show the efficiency of our proposed system compared to other algorithms Improvements on the perceptron algorithm so that it can be used in an online setting 1,2,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84898047800&partnerID=40&md5=05d6ce0fb3b1d770bf3446da7acc8303}
}

@InProceedings{Tabatabaei2013,
  Title                    = {{Adaptive Budget for Online Learning}},
  Author                   = {Tabatabaei, Talieh S. and Karray, Fakhri and Kamel, Mohamed S.},
  Booktitle                = {2013 IEEE 13th International Conference on Data Mining Workshops},
  Year                     = {2013},
  Month                    = dec,
  Pages                    = {577--583},
  Publisher                = {IEEE},

  Abstract                 = {Although the perceptron algorithm has been considered a simple supervised learning algorithm, it has the advantage of learning from the training data set one at a time. This makes it more suitable for online learning tasks and new families of kernelized perceptrons have been shown to be effective in handling streaming data. However, the amount of memory required for storing the online model which grows without any limits and the consequent excessive computation and time complexity makes this framework infeasible in real problems. A common solution to this restriction is to limit the allowed budget size and discard some of the examples in the memory when the budget size is exceeded. In this paper we present a framework for choosing a proper adaptive budget size based on underlying properties of data streams. The experimental results on several synthetic and real data sets show the efficiency of our proposed system compared to other algorithms.},
  Doi                      = {10.1109/ICDMW.2013.40},
  ISBN                     = {978-1-4799-3142-2},
  Keywords                 = {Algorithm design and analysis,Computational modeling,Data models,Internet,Kernel,Online learning,Prediction algorithms,Support vector machines,adaptive budget size,computational complexity,concept drift,data handling,incremental learning,kernelized perceptrons,learning (artificial intelligence),online learning,perceptron algorithm,perceptrons,real data sets,streaming data handling,supervised learning algorithm,synthetic data sets,time complexity,training data set},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Tabatabaei2013a},
  Shorttitle               = {Data Mining Workshops (ICDMW), 2013 IEEE 13th Inte},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6753972}
}

@Article{Tan2013,
  Title                    = {Efficient data streams based closed frequent itemsets mining algorithm},
  Author                   = {Tan, J.},
  Journal                  = {Applied Mechanics and Materials},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 1},
  Pages                    = {2910-2913},
  Volume                   = {256-259},

  Abstract                 = {Online mining of frequent closed itemsets over streaming data is one of the most important issues in mining data streams. In this paper, we proposed a novel sliding window based algorithm. The algorithm exploits lattice properties to limit the search to frequent close itemsets which share at least one item with the new transaction. Experiments results on synthetic datasets show that our proposed algorithm is both time and space efficient. Ã‚Â© (2013) Trans Tech Publications, Switzerland.},
  Affiliation              = {College of Computer and Information Engineering, Central South University of Forestry and Technology, Changsha, Hunan, China},
  Author_keywords          = {Closed frequent itemsets; Concept lattice; Data streams; Sliding window},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Most likely a newer version of Tan2009a, but the abstract is a little different},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84872953878&partnerID=40&md5=74cb4c2a053ea679fe6a93cda3bfed67}
}

@InProceedings{Tan2009,
  Title                    = {{An Efficient Frequent Closed Itemsets Mining Algorithm Over Data Streams}},
  Author                   = {Tan, Jun and Bu, Yingyong and Yang, Bo},
  Booktitle                = {2009 International Conference on Information Management, Innovation Management and Industrial Engineering},
  Year                     = {2009},
  Pages                    = {65--68},
  Publisher                = {IEEE},
  Volume                   = {3},

  Abstract                 = {Mining frequent closed itemsets provides complete and condensed information for frequent pattern mining. Online mining of frequent closed itemsets over streaming data is one of the most important issues in mining data streams. In this paper, we first present a general methodology to identify closed itemsets over data streams, using concept lattice theory. Using this methodology, we then proposed a novel sliding-window based algorithm which is based on concept lattice incremental restructuring and lattice construction. The algorithm exploits lattice properties to limit the search to frequent close itemsets which share at least one item with the new transaction. A thorough performance study on synthetic datasets has shown that our proposed algorithm is both time and space efficient and adapts very rapidly to the change in data streams.},
  Doi                      = {10.1109/ICIII.2009.326},
  ISBN                     = {978-0-7695-3876-1},
  Keywords                 = {Computer science,Concept lattice,Data mining,Data streams,Educational institutions,Electronic mail,Forestry,Frequent closed itemsets,Industrial engineering,Information management,Innovation management,Itemsets,Lattices,Sliding window,concept lattice incremental restructuring,concept lattice theory,data mining,data streams,efficient frequent closed itemsets mining algorith,lattice construction,pattern mining,sliding-window based algorithm},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate},
  Shorttitle               = {Information Management, Innovation Management and },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5369750}
}

@Conference{Tan2009a,
  Title                    = {An efficient frequent closed itemsets mining algorithm over data streams},
  Author                   = {Tan, J.a b and Bu, Y.a and Yang, B.a },
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Pages                    = {65-68},
  Volume                   = {3},

  Abstract                 = {Mining frequent closed itemsets provides complete and condensed information for frequent pattern mining. Online mining of frequent closed itemsets over streaming data is one of the most important issues in mining data streams. In this paper, we first present a general methodology to identify closed itemsets over data streams, using concept lattice theory. Using this methodology, we then proposed a novel slidingwindow based algorithm which is based on concept lattice incremental restructuring and lattice construction. The algorithm exploits lattice properties to limit the search to frequent close itemsets which share at least one item with the new transaction. A thorough performance study on synthetic datasets has shown that our proposed algorithm is both time and space efficient and adapts very rapidly to the change in data streams. Ã‚Â© 2009 IEEE.},
  Affiliation              = {College of Mechanical and Electrical Engineering, Central South University, Changsha, Hunan Province, China; College of Computer Science, Central South University, Forestry and Technology University, Changsha, Hunan Province, China},
  Art_number               = {5369750},
  Author_keywords          = {Concept lattice; Data streams; Frequent closed itemsets; Sliding window},
  Document_type            = {Conference Paper},
  Journal                  = {2009 International Conference on Information Management, Innovation Management and Industrial Engineering, ICIII 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The paper first present a general methodology for identifying closed itemsets, then presents a sliding-window algorithm based on lattices. Uses synthetic data sets, and proves that the algorithm is time and space efficient and adapth rapidly to change. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77649332551&partnerID=40&md5=d322f4ce0f83f7577c75bdc336c76b36}
}

@Article{Tanbeer2010,
  Title                    = {Mining regular patterns in data streams},
  Author                   = {Tanbeer, S.K. and Ahmed, C.F. and Jeong, B.-S.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2010},
  Note                     = {cited By (since 1996)3},
  Number                   = {PART 1},
  Pages                    = {399-413},
  Volume                   = {5981 LNCS},

  Abstract                 = {Discovering interesting patterns from high-speed data streams is a challenging problem in data mining. Recently, the support metric-based frequent pattern mining from data stream has achieved a great attention. However, the occurrence frequency of a pattern may not be an appropriate criterion for discovering meaningful patterns. Temporal regularity in occurrence behavior can be a key criterion for assessing the importance of patterns in several online applications such as market basket analysis, gene data analysis, network monitoring, and stock market. A pattern can be said regular if its occurrence behavior satisfies a user-given interval in the data steam. Mining regular patterns from static databases has recently been addressed. However, even though mining regular patterns from stream data is extremely required in online applications, no such algorithm has been proposed yet. Therefore, in this paper we develop a novel tree structure called Regular Pattern Stream tree (RPS-tree), and an efficient mining technique for discovering regular patterns over data stream. Using a sliding window method the RPS-tree captures the stream content, and with an efficient tree updating mechanism it constantly processes exact stream data when the stream flows. Extensive experimental analyses show that our RPS-tree is highly efficient in discovering regular patterns from a high-speed data stream. Ã‚Â© Springer-Verlag Berlin Heidelberg 2010.},
  Affiliation              = {Department of Computer Engineering, Kyung Hee University, 1 Sochun-dong, Kihung-eup, Youngin-si, Kyonggi-do, 446-701, South Korea},
  Author_keywords          = {Data mining; Data stream; Pattern mining; Regular pattern; Sliding window},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They develop a novel tree structure called Regular Pattern Stream tree (RPS-tree), and an efficient mining technique for discovering regular patterns over data stream. Using a sliding window method the RPS-tree captures the stream content, and with a tree updating mechanism it constantly processes exact stream data when the stream flows. Extensive experimental analyses show that our RPS-tree is highly efficient 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650450578&partnerID=40&md5=e8643cb9acf2aec8b2b9ceb9b9e42d74}
}

@Article{Tang2006,
  Title                    = {Distributed resource allocation for stream data processing},
  Author                   = {Tang, A.a and Liu, Z.b and Xia, C.b and Zhang, L.b },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2006},
  Note                     = {cited By (since 1996)2},
  Pages                    = {91-100},
  Volume                   = {4208 LNCS},

  Abstract                 = {Data streaming applications are becoming more and more common due to the rapid development in the areas such as sensor networks, multimedia streaming, and on-line data mining, etc. These applications are often running in a decentralized, distributed environment. The requirements for processing large volumes of streaming data at real time have posed many great design challenges. It is critical to optimize the ongoing resource consumption of multiple, distributed, cooperating, processing units. In this paper, we consider a generic model for the general stream data processing systems. We address the resource allocation problem for a collection of processing units so as to maximize the weighted sum of the throughput of different streams. Each processing unit may require multiple input data streams simultaneously and produce one or many valuable output streams. Data streams flow through such a system after processing at multiple processing units. Based on this framework, we develop distributed algorithms for finding the best resource allocation schemes in such data stream processing networks. Performance analysis on the optimality and complexity of these algorithms are also provided. Ã‚Â© Springer-Verlag Berlin Heidelberg 2006.},
  Affiliation              = {California Institute of Technology, Department of Electrical Engineering, Pasadena, CA 91125, United States; IBM T.J. Watson Research Center, 19 Skyline Drive, Hawthorne, NY 10532, United States},
  Author_keywords          = {Distributed algorithm; Resource allocation; Stream processing},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {They develop distributed algorithms for finding the best resource allocation schemes in such data stream processing networks. Performance analysis on the optimality and complexity of these algorithms are also provided. Discarded under uncertainty. The main goal is resource allocation, and nothing points to ML being used for this.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33750337744&partnerID=40&md5=ff3fbf4094c32fbcf78fa94d3271aaa7}
}

@Article{Tang2012,
  Title                    = {CMNL-SW algorithm on online mining closed frequent itemsets over data stream},
  Author                   = {Tang, C.a and Wang, P.a and Qu, Y.b },
  Journal                  = {Shuju Caiji Yu Chuli/Journal of Data Acquisition and Processing},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {4},
  Pages                    = {508-513},
  Volume                   = {27},

  Abstract                 = {A new online mining algorithm called the closed map and num list-sliding window (CMNL-SW) is proposed. It uses two data structures, i.e. closed map stores, the closed itemsets, those are mined and the num list stores the number of all different items. Via the simple union operation on item number contained within a new arriving or an old deleting transaction and the intersection operation on certain previous closed itemsets once, it incrementally updates the current sliding window and makes the closed frequent itemsets be output in real time based on the specified thresholds of any user. Theoretical analysis and experimental results of the real datasets, such as mushroom, retail-chain and artificially synthesized datasets T40I10D100K show that the proposed method is superior to the classic algorithms Moment and CFI-Stream in terms of time and space efficiencies, and it has good stability as the number of transactions processed increases and adapts rapidly to the change in data streams.},
  Affiliation              = {College of Information and Communication Engineering, Harbin Engineering University, Harbin, 150001, China; Center of Network Message, Harbin Engineering University, Harbin, 150001, China},
  Author_keywords          = {Closed frequent itemsets; Data stream; Mining algorithm; Sliding window},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A new online mining algorithm called the closed map and num list-sliding window (CMNL-SW) is proposed. Theoretical analysis and experimental results of the real datasets show that the proposed method is superior to the classic algorithms Moment and CFI-Stream in terms of time and space efficiencies, and it has good stability as the number of transactions processed increases and adapts rapidly to the change in data streams. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867156892&partnerID=40&md5=085a03485630b734c6c963ab4561ceab}
}

@InProceedings{Tang2009,
  Title                    = {{Fast Detecting Outliers over Online Data Streams}},
  Author                   = {Tang, Xianghong and Li, Guohui and Chen, Gang},
  Booktitle                = {2009 International Conference on Information Engineering and Computer Science},
  Year                     = {2009},
  Month                    = dec,
  Pages                    = {1--4},
  Publisher                = {IEEE},

  Abstract                 = {How to mine outliers of online data streams in a short time is an unsolved problem. We propose a new outlier factor metric whose name is the frequent pattern contradiction outlier factor called FPCOF for short. FPCOF can easily measure the degree to which each data instance in data streams is considered as an outlier. In order to compute FPCOF, we construct an outlier detection tree (or OD-tree in short) and design a set of algorithms (ODFP-SW). These algorithms can fast compute FPCOF of new incoming elements by incrementally updating them on the OD-tree, and dynamically maintain the candidate outlier sets and FPCOF of the candidate outliers. The results of experiments show that the proposed method not only can efficiently and accurately mine the outliers in online data streams, but also is more scalable than other existing algorithms.},
  Doi                      = {10.1109/ICIECS.2009.5363123},
  ISBN                     = {978-1-4244-4994-1},
  Keywords                 = {Algorithm design and analysis,Computer science,Data mining,Detection algorithms,ODFP-SW,data mining,frequent pattern contradiction outlier factor,online data streams,outlier detection tree,outlier factor metric,outliers detection,outliers mining,trees (mathematics)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {THey propose a new outlier factor metric whose name is the frequent pattern contradiction outlier factor called FPCOF. It can easily measure the degree to which each data instance in data streams is considered as an outlier. The results of experiments show that the proposed method not only can efficiently and accurately mine the outliers in online data streams, but also is more scalable than other existing algorithms. 1.2.3.4.6},
  Shorttitle               = {Information Engineering and Computer Science, 2009},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5363123}
}

@Article{Tang2013,
  Title                    = {{Autopipelining for Data Stream Processing}},
  Author                   = {Tang, Yuzhe and Gedik, Bugra},
  Journal                  = {IEEE Transactions on Parallel and Distributed Systems},
  Year                     = {2013},

  Month                    = dec,
  Number                   = {12},
  Pages                    = {2344--2354},
  Volume                   = {24},

  Abstract                 = {Stream processing applications use online analytics to ingest high-rate data sources, process them on-the-fly, and generate live results in a timely manner. The data flow graph representation of these applications facilitates the specification of stream computing tasks with ease, and also lends itself to possible runtime exploitation of parallelization on multicore processors. While the data flow graphs naturally contain a rich set of parallelization opportunities, exploiting them is challenging due to the combinatorial number of possible configurations. Furthermore, the best configuration is dynamic in nature; it can differ across multiple runs of the application, and even during different phases of the same run. In this paper, we propose an autopipelining solution that can take advantage of multicore processors to improve throughput of streaming applications, in an effective and transparent way. The solution is effective in the sense that it provides good utilization of resources by dynamically finding and exploiting sources of pipeline parallelism in streaming applications. It is transparent in the sense that it does not require any hints from the application developers. As a part of our solution, we describe a light-weight runtime profiling scheme to learn resource usage of operators comprising the application, an optimization algorithm to locate best places in the data flow graph to explore additional parallelism, and an adaptive control scheme to find the right level of parallelism. We have implemented our solution in an industrial-strength stream processing system. Our experimental evaluation based on microbenchmarks, synthetic workloads, as well as real-world applications confirms that our design is effective in optimizing the throughput of stream processing applications without requiring any changes to the application code.},
  Doi                      = {10.1109/TPDS.2012.333},
  ISSN                     = {1045-9219},
  Keywords                 = {Instruction sets,Multicore processing,Parallel processing,Runtime,Stream processing,Streaming media,Throughput,adaptive control,adaptive control scheme,autopipelining,autopipelining solution,data flow graph representation,data flow graphs,data stream processing application,formal specification,high-rate data sources,industrial-strength stream processing system,manufacturing data processing,microbenchmarks,multicore processors,multiprocessing systems,online analytics,optimisation,optimization algorithm,parallel processing,parallelization,parallelization runtime exploitation,pipeline parallelism,pipeline processing,resource allocation,resources utilization,runtime profiling scheme,stream computing task specification,synthetic workloads},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an autopipelining solution that can take advantage of multicore processors to improve throughput of streaming applications, in an effective and transparent way. They propose optimization algorithm to locate the best places in the data flow graph to explore paralellism. Their implementation shows good test results.},
  Shorttitle               = {Parallel and Distributed Systems, IEEE Transaction},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6381402}
}

@Misc{Tao,
  Title                    = {{Mining Frequent Itemsets in Time-Varying Data Streams}},

  Author                   = {Tao, Yingying and \"{O}zsu, M. Tamer},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Mining frequent itemsets in data streams is beneficial to many real-world applications but is also a challenging task since data streams are unbounded and have high arrival rates. Moreover, the distribution of data streams can change over time, which makes the task of maintaining frequent itemsets even harder. In this paper, we propose a falsenegative oriented algorithm, called TWIM, that can find most of the frequent itemsets, detect distribution changes, and update the mining results accordingly. Experimental results show that our algorithm performs as good as other false-negative algorithms on data streams without distribution change, and has the ability to detect changes over time-varying data streams in real-time with a high accuracy rate.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THey propose a falsenegative oriented algorithm, called TWIM, that can find most of the frequent itemsets. Experimental results show that the algorithm performs as good as other false-negative algorithms on data streams without distribution change, and has the ability to detect changes over time-varying data streams in real-time with a high accuracy rate. "Performs as good as others", nothing revolutionary here then 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.147.7376}
}

@Misc{Taoa,
  Title                    = {{Efficient Decision Tree Construction for Mining Time-Varying Data Streams}},

  Author                   = {Tao, Yingying and \"{O}zsu, M. Tamer},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Mining streaming data has been an active research area to address requirements of applications, such as financial marketing, telecommunication, network monitoring, and so on. A popular technique for mining these continuous and fast-arriving data streams is decision trees. The accuracy of decision trees can deteriorate if the distribution of values in the stream changes over time. In this paper, we propose an approach based on decision trees that can detect distribution changes and re-align the decision tree quickly to reflect the change. The technique exploits a set of synopses on the leaf nodes, which are also used to prune the decision tree. Experimental results demonstrate that the proposed approach can detect the distribution changes in real-time with high accuracy, and re-aligning a decision tree can improve its performance in clustering the subsequent data stream tuples},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Tao2010},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.148.3562}
}

@InProceedings{Tao2009a,
  Title                    = {{Efficient decision tree construction for mining time-varying data streams}},
  Author                   = {Tao, Yingying and \"{O}zsu, M. Tamer},
  Booktitle                = {Proceedings of the 2009 Conference of the Center for Advanced Studies on Collaborative Research - CASCON '09},
  Year                     = {2009},

  Address                  = {New York, New York, USA},
  Month                    = nov,
  Pages                    = {43},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/1723028.1723036},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Tao2010},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1723028.1723036}
}

@Article{Tao2010,
  Title                    = {Efficient decision tree re-alignment for clustering time-changing data streams},
  Author                   = {Tao, Y. and Ãƒâ€“zsu, M.T.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2010},
  Note                     = {cited By (since 1996)1},
  Pages                    = {20-43},
  Volume                   = {6462 LNCS},

  Abstract                 = {Mining streaming data has been an active research area to address requirements of applications, such as financial marketing, telecommunication, network monitoring, and so on. A popular technique for mining these continuous and fast-arriving data streams is decision trees. The accuracy of decision trees can deteriorate if the distribution of values in the stream changes over time. In this paper, we propose an approach based on decision trees that can detect distribution changes and re-align the decision tree quickly to reflect the change. The technique exploits a set of synopses on the leaf nodes, which are also used to prune the decision tree. Experimental results demonstrate that the proposed approach can detect the distribution changes in real-time with high accuracy, and re-aligning a decision tree can improve its performance in clustering the subsequent data stream tuples. Ã‚Â© 2010 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {University of Waterloo, Waterloo, ON, Canada},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THey propose an approach based on decision trees that can detect distribution changes and re-align the decision tree quickly to reflect the change. Experimental results demonstrate that the proposed approach can detect the distribution changes in real-time with high accuracy, and re-aligning a decision tree can improve its performance in clustering the subsequent data stream tuples 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650444095&partnerID=40&md5=abdc031305b0c43dcb111f5a28e65929}
}

@Conference{Tao2009,
  Title                    = {Efficient decision tree construction for mining time-varying data streams},
  Author                   = {Tao, Y. and Ãƒâ€“zsu, M.T.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {43-57},

  Abstract                 = {Mining streaming data has been an active research area to address requirements of applications, such as financial marketing, telecommunication, network monitoring, and so on. A popular technique for mining these continuous and fast-arriving data streams is decision trees. The accuracy of decision trees can deteriorate if the distribution of values in the stream changes over time. In this paper, we propose an approach based on decision trees that can detect distribution changes and re-align the decision tree quickly to reflect the change. The technique exploits a set of synopses on the leaf nodes, which are also used to prune the decision tree. Experimental results demonstrate that the proposed approach can detect the distribution changes in real-time with high accuracy, and re-aligning a decision tree can improve its performance in clustering the subsequent data stream tuples. Copyright Ã‚Â© 2009 Yingying Tao and M. Tamer Ãƒâ€“zsu.},
  Affiliation              = {University of Waterloo, Waterloo, ON, Canada},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2009 Conference of the Center for Advanced Studies on Collaborative Research, CASCON '09},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Tao2010},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77951548227&partnerID=40&md5=2690be0de0f4f0556f38db8c81b175c1}
}

@Article{Tapson2013a,
  Title                    = {Learning the pseudoinverse solution to network weights},
  Author                   = {Tapson, J. and van Schaik, A.},
  Journal                  = {Neural Networks},
  Year                     = {2013},
  Note                     = {cited By (since 1996)6},
  Pages                    = {94-100},
  Volume                   = {45},

  Abstract                 = {The last decade has seen the parallel emergence in computational neuroscience and machine learning of neural network structures which spread the input signal randomly to a higher dimensional space; perform a nonlinear activation; and then solve for a regression or classification output by means of a mathematical pseudoinverse operation. In the field of neuromorphic engineering, these methods are increasingly popular for synthesizing biologically plausible neural networks, but the "learning method"-computation of the pseudoinverse by singular value decomposition-is problematic both for biological plausibility and because it is not an online or an adaptive method. We present an online or incremental method of computing the pseudoinverse precisely, which we argue is biologically plausible as a learning method, and which can be made adaptable for non-stationary data streams. The method is significantly more memory-efficient than the conventional computation of pseudoinverses by singular value decomposition. Ã‚Â© 2013 Elsevier Ltd.},
  Affiliation              = {Bioelectronics and Neuroscience Group, MARCS Institute, University of Western Sydney, Building XB, Kingswood Campus, Kingswood 2751 NSW, Australia},
  Author_keywords          = {Biological plausibility; Extreme learning machine; Moore-Penrose pseudoinverse; Neural engineering},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present an online or incremental method of computing the pseudoinverse precisely, which they argue is biologically plausible as a learning method, and which can be made adaptable for non-stationary data streams. Memory efficient compared to conventional computation. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880787590&partnerID=40&md5=4b7a89a18a3060599566c855e0afe29f}
}

@Conference{Tasoulis2011a,
  Title                    = {Statistical data mining of streaming motion data for fall detection in assistive environments},
  Author                   = {Tasoulis, S.K.a and Doukas, C.N.b and Maglogiannis, I.a and Plagianakos, V.P.a },
  Year                     = {2011},
  Note                     = {cited By (since 1996)3},
  Pages                    = {3720-3723},

  Abstract                 = {The analysis of human motion data is interesting for the purpose of activity recognition or emergency event detection, especially in the case of elderly or disabled people living independently in their homes. Several techniques have been proposed for identifying such distress situations using either motion, audio or video sensors on the monitored subject (wearable sensors) or the surrounding environment. The output of such sensors is data streams that require real time recognition, especially in emergency situations, thus traditional classification approaches may not be applicable for immediate alarm triggering or fall prevention. This paper presents a statistical mining methodology that may be used for the specific problem of real time fall detection. Visual data captured from the user's environment, using overhead cameras along with motion data are collected from accelerometers on the subject's body and are fed to the fall detection system. The paper includes the details of the stream data mining methodology incorporated in the system along with an initial evaluation of the achieved accuracy in detecting falls. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Department of Computer Science and Biomedical Informatics, University of Central Greece, Papassiopoulou 24, Lamia, 35100, Greece; Department of Information and Communication Systems Engineering, University of the Aegean, Karlovassi, 83200, Samos, Greece},
  Art_number               = {6090632},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Tasoulis2013},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84055198840&partnerID=40&md5=4fb8348149fb8119fe25f388c1c3b366}
}

@Article{Tasoulis2011b,
  Title                    = {Statistical data mining of streaming motion data for fall detection in assistive environments.},
  Author                   = {Tasoulis, S.K. and Doukas, C.N. and Maglogiannis, I. and Plagianakos, V.P.},
  Journal                  = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {3720-3723},
  Volume                   = {2011},

  Abstract                 = {The analysis of human motion data is interesting for the purpose of activity recognition or emergency event detection, especially in the case of elderly or disabled people living independently in their homes. Several techniques have been proposed for identifying such distress situations using either motion, audio or video sensors on the monitored subject (wearable sensors) or the surrounding environment. The output of such sensors is data streams that require real time recognition, especially in emergency situations, thus traditional classification approaches may not be applicable for immediate alarm triggering or fall prevention. This paper presents a statistical mining methodology that may be used for the specific problem of real time fall detection. Visual data captured from the user's environment, using overhead cameras along with motion data are collected from accelerometers on the subject's body and are fed to the fall detection system. The paper includes the details of the stream data mining methodology incorporated in the system along with an initial evaluation of the achieved accuracy in detecting falls.},
  Affiliation              = {Department of Computer Science and Biomedical Informatics, University of Central Greece, Papassiopoulou 2-4, Lamia 35100, Greece.},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Newer and better abstract in Tasoulis2013},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84863600398&partnerID=40&md5=53c1558b16f7b6b646781cb6f8446502}
}

@Article{Tasoulis2013,
  Title                    = {Statistical data mining of streaming motion data for activity and fall recognition in assistive environments },
  Author                   = {S.K. Tasoulis and C.N. Doukas and V.P. Plagianakos and I. Maglogiannis},
  Journal                  = {Neurocomputing },
  Year                     = {2013},
  Note                     = {Timely Neural Networks Applications in Engineering Selected Papers from the 12th \{EANN\} International Conference, 2011 },
  Number                   = {0},
  Pages                    = {87 - 96},
  Volume                   = {107},

  Abstract                 = {The analysis of human motion data is interesting in the context of activity recognition or emergency event detection, especially in the case of elderly or disabled people living independently in their homes. Several techniques have been proposed for identifying such distress situations using either motion, audio and video sensors on the monitored subject (wearable sensors) or devices installed at the surrounding environment. Visual data captured from the user's environment, using overhead cameras along with motion data, which are collected from accelerometers on the subject's body, can be fed to activity detection systems that can detect emergency situations like falls and injuries. The output of these sensors is data streams that require real time recognition, especially in such emergency situations. In this paper, we study motion and activity related streaming data and we propose classification schemes using traditional classification approaches. However, such approaches may not be always applicable for immediate alarm triggering and fall prevention or when \{CPU\} power and memory resources are limited (e.g.&#xa0;running the detection algorithm on a mobile device such as smartphones). To this end, we also propose a statistical mining methodology that may be used for real time motion data processing. The paper includes details of the stream data analysis methodology incorporated in the activity recognition and fall detection system along with an initial evaluation of the achieved accuracy in detecting falls. The results are promising and indicate that using the proposed methodology real time fall detection is feasible.},
  Doi                      = {http://dx.doi.org/10.1016/j.neucom.2012.08.036},
  ISSN                     = {0925-2312},
  Keywords                 = {Streaming motion data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a statistical mining methodology that may be used for real time motion data processing. The paper includes details of the stream data analysis methodology incorporated in the activity recognition and fall detection system along with an initial evaluation of the achieved accuracy in detecting falls. The results are promising and indicate that using the proposed methodology real time fall detection is feasible. Real time analysis of falling people. maybe not relevant 1,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0925231212007606}
}

@InProceedings{Tekin2013,
  Title                    = {{Distributed online Big Data classification using context information}},
  Author                   = {Tekin, Cem and van der Schaar, Mihaela},
  Booktitle                = {2013 51st Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  Year                     = {2013},
  Month                    = oct,
  Pages                    = {1435--1442},
  Publisher                = {IEEE},

  Abstract                 = {Distributed, online data mining systems have emerged as a result of applications requiring analysis of large amounts of correlated and high-dimensional data produced by multiple distributed data sources. We propose a distributed online data classification framework where data is gathered by distributed data sources and processed by a heterogeneous set of distributed learners which learn online, at run-time, how to classify the different data streams either by using their locally available classification functions or by helping each other by classifying each other's data. Importantly, since the data is gathered at different locations, sending the data to another learner to process incurs additional costs such as delays, and hence this will be only beneficial if the benefits obtained from a better classification will exceed the costs. We model the problem of joint classification by the distributed and heterogeneous learners from multiple data sources as a distributed contextual bandit problem where each data is characterized by a specific context. We develop a distributed online learning algorithm for which we can prove sublinear regret. Compared to prior work in distributed online data mining, our work is the first to provide analytic regret results characterizing the performance of the proposed algorithm.},
  Doi                      = {10.1109/Allerton.2013.6736696},
  ISBN                     = {978-1-4799-3410-2},
  Keywords                 = {Accuracy,Big Data,Context,Data mining,Distributed databases,Nickel,Partitioning algorithms,Training,available classification functions,context information,data mining,distributed contextual bandit problem,distributed learners,distributed online big data classification framewo,distributed online data mining,distributed online learning algorithm,high dimensional data,learning (artificial intelligence),multiple data sources,multiple distributed data sources,online data mining systems,sublinear regret},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Tekin2013a},
  Shorttitle               = {Communication, Control, and Computing (Allerton), },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6736696}
}

@Conference{Tekin2013a,
  Title                    = {Distributed online big data classification using context information},
  Author                   = {Tekin, C. and Van Der Schaar, M.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1435-1442},

  Abstract                 = {Distributed, online data mining systems have emerged as a result of applications requiring analysis of large amounts of correlated and high-dimensional data produced by multiple distributed data sources. We propose a distributed online data classification framework where data is gathered by distributed data sources and processed by a heterogeneous set of distributed learners which learn online, at run-time, how to classify the different data streams either by using their locally available classification functions or by helping each other by classifying each other's data. Importantly, since the data is gathered at different locations, sending the data to another learner to process incurs additional costs such as delays, and hence this will be only beneficial if the benefits obtained from a better classification will exceed the costs. We model the problem of joint classification by the distributed and heterogeneous learners from multiple data sources as a distributed contextual bandit problem where each data is characterized by a specific context. We develop a distributed online learning algorithm for which we can prove sublinear regret. Compared to prior work in distributed online data mining, our work is the first to provide analytic regret results characterizing the performance of the proposed algorithm. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Dept. of Electrical Engineering, University of California, Los Angeles, CA, United States},
  Art_number               = {6736696},
  Document_type            = {Conference Paper},
  Journal                  = {2013 51st Annual Allerton Conference on Communication, Control, and Computing, Allerton 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They develop a distributed online learning algorithm for which we can prove sublinear regret. Compared to prior work in distributed online data mining, our work is the first to provide analytic regret results characterizing the performance of the proposed algorithm Online learning for classifying data streams. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84897696286&partnerID=40&md5=f241eca60b18ff4f186fc676cdde18e2}
}

@InCollection{Teng2003,
  Title                    = {A Regression-Based Temporal Pattern Mining Scheme for Data Streams },
  Author                   = {Wei-Guang Teng and Ming-Syan Chen and Philip S. Yu},
  Booktitle                = {Proceedings 2003 \{VLDB\} Conference },
  Publisher                = {Morgan Kaufmann},
  Year                     = {2003},

  Address                  = {San Francisco},
  Editor                   = {Freytag, Johann-Christoph and Lockemann, Peter and Abiteboul, Serge and Carey, Michael and Selinger, Patricia and Heuer, Andreas},
  Pages                    = {93 - 104},

  Abstract                 = {Publisher Summary This chapter develops a regression-based algorithm, frequent temporal patterns of data streams (FTP-DS), to mine frequent temporal patterns for data streams. Algorithm FTP-DS has two major features, namely, one data scan for online statistics collection and regression-based compact pattern representation, which are designed to address the time and the space constraints respectively in a data stream environment. With these features, algorithm FTP-DS is able to not only conduct mining with variable time intervals but also perform trend detection effectively. The experimental results show, while, allowing one data scan to meet the time and space constraints in a data stream environment, FTP-DS is able to obtain the mining results of very good quality. Moreover, sensitivity analysis on the lift of support threshold has also been conducted to provide more insights into algorithm FTP-DS. The chapter also develops the techniques of the segmentation tuning and segment relaxation to enhance the functions of FTP-DS.},
  Doi                      = {http://dx.doi.org/10.1016/B978-012722442-8/50017-3},
  ISBN                     = {978-0-12-722442-8},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Teng2003b},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780127224428500173}
}

@Article{Teng2003a,
  Title                    = {{A regression-based temporal pattern mining scheme for data streams}},
  Author                   = {Teng, Wei-Guang and Chen, Ming-Syan and Yu, Philip S.},
  Year                     = {2003},

  Month                    = sep,
  Pages                    = {93--104},

  Abstract                 = {We devise in this paper a regression-based algorithm, called algorithm FTP-DS (Frequent Temporal Patterns of Data Streams), to mine frequent temporal patterns for data streams. While providing a general framework of pattern frequency counting, algorithm FTP-DS has two major features, namely one data scan for online statistics collection and regression-based compact pattern representation.To attain the feature of one data scan, the data segmentation and the pattern growth scenarios are explored for the frequency counting purpose. Algorithm FTP-DS scans online transaction flows and generates candidate frequent patterns in real time. The second important feature of algorithm FTP-DS is on the regression-based compact pattern representation. Specifically, to meet the space constraint, we devise for pattern representation a compact ATF (standing for Accumulated Time and Frequency) form to aggregately comprise all the information required for regression analysis. In addition, we develop the techniques of the segmentation tuning and segment relaxation to enhance the functions of FTP-DS. With these features, algorithm FTP-DS is able to not only conduct mining with variable time intervals but also perform trend detection effectively. Synthetic data and a real dataset which contains net-Permission work alarm logs from a major telecommunication company are utilized to verify the feasibility of algorithm FTP-DS.},
  ISBN                     = {0-12-722442-4},
  Owner                    = {alex},
  Publisher                = {VLDB Endowment},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Teng2003b},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1315451.1315461}
}

@Article{Teng2003b,
  Title                    = {{A regression-based temporal pattern mining scheme for data streams}},
  Author                   = {Teng, Wei-guang and Chen, Ming-syan and Yu, Philip S.},
  Journal                  = {IN VLDB},
  Year                     = {2003},
  Pages                    = {93 -- 104},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We devise in this paper a regression-based algorithm, called algorithm FTP-DS (Frequent Temporal Patterns of Data Streams), to mine frequent temporal patterns for data streams. While providing a general framework of pattern frequency counting, algorithm FTP-DS has two major features, namely one data scan for online statistics collection and regression-based compact pattern representation.To attain the feature of one data scan, the data segmentation and the pattern growth scenarios are explored for the frequency counting purpose. Algorithm FTP-DS scans online transaction flows and generates candidate frequent patterns in real time. The second important feature of algorithm FTP-DS is on the regression-based compact pattern representation. Specifically, to meet the space constraint, we devise for pattern representation a compact ATF (standing for Accumulated Time and Frequency) form to aggregately comprise all the information required for regression analysis. In addition, we develop the techniques of the segmentation tuning and segment relaxation to enhance the functions of FTP-DS. With these features, algorithm FTP-DS is able to not only conduct mining with variable time intervals but also perform trend detection effectively. Synthetic data and a real dataset which contains net-Permission work alarm logs from a major telecommunication company are utilized to verify the feasibility of algorithm FTP-DS.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a regression-based algorithm, called algorithm FTP-DS (Frequent Temporal Patterns of Data Streams), to mine frequent temporal patterns for data streams. The algorithm is able to not only conduct mining with variable time intervals but also perform trend detection effectively. Synthetic data and a real dataset which contains net-Permission work alarm logs from a major telecommunication company are utilized to verify the feasibility of algorithm},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.81.6412}
}

@InProceedings{Thakkar2011,
  Title                    = {{SMM: A data stream management system for knowledge discovery}},
  Author                   = {Thakkar, Hetal and Laptev, Nikolay and Mousavi, Hamid and Mozafari, Barzan and Russo, Vincenzo and Zaniolo, Carlo},
  Booktitle                = {2011 IEEE 27th International Conference on Data Engineering},
  Year                     = {2011},
  Month                    = apr,
  Pages                    = {757--768},
  Publisher                = {IEEE},

  Abstract                 = {The problem of supporting data mining applications proved to be difficult for database management systems and it is now proving to be very challenging for data stream management systems (DSMSs), where the limitations of SQL are made even more severe by the requirements of continuous queries. The major technical advances that achieved separately on DSMSs and on data stream mining algorithms have failed to converge and produce powerful data stream mining systems. Such systems, however, are essential since the traditional pull-based approach of cache mining is no longer applicable, and the push-based computing mode of data streams and their bursty traffic complicate application development. For instance, to write mining applications with quality of service (QoS) levels approaching those of DSMSs, a mining analyst would have to contend with many arduous tasks, such as support for data buffering, complex storage and retrieval methods, scheduling, fault-tolerance, synopsis-management, load shedding, and query optimization. Our Stream Mill Miner (SMM) system solves these problems by providing a data stream mining workbench that combines the ease of specifying high-level mining tasks, as in Weka, with the performance and QoS guarantees of a DSMS. This is accomplished in three main steps. The first is an open and extensible DSMS architecture where KDD queries can be easily expressed as user-defined aggregates (UDAs) - our system combines that with the efficiency of synoptic data structures and mining-aware load shedding and optimizations. The second key component of SMM is its integrated library of fast mining algorithms that are light enough to be effective on data streams. The third advanced feature of SMM is a Mining Model Definition Language (MMDL) that allows users to define the flow of mining tasks, integrated with a simple box\&arrow GUI, to shield the mining analyst from the complexities of lower-level queries. SMM is the first DSMS capable of online mining and t his paper describes its architecture, design, and performance on mining queries.},
  Doi                      = {10.1109/ICDE.2011.5767879},
  ISBN                     = {978-1-4244-8959-6},
  ISSN                     = {1063-6382},
  Keywords                 = {Aggregates,DSMS architecture,Data mining,Graphical user interfaces,Humidity,KDD query,Libraries,Quality of service,SMM,SQL,Training,cache mining,data buffering,data mining,data mining application,data stream management system,database management system,database management systems,fault tolerance,integrated library,knowledge discovery,mining aware load shedding,mining model definition language,pull based approach,push based computing mode,quality of service level,query languages,query optimization,query processing,retrieval method,stream mill miner system,synopsis management,synoptic data structure,user defined aggregate},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Thakkar2011a},
  Shorttitle               = {Data Engineering (ICDE), 2011 IEEE 27th Internatio},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5767879}
}

@Conference{Thakkar2011a,
  Title                    = {SMM: A data stream management system for knowledge discovery},
  Author                   = {Thakkar, H.a and Laptev, N.b and Mousavi, H.b and Mozafari, B.b and Russo, V.c and Zaniolo, C.b },
  Year                     = {2011},
  Note                     = {cited By (since 1996)6},
  Pages                    = {757-768},

  Abstract                 = {The problem of supporting data mining applications proved to be difficult for database management systems and it is now proving to be very challenging for data stream management systems (DSMSs), where the limitations of SQL are made even more severe by the requirements of continuous queries. The major technical advances that achieved separately on DSMSs and on data stream mining algorithms have failed to converge and produce powerful data stream mining systems. Such systems, however, are essential since the traditional pull-based approach of cache mining is no longer applicable, and the push-based computing mode of data streams and their bursty traffic complicate application development. For instance, to write mining applications with quality of service (QoS) levels approaching those of DSMSs, a mining analyst would have to contend with many arduous tasks, such as support for data buffering, complex storage and retrieval methods, scheduling, fault-tolerance, synopsis-management, load shedding, and query optimization. Our Stream Mill Miner (SMM) system solves these problems by providing a data stream mining workbench that combines the ease of specifying high-level mining tasks, as in Weka, with the performance and QoS guarantees of a DSMS. This is accomplished in three main steps. The first is an open and extensible DSMS architecture where KDD queries can be easily expressed as user-defined aggregates (UDAs)our system combines that with the efficiency of synoptic data structures and mining-aware load shedding and optimizations. The second key component of SMM is its integrated library of fast mining algorithms that are light enough to be effective on data streams. The third advanced feature of SMM is a Mining Model Definition Language (MMDL) that allows users to define the flow of mining tasks, integrated with a simple box&arrow GUI, to shield the mining analyst from the complexities of lower-level queries. SMM is the first DSMS capable of online mining and this paper describes its architecture, design, and performance on mining queries. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Google Inc., UCLA, United States; Computer Science Department, UCLA, United States; ICAR/CNR, Italy},
  Art_number               = {5767879},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Our Stream Mill Miner (SMM) system solves these problems by providing a data stream mining workbench that combines the ease of specifying high-level mining tasks, as in Weka, with the performance and QoS guarantees of a DSMS. SMM is the first DSMS capable of online mining and t his paper describes its architecture, design, and performance on mining queries. Seems to be an extension of Thakkar2008a 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79957835980&partnerID=40&md5=60e3a3d81a1643a3d55fa9604bc1b7c3}
}

@Misc{Thakkar,
  Title                    = {{Designing an Inductive Data Stream Management System: the Stream Mill Experience}},

  Author                   = {Thakkar, Hetal and Mozafari, Barzan and Zaniolo, Carlo},

  __markedentry            = {[Alexander:]},
  Abstract                 = {There has been much recent interest in on-line data mining. Existing mining algorithms designed for stored data are either not applicable or not effective on data streams, where real-time response is often needed and data characteristics change frequently. Therefore, researchers have been focusing on designing new and improved algorithms for on-line mining tasks, such as classification, clustering, frequent itemsets mining, pattern matching, etc. Relatively little attention has been paid to designing DSMSs, which facilitate and integrate the task of mining data streams—i.e., stream systems that provide Inductive functionalities analogous to those provided by Weka and MS OLE DB for stored data. In this paper, we propose the notion of an Inductive DSMS—a system that besides providing a rich library of inter-operable functions to support the whole mining process, also supports the essentials of DSMS, including optimization of continuous queries, load shedding, synoptic constructs, and non-stop computing. Ease-of-use and extensibility are additional desiderata for the proposed Inductive DSMS. We first review the many challenges involved in realizing such a system and then present our approach of extending the Stream Mill DSMS toward that goal. Our system features (i) a powerful query language where mining methods are expressed via aggregates for generic streams and arbitrary windows, (ii) a library of fast and light mining algorithms, and (iii) an architecture that makes it easy to customize and extend existing mining methods and introduce new ones},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.116.3991}
}

@Misc{Thakkara,
  Title                    = {{Continuous Post-Mining of Association Rules in a Data Stream Management System}},

  Author                   = {Thakkar, Hetal and Mozafari, Barzan and Zaniolo, Carlo},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The real-time (or just-on-time) requirement associated with online association rule mining implies the need to expedite the analysis and validation of the many candidate rules, which are typically created from the discovered frequent patterns. Moreover, the mining process, from data cleaning to post-mining, can no longer be structured as a sequence of steps performed by the analyst, but must be streamlined into a workflow supported by an efficient system providing quality of service guarantees that are expected from modern Data Stream Management Systems (DSMSs). This paper describes the architecture and techniques used to achieve this advanced functionality in the Stream Mill Miner (SMM) prototype, an SQL-based DSMS designed to support continuous mining queries.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper describes the architecture and techniques used to achieve this advanced functionality in the Stream Mill Miner (SMM) prototype, an SQL-based DSMS designed to support continuous mining queries. Extension of Thakkar2011a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.161.2407}
}

@InProceedings{Thakkar2008,
  Title                    = {{A Data Stream Mining System}},
  Author                   = {Thakkar, Hetal and Mozafari, Barzan and Zaniolo, Carlo},
  Booktitle                = {2008 IEEE International Conference on Data Mining Workshops},
  Year                     = {2008},
  Month                    = dec,
  Pages                    = {987--990},
  Publisher                = {IEEE},

  Abstract                 = {On-line data stream mining has attracted much research interest, but systems that can be used as a workbench for online mining have not been researched, since they pose many difficult research challenges. The proposed system addresses these challenges by an architecture based on three main technical advances, (i) introduction of new constructs and synoptic data structures whereby complex KDD queries can be easily expressed and efficiently supported, (ii) an integrated library of mining algorithms that are fast \& light enough to be effective on data streams, and (iii) support for Mining Model Definition Language (MMDL) that allows users to define new mining algorithms as a set of tasks and flows. Thus, the proposed system provides an extensible workbench for online mining, which is beyond the existing proposals for even static mining.},
  Doi                      = {10.1109/ICDMW.2008.133},
  Keywords                 = {Algorithm design and analysis,Association rules,Buildings,Conferences,Data mining,Data structures,Intrusion detection,Libraries,Milling machines,Proposals,complex KDD queries,data analysis,data mining,data stream mining system,high level mining language,integrated library,mining algorithm,mining model definition language,online data stream mining,online mining,online mining system,query processing,synoptic data structures},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {Seems to be the same as Thakkar2008a},
  Shorttitle               = {Data Mining Workshops, 2008. ICDMW '08. IEEE Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4734034}
}

@Conference{Thakkar2008a,
  Title                    = {Designing an inductive data stream management system: The stream mill experience},
  Author                   = {Thakkar, H. and Mozafari, B. and Zaniolo, C.},
  Year                     = {2008},
  Note                     = {cited By (since 1996)1},
  Pages                    = {79-88},

  Abstract                 = {There has been much recent interest in on-line data mining. Existing mining algorithms designed for stored data are either not applicable or not effective on data streams, where real-time response is often needed and data characteristics change frequently. Therefore, researchers have been focusing on designing new and improved algorithms for on-line mining tasks, such as classification, clustering, frequent itemsets mining, pattern matching, etc. Relatively little attention has been paid to designing DSMSs, which facilitate and integrate the task of mining data streams-i.e., stream systems that provide Inductive functionalities analogous to those provided by Weka and MS OLE DB for stored data. In this paper, we propose the notion of an Inductive DSMS-a system that besides providing a rich library of inter-operable functions to support the whole mining process, also supports the essentials of DSMS, including optimization of continuous queries, load shedding, synoptic constructs, and non-stop computing. Ease-of-use and extensibility are additional desiderata for the proposed Inductive DSMS. We first review the many challenges involved in realizing such a system and then present our approach of extending the Stream Mill DSMS toward that goal. Our system features (i) a powerful query language where mining methods are expressed via aggregates for generic streams and arbitrary windows, (ii) a library of fast and light mining algorithms, and (iii) an architecture that makes it easy to customize and extend existing mining methods and introduce new ones. Copyright 2008 ACM.},
  Affiliation              = {University of California at Los, Angeles, United States},
  Author_keywords          = {Design; Languages; Management},
  Document_type            = {Conference Paper},
  Journal                  = {ACM International Conference Proceeding Series},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THis paper proposes a DSMS (Data Stream Management System), which features (i) a powerful query language where mining methods are expressed via aggregates for generic streams and arbitrary windows, (ii) a library of fast and light mining algorithms, and (iii) an architecture that makes it easy to customize and extend existing mining methods and introduce new ones Approved under uncertainty. 1},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57349149485&partnerID=40&md5=d5cc0aaa0e6cc4cced67f4844e338edb}
}

@Conference{Thakkar2008b,
  Title                    = {A data stream mining system},
  Author                   = {Thakkar, H. and Mozafari, B. and Zaniolo, C.},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Pages                    = {987-990},

  Abstract                 = {On-line data stream mining has attracted much research interest, but systems that can be used as a workbench for online mining have not been researched, since they pose many difficult research challenges. The proposed system addresses these challenges by an architecture based on three main technical advances, (i) introduction of new constructs and synoptic data structures whereby complex KDD queries can be easily expressed and efficiently supported, (ii) an integrated library of mining algorithms that are fast & light enough to be effective on data streams, and (iii) support for Mining Model Definition Language (MMDL) that allows users to define new mining algorithms as a set of tasks and flows. Thus, the proposed system provides an extensible workbench for online mining, which is beyond the existing proposals for even static mining. Ã‚Â© 2008 IEEE.},
  Affiliation              = {University of California, Los Angeles, United States},
  Art_number               = {4734034},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining Workshops, ICDM Workshops 2008},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Seems to be the same as Thakkar2008a},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-62449148418&partnerID=40&md5=600191d96293b35a9580b01b3f62bf7d}
}

@InProceedings{Thakkar2008c,
  Title                    = {{Designing an inductive data stream management system}},
  Author                   = {Thakkar, Hetal and Mozafari, Barzan and Zaniolo, Carlo},
  Booktitle                = {Proceedings of the 2nd international workshop on Scalable stream processing system - SSPS '08},
  Year                     = {2008},

  Address                  = {New York, New York, USA},
  Month                    = mar,
  Pages                    = {79},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/1379272.1379286},
  ISBN                     = {9781595939630},
  Keywords                 = {data stream mining language,data stream mining system,integration of online mining in a DSMS},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Thakkar2008a},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1379272.1379286}
}

@Misc{Thakkar2008d,
  Title                    = {{A Data Stream Mining System}},

  Author                   = {Thakkar, Hetal and Mozafari, Barzan and Zaniolo, Carlo},
  Year                     = {2008},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Seems to be the same as Thakkar2008a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.157.3776}
}

@Book{Thakkar2009,
  Title                    = {Continuous post-mining of association rules in a data stream management system},
  Author                   = {Thakkar, H.a and Mozafari, B.b and Zaniolo, C.a c },
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},

  Abstract                 = {The real-time (or just-on-time) requirement associated with online association rule mining implies the need to expedite the analysis and validation of the many candidate rules, which are typically created from the discovered frequent patterns. Moreover, the mining process, from data cleaning to post-mining, can no longer be structured as a sequence of steps performed by the analyst, but must be streamlined into a workflow supported by an efficient system providing quality of service guarantees that are expected from modern Data Stream Management Systems (DSMSs). This chapter describes the architecture and techniques used to achieve this advanced functionality in the Stream Mill Miner (SMM) prototype, an SQL-based DSMS designed to support continuous mining queries. Ã‚Â© 2009, IGI Global.},
  Affiliation              = {Computer Science Department, University of California, Los Angeles, United States; University of California, Los Angeles, United States; U.S. Research Consortium, Austin, TX, United States},
  Document_type            = {Book Chapter},
  Journal                  = {Post-Mining of Association Rules: Techniques for Effective Knowledge Extraction},
  Owner                    = {Alexander},
  Pages                    = {116-132},
  Qualityassured           = {qualityAssured},
  Review                   = {Just a chapter from a book on designing the DSMS from Thakkar2008a},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84892228404&partnerID=40&md5=e907d2e91a6ce295be6ddb38b1db876d}
}

@Book{Tham2007,
  Title                    = {SensorGrid architecture for distributed event classification},
  Author                   = {Tham, C.-K.},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Recent advances in electronic circuit miniaturisation and micro-electromechanical systems (MEMS) have led to the creation of small sensor nodes which integrate several kinds of sensors, a central processing unit (CPU), memory and a wireless transceiver. A collection of these sensor nodes forms a sensor network which is easily deployable to provide a high degree of visibility into real-world physical processes as they happen, thus benefiting a variety of applications such as environmental monitoring, surveillance and target tracking. Some of these sensor nodes may also incorporate actuators such as buzzers and switches which can affect the environment directly. We shall simply use the generic term sensor node to refer to these sensor-actuator nodes as well. A parallel development in the technology landscape is grid computing, which is essentially the federation of heterogeneous computational servers connected by high-speed network connections. Middleware technologies such as Globus (2006) and Gridbus (2005) enable secure and convenient sharing of resources such as CPU, memory, storage, content and databases by users and applications. This has caused grid computing to be referred to as computing on tap, utility computing and IBMs mantra, on demand computing. Many countries have recognised the importance of grid computing for eScience and the grid has a number of success stories from the fields of bioinformatics, drug design, engineering design, business, manufacturing, and logistics. There is some existing work on the intersecting fields of sensor networks and grid computing which can be broadly grouped into three categories: (1) sensorwebs, (2) sensors to grid, and (3) sensor networks to grid. In the first category of sensorwebs, many different kinds of sensors are connected together through middleware to enable timely and secure access to sensor readings. Examples are the SensorNet effort by the Oak Ridge National Laboratories (ORNL) and NIST (USA) which aims to collect sensor data from different places to facilitate the operations of the emergency services; the IrisNet effort by Intel to create the seeing Internet by enabling data collection and storage, and the support of rich queries over the Internet; and the Department of Defense (USA) ForceNet which integrates many kinds of sensor data to support air, sea and land military operations. In the second category of sensors to grid, the aim is to connect sensors and instruments to the grid to facilitate collaborative scientific research and visualisation (Chiu and Frey 2005). Examples are the efforts by the Internet2 and eScience communities in areas such as the collaborative design of aircraft engines and environment monitoring; DiscoveryNet (Imperial College UK) which aims to perform knowledge discovery and air pollution monitoring; and the earthquake science efforts by the CrisisGrid team (Indiana University USA) and iSERVO (International Solid Earth Research Virtual Observatory). Finally, in the third category of sensor networks to grid, the aim is mainly to use grid web services to integrate sensor networks and enable queries on live data. Examples are efforts by Gaynor et al (2004) to facilitate quicker medical response and supply chain management; and the SPRING framework proposed by Lim et al (2005). Our focus and approach, which we refer to as sensor-grid computing executing on an integrated sensor-grid architecture or simply SensorGrid for short (Tham and Buyya 2005), see Fig. 5.1 builds on the three categories of existing work described above and aims to achieve more by exploiting the complementary strengths and characteristics of sensor networks and grid computing. Sensor-grid computing combines the real-time acquisition and processing of data about the environment by sensor networks with intensive distributed computations on the grid. This enables the construction of real-time models and databases of the environment and physical processes as they unfold, from which high-value computations such as analytics, data mining, decision-making, optimisation and prediction can be carried out to generate on-the-fly results. This powerful combination would enable, for example, effective early warning of threats (such as missiles) and natural disasters, and real-time business process optimisation. One other key aspect of sensor-grid computing is the emphasis on distributed and hierarchical in-network processing at several levels of the SensorGrid architecture. As will be explained later, the sensor-grid computing approach is more robust and scalable compared to other approaches in which computations are mainly performed on the grid itself. The sensor-grid computing approach together with the SensorGrid architecture enable more timely responses to be achieved and useful results to be available even in the presence of failures in some parts of the architecture. The organisation of this chapter is as follows. In Section 2, we describe a simple centralised approach to realise sensor-grid computing. We then point out its weaknesses and propose a distributed approach. In Section 3, we describe two applications of distributed sensor-grid computing which we have implemented. In Section 4, several challenges and research issues related to sensorgrid computing are discussed. Finally, we conclude in Section 5. Ã‚Â© Springer-Verlag Berlin Heidelberg 2007.},
  Affiliation              = {Dept of Electrical and Computer Engineering, National University of Singapore, Singapore, Singapore},
  Document_type            = {Book Chapter},
  Journal                  = {Sensor Networks and Configuration: Fundamentals, Standards, Platforms, and Applications},
  Owner                    = {Alexander},
  Pages                    = {99-117},
  Qualityassured           = {qualityAssured},
  Review                   = {discarded. about sensorgrid, a distributed systems architechture.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84892194330&partnerID=40&md5=5bc68b808bf2db17847b857efd6f2e00}
}

@Article{Theeten2014,
  Title                    = {{Towards the Optimization of a Parallel Streaming Engine for Telco Applications}},
  Author                   = {Theeten, Bart and Bedini, Ivan and Cogan, Peter and Sala, Alessandra and Cucinotta, Tommaso},
  Journal                  = {Bell Labs Technical Journal},
  Year                     = {2014},

  Month                    = mar,
  Number                   = {4},
  Pages                    = {181--197},
  Volume                   = {18},

  Abstract                 = {Parallel and distributed computing is becoming essential to process in real time the increasingly massive volume of data collected by telecommunications companies. Existing computational paradigms such as MapReduce (and its popular open-source implementation Hadoop) provide a scalable, fault tolerant mechanism for large scale batch computations. However, many applications in the telco ecosystem require a real time, incremental streaming approach to process data in real time and enable proactive care. Storm is a scalable, fault tolerant framework for the analysis of real time streaming data. In this paper we provide a motivation for the use of real time streaming analytics in the telco ecosystem. We perform an experimental investigation into the performance of Storm, focusing in particular on the impact of parameter configuration. This investigation reveals that optimal parameter choice is highly non-trivial and we use this as motivation to create a parameter configuration engine. As first steps towards the creation of this engine we provide a deep analysis of the inner workings of Storm and provide a set of models describing data flow cost, central processing unit (CPU) cost, and system management cost. Ã‚Â® 2014 Alcatel-Lucent.},
  Doi                      = {10.1002/bltj.21652},
  ISSN                     = {10897089},
  Keywords                 = {Central Processing Unit,Costs,Data analysis,Distributed processing,Engines,Fault tolerant systems,Flow management,Media streaming,Parallel computing,Real-time systems,Scalability},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper we provide a motivation for the use of real time streaming analytics in the telco ecosystem. We perform an experimental investigation into the performance of Storm, focusing in particular on the impact of parameter configuration. This investigation reveals that optimal parameter choice is highly non-trivial and we use this as motivation to create a parameter configuration engine. About the use of Storm in a telco analytics engine. possible primary source. Only analysis mentioned, no experiments. 1,2,6},
  Shorttitle               = {Bell Labs Technical Journal},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6770354}
}

@Misc{Thombre,
  Title                    = {{Techniques of Data Stream Mining ining for Health Care Application 1}},

  Author                   = {Thombre, Satish and Dongre, Snehalata},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Data stream mining plays a key role to analyze the continuous data. The effective and efficient analysis of this data in such different forms becomes a challenging task. Developments in sensors device, miniaturization of low power microelectronics device, and wireless networks devices are becoming a significant opportunity for good quality of health care services. Signals like ECG, EEG, and BP etc. can be monitor through wireless sensor networks and analyzed with the help of data mining techniques. These real-time signals are continuous in nature and abruptly changing hence there is a need to apply an efficient and concept real-time data stream mining techniques for taking intelligent health care decisions. The high speed and large amount of data set in data stream, the traditional classifier and classification technologies are no more applicable. The important criteria are to handle the ‘concept drift ’ in data streams mining. Data Stream Mining (DSM) process performs data analysis and may uncover important data patterns, knowledge base data, and scientific and medical research data. than the P wave. Flat segments between the above mentioned components are PQ, ST and TP segments. An RR interval, which is the delay between two consecutive QRS complexes, gives us useful information about the action of the heart. The most important parameters for the cardiologists are the durations and the amplitudes of the above mentioned subpatterns.},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {This seems to be a summary of DSM techniques. discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.300.6031}
}

@InProceedings{Thommandram2014,
  Title                    = {{A Rule-Based Temporal Analysis Method for Online Health Analytics and Its Application for Real-Time Detection of Neonatal Spells}},
  Author                   = {Thommandram, Anirudh and Eklund, J. Mikael and McGregor, Carolyn and Pugh, James Edward and James, Andrew G.},
  Booktitle                = {2014 IEEE International Congress on Big Data},
  Year                     = {2014},
  Month                    = jun,
  Pages                    = {470--477},
  Publisher                = {IEEE},

  Abstract                 = {Neonatal spells are cardiorespiratory events that occur in newborn infants with variable combinations of cessation of breathing, decrease in blood oxygen saturation and decrease in heart rate. A system using real-time temporal analysis of physiological data streams to accurately detect pauses in breathing and changes in heart rate and oxygen saturation for classifying neonatal spells is described. The system uses a multidimensional online health analytics environment that supports the acquisition, transmission and real-time processing of high volume, high rate data. A family of algorithms has been developed using IBM InfoSphere Streams, a scalable middleware component for analysing multiple streams of data in real-time. Respiratory pauses are identified by accurately detecting breaths and calculating time intervals between breaths. Changes in heart rate and blood oxygen saturation are identified by both threshold breaches and the detection of relative change by assessing a sliding baseline and generating alerts when values fall out of range. Events detected in individual signals are synced together based on timestamps and assessed using a classifier based on clinical rules to determine a classification of neonatal spells. The output of these algorithms has been shown, in a single use case study with 24 hours of patient data, to detect clinically significant events in heart rate, blood oxygen saturation and pauses in breathing. The accuracy for detecting these is 97.8\%, 98.3\% and 98.9\% respectively. The accuracy for determining spells classifications is 98.9\%. Future research will focus on the clinical validation of these algorithms.},
  Doi                      = {10.1109/BigData.Congress.2014.74},
  ISBN                     = {978-1-4799-5057-7},
  Keywords                 = {Biomedical monitoring,Blood,Heart rate,Impedance,Monitoring,Pediatrics,Real-time systems,neonatal spells,real-time analysis,temporal analysis},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A family of algorithms has been developed using IBM InfoSphere Streams, a scalable middleware component for analysing multiple streams of data in real-time. They identify health signals from patients, and assess them with a classifier The accuracy for detecting sickness is 97.8\%, 98.3\% and 98.9\% respectively. The accuracy for determining spells classifications is 98.9\% Very weak on the ML front, uncertain 1,3,4,6},
  Shorttitle               = {Big Data (BigData Congress), 2014 IEEE Internation},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6906817}
}

@Conference{Thommandram2013a,
  Title                    = {Classifying neonatal spells using real-time temporal analysis of physiological data streams: Algorithm development},
  Author                   = {Thommandram, A.a and Pugh, J.E.a b and Eklund, J.M.a and McGregor, C.a and James, A.G.b c },
  Year                     = {2013},
  Note                     = {cited By (since 1996)7},
  Pages                    = {240-243},

  Abstract                 = {Neonatal spells are cardiorespiratory events that occur in newborn infants with variable combinations of cessation of breathing, decrease in blood oxygen saturation and decrease in heart rate. A system using real-time temporal analysis of physiological data streams to accurately detect pauses in breathing together with changes in heart rate and blood oxygen saturation is described. The system uses a multidimensional online health analytics environment that supports the acquisition, transmission and real-time processing of high volume, high rate data. A family of algorithms has been developed using IBM Infosphere Streams, a scalable middleware component for analysing multiple streams of data in real-time. Respiratory pauses are identified by accurately detecting breaths and by calculating the time interval since the last breath. Changes in heart rate and blood oxygen saturation are identified by both threshold breaches and the detection of relative change. The algorithms detect relative change by assessing a sliding normal baseline and generating alerts when values fall out of range. The output of these algorithms has been shown to detect clinically significant relative changes in both heart rate and blood oxygen saturation in a single use case study. The specificity of the algorithm is 98.5%; the sensitivity is 100%. Future research will focus on the application of these algorithms for the assessment and classification of neonatal spells. Ã‚Â© 2013 IEEE.},
  Affiliation              = {University of Ontario, Institute of Technology, Oshawa, ON, Canada; Hospital for Sick Children, Toronto, ON, Canada; Department of Paediatrics, University of Toronto, Toronto, ON, Canada},
  Art_number               = {6461329},
  Document_type            = {Conference Paper},
  Journal                  = {IEEE EMBS Special Topic Conference on Point-of-Care (POC) Healthcare Technologies: Synergy Towards Better Global Healthcare, PHT 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {newer version in Thommandram2014},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84874561125&partnerID=40&md5=047845975c208555c43a68d209372560}
}

@InProceedings{Thommandram2013,
  Title                    = {{Classifying neonatal spells using real-time temporal analysis of physiological data streams: Algorithm development}},
  Author                   = {Thommandram, Anirudh and Pugh, James Edward and Eklund, J. Mikael and McGregor, Carolyn and James, Andrew G.},
  Booktitle                = {2013 IEEE Point-of-Care Healthcare Technologies (PHT)},
  Year                     = {2013},
  Month                    = jan,
  Pages                    = {240--243},
  Publisher                = {IEEE},

  Abstract                 = {Neonatal spells are cardiorespiratory events that occur in newborn infants with variable combinations of cessation of breathing, decrease in blood oxygen saturation and decrease in heart rate. A system using real-time temporal analysis of physiological data streams to accurately detect pauses in breathing together with changes in heart rate and blood oxygen saturation is described. The system uses a multidimensional online health analytics environment that supports the acquisition, transmission and real-time processing of high volume, high rate data. A family of algorithms has been developed using IBM Infosphere Streams, a scalable middleware component for analysing multiple streams of data in real-time. Respiratory pauses are identified by accurately detecting breaths and by calculating the time interval since the last breath. Changes in heart rate and blood oxygen saturation are identified by both threshold breaches and the detection of relative change. The algorithms detect relative change by assessing a sliding normal baseline and generating alerts when values fall out of range. The output of these algorithms has been shown to detect clinically significant relative changes in both heart rate and blood oxygen saturation in a single use case study. The specificity of the algorithm is 98.5\%; the sensitivity is 100\%. Future research will focus on the application of these algorithms for the assessment and classification of neonatal spells.},
  Doi                      = {10.1109/PHT.2013.6461329},
  ISBN                     = {978-1-4673-2767-1},
  Keywords                 = {Algorithm design and analysis,Biomedical monitoring,Blood,Heart rate,IBM infosphere streams,Internet,Monitoring,Pediatrics,Real-time systems,algorithm development,blood oxygen saturation,breathing cessation,cardiology,cardiorespiratory events,data analysis,medical information systems,middleware,multidimensional online health analytics environme,multiple streams,neonatal spells,newborn infants,paediatrics,physiological data streams,pneumodynamics,real-time processing,real-time systems,real-time temporal analysis,respiratory pauses,scalable middleware component},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {DUplicate of Thommandram2013a},
  Shorttitle               = {Point-of-Care Healthcare Technologies (PHT), 2013 },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6461329}
}

@Misc{Thuraisingham,
  Title                    = {{Dependable Real-time Data Mining}},

  Author                   = {Thuraisingham, Bhavani and Khan, Latifur and Clifton, Chris and Maurer, John and Ceruti, Marion},

  __markedentry            = {[Alexander:]},
  Abstract                 = {In this paper we discuss the need for real-time data mining for many applications in government and industry and describe resulting research issues. We also discuss dependability issues including incorporating security, integrity, timeliness and fault tolerance into data mining. Several different data mining outcomes are described with regard to their implementation in a real-time environment. These outcomes include clustering, association-rule mining, link analysis and anomaly detection. The paper describes how they would be used together in various parallel-processing architectures. Stream mining is discussed with respect to the challenges of performing data mining on stream data from sensors. The paper concludes with a summary and discussion of directions in this emerging area},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {In this paper we discuss the need for real-time data mining for many applications in government and industry and describe resulting research issues This is a discussion paper on various stream mining techniques. set aside.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.158.8916}
}

@InProceedings{Tian2009,
  Title                    = {{A Dynamic Online Traffic Classification Methodology Based on Data Stream Mining}},
  Author                   = {Tian, Xu and Sun, Qiong and Huang, Xiaohong and Ma, Yan},
  Booktitle                = {2009 WRI World Congress on Computer Science and Information Engineering},
  Year                     = {2009},
  Pages                    = {298--302},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Recently, traffic classification (TC) becomes more and more important for network management and measurement tasks. The new-coming machine learning based classification methods can achieve high classification accuracy and fast identification ability; however, all these related TC methods up to now always have the assumption of the stability of classification model constituted from network traffic. It is not true since seldom real-world traffic is static. In this paper, we make a first step towards classifying dynamic online traffic in a data stream perspective to handle the dynamic real-time network traffic. In this paper, we validate the dynamic feature of real-world traffic for the first time, using concept drift from two different levels: overall traffic level and application level. The conclusion convinces us that the user behavior reflected in traffic can vary dramatically due to different conditions and different periods. We then propose a novel integrated dynamic online traffic classification framework; called DSTC (data stream based traffic classification). This DSTC differs from previous work since it aims to deal with dynamic traffic with online identification ability. It is a more realistic framework in which training phase can go simultaneously with classification phase and more accurate training model can be constructed with the feedback from classification result. Experiment results have shown that DSTC can have a high stable classification accuracy of above 95\% for network traffic with different periods and user conditions, while accuracy for the traditional classification methodology can vary from 81\% to 97\% when dealing with different traffic.},
  Doi                      = {10.1109/CSIE.2009.904},
  ISBN                     = {978-0-7695-3507-4},
  Keywords                 = {Communication system traffic control,Computer science,Data engineering,Data mining,Internet,Laboratories,Machine learning,Statistics,Streaming media,Telecommunication traffic,Traffic control,computer network management,data mining,data stream based traffic classification,data stream mining,dynamic online traffic classification methodology,dynamic real-time network traffic,learning (artificial intelligence),machine learning,network management,pattern classification,telecommunication traffic},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Tian2009a},
  Shorttitle               = {Computer Science and Information Engineering, 2009},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5171181}
}

@InProceedings{Tian2008,
  Title                    = {{Dynamic Online Traffic Classification Using Data Stream Mining}},
  Author                   = {Tian, Xu and Sun, Qiong and Huang, Xiaohong and Ma, Yan},
  Booktitle                = {2008 International Conference on MultiMedia and Information Technology},
  Year                     = {2008},
  Month                    = dec,
  Pages                    = {104--107},
  Publisher                = {IEEE},

  Abstract                 = {Recently, traffic classification becomes more and more important for network management and measurement tasks. In this paper, we make a first step towards dynamic online traffic classification using data stream mining method. Two main contributions are as follows. Firstly, we propose a novel integrated dynamic online traffic classification framework, called DSTC (data stream based traffic classification). Secondly, a data stream mining algorithm, called VFDT (very fast decision tree) is implemented in DSTC, which can identify all kinds of traffic, e.g. encrypted traffic and peer-to-peer traffic, with several remarkable advantages: 1) It was designed to handle multiple, continuous, rapid, time-vary, and potential unbounded network traffic; 2) It provides real-time high accuracy traffic classification by using memory efficient method; 3) The underlying training model can adjust incrementally for newly emerging applications; 4) The training phase can go simultaneously with classification phase. The experiment results show that DSTC achieves extremely fast update speed and small memory cost with high accuracy of above 98\%.},
  Doi                      = {10.1109/MMIT.2008.185},
  ISBN                     = {978-0-7695-3556-2},
  Keywords                 = {Classification algorithms,Classification tree analysis,Communication system traffic control,Costs,DSTC,Data Stream mining,Data mining,Laboratories,Machine learning algorithms,Streaming media,Telecommunication traffic,Traffic Classification,Traffic control,VFDT,data mining,data stream mining method,decision trees,dynamic online traffic classification,memory efficient method,network management,network measurement tasks,network traffic,telecommunication network management,telecommunication traffic,very fast decision tree},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Newer version in Tian2009a},
  Shorttitle               = {MultiMedia and Information Technology, 2008. MMIT },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5089070}
}

@Conference{Tian2009a,
  Title                    = {A dynamic online traffic classification methodology based on data stream mining},
  Author                   = {Tian, X.a c and Sun, Q.a c and Huang, X.a c and Ma, Y.a b c },
  Year                     = {2009},
  Note                     = {cited By (since 1996)10},
  Pages                    = {298-302},
  Volume                   = {1},

  Abstract                 = {Recently, traffic classification (TC) becomes more and more important for network management and measurement tasks. The new-coming machine learning based classification methods can achieve high classification accuracy and fast identification ability; however, all these related TC methods up to now always have the assumption of the stability of classification model constituted from network traffic. It is not true since seldom real-world traffic is static. In this paper, we make a first step towards classifying dynamic online traffic in a data stream perspective to handle the dynamic real-time network traffic. In this paper, we validate the dynamic feature of real-world traffic for the first time, using concept drift from two different levels: overall traffic level and application level. The conclusion convinces us that the user behavior reflected in traffic can vary dramatically due to different conditions and different periods. We then propose a novel integrated dynamic online traffic classification framework; called DSTC (Data Stream based Traffic Classification). This DSTC differs from previous work since it aims to deal with dynamic traffic with online identification ability. It is a more realistic framework in which training phase can go simultaneously with classification phase and more accurate training model can be constructed with the feedback from classification result. Experiment results have shown that DSTC can have a high stable classification accuracy of above 95% for network traffic with different periods and user conditions, while accuracy for the traditional classification methodology can vary from 81% to 97% when dealing with different traffic. Ã‚Â© 2008 IEEE.},
  Affiliation              = {State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, 100876, Beijing, China; Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, 100876, Beijing, China; Network Technology Research Institute, Beijing University of Posts and Telecommunications, 100876, Beijing, China},
  Art_number               = {5171181},
  Document_type            = {Conference Paper},
  Journal                  = {2009 WRI World Congress on Computer Science and Information Engineering, CSIE 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They make a first step towards classifying dynamic online traffic in a data stream perspective to handle the dynamic real-time network traffic. They then propose a novel integrated dynamic online traffic classification framework; called DSTC (Data Stream based Traffic Classification). Experiment results have shown that DSTC can have a high stable classification accuracy of above 95% for network traffic with different periods and user conditions, while accuracy for the traditional classification methodology can vary from 81% to 97% when dealing with different traffic 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70449099466&partnerID=40&md5=8b92c69c48fcb342ce02cb97b2b1db1b}
}

@Conference{Tian2008a,
  Title                    = {Dynamic online traffic classification using data stream mining},
  Author                   = {Tian, X.a c and Sun, Q.a c and Huang, X.a c and Ma, Y.a b c },
  Year                     = {2008},
  Note                     = {cited By (since 1996)1},
  Pages                    = {104-107},

  Abstract                 = {Recently, traffic classification becomes more and more important for network management and measurement tasks. In this paper, we make a first step towards dynamic online traffic classification using data stream mining method. Two main contributions are as follows. Firstly, we propose a novel integrated dynamic online traffic classification framework, called DSTC (Data Stream based Traffic Classification). Secondly, a data stream mining algorithm, called VFDT (Very Fast Decision Tree) is implemented in DSTC, which can identify all kinds of traffic, e.g. encrypted traffic and peer-to-peer traffic, with several remarkable advantages: 1) It was designed to handle multiple, continuous, rapid, time-vary, and potential unbounded network traffic; 2) It provides real-time high accuracy traffic classification by using memory efficient method; 3) The underlying training model can adjust incrementally for newly emerging applications; 4) The training phase can go simultaneously with classification phase. The experiment results show that DSTC achieves extremely fast update speed and small memory cost with high accuracy of above 98%. Ã‚Â© 2008 IEEE.},
  Affiliation              = {State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, 100876, Beijing, China; Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, 100876, Beijing, China; Network Technology Research Institute, Beijing University of Posts and Telecommunications, 100876, Beijing, China},
  Art_number               = {5089070},
  Author_keywords          = {Data stream mining; DSTC; Traffic classification; VFDT},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2008 International Conference on MultiMedia and Information Technology, MMIT 2008},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Newer version in Tian2009a},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70349583554&partnerID=40&md5=888754b8296c43a0f593974dec22ddfc}
}

@Conference{Tiwari2013a,
  Title                    = {Integrated wireless sensor network for large scale intelligent systems},
  Author                   = {Tiwari, P.K.a and Parthasarathy, S.a and Chatterjee, A.N.a and Krishna, N.b },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1849-1854},

  Abstract                 = {There is a critical need to improve the efficiency of the large systems and eco-system of this planet. It is important to successfully integrate a variety of technology blocks ranging from sensors to communication system to analytics software in order to realize our goal of smarter systems and eco-systems. In order to apply a proactive approach to solve this planet's problem, everything must be instrumented. We would like to deploy the sensors widely so that these sensors act as the eyes, ears, and noses for the analytics engine and provide real time data at a desired frequency. In this paper, we demonstrate the first step to realize a convergence of wireless sensor network with analytics software. The wireless sensors transmit data at regular intervals through the 2.4 GHz ISM band to a coordinator. The coordinator forwards the aggregated data to a messaging software. The time stamps, topics, and payloads of the messages can be visualized using a GUI explorer of the messaging software. These messages can be further forwarded through a message broker to database servers and web servers via internet. Accordingly, the analytics software could make use of the live data to provide decision support for engineers, automated control system, and actuators. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Semiconductor RandD Center, IBM, Bangalore, India; India Software Lab, IBM, Bangalore, India},
  Art_number               = {6637463},
  Author_keywords          = {Intelligent Systems; Internet of Things; MQTT; Wireless sensor network; ZigBee PRO},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2013 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we demonstrate the first step to realize a convergence of wireless sensor network with analytics software they've added a analytics engine, so it's technically ML. No results though. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84891943511&partnerID=40&md5=cfd9d54224ef04f3914f75035b2a4d27}
}

@InProceedings{Tiwari2013,
  Title                    = {{Integrated wireless sensor network for large scale intelligent systems}},
  Author                   = {Tiwari, P. K. and Parthasarathy, S. and Chatterjee, A. N. and Krishna, N.},
  Booktitle                = {2013 International Conference on Advances in Computing, Communications and Informatics (ICACCI)},
  Year                     = {2013},
  Month                    = aug,
  Pages                    = {1849--1854},
  Publisher                = {IEEE},

  Abstract                 = {There is a critical need to improve the efficiency of the large systems and eco-system of this planet. It is important to successfully integrate a variety of technology blocks ranging from sensors to communication system to analytics software in order to realize our goal of smarter systems and eco-systems. In order to apply a proactive approach to solve this planet's problem, everything must be instrumented. We would like to deploy the sensors widely so that these sensors act as the eyes, ears, and noses for the analytics engine and provide real time data at a desired frequency. In this paper, we demonstrate the first step to realize a convergence of wireless sensor network with analytics software. The wireless sensors transmit data at regular intervals through the 2.4 GHz ISM band to a coordinator. The coordinator forwards the aggregated data to a messaging software. The time stamps, topics, and payloads of the messages can be visualized using a GUI explorer of the messaging software. These messages can be further forwarded through a message broker to database servers and web servers via internet. Accordingly, the analytics software could make use of the live data to provide decision support for engineers, automated control system, and actuators.},
  Doi                      = {10.1109/ICACCI.2013.6637463},
  ISBN                     = {978-1-4673-6217-7},
  Keywords                 = {Databases,GUI explorer,Intelligent Systems,Internet,Internet of Things,MQTT,Protocols,Sensors,Software,Wireless communication,Wireless sensor network,Wireless sensor networks,ZigBee PRO,Zigbee,analytics software,data analysis,data visualisation,graphical user interface,graphical user interfaces,integrated wireless sensor network,large scale intelligent systems,message visualization,messaging software,network convergence,telecommunication computing,wireless sensor networks},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Tiwari2013a},
  Shorttitle               = {Advances in Computing, Communications and Informat},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6637463}
}

@Misc{Tiwari,
  Title                    = {{Prediction of Stock Market from Stream Data Time Series Pattern using Neural Network and Decision Tree 1}},

  Author                   = {Tiwari, Shweta and Gulati, Alka},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Stock market prediction has been an area of intense interest due to the potential of obtaining a very high return on the invested money in a very short time. However, according to the efficient market hypothesis, all such attempts at prediction are futile as all the information that could affect the behavior of stock price or the market index must have been already incorporated into the current market quotation. At present, the stream data has been widely used in telecommunications, financial securities, retail trade and other fields. The stock price data coming from transactions are real-time, continuous, everchanging with time, and the long-term accumulation of data on stock transactions that can be regarded as massive and unlimited. Continuous variation in stock market lays the user into the situation of confusion. The paper proposes a tree based data mining algorithm that treats market’s behavior and interest as input & filter the desired output efficiently & a mining model of stream data time-series pattern in a dynamic stock market},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The paper proposes a tree based data mining algorithm that treats market’s behavior and interest as input & filter the desired output efficiently & a mining model of stream data time-series pattern in a dynamic stock market 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.219.5470}
}

@Article{Tsai2009,
  Title                    = {Mining frequent itemsets in data streams using the weighted sliding window model },
  Author                   = {Pauray S.M. Tsai},
  Journal                  = {Expert Systems with Applications },
  Year                     = {2009},
  Number                   = {9},
  Pages                    = {11617 - 11625},
  Volume                   = {36},

  Abstract                 = {In recent years, data stream mining has become an important research topic. With the emergence of new applications, the data we process are not again static, but the continuous dynamic data stream. Examples include network traffic analysis, Web click stream mining, network intrusion detection, and on-line transaction analysis. In this paper, we propose a new framework for data stream mining, called the weighted sliding window model. The proposed model allows the user to specify the number of windows for mining, the size of a window, and the weight for each window. Thus users can specify a higher weight to a more significant data section, which will make the mining result closer to userÃ¢â‚¬â„¢s requirements. Based on the weighted sliding window model, we propose a single pass algorithm, called WSW, to efficiently discover all the frequent itemsets from data streams. By analyzing data characteristics, an improved algorithm, called WSW-Imp, is developed to further reduce the time of deciding whether a candidate itemset is frequent or not. Empirical results show that WSW-Imp outperforms \{WSW\} under the weighted sliding window model.},
  Doi                      = {http://dx.doi.org/10.1016/j.eswa.2009.03.025},
  ISSN                     = {0957-4174},
  Keywords                 = {Data mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {we propose a new framework for data stream mining, called the weighted sliding window model. model allows the user to specify parameters. Based on the weighted sliding window model, we propose a single pass algorithm, called WSW, to efficiently discover all the frequent itemsets from data streams. An improved algorithm, called WSW-Imp, is developed. . Empirical results show that WSW-Imp outperforms WSW Approved 3,4},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0957417409002723}
}

@InProceedings{Ueno2012,
  Title                    = {{GPU task parallelism for scalable anomaly detection}},
  Author                   = {Ueno, Koji and Suzumura, Toyotaro},
  Booktitle                = {2012 19th International Conference on High Performance Computing},
  Year                     = {2012},
  Month                    = dec,
  Pages                    = {1--10},
  Publisher                = {IEEE},

  Abstract                 = {Stream computing has emerged as a new processing paradigm that processes incoming data streams from large numbers of sensors in real time. At the same time, many recent efforts have shown the suitability of GPGPU s for batch-typed long-running applications. However, few studies conduct the applicability of GPGPU to stream computing and also our first experiment shows that the performance does not scale as expected if one introduces the GPGPU to stream computing applications. This paper presents the workload characterization of GPGPU-based stream computing. We especially focus on computing SVD (Singular Value Decomposition) with GPGPUs for small-sized matrix since it can be widely applicable to real-time stream-based data mining applications such as real-time anomaly detection. In this paper, we not only show the workload characterization of GPGPU-based stream computing but also propose the optimization approach of SVD for stream computing applications called Ã¢â‚¬Å“GPU task ParallelismÃ¢â‚¬ï¿½ to leverage the sufficient capability of GPGPUs. This optimization offers new levels of scalability for real-time operations with large numbers of sensors. Our experimental results show that GPU task parallelism provides roughly four-fold performance gains against a quad-core CPU for matrixes of 300 Ãƒâ€” 300 to 500 Ãƒâ€” 500 data values. We also implemented a stream-based change-point and anomaly detection system based on the optimized SVD and stream computing system called System S. By porting the optimized version of SVD to the distributed stream computing system, it was easy to exploit multiple GPUs on multiple nodes. The performance results showed performance around 7.6 times faster than CPUs. The scalability of our proposed system was tested up to 1,525 sensors, which were simultaneously handled for change-point detection every 5 seconds.},
  Doi                      = {10.1109/HiPC.2012.6507508},
  ISBN                     = {978-1-4673-2371-0},
  Keywords                 = {Algorithm,Design,GPGPU-based stream computing,GPU task parallelism,Measurement,Performance,SVD,System S,distributed stream computing system,graphics processing units,parallel processing,quad-core CPU,real- time stream-based data mining,real-time anomaly detection,real-time systems,scalable anomaly detection,singular value decomposition,small-sized matrix,stream-based anomaly detection system,stream-based change-point system,time 5 s},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This is a hardware implementation with focus on computing SVD (Singular Value Decomposition). Works on stream computing on large number of sensors. Included because the hardware solution have been tested by implementing an anomaly detection system, which indicate ML techniques (but this is not certain). 1,2,3,4,5},
  Shorttitle               = {High Performance Computing (HiPC), 2012 19th Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6507508}
}

@Conference{Ueno2012a,
  Title                    = {GPU task parallelism for scalable anomaly detection},
  Author                   = {Ueno, K.a and Suzumura, T.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Stream computing has emerged as a new processing paradigm that processes incoming data streams from large numbers of sensors in real time. At the same time, many recent efforts have shown the suitability of GPGPU s for batch-typed long-running applications. However, few studies conduct the applicability of GPGPU to stream computing and also our first experiment shows that the performance does not scale as expected if one introduces the GPGPU to stream computing applications. This paper presents the workload characterization of GPGPU-based stream computing. We especially focus on computing SVD (Singular Value Decomposition) with GPGPUs for small-sized matrix since it can be widely applicable to real-time stream-based data mining applications such as real-time anomaly detection. In this paper, we not only show the workload characterization of GPGPU-based stream computing but also propose the optimization approach of SVD for stream computing applications called 'GPU task Parallelism' to leverage the sufficient capability of GPGPUs. This optimization offers new levels of scalability for real-time operations with large numbers of sensors. Our experimental results show that GPU task parallelism provides roughly four-fold performance gains against a quad-core CPU for matrixes of 300 Ãƒâ€” 300 to 500 Ãƒâ€” 500 data values. We also implemented a stream-based change-point and anomaly detection system based on the optimized SVD and stream computing system called System S. By porting the optimized version of SVD to the distributed stream computing system, it was easy to exploit multiple GPUs on multiple nodes. The performance results showed performance around 7.6 times faster than CPUs. The scalability of our proposed system was tested up to 1,525 sensors, which were simultaneously handled for change-point detection every 5 seconds. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Tokyo Institute of Technology, JST CREST, Japan; Tokyo Institute of Technology, IBM Research - Tokyo, JST CREST, Japan},
  Art_number               = {6507508},
  Author_keywords          = {Algorithm; Design; Measurement; Performance},
  Document_type            = {Conference Paper},
  Journal                  = {2012 19th International Conference on High Performance Computing, HiPC 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Ueno2012},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880258153&partnerID=40&md5=f3b8192ad8f47520a33ea7bac4f251b6}
}

@InProceedings{Vachkov2007,
  Title                    = {{Real Time Knowledge Acquisition Based on Unsupervised Learning of Evolving Neural Models}},
  Author                   = {Vachkov, Gancho},
  Booktitle                = {2007 IEEE International Fuzzy Systems Conference},
  Year                     = {2007},
  Month                    = jun,
  Pages                    = {1--6},
  Publisher                = {IEEE},

  Abstract                 = {This paper presents a method for extraction of knowledge from a real time process by using the so called evolving neural model (ENM). The ENM learns from real time data streams by a specially proposed evolving unsupervised learning algorithm. This algorithm is further development of the off-line neural-gas learning with a different way of updating the neurons. It also uses a special logic to prevent the neurons from gradually becoming "idling" during the evolutions. Two characteristics of the ENM, namely the center-of-gravity COG and the weighted average size WAS of the model are further used to capture the general trends of operation changes in the process. Big changes serve as indication for acquisition of a new knowledge about the process that should be saved in the knowledge base. Normalized data taken from different operations of a diesel engine for hydraulic excavator are used to test and verify the merits of the proposed learning algorithm and the whole knowledge acquisition method.},
  Doi                      = {10.1109/FUZZY.2007.4295560},
  ISBN                     = {1-4244-1209-9},
  ISSN                     = {1098-7584},
  Keywords                 = {Clustering algorithms,Data mining,Data structures,Diesel engines,Fault diagnosis,Knowledge acquisition,Logic,Neurons,Real time systems,Unsupervised learning,center-of-gravity,data streams,diesel engine,hydraulic excavator,knowledge acquisition,knowledge based systems,neural models,neural nets,off-line neural-gas learning,real time knowledge acquisition,unsupervised learning,weighted average size},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Vachkov2007a},
  Shorttitle               = {Fuzzy Systems Conference, 2007. FUZZ-IEEE 2007. IE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4295560}
}

@Conference{Vachkov2007a,
  Title                    = {Real time knowledge acquisition based on unsupervised learning of evolving neural models},
  Author                   = {Vachkov, G.a b },
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {This paper presents a method for extraction of knowledge from a real time process by using the so called evolving neural model (ENM). The ENM learns from real time data streams by a specially proposed evolving unsupervised learning algorithm. This algorithm is further development of the off-line neural-gas learning with a different way of updating the neurons. It also uses a special logic to prevent the neurons from gradually becoming "idling" during the evolutions. Two characteristics of the ENM, namely the Center-of-Gravity COG and the Weighted Average Size WAS of the model are further used to capture the general trends of operation changes in the process. Big changes serve as indication for acquisition of a new knowledge about the process that should be saved in the Knowledge Base. Normalized data taken from different operations of a diesel engine for hydraulic excavator are used to test and verify the merits of the proposed learning algorithm and the whole knowledge acquisition method. Ã‚Â©2007 IEEE.},
  Affiliation              = {IEEE; Department of Reliability-based Information Systems Engineering, Kagawa University, Hayashi-cho 2217-20, Takamatsu, Kagawa-ken 761-0396, Japan},
  Art_number               = {4295560},
  Document_type            = {Conference Paper},
  Journal                  = {IEEE International Conference on Fuzzy Systems},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents a method for extraction of knowledge from a real time process by using the evolving neural model (ENM). The ENM learns from real time data streams by a specially proposed evolving unsupervised learning algorithm. Normalized data taken from different operations of a diesel engine for hydraulic excavator are used to test and verify the merits of the proposed learning algorithm and the whole knowledge acquisition method Very weak abstract. Nothing about the results, no introduction or research goal. Goes straight to what they have made. 6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-50249177779&partnerID=40&md5=46d33829843f06fcf205906ccd6760b4}
}

@Article{Vallim2013a,
  Title                    = {Online behavior change detection in computer games},
  Author                   = {Vallim, R.M.M. and Andrade Filho, J.A. and De Mello, R.F. and De Carvalho, A.C.P.L.F.},
  Journal                  = {Expert Systems with Applications},
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Number                   = {16},
  Pages                    = {6258-6265},
  Volume                   = {40},

  Abstract                 = {Player Modelling has been receiving much attention from the game community in the recent years. The ability to build accurate models of player behavior can be useful in many aspects of a game. One important aspect is the tracking of a player's behavior along time, informing every time a change is perceived. This way, the game Artificial Intelligence can adapt itself to better respond to this new behavior. In order to build models of player behavior, researchers frequently resort to Machine Learning techniques. Such methods work on previously recorded game metrics representing player's interactions with the game environment. However, if the player changes styles over time, the constructed models get out of date. In order to address this drawback, this work proposes the use of and incremental learning technique to track a player's behavior during his/her interaction with the game environment. Our approach attempts to automatically detect the moments in time when the player changes behavior. We apply a change detection technique from the area of Data Stream Mining that is based on incremental clustering and novelty detection. We also propose three modifications to the original technique, in order to formalize change detection, improve detection rate and reduce detection delay. Simulations were performed considering data produced by the Unreal Tournament game, showing the applicability of the method to online tracking of a player's behavior and informing whenever behavior changes occur. Ã‚Â© 2013 Elsevier B.V. All rights reserved.},
  Affiliation              = {ICMC, Universidade de SÃƒÂ£o Paulo, Av. Trabalhador SÃƒÂ£o Carlense 400, SÃƒÂ£o Carlos, SP 13566-590, Brazil},
  Author_keywords          = {Behavior change detection; Data; Mining; Online player modeling; Stream},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Our approach attempts to automatically detect the moments in time when the player changes behavior. We apply a change detection technique from the area of Data Stream Mining that is based on incremental clustering and novelty detection. We also propose three modifications to the original technique, in order to formalize change detection, improve detection rate and reduce detection delay. Experiments showed the applicability. 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84879488574&partnerID=40&md5=b59e14b775d4818dba171ad6cb6775e1}
}

@Conference{Vallim2011,
  Title                    = {Data stream mining algorithms for building decision models in a computer roleplaying game simulation},
  Author                   = {Vallim, R.M.M.a and De Carvalho, A.C.P.L.F.a and Gama, J.b },
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {108-116},

  Abstract                 = {Computer games are attracting increasing interest in the Artificial Intelligence (AI) research community, mainly because games involve reasoning, planning and learning [1]. One area of particular interest in the last years is the creation of adaptive game AI. Adaptive game AI is the implementation of AI in computer games that holds the ability to adapt to changing circumstances, i.e., to exhibit adaptive behavior during the play. This kind of adaptation can be created using Machine Learning techniques, such as neural networks, reinforcement learning and bioinspired methods. In order to learn online, a system needs to overcome the main difficulties imposed by games: processing time and memory requirements. Learning in a game needs to be fast and the memory available is usually not enough to store a large number of training examples to a traditional Machine Learning technique. In this context, methods for mining data streams seem to be a natural approach. Data streams are, by definition, sequences of training examples that arrive over time [2]. In the data stream scenario, algorithms are usually incremental and capable of adapting the decision model when a change in the distribution of the training examples is detected. One particularly interesting algorithm for mining data streams is the Very Fast Decision Tree (VFDT) [3]. VFDTs are incremental decision trees designed specifically to meet the data stream problem requirements. In this paper, we analyse the use of VFDTs in the task of learning in a Computer RolePlaying Game context. First, we simulate data from manually designed tactics for a Computer RolePlaying Game, based on Spronck's static tactics [4], and test the suitability of VFDT to rapid learn these tactics. Afterwards, we conduct an experiment in order to simulate a data stream of examples where changes of tactics occur over time, and analyse how VFDT and some of its variations respond to these changes in the target concept. Ã‚Â© 2010 IEEE.},
  Affiliation              = {Instituto de CiÃƒÂªncias MatemÃƒÂ¡ticas e de ComputaÃƒÂ§ÃƒÂ£ o, Universidade de SÃƒÂ£o Paulo, SÃƒÂ£o Carlos, Brazil; LIAAD, INESC-Porto, Universidade do Porto, Porto, Portugal},
  Art_number               = {5772278},
  Author_keywords          = {Computer roleplaying games; Data stream mining; Player modelling},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2010 Brazilian Symposium on Games and Digital Entertainment, SBGames 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {VFDTs (Very Fast Decision Trees) are incremental decision trees designed specifically to meet the data stream problem requirements.In this paper, we analyse the use of VFDTs in the task of learning in a Computer RolePlaying Game context. Afterwards, they conduct an experiment in order to simulate a data stream of examples where changes of tactics occur over time, and analyse how VFDT and some of its variations respond to these changes in the target concept. Interesting algorithm used, but does not seem like they made any improvements on it, therefore no innovation. The approach is new though, but they say nothing about their results. 1,2,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79960225373&partnerID=40&md5=ce682ef25b0627a30c7a8677c575a34a}
}

@Article{Vallim2013,
  Title                    = {Online behavior change detection in computer games },
  Author                   = {Rosane M.M. Vallim and JosÃƒÂ© A. Andrade Filho and Rodrigo F. de Mello and AndrÃƒÂ© C.P.L.F. de Carvalho},
  Journal                  = {Expert Systems with Applications },
  Year                     = {2013},
  Number                   = {16},
  Pages                    = {6258 - 6265},
  Volume                   = {40},

  Abstract                 = {Abstract Player Modelling has been receiving much attention from the game community in the recent years. The ability to build accurate models of player behavior can be useful in many aspects of a game. One important aspect is the tracking of a playerÃ¢â‚¬â„¢s behavior along time, informing every time a change is perceived. This way, the game Artificial Intelligence can adapt itself to better respond to this new behavior. In order to build models of player behavior, researchers frequently resort to Machine Learning techniques. Such methods work on previously recorded game metrics representing playerÃ¢â‚¬â„¢s interactions with the game environment. However, if the player changes styles over time, the constructed models get out of date. In order to address this drawback, this work proposes the use of and incremental learning technique to track a playerÃ¢â‚¬â„¢s behavior during his/her interaction with the game environment. Our approach attempts to automatically detect the moments in time when the player changes behavior. We apply a change detection technique from the area of Data Stream Mining that is based on incremental clustering and novelty detection. We also propose three modifications to the original technique, in order to formalize change detection, improve detection rate and reduce detection delay. Simulations were performed considering data produced by the Unreal Tournament game, showing the applicability of the method to online tracking of a playerÃ¢â‚¬â„¢s behavior and informing whenever behavior changes occur.},
  Doi                      = {http://dx.doi.org/10.1016/j.eswa.2013.05.059},
  ISSN                     = {0957-4174},
  Keywords                 = {Online player modeling},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Vallim2013a},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0957417413003576}
}

@Article{Vallim2014,
  Title                    = {Proposal of a new stability concept to detect changes in unsupervised data streams },
  Author                   = {Rosane M.M. Vallim and Rodrigo F. de Mello},
  Journal                  = {Expert Systems with Applications },
  Year                     = {2014},
  Number                   = {16},
  Pages                    = {7350 - 7360},
  Volume                   = {41},

  Abstract                 = {Abstract Learning from continuous streams of data has been receiving an increasingly attention in the last years. Among the many challenges related to mining data streams, change detection is one topic frequently addressed. Being able to determine whether or not data characteristics are changing along time is a major concern for data stream algorithms, be it on the supervised or unsupervised scenario. The unsupervised scenario is particularly relevant due to many practical applications do not provide target labeling information. In this scenario, most of the strategies induce consecutive models over time and compare them in order to detect data changes. In this situation, model changes are assumed to be a consequence of data modifications. However, there is no guarantee this assumption is true, since those algorithms do not rely on any theoretical background to ensure that model divergences truly indicate data changes. The need for such theoretical framework has motivated this paper to propose a new stability concept to establish bounds on the learning abilities of unsupervised algorithms designed to detect changes on data streams. This stability concept, based on the surrogate data strategy from time series analysis, provides learning guarantees for online unsupervised algorithms even in case of time dependency among observations. Furthermore, we propose a new change detection algorithm that meets the requirements of this stability concept. Experimental results on different synthetical scenarios illustrate how the stability concept proposed in this paper is applied to detect changes in unsupervised data streams.},
  Doi                      = {http://dx.doi.org/10.1016/j.eswa.2014.06.031},
  ISSN                     = {0957-4174},
  Keywords                 = {Data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new stability concept to establish bounds on the learning abilities of unsupervised algorithms designed to detect changes on data streams. This stability concept, based on the surrogate data strategy from time series analysis, provides learning guarantees for online unsupervised algorithms even in case of time dependency among observations. Furthermore, we propose a new change detection algorithm that meets the requirements of this stability concept. Experimental results on different synthetical scenarios illustrate how the stability concept proposed in this paper is applied to detect changes in unsupervised data streams. 1,3,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0957417414003728}
}

@InProceedings{Vallim2010,
  Title                    = {{Data Stream Mining Algorithms for Building Decision Models in a Computer Role-Playing Game Simulation}},
  Author                   = {Vallim, Rosane Maria Maffei and de Carvalho, Andr\'{e} Carlos Ponce de Leon Ferreira and Gama, Jo\~{a}o},
  Booktitle                = {2010 Brazilian Symposium on Games and Digital Entertainment},
  Year                     = {2010},
  Month                    = nov,
  Pages                    = {108--116},
  Publisher                = {IEEE},

  Abstract                 = {Computer games are attracting increasing interest in the Artificial Intelligence (AI) research community, mainly because games involve reasoning, planning and learning. One area of particular interest in the last years is the creation of adaptive game AI. Adaptive game AI is the implementation of AI in computer games that holds the ability to adapt to changing circumstances, i.e., to exhibit adaptive behavior during the play. This kind of adaptation can be created using Machine Learning techniques, such as neural networks, reinforcement learning and bioinspired methods.In order to learn online, a system needs to overcome the main difficulties imposed by games: processing time and memory requirements. Learning in a game needs to be fast and the memory available is usually not enough to store a large number of training examples to a traditional Machine Learning technique. In this context, methods for mining data streams seem to be a natural approach. Data streams are, by definition, sequences of training examples that arrive over time. In the data stream scenario, algorithms are usually incremental and capable of adapting the decision model when a change in the distribution of the training examples is detected. One particularly interesting algorithm for mining data streams is the Very Fast Decision Tree (VFDT). VFDTs are incremental decision trees designed specifically to meet the data stream problem requirements.In this paper, we analyse the use of VFDTs in the task of learning in a Computer RolePlaying Game context. First, we simulate data from manually designed tactics for a Computer RolePlaying Game, based on Spronck's static tactics, and test the suitability of VFDT to rapid learn these tactics. Afterwards, we conduct an experiment in order to simulate a data stream of examples where changes of tactics occur over time, and analyse how VFDT and some of its variations respond to these changes in the target concept.},
  Doi                      = {10.1109/SBGAMES.2010.14},
  ISBN                     = {978-1-61284-391-9},
  ISSN                     = {2159-6654},
  Keywords                 = {Adaptation model,Algorithm design and analysis,Data mining,Games,Learning systems,Spronck static tactics,Training,adaptive game AI,artificial intelligence research community,bioinspired methods,computer games,computer roleplaying game simulation,computer roleplaying games,data mining,data stream mining,data stream mining algorithms,decision making,decision models,decision trees,learning,learning (artificial intelligence),machine learning techniques,neural nets,neural networks,planning,player modelling,reasoning,reinforcement learning,very fast decision tree},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Vallim2011},
  Shorttitle               = {Games and Digital Entertainment (SBGAMES), 2010 Br},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5772278}
}

@Article{Vatsavai2008,
  Title                    = {{Knowledge discovery from sensor data (SensorKDD)}},
  Author                   = {Vatsavai, Ranga Raju and Omitaomu, Olufemi A. and Gama, Joao and Chawla, Nitesh V. and Gaber, Mohamed Medhat and Ganguly, Auroop R.},
  Journal                  = {ACM SIGKDD Explorations Newsletter},
  Year                     = {2008},

  Month                    = dec,
  Number                   = {2},
  Pages                    = {68},
  Volume                   = {10},

  Abstract                 = {Extracting knowledge and emerging patterns from sensor data is a nontrivial task. The challenges for the knowledge discovery community are expected to be immense. On one hand, dynamic data streams or events require real-time analysis methodologies and systems, while on the other hand centralized processing through high end computing is also required for generating offline predictive insights, which in turn can facilitate real-time analysis. In addition, emerging societal problems require knowledge discovery solutions that are designed to investigate anomalies, changes, extremes and nonlinear processes, and departures from the normal. Keeping in view the requirements of the emerging field of knowledge discovery from sensor data, we took initiative to develop a community of researchers with common interests and scientific goals, which culminated into the organization of Sensor-KDD series of workshops in conjunction with the prestigious ACM SIGKDD International Conference of Knowledge Discovery and Data Mining. In this report, we summarize the events of the Second ACM-SIGKDD International Workshop on Knowledge Discovery form Sensor Data (Sensor-KDD 2008).},
  Doi                      = {10.1145/1540276.1540297},
  ISSN                     = {19310145},
  Owner                    = {alex},
  Publisher                = {ACM},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, just a summary of KDD2008},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1540276.1540297}
}

@Article{Vaziri2014,
  Title                    = {Stream processing with a spreadsheet},
  Author                   = {Vaziri, M. and Tardieu, O. and Rabbah, R. and Suter, P. and Hirzel, M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {360-384},
  Volume                   = {8586 LNCS},

  Abstract                 = {Continuous data streams are ubiquitous and represent such a high volume of data that they cannot be stored to disk, yet it is often crucial for them to be analyzed in real-time. Stream processing is a programming paradigm that processes these immediately, and enables continuous analytics. Our objective is to make it easier for analysts, with little programming experience, to develop continuous analytics applications directly. We propose enhancing a spreadsheet, a pervasive tool, to obtain a programming platform for stream processing. We present the design and implementation of an enhanced spreadsheet that enables visualizing live streams, live programming to compute new streams, and exporting computations to be run on a server where they can be shared with other users, and persisted beyond the life of the spreadsheet. We formalize our core language, and present case studies that cover a range of stream processing applications. Ã‚Â© 2014 Springer-Verlag.},
  Affiliation              = {IBM T.J. Watson Research Center, Yorktown Height, NY, United States},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {propose enhancing a spreadsheet, a pervasive tool, to obtain a programming platform for stream processing Discarded. No ML used.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905398599&partnerID=40&md5=80bd5e0d33c836a2990f85cdb61863d5}
}

@Misc{Veloso2003,
  Title                    = {{Parallel, Incremental and Interactive Mining for Frequent Itemsets in Evolving Databases}},

  Author                   = {Veloso, Adriano and Jr., Wagner Meira and {De Carvalho}, Marcio Bunte and Parthasarathy, Srinivasan and Zaki, Mohammed},
  Year                     = {2003},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper deals with new approaches to maintaining frequent itemsets in evolving databases. Our new approaches make use of incremental techniques to provide significant I/O reduction, and parallel techniques to provide computational savings. At the same time, our approaches are able to effectively handle online data updates (deletions/insertions) and interactive response times (approximate/partial results). Some additional highlights of the proposed approaches include extending the validity of the itemsets (generating approximate models of itemsets), and performing selective updates (tracking stable and predictable itemsets). These features allow our approaches to mine evolving data stored in warehouses as well as (potentially) streaming data. Extensive experimental benchmarking on evolving data demonstrates the potential advantages of the proposed approaches. We believe that this work can have high impact in application areas such as electronic commerce, web mining, and network intrusion detection.},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Seems to only be about maintaining freq itemsets in warehouses. Nothing about ML.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.8570}
}

@Conference{Vestrand2002,
  Title                    = {The RAPTOR experiment: A system for monitoring the optical sky in real time},
  Author                   = {Vestrand, W.T. and Borozdin, K. and Brumby, S. and Casperson, D. and Fenimore, E. and Galassi, M. and McGowan, K. and Perkins, S. and Priedhorsky, W. and Starr, D. and White, R. and Wozniak, P. and Wren, J.},
  Year                     = {2002},
  Note                     = {cited By (since 1996)32},
  Pages                    = {126-136},
  Volume                   = {4845},

  Abstract                 = {The Rapid Telescopes for Optical Response (RAPTOR) experiment is a spatially distributed system of autonomous robotic telescopes that is designed to monitor the sky for optical transients. The core of the system is composed of two telescope arrays, separated by 38 kilometers, that stereoscopically view the same 1500 square-degree field with a wide-field imaging array and a central 4 square-degree field with a more sensitive narrow-field "fovea" imager. Coupled to each telescope array is a real-time data analysis pipeline that is designed to identify interesting transients on timescales of seconds and, when a celestial transient is identified, to command the rapidly slewing robotic mounts to point the narrow-field "fovea" imagers at the transient. The two narrow-field telescopes then image the transient with higher spatial resolution and at a faster cadence to gather light curve information. Each "fovea" camera also images the transient through a different filter to provide color information. This stereoscopic monitoring array is supplemented by a rapidly slewing telescope with a low resolution spectrograph for follow-up observations of transients and a sky patrol telescope that nightly monitors about 10,000 square-degrees for variations, with timescales of a day or longer, to a depth about 100 times fainter. In addition to searching for fast transients, we will use the data stream from RAPTOR as a real-time sentinel for recognizing important variations in known sources. All of the data will be publically released through a virtual observatory called SkyDOT (Sky Database for Objects in the Time Domain) that we are developing for studying variability of the optical sky. Altogether, the RAPTOR project aims to construct a new type of system for discovery in optical astronomy - one that explores the time domain by "mining the sky in real time".},
  Affiliation              = {Los Alamos National Laboratory, MS-D436, Los Alamos, NM 87545, United States},
  Author_keywords          = {Data mining; Distributed sensors; Optical transients; Real-time processing; Robotic telescopes; Sky monitoring},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of SPIE - The International Society for Optical Engineering},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {It's about a data stream from telescopes. They say they will use it in recognizing important variations in known sources, but says nothing about ML Discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0036994793&partnerID=40&md5=5400737030127caa036aeec8c44df3cd}
}

@Article{Vestrand2004,
  Title                    = {Unsolved problems in observational astronomy. II. Focus on rapid response - Mining the sky with "thinking" telescopes},
  Author                   = {Vestrand, W.T. and Theiler, J. and Wozniak, P.R.},
  Journal                  = {Astronomische Nachrichten},
  Year                     = {2004},
  Note                     = {cited By (since 1996)6},
  Number                   = {6-8},
  Pages                    = {477-482},
  Volume                   = {325},

  Abstract                 = {The existence of rapidly slewing robotic telescopes and fast alert distribution via the Internet is revolutionizing our capability to study the physics of fast astrophysical transients. But the salient challenge that optical time domain surveys must conquer is mining the torrent of data to recognize important transients in a scene full of normal variations. Humans simply do not have the attention span, memory, or reaction time required to recognize fast transients and rapidly respond. Autonomous robotic instrumentation with the ability to extract pertinent information from the data stream in real time will therefore be essential for recognizing transients and commanding rapid follow-up observations while the ephemeral behavior is still present. Here we discuss how the development and integration of three technologies: (1) robotic telescope networks; (2) machine learning; and (3) advanced database technology, can enable the construction of smart robotic telescopes, which we loosely call "thinking" telescopes, capable of mining the sky in real time.},
  Affiliation              = {Los Alamos National Laboratory, MS B244, Los Alamos, NM, United States},
  Author_keywords          = {Instrumentation:miscellaneous; Method:observational; Surveys},
  Document_type            = {Review},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {Discusiion paper . Here we discuss how the development and integration of three technologies: (1) robotic telescope networks; (2) machine learning; and (3) advanced database technology, can enable the construction of smart robotic telescopes, which we loosely call "thinking" telescopes, capable of mining the sky in real time. That is not a tangible result right?},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-9944245401&partnerID=40&md5=6616cb2fc225b1e409eaa23896e2024c}
}

@Article{Vijayakumar2010,
  Title                    = {Concept mining of high volume data streams in network traffic using hierarchical clustering},
  Author                   = {Vijayakumar, M.a and Parvathi, R.M.S.b },
  Journal                  = {European Journal of Scientific Research},
  Year                     = {2010},
  Note                     = {cited By (since 1996)1},
  Number                   = {2},
  Pages                    = {234-242},
  Volume                   = {39},

  Abstract                 = {This research work concerned with the problem of mining network traffic data discovering useful associations, relationships, and groupings in large collections of data. Mathematical transformation algorithms have proven effective at reducing the content of multilingual, unstructured data into a vector that describes the content. Such methods are particularly desirable in fields undergoing information explosions, such as network traffic analysis, bio-informatics, and the intelligence community. In response, traffic mining methodology is being extended to improve performance and sufficiently scalable. There is an additional need within the intelligence community to cluster related sets of data obtained from the network traffic. To allow this activity to happen at high speed, this work implements a system that hierarchically clusters streaming content. The method, streaming hierarchical partitioning, is designed to be implemented and handle extremely high congestion rates. As new data traffic is injected, they are dynamically organized into a hierarchy, which has a fixed maximal size. Once this limit is reached, traffic data must consequently be excreted at a rate equaling their congestion. The choice of data to excrete is a point of interest, present several autonomous heuristics for doing so intelligently, as well as a proposal for incorporating user interaction to focus attention on nature of the traffic data. Accordingly, analyzes experimental results for traffic data streams evolving over time under several regimes. Current and proposed methods for concisely and informatively mining traffic data from streaming hierarchical clustering to the user are analyzed. To summarize, this work describe a system designed to satisfy three primary goals i.e., real-time concept mining of high-volume data streams, dynamic data flow into a relational hierarchy; and adaptive reorganization of the traffic data hierarchy in response to evolving circumstances and network traffic time to time. Ã‚Â© EuroJournals Publishing, Inc. 2010.},
  Affiliation              = {Department of Computer Science and Engineering, Sasurie College of Engineering, Tamil Nadu, India; Department of Computer Science and Engineering, Sengunthar College of Engineering for Women, Tamil Nadu, India},
  Author_keywords          = {Frequent item set; Hierarchical clustering; Network management; Traffic analysis},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {this work describe a system designed to satisfy three primary goals i.e., real-time concept mining of high-volume data streams, dynamic data flow into a relational hierarchy; and adaptive reorganization of the traffic data hierarchy in response to evolving circumstances and network traffic time to time 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79960012692&partnerID=40&md5=9de372da2c47d9a3e0e9af356ef62dbe}
}

@Article{Vijayakumar2006,
  Title                    = {Towards low overhead provenance tracking in near real-time stream filtering},
  Author                   = {Vijayakumar, N.N. and Plale, B.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2006},
  Note                     = {cited By (since 1996)11},
  Pages                    = {46-54},
  Volume                   = {4145 LNCS},

  Abstract                 = {Data streams flowing from the physical environment are as unpredictable as the environment itself. Radars go down, long haul networks drop packets, and readings are corrupted on the wire. Yet the data driven scientific models and data mining algorithms do not necessarily account for the inaccuracies when assimilating the data. Low overhead provenance collection partially solves this problem. We propose a data model and collection model for near real time provenance collection. We define a system architecture for stream provenance tracking and motivate with a real-world application in meteorology forecasting. Ã‚Â© Springer-Verlag Berlin Heidelberg 2006.},
  Affiliation              = {Department of Computer Science, Indiana University, United States},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Vijayakumar2006b},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33750047467&partnerID=40&md5=19f5731f3da36d00a14a60ae0b308ba1}
}

@Book{Vijayakumar2006a,
  Title                    = {{Provenance and Annotation of Data}},
  Author                   = {Vijayakumar, Nithya N. and Plale, Beth},
  Editor                   = {Moreau, Luc and Foster, Ian},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2006},

  Address                  = {Berlin, Heidelberg},
  Month                    = may,
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {4145},

  Abstract                 = {Data streams flowing from the physical environment are as unpredictable as the environment itself. Radars go down, long haul networks drop packets, and readings are corrupted on the wire. Yet the data driven scientific models and data mining algorithms do not necessarily account for the inaccuracies when assimilating the data. Low overhead provenance collection partially solves this problem. We propose a data model and collection model for near real time provenance collection. We define a system architecture for stream provenance tracking and motivate with a real-world application in meteorology forecasting.},
  Doi                      = {10.1007/11890850},
  ISBN                     = {978-3-540-46302-3},
  Owner                    = {alex},
  Pages                    = {46--54},
  Qualityassured           = {qualityAssured},
  Review                   = {Vijayakumar2006b},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2165554.2165562}
}

@Article{Vijayakumar2006b,
  Title                    = {{Towards low overhead provenance tracking in near real-time stream filtering}},
  Author                   = {Vijayakumar, Nithya N. and Plale, Beth},
  Journal                  = {LNCS},
  Year                     = {2006},
  Volume                   = {4145},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Data streams flowing from the physical environment are as unpredictable as the environment itself. Radars go down, long haul networks drop packets, and readings are corrupted on the wire. Yet the data driven scientific models and data mining algorithms do not necessarily account for the inaccuracies when assimilating the data. Low overhead provenance collection partially solves this problem. We propose a data model and collection model for near real time provenance collection. We define a system architecture for stream provenance tracking and motivate with a real-world application in meteorology forecasting},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {We define a system architecture for stream provenance tracking and motivate with a real-world application in meteorology forecasting Nothing about ML},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.5086}
}

@Misc{Vinceslas,
  Title                    = {{SPAMS: a novel Incremental Approach for Sequential Pattern Mining in Data Streams}},

  Author                   = {Vinceslas, Lionel and Symphor, Jean-emile and Mancheron, Alban and Poncelet, Pascal},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Mining sequential patterns in data streams is a new challenging problem for the datamining community since data arrives sequentially in the form of continuous rapid and infinite streams. In this paper, we propose a new on-line algorithm, SPAMS, to deal with the sequential patterns mining problem in data streams. This algorithm uses an automaton-based structure to maintain the set of frequent sequential patterns, i.e. SPA (Sequential Pattern Automaton). The sequential pattern automaton can be smaller than the set of frequent sequential patterns by two or more orders of magnitude, which allows us to overcome the problem of combinatorial explosion of sequential patterns. Current results can be output constantly on any user’s specified thresholds. In addition, taking into account the characteristics of data streams, we propose a well-suited method said to be approximate since we can provide near optimal results with a high probability. Experimental studies show the relevance of the SPA data structure and the efficiency of the SPAMS algorithm on various datasets. Our contribution opens a promising gateway, by using an automaton as a data structure for mining frequent sequential patterns in data strea},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new on-line algorithm, SPAMS, to deal with the sequential patterns mining problem in data streams. This algorithm uses an automaton-based structure to maintain the set of frequent sequential patterns. Experimental studies show the relevance of the SPA data structure and the efficiency of the SPAMS algorithm on various datasets. Our contribution opens a promising gateway, by using an automaton as a data structure for mining frequent sequential patterns in data stream 1,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.170.6740}
}

@Article{Vivekanandan2011,
  Title                    = {Mining data streams with concept drifts using genetic algorithm},
  Author                   = {Vivekanandan, P.a and Nedunchezhian, R.b },
  Journal                  = {Artificial Intelligence Review},
  Year                     = {2011},
  Note                     = {cited By (since 1996)6},
  Number                   = {3},
  Pages                    = {163-178},
  Volume                   = {36},

  Abstract                 = {Recent research shows that rule based models perform well while classifying large data sets such as data streams with concept drifts. A genetic algorithm is a strong rule based classification algorithm which is used only for mining static small data sets. If the genetic algorithm can be made scalable and adaptable by reducing its I/O intensity, it will become an efficient and effective tool for mining large data sets like data streams. In this paper a scalable and adaptable online genetic algorithm is proposed to mine classification rules for the data streams with concept drifts. Since the data streams are generated continuously in a rapid rate, the proposed method does not use a fixed static data set for fitness calculation. Instead, it extracts a small snapshot of the training example from the current part of data stream whenever data is required for the fitness calculation. The proposed method also builds rules for all the classes separately in a parallel independent iterative manner. This makes the proposed method scalable to the data streams and also adaptable to the concept drifts that occur in the data stream in a fast and more natural way without storing the whole stream or a part of the stream in a compressed form as done by the other rule based algorithms. The results of the proposed method are comparable with the other standard methods which are used for mining the data streams. Ã‚Â© 2011 Springer Science+Business Media B.V.},
  Affiliation              = {Department of Computer Science and Engineering, Park College of Engineering and Technology, Coimbatore, India; Department of Computer Science and Engineering, Kalaignar Karunanidhi Institute of Technology, Coimbatore, India},
  Author_keywords          = {Classification; Concept drift; Genetic algorithm (GA); Online learning},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper a scalable and adaptable online genetic algorithm is proposed to mine classification rules for the data streams with concept drifts. it extracts a small snapshot of the training example from the current part of data stream whenever data is required for the fitness calculation. The results of the proposed method are comparable with the other standard methods which are used for mining the data streams 1,2,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052971400&partnerID=40&md5=e537ac4cd39ac5e7e82700cd9e019ea8}
}

@Conference{Vosecky2013,
  Title                    = {Dynamic multi-faceted topic discovery in twitter},
  Author                   = {Vosecky, J. and Jiang, D. and Leung, K.W.-T. and Ng, W.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Pages                    = {879-884},

  Abstract                 = {Microblogging platforms, such as Twitter, already play an important role in cultural, social and political events around the world. Discovering high-level topics from social streams is therefore important for many downstream applications. However, traditional text mining methods that rely on the bag-of-words model are insufficient to uncover the rich semantics and temporal aspects of topics in Twitter. In particular, topics in Twitter are inherently dynamic and often focus on specific entities, such as people or organizations. In this paper, we therefore propose a method for mining multi-faceted topics from Twitter streams. The Multi-Faceted Topic Model (MfTM) is proposed to jointly model latent semantics among terms and entities and captures the temporal characteristics of each topic. We develop an efficient online inference method for MfTM, which enables our model to be applied to large-scale and streaming data. Our experimental evaluation shows the effectiveness and efficiency of our model compared with state-of-the-art baselines. We further demonstrate the effectiveness of our framework in the context of tweet clustering. Copyright 2013 ACM.},
  Affiliation              = {Hong Kong University of Science and Technology, Kowloon, Hong Kong},
  Author_keywords          = {Clustering; Topic model; Twitter; Unsupervised learning},
  Document_type            = {Conference Paper},
  Journal                  = {International Conference on Information and Knowledge Management, Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {they propose a method for mining multi-faceted topics from Twitter streams. The Multi-Faceted Topic Model (MfTM) is proposed to jointly model latent semantics among terms and entities and captures the temporal characteristics of each topic. We develop an efficient online inference method for MfTM, which enables our model to be applied to large-scale and streaming data. Our experimental evaluation shows the effectiveness and efficiency of our model compared with state-of-the-art baselines. 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84889594913&partnerID=40&md5=13c6b5b4444d32490df2c30d0ff5333a}
}

@Article{Vyas2011,
  Title                    = {Efficient minimization of servo lag error in adaptive optics using data stream mining},
  Author                   = {Vyas, A.a b and Roopashree, M.B.a and Prasad, B.R.a },
  Journal                  = {Communications in Computer and Information Science},
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Pages                    = {13-18},
  Volume                   = {148 CCIS},

  Abstract                 = {Prediction of the wavefronts helps in reducing the servo lag error in adaptive optics caused by finite time delays (Ã¢Ë†Â¼ 1-5 ms) before wavefront correction. Piecewise linear segmentation based prediction is not suitable in cases where the turbulence statistics of the atmosphere are fluctuating. In this paper, we address this problem by real time control of the prediction parameters through the application of data stream mining on wavefront sensor data obtained in real-time. Numerical experiments suggest that pixel-wise prediction of phase screens and slope extrapolation techniques lead to similar improvement while modal prediction is sensitive to the number of moments used and can yield better results with optimum number of modes. Ã‚Â© 2011 Springer-Verlag.},
  Affiliation              = {Indian Institute of Astrophysics, II Block, Koramangala, Bangalore 560034, India; Indian Institute of Science, Malleswaram, Bangalore 560012, India},
  Author_keywords          = {Adaptive optics; data stream mining; servo lag error; turbulence prediction},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper, we address this problem by real time control of the prediction parameters through the application of data stream mining on wavefront sensor data obtained in real-time. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79955103668&partnerID=40&md5=bd3611a349023879d7d200caec52b815}
}

@Misc{Wakchaure,
  Title                    = {{Apnea Pulse-Care: Real-time Data mining in Sleep Apnea Monitor}},

  Author                   = {Wakchaure, Sushma Laxman and Dny, Ganesh and Ghuge, Ev},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Among the world population 4 % people are suffering from Apnea. Basically Apnea is sleep related disorder in which a person affected with Apnea stops breathing for 20-30 sec or more than that while sleeping. The basic cause of this sleep disorder is the obstruction in upper airway through windpipe due to expansion of muscles above the windpipe. People suffering from such kind of sleep disorders are called as to be having SAHS (Sleep Apnea And Hyponea Syndrome). In medical science the process of studying, observing and detecting the Apnea period is called as Polysomnography (PSG). The method screens night time pulsioximetry is recordings for the presence of major sleep apnea and provides a minute-by-minute analysis of disordered breathing. “Apnea Pulse-Care ” will be implemented on Android operating system (OS) based smart phones, uses the Hoeffding Window data mining algorithm which will be applied on data stream.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {The method screens night time pulsioximetry is recordings for the presence of major sleep apnea and provides a minute-by-minute analysis of disordered breathing. “Apnea Pulse-Care ” will be implemented on Android operating system (OS) based smart phones, uses the Hoeffding Window data mining algorithm which will be applied on data stream. Healt care analytics on smartphone. 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.414.5597}
}

@Article{Walton2005,
  Title                    = {The Virtual Observatories: A major new facility for astronomy: Linking ELTs, great observatories and the science community},
  Author                   = {Walton, N.A.a and Richards, A.M.S.b and Padovani, P.c and Allen, M.G.d },
  Journal                  = {Proceedings of the International Astronomical Union},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Pages                    = {398-403},
  Volume                   = {1},

  Abstract                 = {We describe how the Virtual Observatory (VO) projects in Europe, the USA, Japan, and elsewhere are meeting the challenge of providing simple and efficient access to the data from the world's observational facilities, together with applications and computational resources required to support the analysis of this data. We note the pan-European Euro-VO project and its technological development VO-TECH project which are now in the process of designing the framework for comprehensive access to emerging high data volume facilities such as ESO's VISTA infrared survey telescope. Science drivers from major new astronomical missions are helping to define the development of the VO. Scientifically this is in terms of developing systems able to meet the demands of the main science programmes shaping the ELTs. VOs must be able to handle the large data streams from the complex multiplexed instruments on the ELTs, and provide access to applications required to analyse/interpret the data. VOs must enable the effective distribution of ELT data to the global community. Conversely, the rapid development of the Virtual Observatory, offers opportunities for major new projects such at the ELTs. This could be: in the design of their down stream data-flow systems; in terms of opening up access to 'real-time' availability of ancillary data flows; in multi-wavelength observational programmes. We highlight these areas, and give some specific current examples of early VO usage in delivering science from, e.g. the mining of deep multi-wavelength surveys to study the high redshift universe. Ã‚Â© 2006 International Astronomical Union.},
  Affiliation              = {Institute of Astronomy, University of Cambridge, Madingley Road, Cambridge, CB3 0HA, United Kingdom; Jodrell Bank Observatory, University of Manchester, Macclesfield, SK11 9DL, United Kingdom; European Southern Observatory, D-85748 Garching bei MÃƒÂ¼nchen, Germany; CDS, ULP, CNRS, 67000, Strasbourg, France},
  Author_keywords          = {Astronomical data bases; Methods: data analysis},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. No new approach or results, only a hightlighting of the use of VO in the world.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-63549111178&partnerID=40&md5=f56c42ce3a9f6571f26c5480087cf910}
}

@InProceedings{Wan2008,
  Title                    = {{A Weighted Fuzzy Clustering Algorithm for Data Stream}},
  Author                   = {Wan, Renxia and Yan, Xiaoya and Su, Xiaoke},
  Booktitle                = {2008 ISECS International Colloquium on Computing, Communication, Control, and Management},
  Year                     = {2008},
  Pages                    = {360--364},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Mining data streams poses great challenges due to the limited memory availability and real time query response requirement. One of the most important mining tasks is clustering. There already lots of clustering algorithms for data stream have been presented. Fuzzy cluster is an important clustering method. However, to the best of our knowledge, all the clustering algorithms are hard clustering methods, fuzzy clustering algorithm is presently not used directly for data streams. Fuzzy c-means (FCM) is a typical fuzzy clustering algorithm. In this paper, we extend FCM and propose a weighted fuzzy algorithm for clustering data stream. Experimental results on both synthetic and real data sets show its superiority over the traditional FCM algorithms.},
  Doi                      = {10.1109/CCCM.2008.186},
  ISBN                     = {978-0-7695-3290-5},
  Keywords                 = {Clustering algorithms,Clustering methods,Communication system control,Data mining,Educational institutions,Fuzzy control,Image sampling,Machine learning algorithms,Sampling methods,Technology management,Weighted Fuzzy C-Mean,cluster,data mining,data stream,data stream mining,fuzzy c-means,fuzzy set theory,pattern clustering,query processing,real time query response,weighted fuzzy clustering algorithm},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Wan2008a},
  Shorttitle               = {Computing, Communication, Control, and Management,},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4609532}
}

@Conference{Wan2008a,
  Title                    = {A weighted fuzzy clustering algorithm for data stream},
  Author                   = {Wan, R.a and Yan, X.b and Su, X.a },
  Year                     = {2008},
  Note                     = {cited By (since 1996)7},
  Pages                    = {360-364},
  Volume                   = {1},

  Abstract                 = {Mining data streams poses great challenges due to the limited memory availability and real time query response requirement. One of the most important mining tasks is clustering. There already lots of clustering algorithms for data stream have been presented. Fuzzy cluster is an important clustering method. However, to the best of our knowledge, all the clustering algorithms are hard clustering methods, fuzzy clustering algorithm is presently not used directly for data streams. Fuzzy c-means (FCM) is a typical fuzzy clustering algorithm. In this paper, we extend FCM and propose a weighted fuzzy algorithm for clustering data stream. Experimental results on both synthetic and real data sets show its superiority over the traditional FCM algorithms. Ã‚Â© 2008 IEEE.},
  Affiliation              = {College of Information Science and Technology, Donghua University, Shanghai 201620, China; College of Foreign Language, Zhanjiang Normal University, Zhanjiang, Guangdong, 524048, China},
  Art_number               = {4609532},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - ISECS International Colloquium on Computing, Communication, Control, and Management, CCCM 2008},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Fuzzy c-means (FCM) is a typical fuzzy clustering algorithm. In this paper, we extend FCM and propose a weighted fuzzy algorithm for clustering data stream. Experimental results on both synthetic and real data sets show its superiority over the traditional FCM algorithms. 1,2,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-54149099610&partnerID=40&md5=bb5703ea553b615fc5fd148aab396694}
}

@Article{Wang2011b,
  Title                    = {Incremental learning extremely random forest classifier for online learning},
  Author                   = {Wang, A.-P. and Wan, G.-W. and Cheng, Z.-Q. and Li, S.-K.},
  Journal                  = {Ruan Jian Xue Bao/Journal of Software},
  Year                     = {2011},
  Note                     = {cited By (since 1996)6},
  Number                   = {9},
  Pages                    = {2059-2074},
  Volume                   = {22},

  Abstract                 = {This paper proposes an incremental extremely random forest (IERF) algorithm, dealing with online learning classification with streaming data, especially with small streaming data. In this method, newly arrived examples are stored at the leaf nodes and used to determine when to split the leaf nodes combined with Gini index, so the trees can be expanded efficiently and fast with a few examples. The proposed online IERF algorithm gives more competitive or even better performance, than the offline extremely random forest (ERF) method, based on the UCI data experiment. On the moderate training datasets, the IERF algorithm beats the decision tree reconstruction algorithm and other incremental learning algorithms on the performance. Finally, the IERF algorithm is used to solve online video object tracking (multi-object tracking also included) problems, and the results on the challenging video sequences demonstrate its effectiveness and robustness. Ã‚Â©2011, Institute of Software, the Chinese Academy of Sciences. All rights reserved.},
  Affiliation              = {College of Computer, National University of Defense Technology, Changsha 410073, China},
  Author_keywords          = {Extremely random forest classifier; Incremental learning; Online learning},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes an incremental extremely random forest (IERF) algorithm, dealing with online learning classification with streaming data, especially with small streaming data. The proposed online IERF algorithm gives more competitive or even better performance, than the offline extremely random forest (ERF) method, based on the UCI data experiment. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053096051&partnerID=40&md5=532dcd7f2d24f53c1e6527b9f21635f3}
}

@Book{Wang2012,
  Title                    = {Online clustering and outlier detection},
  Author                   = {Wang, B.a and Dong, A.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Clustering and outlier detection are important data mining areas. Online clustering and outlier detection generally work with continuous data streams generated at a rapid rate and have many practical applications, such as network instruction detection and online fraud detection. This chapter first reviews related background of online clustering and outlier detection. Then, an incremental clustering and outlier detection method for market-basket data is proposed and presented in details. This proposed method consists of two phases: weighted affinity measure clustering (WC clustering) and outlier detection. Specifically, given a data set, the WC clustering phase analyzes the data set and groups data items into clusters. Then, outlier detection phase examines each newly arrived transaction against the item clusters formed in WC clustering phase, and determines whether the new transaction is an outlier. Periodically, the newly collected transactions are analyzed using WC clustering to produce an updated set of clusters, against which transactions arrived afterwards are examined. The process is carried out continuously and incrementally. Finally, the future research trends on online data mining are explored at the end of the chapter. Ã‚Â© 2013, IGI Global.},
  Affiliation              = {Waynesburg University, PA, United States; Hood College, United States},
  Document_type            = {Book Chapter},
  Journal                  = {Meta-Heuristics Optimization Algorithms in Engineering, Business, Economics, and Finance},
  Owner                    = {Alexander},
  Pages                    = {529-545},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {This chapter first reviews related background of online clustering and outlier detection. Then, an incremental clustering and outlier detection method for market-basket data is proposed and presented in details. This proposed method consists of two phases: weighted affinity measure clustering (WC clustering) and outlier detection This seems to be a book from the same author as Wang2010, with the same experiment.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84900674048&partnerID=40&md5=462c6e38ba92304563d3c76f508c1f0a}
}

@Conference{Wang2010,
  Title                    = {Fraud detection on online data streams},
  Author                   = {Wang, B.a and Dong, A.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Pages                    = {89-93},

  Abstract                 = {Fraud detection is one of the important data mining areas. This paper presents an efficient dynamic fraud detection method for online data streams in form of market basket data. The method consists of two phases: WC clustering (weighted affinity measure clustering) and fraud detection. First, the transaction set is analyzed so that items are grouped into clusters in WC clustering phase. Then, each newly arrived transaction is examined against the item clusters retrieved from WC clustering phase. Phase two decides whether the transaction is a fraud (an outlier). After a period of time, the newly collected transactions are analyzed using WC clustering to produce the updated item clusters, against which each newly arrived transaction is examined. The process is carried out dynamically and incrementally.},
  Affiliation              = {Waynesburg University, Waynesburg, PA 15370, United States; Hood College, Frederick, MD 21701, United States},
  Author_keywords          = {Categorical; Clustering; Fraud detection; Market basket data; Outlier detection},
  Document_type            = {Conference Paper},
  Journal                  = {International Conference on Artificial Intelligence and Pattern Recognition 2010, AIPR 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. This paper presents an efficient dynamic fraud detection method for online data streams in form of market basket data. The method consists of two phases: WC clustering (weighted affinity measure clustering) and fraud detection. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84876753660&partnerID=40&md5=642e21a8723bbc431ea54e3769e5c85c}
}

@Article{Wang2006,
  Title                    = {Framework of urban mass transit intelligent integration supervision and control system},
  Author                   = {Wang, F.-Z.a and Zhang, L.-Y.a and Li, P.a and Xu, J.b },
  Journal                  = {Zhongguo Tiedao Kexue/China Railway Science},
  Year                     = {2006},
  Note                     = {cited By (since 1996)5},
  Number                   = {1},
  Pages                    = {126-132},
  Volume                   = {27},

  Abstract                 = {Intelligent integration supervision and control system has the characteristics of integration supervision of every subsystem in the whole lines, the linkage of every subsystem under different working conditions, information share at high level, system self-determination and so on. On the basis of data stream and control flow, the system framework with three layers is put forward, that is integration determination layer, station determination layer and local control layer. Integration determination layer answers for the supervision of the system in the whole lines, establishing integration decisions of whole lines and data and information interchanging with exterior systems. Centrality integration supervision center has the functions of control, alarm, display and so on. Station determination layer answers for the supervision of every subsystem in the station scope, coordination the linkage functions of every subsystem and providing the decision at station layer. Station integration supervision system has the functions of real-time information collection, maintenance, supervision, alarm management and so on. Local control layer include six subsystems and can be divided into three classes, namely, service class, operation class and safety class. The central parts of the system are information share platform and network communication platform. The key techniques for constructing the information share platform include data interface technique, information fusion technique, data mining technique, information issuance technique and so on. The key techniques for constructing the network communication platform are the common standard communication techniques such as SDH, ATM and so on.},
  Affiliation              = {Institute of Computing Technologies, China Academy of Railway Sciences, Beijing 100081, China; School of Traffic and Transportation, Beijing Jiaotong University, Beijing 100044, China},
  Author_keywords          = {Framework model; Information sharing; Integration supervision; Network communication; Urban mass transit},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {This paper proposes a framework for smart urban transit, using data interface technique, information fusion technique, data mining technique, information issuance technique and so on. This is a big issue, nor tangible results.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33645646187&partnerID=40&md5=1d54ecfc4835ea316848cb7dbabdb5f3}
}

@Conference{Wang2005,
  Title                    = {An efficient K-Means algorithm in the data stream model},
  Author                   = {Wang, H.},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Pages                    = {145-150},

  Abstract                 = {Many organizations accumulate data at an increasingly high rate. Usually these data can only be read one time in order. This kind of data model is called data stream. Real world applications such as telephone records, financial data transactions, web logs and customer click streams require analysis of the data stream in an efficient way with limited memory space. Clustering has been an important research topic in data mining for long time, but most traditional algorithms [10, 4, 6, 9, 8, 7] are not efficient to perform data stream analysis. Some data stream algorithms have resolved the scalability problem, but they are not suitable for online analysis because of their complex data structures or time-consuming functions [3, 2]. In this paper we propose an efficient incremental clustering algorithm on data stream model for the K-Means problem. This approach can obtain approximately optimal results online with a small amount of memory space requirement. The empirical results indicate that our algorithm can produce better results from large, high-dimensional data streams than some other data stream algorithms.},
  Affiliation              = {Ph.D. Program in Computer Science, Graduate Center, City University of New York, New York, NY 10016, United States},
  Author_keywords          = {Clustering algorithms; Data streams; K-Means; Multidimensional data},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2005 International Conference on Data Mining, DMIN'05},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper we propose an efficient incremental clustering algorithm on data stream model for the K-Means problem. This approach can obtain approximately optimal results online with a small amount of memory space requirement. The empirical results indicate that our algorithm can produce better results from large, high-dimensional data streams than some other data stream algorithms. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-60749117525&partnerID=40&md5=64be9024cffe6f41e49026906d388ad4}
}

@InProceedings{Wang2011,
  Title                    = {{Online ngram-enhanced topic model for academic retrieval}},
  Author                   = {Wang, Han and Lang, Bo},
  Booktitle                = {2011 Sixth International Conference on Digital Information Management},
  Year                     = {2011},
  Month                    = sep,
  Pages                    = {137--142},
  Publisher                = {IEEE},

  Abstract                 = {Applying topic model to text mining has achieved a great success. However, state-of-art topic modeling methods still have potential to improve in academic retrieval field. In this paper, we propose an online unified topic model, which is ngram-enhanced. Our model discovers topics with unigrams as well as topical bigrams and is updated by an online inference algorithm with the new incoming data streams. On this basis, we combine our model into the query likelihood model and develop an integrated academic searching system. Experiment results on ACM collection show that our proposed methods outperform the existing approaches on document modeling and searching accuracy. Especially, we prove the efficiency of our system on academic retrieval problem.},
  Doi                      = {10.1109/ICDIM.2011.6093316},
  ISBN                     = {978-1-4577-1539-6},
  Keywords                 = {Computational modeling,Data models,Inference algorithms,Mathematical model,Neodymium,Object oriented modeling,Predictive models,academic retrieval,data mining,document modeling,document search,inference mechanisms,information retrieval,integrated academic searching system,maximum likelihood estimation,ngram enhanced topic model,online inference algorithm,query likelihood model,text analysis,text mining,topical bigram,unigram},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Wang2011c},
  Shorttitle               = {Digital Information Management (ICDIM), 2011 Sixth},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6093316}
}

@Conference{Wang2011c,
  Title                    = {Online ngram-enhanced topic model for academic retrieval},
  Author                   = {Wang, H. and Lang, B.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)1},
  Pages                    = {137-142},

  Abstract                 = {Applying topic model to text mining has achieved a great success. However, state-of-art topic modeling methods still have potential to improve in academic retrieval field. In this paper, we propose an online unified topic model, which is ngram-enhanced. Our model discovers topics with unigrams as well as topical bigrams and is updated by an online inference algorithm with the new incoming data streams. On this basis, we combine our model into the query likelihood model and develop an integrated academic searching system. Experiment results on ACM collection show that our proposed methods outperform the existing approaches on document modeling and searching accuracy. Especially, we prove the efficiency of our system on academic retrieval problem. Ã‚Â© 2011 IEEE.},
  Affiliation              = {State Key Laboratory, Software Development Environment, Beihang University, Beijing, 100191, China},
  Art_number               = {6093316},
  Document_type            = {Conference Paper},
  Journal                  = {2011 6th International Conference on Digital Information Management, ICDIM 2011},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an online unified topic model, which is ngram-enhanced. Our model discovers topics with unigrams as well as topical bigrams and is updated by an online inference algorithm with the new incoming data streams. Experiment results on ACM collection show that the proposed methods outperform the existing approaches on document modeling and searching accuracy. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-83755181776&partnerID=40&md5=ee69f8ec20c4c3406e7432cdd5677e08}
}

@Conference{Wang2005a,
  Title                    = {Online mining of data streams: Applications, techniques and progress},
  Author                   = {Wang, H.a and Pei, J.b and Yu, P.S.a},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1146},

  Abstract                 = {[No abstract available]},
  Affiliation              = {IBM T.J. Watson Research Center, United States; Simon Fraser University, Canada},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-28444461756&partnerID=40&md5=f986a3c72e8d0284440e0c324ff79440}
}

@Conference{Wang2006a,
  Title                    = {Suppressing model overfitting in mining concept-drifting data streams},
  Author                   = {Wang, H.a and Yin, J.a and Pei, J.b and Yu, P.S.a and Yu, J.X.c },
  Year                     = {2006},
  Note                     = {cited By (since 1996)13},
  Pages                    = {736-741},
  Volume                   = {2006},

  Abstract                 = {Mining data streams of changing class distributions is important for real-time business decision support. The stream classifier must evolve to reflect the current class distribution. This poses a serious challenge. On the one hand, relying on historical data may increase the chances of learning obsolete models. On the other hand, learning only from the latest data may lead to biased classifiers, as the latest data is often an unrepresentative sample of the current class distribution. The problem is particularly acute in classifying rare events, when, for example, instances of the rare class do not even show up in the most recent training data. In this paper, we use a stochastic model to describe the concept shifting patterns and formulate this problem as an optimization one: from the historical and the current training data that we have observed, find the most-likely current distribution, and learn a classifier based on the most-likely distribution. We derive an analytic solution and approximate this solution with an efficient algorithm, which calibrates the influence of historical data carefully to create an accurate classifier. We evaluate our algorithm with both synthetic and real-world datasets. Our results show that our algorithm produces accurate and efficient classification. Copyright 2006 ACM.},
  Affiliation              = {IBM T. J. Watson Research, United States; Simon Fraser University, Canada; Chinese University of Hong Kong, Hong Kong},
  Author_keywords          = {Classifier; Classifier ensemble; Concept drift; Data streams},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They use a stochastic model to describe the concept shifting patterns and formulate this problem as an optimization one: from the historical and the current training data that we have observed, find the most-likely current distribution, and learn a classifier based on the most-likely distribution. results show that their algorithm produces accurate and efficient classification 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33749559199&partnerID=40&md5=10e50f0bd9facc52e52ef969563db465}
}

@InProceedings{Wang2006c,
  Title                    = {{Suppressing model overfitting in mining concept-drifting data streams}},
  Author                   = {Wang, Haixun and Yin, Jian and Pei, Jian and Yu, Philip S. and Yu, Jeffrey Xu},
  Booktitle                = {Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '06},
  Year                     = {2006},

  Address                  = {New York, New York, USA},
  Month                    = aug,
  Pages                    = {736},
  Publisher                = {ACM Press},

  Abstract                 = {Mining data streams of changing class distributions is important for real-time business decision support. The stream classifier must evolve to reflect the current class distribution. This poses a serious challenge. On the one hand, relying on historical data may increase the chances of learning obsolete models. On the other hand, learning only from the latest data may lead to biased classifiers, as the latest data is often an unrepresentative sample of the current class distribution. The problem is particularly acute in classifying rare events, when, for example, instances of the rare class do not even show up in the most recent training data. In this paper, we use a stochastic model to describe the concept shifting patterns and formulate this problem as an optimization one: from the historical and the current training data that we have observed, find the most-likely current distribution, and learn a classifier based on the most-likely distribution. We derive an analytic solution and approximate this solution with an efficient algorithm, which calibrates the influence of historical data carefully to create an accurate classifier. We evaluate our algorithm with both synthetic and real-world datasets. Our results show that our algorithm produces accurate and efficient classification.},
  Doi                      = {10.1145/1150402.1150496},
  ISBN                     = {1595933395},
  Keywords                 = {classifier,classifier ensemble,concept drift,data streams},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Wang2006a},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1150402.1150496}
}

@Article{Wang2014,
  Title                    = {Seamless integrating and parallel processing based on cloud architecture for hydrocarbon reservoir data},
  Author                   = {Wang, J.a b and Yao, W.a b and Shi, Y.a b and Chen, F.a b and Yang, Z.a b },
  Journal                  = {Natural Gas Industry},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {3},
  Pages                    = {137-141},
  Volume                   = {34},

  Abstract                 = {Hydrocarbon reservoir data are the important resources of scientific research and technological innovation in oil and gas sector. Due to the heterogeneity of multi-source data and the imperfection of integration mechanisms, a large amount of information in the domain of hydrocarbon reservoirs can hardly be reused and shared, which has hindered the process of data mining and decision making in the research and development of oil and gas reservoirs. Therefore, in order to achieve the goals of digital oilfield construction of the PetroChina Changqing Oilfield Company, we proposed a large-scale data processing technology under the cloud computing environments based on the Wrapper/Mediator seamless integrating heterogeneous data and the MapReduce parallel framework. Before this, we first analyzed the dependencies among the various heterogeneous data sets of hydrocarbon reservoirs and the correlation between the service requirement and data center. Then, we applied the improved Wrapper/Mediator strategy to integrate seamlessly those heterogeneous data to conform a standard data stream. Finally, we built a data stream model by the cloud computing technology, and introduced the improved MapReduce technology to parallel and real-time process the hydrocarbon reservoir data stream. The preliminary application results show that the proposed technology guarantees the efficient operation of research and development of hydrocarbon reservoir business, reduces such cost, improves the working efficiency, and enhances the comprehensive competitiveness of an enterprise.},
  Affiliation              = {Exploration and Development Research Institute of Changqing Oilfield Company, PetroChina, Xi'an, Shaanxi 710018, China; State Engineering Laboratory for Exploration and Development of Low-Permeability Gas Fields, Xi'an, Shaanxi 710011, China},
  Author_keywords          = {Cloud architecture; Data stream; Hydrocarbon reservoir; MapReduce; PetroChina Changqing; Seamless integration; Wrapper/Mediator},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper want to make a cloud computing environment based on the Wrapper/Mediator seamless integrating heterogeneous data and the MapReduce parallel framework, used in the oil industri for decision making. approved under uncertainty. could not determine ML 1,4},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84897982993&partnerID=40&md5=a0afebf32fec2bd85a2597555ff8b7da}
}

@Article{Wang2013,
  Title                    = {Online class imbalance learning and its applications in fault detection},
  Author                   = {Wang, S. and Minku, L.L. and Yao, X.},
  Journal                  = {International Journal of Computational Intelligence and Applications},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {4},
  Volume                   = {12},

  Abstract                 = {Although class imbalance learning and online learning have been extensively studied in the literature separately, online class imbalance learning that considers the challenges of both fields has not drawn much attention. It deals with data streams having very skewed class distributions, such as fault diagnosis of real-time control monitoring systems and intrusion detection in computer networks. To fill in this research gap and contribute to a wide range of real-world applications, this paper first formulates online class imbalance learning problems. Based on the problem formulation, a new online learning algorithm, sampling-based online bagging (SOB), is proposed to tackle class imbalance adaptively. Then, we study how SOB and other state-of-the-art methods can benefit a class of fault detection data under various scenarios and analyze their performance in depth. Through extensive experiments, we find that SOB can balance the performance between classes very well across different data domains and produce stable G-mean when learning constantly imbalanced data streams, but it is sensitive to sudden changes in class imbalance, in which case SOB's predecessor undersampling-based online bagging (UOB) is more robust. Ã‚Â© 2013 Imperial College Press.},
  Affiliation              = {CERCIA, School of Computer Science, University of Birmingham, Birmingham, B15 2TT, United Kingdom},
  Art_number               = {1340001},
  Author_keywords          = {fault detection; Online class imbalance; resampling},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {this paper first formulates online class imbalance learning problems. Based on the problem formulation, a new online learning algorithm, sampling-based online bagging (SOB), is proposed to tackle class imbalance adaptively. They find that SOB can balance the performance between classes very well across different data domains and produce stable G-mean when learning constantly imbalanced data streams, but it is sensitive to sudden changes in class imbalance, in which case SOB's predecessor undersampling-based online bagging (UOB) is more robust 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84890359657&partnerID=40&md5=bc81e17cb86eea97625da57ccf876ed7}
}

@Conference{Wang2013a,
  Title                    = {A learning framework for online class imbalance learning},
  Author                   = {Wang, S. and Minku, L.L. and Yao, X.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Pages                    = {36-45},

  Abstract                 = {Online learning has been showing to be very useful for a large number of applications in which data arrive continuously and a timely response is required. In many online cases, the data stream can have very skewed class distributions, known as class imbalance, such as fault diagnosis of realtime control monitoring systems and intrusion detection in computer networks. Classifying imbalanced data streams poses new challenges, which have attracted very little attention so far. As the first work that formally addresses this problem, this paper looks into the underlying issues, clarifies the research questions, and proposes a framework for online class imbalance learning that decomposes the learning task into three modules. Within the framework, we use a time decay function to capture the imbalance rate dynamically. Then, we propose a class imbalance detection method, in order to decide the current imbalance status in data streams. According to this information, two resampling-based online learning algorithms are developed to tackle class imbalance in data streams. Three basic types of class imbalance change are discussed in our studies. The results suggest the usefulness of the learning framework. The proposed methods are shown to be effective on both minority-class accuracy and overall performance in all three cases we considered. Ã‚Â© 2013 IEEE.},
  Affiliation              = {CERCIA, School of Computer Science, University of Birmingham, Birmingham B15 2TT, United Kingdom},
  Art_number               = {6613138},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2013 IEEE Symposium on Computational Intelligence and Ensemble Learning, CIEL 2013 - 2013 IEEE Symposium Series on Computational Intelligence, SSCI 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper tackles the problem of Classifying imbalanced data streams. this paper looks into the underlying issues, clarifies the research questions, and proposes a framework for online class imbalance learning. The authors claim to be the first to look at defining and solve this problem. Could be interesting. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84886779110&partnerID=40&md5=d41687c99accbbf9f44bf6abf0b4e2f1}
}

@Article{Wang2012a,
  Title                    = {Cloud and the city: Facilitating flexible access control over data-streams},
  Author                   = {Wang, W.Q. and Anh, D.T.T. and Lim, H.B. and Datta, A.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {58-74},
  Volume                   = {7482 LNCS},

  Abstract                 = {The proliferation of sensing devices create plethora of data-streams, which in turn can be harnessed to carry out sophisticated analytics to support various real-time applications and services as well as long-term planning, e.g., in the context of intelligent cities or smart homes. A mature cloud infrastructure brings such a vision closer to reality than ever before, as more and more data owners are moving their data to the cloud. Hence, the ability to flexibly and easily control the granularity at which they share their data with other entities become more important. It makes data owners feel comfortable to share to start with, and also provide them a platform to realize different business models or logics. In this paper, we explore some basic operations to flexibly control the access on a data-stream and propose a framework eXACML+ that extends the standard XACML model to achieve the same. We develop a prototype using the commercial StreamBase engine to demonstrate a seamless combination of stream data processing with (a small but important selected set of) fine-grained access control mechanisms, and to evaluate the framework's efficacy based on experiments in cloud like environments. Ã‚Â© 2012 Springer-Verlag.},
  Affiliation              = {Nanyang Technological University, Singapore, Singapore},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {. In this paper, we explore some basic operations to flexibly control the access on a data-stream and propose a framework eXACML+ that extends the standard XACML model to achieve the same. We develop a prototype using the commercial StreamBase engine to demonstrate a seamless combination of stream data processing with (a small but important selected set of) fine-grained access control mechanisms, and to evaluate the framework's efficacy based on experiments in cloud like environments Discarded. only about access controls for streams not ML.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84865639280&partnerID=40&md5=52b5f085c543088d55fa30e206253c5b}
}

@InProceedings{Wang2009,
  Title                    = {{Maintaining only frequent itemsets to mine approximate frequent itemsets over online data streams}},
  Author                   = {Wang, Yongyan and Li, Kun and Wang, Hongan},
  Booktitle                = {2009 IEEE Symposium on Computational Intelligence and Data Mining},
  Year                     = {2009},
  Month                    = mar,
  Pages                    = {381--388},
  Publisher                = {IEEE},

  Abstract                 = {Mining frequent itemsets over online data streams, where the new data arrive and the old data will be removed with high speed, is a challenge for the computational complexity. Existing approximate mining algorithms suffer from explosive computational complexity when decreasing the error parameter, isin, which is used to control the mining accuracy. We propose a new approximate mining algorithm using an approximate frequent itemset tree (abbreviated as AFI-tree), called AFI algorithm, to mine approximate frequent itemsets over online data streams. The AFI-tree based on prefix tree maintains only frequent itemsets, so the number of nodes in the tree is very small. All the infrequent child nodes of any frequent node are pruned and the maximal support of the pruned nodes is estimated to detect new frequent itemsets. In order to guarantee the mining accuracy, when the estimated maximal support of the pruned nodes is a bit more than the minimum support, their supports will be re-computed and the frequent nodes among them will be inserted into the AFI-tree. Experimental results show that the AFI algorithm consumes much less memory space than existing algorithms, and runs much faster than existing algorithms in most occasions.},
  Doi                      = {10.1109/CIDM.2009.4938675},
  ISBN                     = {978-1-4244-2765-9},
  Keywords                 = {AFI-tree,Computational complexity,Data mining,Databases,Degradation,Error correction,Explosives,Financial management,Itemsets,Monitoring,Telecommunication network management,approximate frequent itemset mining algorithm,approximation theory,computational complexity,data mining,online data stream,prefix tree,trees (mathematics)},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Wang2009a},
  Shorttitle               = {Computational Intelligence and Data Mining, 2009. },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4938675}
}

@Conference{Wang2009a,
  Title                    = {Maintaining only frequent itemsets to mine approximate frequent itemsets over online data streams},
  Author                   = {Wang, Y. and Li, K. and Wang, H.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {381-388},

  Abstract                 = {Mining frequent itemsets over online data streams, where the new data arrive and the old data will be removed with high speed, is a challenge for the computational complexity. Existing approximate mining algorithms suffer from explosive computational complexity when decreasing the error parameter, isin, which is used to control the mining accuracy. We propose a new approximate mining algorithm using an approximate frequent itemset tree (abbreviated as AFI-tree), called AFI algorithm, to mine approximate frequent itemsets over online data streams. The AFI-tree based on prefix tree maintains only frequent itemsets, so the number of nodes in the tree is very small. All the infrequent child nodes of any frequent node are pruned and the maximal support of the pruned nodes is estimated to detect new frequent itemsets. In order to guarantee the mining accuracy, when the estimated maximal support of the pruned nodes is a bit more than the minimum support, their supports will be re-computed and the frequent nodes among them will be inserted into the AFI-tree. Experimental results show that the AFI algorithm consumes much less memory space than existing algorithms, and runs much faster than existing algorithms in most occasions. Ã‚Â© 2009 IEEE.},
  Affiliation              = {Intelligence Engineering Lab, Institute of Software, Chinese Academy of Sciences, Beijing, China},
  Art_number               = {4938675},
  Document_type            = {Conference Paper},
  Journal                  = {2009 IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2009 - Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new approximate mining algorithm using an approximate frequent itemset tree (abbreviated as AFI-tree), called AFI algorithm, to mine approximate frequent itemsets over online data streams. Experimental results show that the AFI algorithm consumes much less memory space than existing algorithms, and runs much faster than existing algorithms in most occasions 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-67650534935&partnerID=40&md5=87f97f510119043b66e8c10414add95a}
}

@Article{Wang2006b,
  Title                    = {Correlation analysis algorithm based on low-rank approximation for multiple dimension data streams},
  Author                   = {Wang, Y.-L.a b and Xu, H.-B.a and Dong, Y.-S.a and Qian, J.-B.a and Liu, X.-J.a },
  Journal                  = {Tien Tzu Hsueh Pao/Acta Electronica Sinica},
  Year                     = {2006},
  Note                     = {cited By (since 1996)5},
  Number                   = {2},
  Pages                    = {293-300},
  Volume                   = {34},

  Abstract                 = {Presently existing correlation analysis method for multiple data streams were all oriented single dimensions data streams only, which could not identify the real correlation between fields built by multiple variables. To quickly detect correlations between two multiple dimension data streams under constrained resources, a novel correlation analysis algorithm based on canonical correlation analysis (CCA), called StreamCCA, is proposed. Focusing on the computational bottleneck of traditional CCA, StreamCCA introduces a low-rank approximation technique to reduce the dimensionality of product matrix resulted from sample correlation matrix and sample variance matrix, which improves computational performance efficiently on the premise of holding approximate precision. Theoretic analysis and experiments results on synthetic and real data sets indicate that StreamCCA can online detect correlations between multiple dimension data streams accurately. The algorithms proposed herein, are presented as generic forecasting and diagnosis tools, with a multitude of applications on data streams mining problems.},
  Affiliation              = {Department of Computer Science and Engineering, Southeast University, Nanjing 210096, China; Department of Common Computer Teaching, Jiamusi University, Jiamusi 154007, China},
  Author_keywords          = {Canonical correlation analysis; Data streams; Data streams mining; Low-rank approximation; Non-equal probability sampling},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A novel correlation analysis algorithm based on canonical correlation analysis (CCA), called StreamCCA, is proposed. Focus on reducing the bottleneck of classic CCA. Theoretic analysis and experiments results on synthetic and real data sets indicate that StreamCCA can online detect correlations between multiple dimension data streams accurately. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33646372209&partnerID=40&md5=c2736adc3604c98db378f09a9a153fa5}
}

@Misc{Wang,
  Title                    = {Breaking the curse of kernelization: budgeted stochastic gradient descent for large-scale SVM training},

  Author                   = {Wang, Zhuang and Crammer, Koby and Bldg, Mayer and Vucetic, Slobodan and Zhang, Tong},
  HowPublished             = {Journal of Machine Learning Research},
  Month                    = {January},
  Year                     = {2012},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Online algorithms that process one example at a time are advantageous when dealing with very large data or with data streams. Stochastic Gradient Descent (SGD) is such an algorithm and it is an attractive choice for online Support Vector Machine (SVM) training due to its simplicity and effectiveness. When equipped with kernel functions, similarly to other SVM learning algorithms, SGD is susceptible to the curse of kernelization that causes unbounded linear growth in model size and update time with data size. This may render SGD inapplicable to large data sets. We address this issue by presenting a class of Budgeted SGD (BSGD) algorithms for large-scale kernel SVM training which have constant space and constant time complexity per update. Specifically, BSGD keeps the number of support vectors bounded during training through several budget maintenance strategies. We treat the budget maintenance as a source of the gradient error, and show that the gap between the BSGD and the optimal SVM solutions depends on the model degradation due to budget maintenance. To minimize the gap, we study greedy budget maintenance methods based on removal, projection, and merging of support vectors. We propose budgeted versions of several popular online SVM algorithms that belong to the SGD family. We further derive BSGD algorithms for multi-class SVM training. Comprehensive empirical results show that BSGD achieves higher accuracy than the state-of-the-art budgeted online algorithms and comparable to non-budget algorithms, while achieving impressive computational efficiency both in time and space during training and prediction.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Wang2012b},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.399.5770}
}

@InProceedings{Wang2011a,
  Title                    = {{Mining group correlations over data streams}},
  Author                   = {Wang, Zhijie and Qian, Jiangbo and Zhou, Maochun and Dong, Yihong and Chen, Huahui},
  Booktitle                = {2011 6th International Conference on Computer Science \& Education (ICCSE)},
  Year                     = {2011},
  Month                    = aug,
  Pages                    = {955--959},
  Publisher                = {IEEE},

  Abstract                 = {Mining correlation over steams attracts a lot of attentions recently. However, group correlation analysis over data streams is relatively few. Moreover, existing literatures are mainly focused on a single time window, with large space and time complexity. This paper proposes an online canonical correlation analysis algorithm called MGDS (Mining Group Data Streams). Based on base-window, the MGDS algorithm dynamically maintains a few statistics from raw data to calculate correlation. The mining range is not limited in a single window, but can be changed according to queries. Theoretical analysis and experimental results show that the algorithm is accurate and efficient with space and time overhead reduced greatly.},
  Doi                      = {10.1109/ICCSE.2011.6028794},
  ISBN                     = {978-1-4244-9717-1},
  Keywords                 = {Algorithm design and analysis,Approximation methods,Complexity theory,Correlation,Covariance matrix,Data mining,Queueing analysis,computational complexity,data mining,group correlation analysis,group correlation mining,mining group data streams,multidimensional data streams,online canonical correlation analysis algorithm,space complexity,time complexity},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Wang2011d},
  Shorttitle               = {Computer Science \& Education (ICCSE), 2011 6th Int},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6028794}
}

@Conference{Wang2011d,
  Title                    = {Mining group correlations over data streams},
  Author                   = {Wang, Z. and Qian, J. and Zhou, M. and Dong, Y. and Chen, H.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {955-959},

  Abstract                 = {Mining correlation over steams attracts a lot of attentions recently. However, group correlation analysis over data streams is relatively few. Moreover, existing literatures are mainly focused on a single time window, with large space and time complexity. This paper proposes an online canonical correlation analysis algorithm called MGDS (Mining Group Data Streams). Based on base-window, the MGDS algorithm dynamically maintains a few statistics from raw data to calculate correlation. The mining range is not limited in a single window, but can be changed according to queries. Theoretical analysis and experimental results show that the algorithm is accurate and efficient with space and time overhead reduced greatly. Ã‚Â© 2011 IEEE.},
  Affiliation              = {College of Information Science and Engineering, Ningbo University, Ningbo, China},
  Art_number               = {6028794},
  Author_keywords          = {data mining; group correlation analysis; multidimensional data streams},
  Document_type            = {Conference Paper},
  Journal                  = {ICCSE 2011 - 6th International Conference on Computer Science and Education, Final Program and Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes an online canonical correlation analysis algorithm called MGDS (Mining Group Data Streams). Based on base-window, the MGDS algorithm dynamically maintains a few statistics from raw data to calculate correlation. The mining range is not limited in a single window, but can be changed according to queries. Theoretical analysis and experimental results show that the algorithm is accurate and efficient with space and time overhead reduced greatly. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054017631&partnerID=40&md5=94bbec37038f56de447eb2aba914988a}
}

@Article{Wang2010a,
  Title                    = {Online Passive-Aggressive algorithms on a budget},
  Author                   = {Wang, Z. and Vucetic, S.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},
  Note                     = {cited By (since 1996)6},
  Pages                    = {908-915},
  Volume                   = {9},

  Abstract                 = {In this paper a kernel-based online learning algorithm, which has both constant space and update time, is proposed. The approach is based on the popular online Passive-Aggressive (PA) algorithm. When used in conjunction with kernel function, the number of support vectors in PA grows with-out bounds when learning from noisy data streams. This implies unlimited memory and ever increasing model update and prediction time. To address this issue, the proposed budgeted PA algorithm maintains only a fixed number of support vectors. By introducing an additional constraint to the original PA optimization problem, a closed-form solution was derived for the support vector removal and model update. Using the hinge loss we developed several budgeted PA algorithms that can trade between accuracy and update cost. We also developed the ramp loss versions of both original and budgeted PA and showed that the resulting algorithms can be interpreted as the combination of active learning and hinge loss PA. All proposed algorithms were comprehensively tested on 7 benchmark data sets. The experiments showed that they are superior to the existing budgeted online algorithms. Even with modest budgets, the budgeted PA achieved very competitive accuracies to the non-budgeted PA and kernel perceptron algorithms. Copyright 2010 by the authors.},
  Affiliation              = {Dept. of Computer and Information Sciences, Temple University, United States},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this paper a kernel-based online learning algorithm, which has both constant space and update time, is proposed. The approach is based on the popular online Passive-Aggressive (PA) algorithm. the proposed budgeted PA algorithm maintains only a fixed number of support vectors. All proposed algorithms were comprehensively tested on 7 benchmark data sets. The experiments showed that they are superior to the existing budgeted online algorithms 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84862293746&partnerID=40&md5=06c71339f7367651e546eeb4d4471b36}
}

@Article{Wang2012b,
  Title                    = {Breaking the curse of kernelization: Budgeted stochastic gradient descent for large-scale SVM training},
  Author                   = {Wang, Z.a d and Crammer, K.b and Vucetic, S.c},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2012},
  Note                     = {cited By (since 1996)5},
  Pages                    = {3103-3131},
  Volume                   = {13},

  Abstract                 = {Online algorithms that process one example at a time are advantageous when dealing with very large data or with data streams. Stochastic Gradient Descent (SGD) is such an algorithm and it is an attractive choice for online Support Vector Machine (SVM) training due to its simplicity and effectiveness. When equipped with kernel functions, similarly to other SVM learning algorithms, SGD is susceptible to the curse of kernelization that causes unbounded linear growth in model size and update time with data size. This may render SGD inapplicable to large data sets. We address this issue by presenting a class of Budgeted SGD (BSGD) algorithms for large-scale kernel SVM training which have constant space and constant time complexity per update. Specifically, BSGD keeps the number of support vectors bounded during training through several budget maintenance strategies. We treat the budget maintenance as a source of the gradient error, and show that the gap between the BSGD and the optimal SVM solutions depends on the model degradation due to budget maintenance. To minimize the gap, we study greedy budget maintenance methods based on removal, projection, and merging of support vectors. We propose budgeted versions of several popular online SVM algorithms that belong to the SGD family. We further derive BSGD algorithms for multi-class SVM training. Comprehensive empirical results show that BSGD achieves higher accuracy than the state-of-the-art budgeted online algorithms and comparable to non-budget algorithms, while achieving impressive computational efficiency both in time and space during training and prediction. Ã‚Â© 2012 Zhuang Wang, Koby Crammer and Slobodan Vucetic.},
  Affiliation              = {Corporate Technology, Siemens Corporation, 755 College Road East, Princeton, NJ 08540, United States; Department of Electrical Engineering, Technion, Mayer Bldg, Haifa, 32000, Israel; Department of Computer and Information Sciences, Temple University, 1805 N Broad Street, Philadelphia, PA 19122, United States; Department of Computer and Information Sciences, Temple University, United States},
  Author_keywords          = {Kernel methods; Large-scale learning; Online learning; Stochastic gradient descent; SVM},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Ranking                  = {rank1},
  Relevance                = {relevant},
  Review                   = {This may render SGD (Stochaistic Gradient Descent) inapplicable to large data sets. We address this issue by presenting a class of Budgeted SGD (BSGD) algorithms for large-scale kernel SVM training which have constant space and constant time complexity per update.We propose budgeted versions of several popular online SVM algorithms that belong to the SGD family. We further derive BSGD algorithms for multi-class SVM training. Comprehensive empirical results show that BSGD achieves higher accuracy than the state-of-the-art budgeted online algorithms and comparable to non-budget algorithms, while achieving impressive computational efficiency both in time and space during training and prediction. 1,2,3,4,5,6


Potentially interesting for review discussion also - this paper has a very nice overview hierarchy of Large scale SVM.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84869463516&partnerID=40&md5=9360a34f58214aeb816a6dc03587f775}
}

@InProceedings{Wankhade2012,
  Title                    = {{New evolving ensemble classifier for handling concept drifting data streams}},
  Author                   = {Wankhade, Kapil and Dongre, Snehlata and Thool, Ravindra},
  Booktitle                = {2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing},
  Year                     = {2012},
  Month                    = dec,
  Pages                    = {657--662},
  Publisher                = {IEEE},

  Abstract                 = {Data streams mining have become a novel research topic of growing interest in knowledge discovery. The data streams which are generated from applications, such as network analysis, real time surveillance systems, sensor networks and financial generate huge data streams. These data streams consist of millions or billions of updates and must be processed to extract the useful information. Because of the high speed and huge size of data set in data streams, the traditional classification technologies are no longer applicable. In recent years a great deal of research has been done on this problem, most intends to efficiently solve the data streams mining problem with concept drift. This paper presents a novel approach for data stream classification which handles concept drift. This approach uses weighted majority approach with adaptive sliding window strategies. The experimental result shows that this novel approach works better than other methods.},
  Doi                      = {10.1109/PDGC.2012.6449898},
  ISBN                     = {978-1-4673-2925-5},
  Keywords                 = {Robustness,adaptive sliding window,classification technologies,concept drift,concept drifting data streams,data mining,data stream mining,data streams mining,ensemble classifier,knowledge discovery,pattern classification,weighted majority},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Wankhade2012a},
  Shorttitle               = {Parallel Distributed and Grid Computing (PDGC), 20},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6449898}
}

@Conference{Wankhade2012a,
  Title                    = {New evolving ensemble classifier for handling concept drifting data streams},
  Author                   = {Wankhade, K.a and Dongre, S.a and Thool, R.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {657-662},

  Abstract                 = {Data streams mining have become a novel research topic of growing interest in knowledge discovery. The data streams which are generated from applications, such as network analysis, real time surveillance systems, sensor networks and financial generate huge data streams. These data streams consist of millions or billions of updates and must be processed to extract the useful information. Because of the high speed and huge size of data set in data streams, the traditional classification technologies are no longer applicable. In recent years a great deal of research has been done on this problem, most intends to efficiently solve the data streams mining problem with concept drift. This paper presents a novel approach for data stream classification which handles concept drift. This approach uses weighted majority approach with adaptive sliding window strategies. The experimental result shows that this novel approach works better than other methods. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Department of Information Technology, G. H. Raisoni College of Engineering, Nagpur, Nagpur, Maharashtra, India; Department of Information Technology, S. G. G. S. Institute of Engg. and Technology, Nanded, Nanded, Maharashtra, India},
  Art_number               = {6449898},
  Author_keywords          = {adaptive sliding window; concept drift; data stream mining; weighted majority},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of 2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing, PDGC 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents a novel approach for data stream classification which handles concept drift. This approach uses weighted majority approach with adaptive sliding window strategies. The experimental result shows that this novel approach works better than other methods. Weak abstract, very few details. 1,2,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84874413581&partnerID=40&md5=3013b1ff07d27fbbaf683a3242998ce6}
}

@InProceedings{Wickramaarachchi2013,
  Title                    = {{Continuous Dataflow Update Strategies for Mission-Critical Applications}},
  Author                   = {Wickramaarachchi, Charith and Simmhan, Yogesh},
  Booktitle                = {2013 IEEE 9th International Conference on e-Science},
  Year                     = {2013},
  Month                    = oct,
  Pages                    = {155--163},
  Publisher                = {IEEE},

  Abstract                 = {Continuous data flows complement scientific work-flows by allowing composition of real time data ingest and analytics pipelines to process data streams from pervasive sensors and "always-on" scientific instruments. Such data flows are mission-critical applications that cannot suffer downtime, need to operate consistently, and are long running, but may need to be updated to fix bugs or add features. This poses the problem: How do we update the continuous dataflow application with minimal disruption? In this paper, we formalize different types of dataflow update models for continuous dataflow applications, and identify the qualitative and quantitative metrics to be considered when choosing an update strategy. We propose five dataflow update strategies, and analytically characterize their performance trade-offs. We validate one of these consistent, low-latency update strategies using the Floe dataflow engine for an eEngineering application from the Smart Power Grid domain, and show its relative performance benefits against a naiÃŒË†ve update strategy.},
  Doi                      = {10.1109/eScience.2013.35},
  ISBN                     = {978-0-7695-5083-1},
  Keywords                 = {Buildings,Engines,Measurement,Predictive models,Sensor phenomena and characterization,Throughput,continuous dataflow update strategies,continuous dataflows,data flow analysis,dataflow engine,dynamic reconfiguration,dynamic update,eEngineering,low-latency update strategies,mission-critical applications,power engineering computing,scientific workflows,smart power grid,smart power grids},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {In this paper, we formalize different types of dataflow update models for continuous dataflow applications, and identify the qualitative and quantitative metrics to be considered when choosing an update strategy. We propose five dataflow update strategies, and analytically characterize their performance trade-offs Discarded, Dataflow update is not ML},
  Shorttitle               = {eScience (eScience), 2013 IEEE 9th International C},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6683903}
}

@Misc{Wojnarski,
  Title                    = {{Debellor: A Data Mining Platform with Stream Architecture}},

  Author                   = {Wojnarski, Marcin},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Wojnarski2008},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.156.4590}
}

@Misc{Wojnarskia,
  Title                    = {{Recent Advances in Intelligent Information Systems ISBN 978-83-60434-59-8, pages 669â€“682 Debellor: Open Source Modular Platform for Scalable Data Mining}},

  Author                   = {Wojnarski, Marcin},

  __markedentry            = {[Alexander:]},
  Abstract                 = {This paper introduces Debellor (www.debellor.org) – an open source extensible data mining platform with stream-oriented architecture, where all data transfers between elementary algorithms take the form of a stream of samples. Data streaming enables implementation of scalable algorithms, which can efficiently process large volumes of data, exceeding available memory. This is very important for data mining research and applications, since the most challenging data mining tasks involve voluminous data, either produced by a data source or generated at some intermediate stage of a complex data processing network. Advantages of data streaming are illustrated by experiments with clustering time series. The experimental results show that even for moderate-size data sets streaming is indispensable for successful execution of algorithms, otherwise the algorithms run hundreds times slower or just crash due to memory shortage. Stream architecture is particularly useful in such application domains as time series analysis, image recognition or mining data streams. It is also the only efficient architecture for implementation of online algorithms. Due to its scalability and modularity Debellor was chosen as the basis for TunedTester application – one of three pillars of TunedIT (tunedit.org) system for automatic evaluation of machine learning algorithms},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.156.5204}
}

@Article{Wojnarski2008,
  Title                    = {Debellor: A data mining platform with stream architecture},
  Author                   = {Wojnarski, M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2008},
  Note                     = {cited By (since 1996)2},
  Pages                    = {405-427},
  Volume                   = {5390 LNCS},

  Abstract                 = {This paper introduces Debellor (www.debellor.org) - an open source extensible data mining platform with stream-based architecture, where all data transfers between elementary algorithms take the form of a stream of samples. Data streaming enables implementation of scalable algorithms, which can efficiently process large volumes of data, exceeding available memory. This is very important for data mining research and applications, since the most challenging data mining tasks involve voluminous data, either produced by a data source or generated at some intermediate stage of a complex data processing network. Advantages of data streaming are illustrated by experiments with clustering time series. The experimental results show that even for moderate-size data sets streaming is indispensable for successful execution of algorithms, otherwise the algorithms run hundreds times slower or just crash due to memory shortage. Stream architecture is particularly useful in such application domains as time series analysis, image recognition or mining data streams. It is also the only efficient architecture for implementation of online algorithms. The algorithms currently available on Debellor platform include all classifiers from Rseslib and Weka libraries and all filters from Weka. Ã‚Â© 2008 Springer Berlin Heidelberg.},
  Affiliation              = {Faculty of Mathematics, Informatics and Mechanics, Warsaw University, ul. Banacha 2, Warszawa 02-097, Poland},
  Author_keywords          = {Library; Online Algorithms; Pipeline; Software Environment},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper introduces Debellor (www.debellor.org) - an open source extensible data mining platform with stream-based architecture, where all data transfers between elementary algorithms take the form of a stream of samples. Data streaming enables implementation of scalable algorithms, which can efficiently process large volumes of data. The experimental results show that even for moderate-size data sets streaming is indispensable for successful execution of algorithms approved under uncertainty. No new algorithms have been developed for this platform, it's basically Weka for streaming. 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-58449113605&partnerID=40&md5=6a4fca25db176d8a55870dba55aefcfc}
}

@Article{Woo2009,
  Title                    = {EstMax: Tracing maximal frequent item sets instantly over online transactional data streams},
  Author                   = {Woo, H.J. and Lee, W.S.},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2009},
  Note                     = {cited By (since 1996)10},
  Number                   = {10},
  Pages                    = {1418-1431},
  Volume                   = {21},

  Abstract                 = {Frequent item set mining is one of the most challenging issues for descriptive data mining. In general, its resulting set tends to produce a large number of frequent item sets. To represent them in a more compact notation, closed or maximal frequent item sets are often used but finding such item sets over online transactional data streams is not easy due to the requirements of a data stream. For this purpose, this paper proposes a method of tracing the set of MFIs instantly over an online data stream. The method, namely estMax, maintains the set of frequent item sets by a prefix tree and extracts all MFIs without any additional superset/subset checking mechanism. Upon processing a new transaction, those frequent item sets that are matched maximally by the transaction are newly marked in their corresponding nodes of the prefix tree as candidates for MFIs. At the same time, if any subset of a newly marked item set has been already marked as a candidate MFI by a previous transaction, it is cleared as well. By employing this additional step, it is possible to extract the set of MFIs at any moment. The performance of the estMax method is comparatively analyzed by a series of experiments to identify its various characteristics. Ã‚Â© 2006 IEEE.},
  Affiliation              = {Department of Computer Science, Yonsei University, Engineering Building, 134 Shinchon-Dong, Seodaemoon-Gu, Seoul, 120-749, South Korea},
  Art_number               = {4711051},
  Author_keywords          = {Data mining; Maximal frequent item sets; Transactional data streams},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {, this paper proposes a method of tracing the set of MFI (Max Frequent Itemsets) instantly over an online data stream. The method, namely estMax, maintains the set of frequent item sets by a prefix tree and extracts all MFIs without any additional superset/subset checking mechanism. The performance of the estMax method is comparatively analyzed by a series of experiments to identify its various characteristics 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70349312375&partnerID=40&md5=b2bc0b2c9bcb32864c0c4f7c21b3dc59}
}

@Conference{Wozniak2002,
  Title                    = {SkyDOT (Sky Database for Objects in the Time domain): A Virtual Observatory for variability studies at LANL},
  Author                   = {Wozniak, P.a b and Borozdin, K.a and Galassi, M.a and Priedhorsky, W.a and Starr, D.a and Vestrand, W.T.a and White, R.a and Wren, J.a },
  Year                     = {2002},
  Note                     = {cited By (since 1996)4},
  Pages                    = {147-157},
  Volume                   = {4846},

  Abstract                 = {The mining of Virtual Observatories (VOs) is becoming a powerful new method for discovery in astronomy. Here we report on the development of SkyDOT (Sky Database for Objects in the Time domain), a new Virtual Observatory, which is dedicated to the study of sky variability. The site will confederate a number of massive variability surveys and enable exploration of the time domain in astronomy. We discuss the architecture of the database and the functionality of the user interface. An important aspect of SkyDOT is that it is continuously updated in near real time so that users can access new observations in a timely manner. The site will also utilize high level machine learning tools that will allow sophisticated mining of the archive. Another key feature is the real time data stream provided by RAPTOR (RAPid Telescopes for Optical Response), a new sky monitoring experiment under construction at Los Alamos National Laboratory (LANL).},
  Affiliation              = {Los Alamos National Laboratory, Los Alamos, NM, United States; Los Alamos National Laboratory, MS-D436, Los Alamos, NM 87545, United States},
  Author_keywords          = {Data Mining; Database; Real-time sky monitoring; Variable stars; Virtual Observatory},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of SPIE - The International Society for Optical Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {discuss the architecture of the database and the functionality of the user interface. discarded.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0037627330&partnerID=40&md5=0968183dbf48098f9d42ceee8b29a0ab}
}

@InProceedings{Wu2009,
  Title                    = {{Mining Frequent Patterns in Data Stream over Sliding Windows}},
  Author                   = {Wu, Feng and Wu, Quanyuan and Zhong, Yan and Jin, Xin},
  Booktitle                = {2009 International Conference on Computational Intelligence and Software Engineering},
  Year                     = {2009},
  Month                    = dec,
  Pages                    = {1--4},
  Publisher                = {IEEE},

  Abstract                 = {Frequent pattern mining in data stream is an important task. Under the time decay model, this paper presents a new algorithm SWFP for mining frequent patterns over sliding windows. The new definitions of the infrequent, critical and frequent patterns which reflect the actual statistical property of each pattern within the sliding windows, grasp the real substance of mining process and help to improve the mining quality essentially. The support decay mechanism is designed not only to differentiate the current and history transaction, but also to make the online pattern maintain operation easily and accurately. The reasonable strategy for the pattern pruning periodically is used to make big cuts in the maintenance cost and the error controlled in a small bound. Theoretical analysis guarantees no false negatives of SWFP. Experimental evaluation over a number of synthetic data sets demonstrates the efficiency and scalability of our method.},
  Doi                      = {10.1109/CISE.2009.5363461},
  ISBN                     = {978-1-4244-4507-3},
  Keywords                 = {Costs,Data mining,Data structures,Dictionaries,Educational institutions,Error correction,History,Scalability,Sliding mode control,data mining,data stream,frequent pattern mining,sliding windows,statistical analysis,statistical property,synthetic data sets},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Wu2009a},
  Shorttitle               = {Computational Intelligence and Software Engineerin},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5363461}
}

@Conference{Wu2009a,
  Title                    = {Mining frequent patterns in data stream over sliding windows},
  Author                   = {Wu, F.a and Wu, Q.a and Zhong, Y.a and Jin, X.b},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {Frequent pattern mining in data stream is an important task. Under the time decay model, this paper presents a new algorithm SWFP for mining frequent patterns over sliding windows. The new definitions of the infrequent, critical and frequent patterns which reflect the actual statistical property of each pattern within the sliding windows, grasp the real substance of mining process and help to improve the mining quality essentially. The support decay mechanism is designed not only to differentiate the current and history transaction, but also to make the online pattern maintain operation easily and accurately. The reasonable strategy for the pattern pruning periodically is used to make big cuts in the maintenance cost and the error controlled in a small bound. Theoretical analysis guarantees no false negatives of SWFP. Experimental evaluation over a number of synthetic data sets demonstrates the efficiency and scalability of our method. Ã‚Â©2009 IEEE.},
  Affiliation              = {School of Computer, National University of Defense Technology, Changsha, China; Changsha Social Work College, Changsha, China},
  Art_number               = {5363461},
  Author_keywords          = {Data stream; Frequent pattern mining; Sliding windows; Time decay model},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2009 International Conference on Computational Intelligence and Software Engineering, CiSE 2009},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Under the time decay model, this paper presents a new algorithm SWFP for mining frequent patterns over sliding windows. The support decay mechanism is designed not only to differentiate the current and history transaction, but also to make the online pattern maintain operation easily and accurately. Experimental evaluation over a number of synthetic data sets demonstrates the efficiency and scalability of our method 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77949683769&partnerID=40&md5=9652abca3e2c93366d906a4171f0c11c}
}

@Article{Wu2013,
  Title                    = {Study on the online clustering algorithm based on grid structure},
  Author                   = {Wu, P. and Jia, J. and Zhu, T.},
  Journal                  = {Advances in Intelligent Systems and Computing},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {401-405},
  Volume                   = {180 AISC},

  Abstract                 = {Clustering is an important task in data mining and knowledge discovery, which groups objects into meaningful subclasses. As the most existing stream clustering, algorithms can not generate online clustering results in real-time, an online data stream clustering algorithm is proposed by using sliding windows and density-based grid storage structure. The algorithm achieves a rapid speed for online clustering data stream and it can provide users with real-time clustering results and reflect the dynamic evolution of data streams. Experimental results show that the algorithm proposed has a good capacity of dealing with rapid evolutional data stream and have a good clustering quality. Ã‚Â© 2013 Springer-Verlag.},
  Affiliation              = {Shenyang University of Technology, School of Software, Shenyang 110023, China},
  Author_keywords          = {data mining; data stream; online clustering},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {an online data stream clustering algorithm is proposed by using sliding windows and density-based grid storage structure. The algorithm achieves a rapid speed for online clustering data stream and it can provide users with real-time clustering results and reflect the dynamic evolution of data streams. Experimental results show that the algorithm proposed has a good capacity of dealing with rapid evolutional data stream and have a good clustering quality 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870730649&partnerID=40&md5=2cbbb9d7fdcfb32af14ae29ee3422c77}
}

@Conference{Wu2012a,
  Title                    = {To taxi or not to taxi? - Enabling personalised and real-time transportation decisions for mobile users},
  Author                   = {Wu, W.a and Ng, W.S.a and Krishnaswamy, S.a and Sinha, A.b },
  Year                     = {2012},
  Note                     = {cited By (since 1996)1},
  Pages                    = {320-323},

  Abstract                 = {We demonstrate a system that monitors the taxi availability at taxi stands by mining real-time taxi trajectory data streams. The system includes a server-side trajectory data stream processing and mining program and a client-side mobile application for Android smart phones. The server program continuously monitors for each taxi stand the numbers of taxis queueing at the taxi stand, the numbers of taxis that will pass the taxi stand, as well as the traffic conditions in the area around the stand. It delivers real time taxi and traffic information to mobile users via Restful web services. The client-side location-based mobile application consumes these services to help mobile users make informed transportation choices. For example the availability of taxis might yet be a deterrent when traffic is congested. Real world taxi trajectory data from more than 14000 taxis are used in the demo. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Data Mining Department, Institute for Infocomm Research, ASTAR, Singapore, Singapore; Faculty of Information Technology, Monash University, Australia},
  Art_number               = {6341410},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2012 IEEE 13th International Conference on Mobile Data Management, MDM 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They demonstrate a system that monitors the taxi availability at taxi stands by mining real-time taxi trajectory data streams 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870744470&partnerID=40&md5=1cb0a10dd839c45f9b72ec4c0af42271}
}

@InProceedings{Wu2012,
  Title                    = {{To Taxi or Not to Taxi? - Enabling Personalised and Real-Time Transportation Decisions for Mobile Users}},
  Author                   = {Wu, Wei and Ng, Wee Siong and Krishnaswamy, Shonali and Sinha, Abhijat},
  Booktitle                = {2012 IEEE 13th International Conference on Mobile Data Management},
  Year                     = {2012},
  Month                    = jul,
  Pages                    = {320--323},
  Publisher                = {IEEE},

  Abstract                 = {We demonstrate a system that monitors the taxi availability at taxi stands by mining real-time taxi trajectory data streams. The system includes a server-side trajectory data stream processing and mining program and a client-side mobile application for Android smart phones. The server program continuously monitors for each taxi stand the numbers of taxis queueing at the taxi stand, the numbers of taxis that will pass the taxi stand, as well as the traffic conditions in the area around the stand. It delivers real time taxi and traffic information to mobile users via Restful web services. The client-side location-based mobile application consumes these services to help mobile users make informed transportation choices. For example the availability of taxis might yet be a deterrent when traffic is congested. Real world taxi trajectory data from more than 14000 taxis are used in the demo.},
  Doi                      = {10.1109/MDM.2012.55},
  ISBN                     = {978-1-4673-1796-2},
  Keywords                 = {Android smartphones,Availability,Data mining,Mobile communication,Monitoring,RESTful Web services,Real-time systems,Servers,Trajectory,Web services,client-side mobile application,data mining,decision making,mobile computing,mobile users,operating systems (computers),personalised transportation decisions,real-time taxi trajectory data stream mining,real-time transportation decisions,taxi availability,taxi queueing,taxi stands,traffic information,traffic information systems,transportation},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Wu2012a},
  Shorttitle               = {Mobile Data Management (MDM), 2012 IEEE 13th Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6341410}
}

@Misc{Xi,
  Title                    = {{Compression and Aggregation for Logistic Regression Analysis in Data Cubes}},

  Author                   = {Xi, Ruibin and Lin, Nan and Chen, Yixin},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Logistic regression is an important technique for analyzing and predicting data with categorical attributes. In this paper, we consider supporting online analytical processing (OLAP) of logistic regression analysis for multi-dimensional data in a data cube where it is expensive in time and space to build logistic regression models for each cell from the raw data. We propose a novel scheme to compress the data in such a way that we can reconstruct logistic regression models to answer any OLAP query without accessing the raw data. Based on a first-order approximation to the maximum likelihood estimating equations, we develop a compression scheme that compresses each base cell into a small compressed data block with essential information to support the aggregation of logistic regression models. Aggregation formulae for deriving high-level logistic regression models from lower level component cells are given. We prove that the compression is asymptotically lossless in the sense that the aggregated estimator deviates from the true model by an error that is bounded and approaches to zero when the data size increases. The results show that the proposed compression and aggregation scheme can make feasible OLAP of logistic regression in a data cube. Further, it supports realtime logistic regression analysis of stream data which can only be scanned once and cannot be permanently retained. Experimental results validate our theoretical analysis and demonstrate that our method can dramatically save time and space costs with almost no degradation of the modelling accuracy. Index Terms — data cubes, online analytical processing, logistic regression, compression, aggregation},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {We propose a novel scheme to compress the data in such a way that we can reconstruct logistic regression models to answer any OLAP query without accessing the raw data. it supports realtime logistic regression analysis of stream data which can only be scanned once and cannot be permanently retained. Experimental results validate our theoretical analysis and demonstrate that our method can dramatically save time and space costs with almost no degradation of the modelling accuracy approved under uncertainty, it's about data compression, but it enables online analytical processing.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.656}
}

@InProceedings{Xiaojun2012,
  Title                    = {{Mining Accurate Top-K Frequent Closed Itemset from Data Stream}},
  Author                   = {Xiaojun, Cao},
  Booktitle                = {2012 International Conference on Computer Science and Electronics Engineering},
  Year                     = {2012},
  Month                    = mar,
  Pages                    = {180--184},
  Publisher                = {IEEE},
  Volume                   = {2},

  Abstract                 = {Frequent Closed Item set mining on data streams is of great significance. Though a minimum support threshold is assumed to be available in classical mining, it is hard to determine it in data streams. Hence, it is more reasonable to ask users to set a bound on the result size. Therefore, a real-time single-pass algorithm, called Top-k frequent closed item sets and a new way of updating the minimum support were proposed for mining top-K closed item sets from data streams efficiently. A novel algorithm, called Can(T), is developed for mining the essential candidate of closed item sets generated so far. Experimental results show that the proposed the algorithm in this paper is an efficient method for mining top-K frequent item sets from data streams.},
  Doi                      = {10.1109/ICCSEE.2012.263},
  ISBN                     = {978-0-7695-4647-6},
  Keywords                 = {Algorithm design and analysis,Approximation algorithms,Association rules,Can(T) algorithm,Data structures,Itemsets,Lattices,closed frequent itemsets,data mining,data streams,minimum support threshold,real-time single-pass algorithm,top-K,top-k frequent closed item set mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A real-time single-pass algorithm, called Top-k frequent closed item sets and a new way of updating the minimum support were proposed for mining top-K closed item sets from data streams efficiently. A novel algorithm, called Can(T), is developed for mining the essential candidate of closed item sets generated so far. Experimental results show that the proposed the algorithm in this paper is an efficient method for mining top-K frequent item sets from data streams. 1,3,4,6},
  Shorttitle               = {Computer Science and Electronics Engineering (ICCS},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6187930}
}

@Conference{Xie2013,
  Title                    = {Local correlation detection with linearity enhancement in streaming data},
  Author                   = {Xie, Q.a and Shang, S.b and Yuan, B.c and Pang, C.d and Zhang, X.a },
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {309-318},

  Abstract                 = {This paper addresses the challenges in detecting the potential correlation between numerical data streams, which facilitates the research of data stream mining and pattern discovery. We focus on local correlation with delay, which may occur in burst at different time in different streams, and last for a limited period. The uncertainty on the correlation occurrence and the time delay make it diff cult to monitor the correlation online. Furthermore, the conventional correlation measure lacks the ability of ref ecting visual linearity, which is more desirable in reality. This paper proposes effective methods to continuously detect the correlation between data streams. Our approach is based on the Discrete Fourier Transform to make rapid cross-correlation calculation with time delay allowed. In addition, we introduce a shape-based similarity measure into the framework, which ref nes the results by representative trend patterns to enhance the signif cance of linearity. The similarity of proposed linear representations can quickly estimate the correlation, and the window sliding strategy in segment level improves the eff ciency for online detection. The empirical study demonstrates the accuracy of our detection approach, as well as more than 30% improvement of eff ciency. Copyright 2013 ACM.},
  Affiliation              = {Division of CEMSE, King Abdullah University of Science and Technology, Saudi Arabia; Beijing Key Laboratory of Petroleum Data Mining, Department of Software Engineering, China University of Petroleum, Beijing, China; Division of Informatics, Graduate School at Shenzhen, Tsinghua University, China; Australian E-Health Research Centre, CSIRO, China},
  Author_keywords          = {Correlation detection; Data stream; Linear approximation},
  Document_type            = {Conference Paper},
  Journal                  = {International Conference on Information and Knowledge Management, Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper proposes effective methods to continuously detect the correlation between data streams. Appears to be gathering trend patterns and using them to estimate correlation. Approved, but under doubt about machine learning or not. 1,3,4},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84889606435&partnerID=40&md5=19bebe5f72c1a193db6990d0b124b8a9}
}

@InProceedings{Xie2013a,
  Title                    = {{Local correlation detection with linearity enhancement in streaming data}},
  Author                   = {Xie, Qing and Shang, Shuo and Yuan, Bo and Pang, Chaoyi and Zhang, Xiangliang},
  Booktitle                = {Proceedings of the 22nd ACM international conference on Conference on information \& knowledge management - CIKM '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = oct,
  Pages                    = {309--318},
  Publisher                = {ACM Press},

  Abstract                 = {This paper addresses the challenges in detecting the potential correlation between numerical data streams, which facilitates the research of data stream mining and pattern discovery. We focus on local correlation with delay, which may occur in burst at different time in different streams, and last for a limited period. The uncertainty on the correlation occurrence and the time delay make it difficult to monitor the correlation online. Furthermore, the conventional correlation measure lacks the ability of reflecting visual linearity, which is more desirable in reality. This paper proposes effective methods to continuously detect the correlation between data streams. Our approach is based on the Discrete Fourier Transform to make rapid cross-correlation calculation with time delay allowed. In addition, we introduce a shape-based similarity measure into the framework, which refines the results by representative trend patterns to enhance the significance of linearity. The similarity of proposed linear representations can quickly estimate the correlation, and the window sliding strategy in segment level improves the efficiency for online detection. The empirical study demonstrates the accuracy of our detection approach, as well as more than $30\%$ improvement of efficiency.},
  Doi                      = {10.1145/2505515.2505746},
  ISBN                     = {9781450322638},
  Keywords                 = {correlation detection,data stream,linear approximation},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Xie2013},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2505515.2505746}
}

@Article{Xie2008,
  Title                    = {Capturing concepts and detecting concept-drift from potential unbounded, ever-evolving and high-dimensional data streams},
  Author                   = {Xie, Y.a and Ravichandran, A.b and Haddad, H.a and Jayasimha, K.b },
  Journal                  = {Studies in Computational Intelligence},
  Year                     = {2008},
  Note                     = {cited By (since 1996)1},
  Pages                    = {485-499},
  Volume                   = {118},

  Abstract                 = {Envisioning the needs of a new platform that supports comprehensive knowledge discovery and retrieval from potential unbounded, multi-dimensional and ever evolving data streams, this paper proposes a novel integrated architecture that encapsulates a suit of interrelated data structures and algorithms which support (1) real-time capturing and compressing dynamics of stream data into space-efficient synopses, (2) online mining and visualizing both dynamics and historical snapshots of multiple types of patterns from stored synopses. Preliminary experimental results are provided to illustrate the effectiveness of the provided architecture in capturing concepts and detecting concept-drift from streaming data. Ã‚Â© 2008 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {The CSIS Department, Kennesaw State University, Kennesaw, GA 30144, United States; CACS, University of Louisiana at Lafayette, Lafayette, LA 70504, United States},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {this paper proposes a novel integrated architecture that encapsulates a suit of interrelated data structures and algorithms which support (1) real-time capturing and compressing dynamics of stream data into space-efficient synopses, (2) online mining and visualizing both dynamics and historical snapshots of multiple types of patterns from stored synopses. Preliminary experimental results are provided to illustrate the effectiveness of the provided architecture 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-51349162574&partnerID=40&md5=a40e8c76d861ab20243458fb12f3f2be}
}

@Article{Xie2010,
  Title                    = {{E.A.: Visual analysis of multivariate data streams based on doi functions}},
  Author                   = {Xie, Zaixian and Ward, Matthew and Rundensteiner, Elke},
  Year                     = {2010},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The analysis of data streams has become quite important in recent years, and is being studied intensively in fields such as database management and data mining. Although some researchers in data and information visualization have investigated the visual analytics of streaming data to a certain degree, there are some obvious limitations in existing work: (1) a lack of effective techniques to show how data patterns change over time; and (2) limited ability to represent multivariate correlations. In this paper, we propose a framework to visualize multivariate data streams via a combination of windowing and sampling strategies. In order to help users observe how data patterns change over time, we display not only the current sliding window but also abstractions of past data in which users are interested. Sampling is applied within each single sliding window to help reduce visual clutter as well as preserve data patterns. Further, we allow different windows to have different sampling ratios to reflect how interested the user is in the contents. We use a DOI (degree of interest) function to represent users ’ interest in the data within a set of windows. Users can apply two types of pre-defined DOI functions. An interactive tool also allows users to adjust the DOI function online, in a manner similar to transfer functions in volume visualization, to enable a trial-and-error exploration process},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a framework to visualize multivariate data streams via a combination of windowing and sampling strategies. In order to help users observe how data patterns change over time, we display not only the current sliding window but also abstractions of past data in which users are interested. 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.309.6463}
}

@InProceedings{XSWC2013,
  Title                    = {{An integrated framework for managing massive and heterogeneous sensor data using cloud computing}},
  Author                   = {{Xin Song} and {Cuirong Wang} and {Yanjun Chen}},
  Booktitle                = {Proceedings 2013 International Conference on Mechatronic Sciences, Electric Engineering and Computer (MEC)},
  Year                     = {2013},
  Month                    = dec,
  Pages                    = {461--464},
  Publisher                = {IEEE},

  Abstract                 = {Cloud computing can provide a powerful, scalable storage and the massive data processing infrastructure to perform both online and offline analysis and mining of the heterogeneous sensor data streams. With the recent explosion of wireless sensor networks and their applicability in military and civilian applications, there is an emerging vision for integrating sensor networks into the cloud computing platform. In contrast to traditional data objects, the sensor data objects have continuously changed, high-dimensional, spatiotemporal relation and heterogeneous attributes. Therefore, the management and processing problem of the massive sensor data objects can be more complicated. The paper formally presents an integrated framework for managing massive and heterogeneous sensor data with insights into the high-dimensional problem using the map-reduce platform of cloud computing. The proposed framework incorporates key concepts such as parallel-processing, scalability and flexibility of resources, sensor data uncertainty and the dynamic deployment and management of applications.},
  Doi                      = {10.1109/MEC.2013.6885113},
  ISBN                     = {978-1-4799-2565-0},
  Keywords                 = {Cloud computing,Data mining,Data processing,Distributed databases,Dynamic scheduling,MapReduce,MapReduce platform,Massive sensor data management,Parallel processing,Wireless sensor networks,cloud computing,data handling,dynamic deployment,heterogeneous sensor data management,high-dimensional data problem,massive data processing infrastructure,parallel processing,sensor data uncertainty},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {The paper formally presents an integrated framework for managing massive and heterogeneous sensor data with insights into the high-dimensional problem using the map-reduce platform of cloud computing DIscarded. Not about ML, only about data processing.},
  Shorttitle               = {Mechatronic Sciences, Electric Engineering and Com},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6885113}
}

@Article{Xiong2009,
  Title                    = {ODMCA: An adaptive data mining control algorithm in multicarrier networks },
  Author                   = {Naixue Xiong and Laurence T. Yang and Yingshu Li},
  Journal                  = {Computer Communications },
  Year                     = {2009},
  Note                     = {Adaptive Multicarrier Communications and Networks },
  Number                   = {3},
  Pages                    = {560 - 567},
  Volume                   = {32},

  Abstract                 = {Multicarrier communication is a promising technique to effectively deliver high data rate and combat delay spread over fading channel, and adaptability is an inherent advantage of multicarrier communication systems. It can be implemented in online data streams. This paper addresses a significant problem in multicarrier networks that arises in data streaming scenarios, namely, todayÃ¢â‚¬â„¢s data mining is ill-equipped to handle data streams effectively, and pays little attention to the network stability and the fast response [http://www-db.standford.edu/stream]. Furthermore, in analysis of massive data streams, the ability to process the data in a single pass, while using little memory, is crucial. For often the data can be transmitted faster than it can be stored or accessed from disks. To address the question, we present an adaptive control-theoretic explicit rate (ER) online data mining control algorithm (ODMCA) to regulate the sending rate of mined data, which accounts for the main memory occupancies of terminal nodes. This single-pass scheme considers limited memory space to process dynamic data streams, and also explores the adaptive capability, which is employed in a general network computation model for dynamic data streams. The proposed method uses a distributed proportional integrative plus derivative (PID) controller combined with data mining, where the control parameters can be designed to ensure the stability of the control loop in terms of sending rate of mined data. The basic \{PID\} approach for the computation network transmission is presented and z-transformation and SchurÃ¢â‚¬â€œCohn stability test are used to achieve the stability criterion, which ensures the bounded rate allocation without steady state oscillation. We further show how the \{ODMCA\} can be used to design a controller, analyze the theoretical aspects of the proposed algorithm and verify its agreement with the simulations in the \{LAN\} case and the \{WAN\} case. Simulation results show the efficiency of our scheme in terms of high main memory occupancy, fast response of the main memory occupancy and of the controlled sending rates.},
  Doi                      = {http://dx.doi.org/10.1016/j.comcom.2008.08.026},
  ISSN                     = {0140-3664},
  Keywords                 = {Control theory},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present an adaptive control-theoretic explicit rate (ER) online data mining control algorithm (ODMCA) to regulate the sending rate of mined data. This single-pass scheme considers limited memory space to process dynamic data streams. Simulation results show the efficiency of our scheme in terms of high main memory occupancy, fast response of the main memory occupancy and of the controlled sending rates. Approved, but not 100% sure about the ML part. It's a control algorithm, is that ML?},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0140366408004659}
}

@Article{Xu2013,
  Title                    = {PRESEE: An MDL/MML algorithm to time-series stream segmenting},
  Author                   = {Xu, K.a and Jiang, Y.b and Tang, M.c and Yuan, C.d and Tang, C.e },
  Journal                  = {The Scientific World Journal},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Volume                   = {2013},

  Abstract                 = {Time-series stream is one of the most common data types in data mining field. It is prevalent in fields such as stock market, ecology, and medical care. Segmentation is a key step to accelerate the processing speed of time-series stream mining. Previous algorithms for segmenting mainly focused on the issue of ameliorating precision instead of paying much attention to the efficiency. Moreover, the performance of these algorithms depends heavily on parameters, which are hard for the users to set. In this paper, we propose PRESEE (parameter-free, real-time, and scalable time-series stream segmenting algorithm), which greatly improves the efficiency of time-series stream segmenting. PRESEE is based on both MDL (minimum description length) and MML (minimum message length) methods, which could segment the data automatically. To evaluate the performance of PRESEE, we conduct several experiments on time-series streams of different types and compare it with the state-of-art algorithm. The empirical results show that PRESEE is very efficient for real-time stream datasets by improving segmenting speed nearly ten times. The novelty of this algorithm is further demonstrated by the application of PRESEE in segmenting real-time stream datasets from ChinaFLUX sensor networks data stream. Ã‚Â© 2013 Kaikuo Xu et al.},
  Affiliation              = {College of Computer Science and Technology, Chengdu University of Information Technology, Chengdu 610225, China; School of Computing and Information Sciences, Florida International University, Miami, IN 33199, United States; Department of Computer Science, Purdue University, West Lafayette, FL 47996, United States; Guangxi Teachers Education University, Nanning 530001, China; School of Computer Science, Sichuan University, Chengdu 610065, China},
  Art_number               = {386180},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose PRESEE (parameter-free, real-time, and scalable time-series stream segmenting algorithm), which greatly improves the efficiency of time-series stream segmenting. PRESEE is based on both MDL (minimum description length) and MML (minimum message length) methods, which could segment the data automatically. empirical results show that PRESEE is very efficient for real-time stream datasets by improving segmenting speed nearly ten times 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880157944&partnerID=40&md5=f42474ac0c20573aaad1618ad11150cb}
}

@Misc{Xua,
  Title                    = {{A Flexible Architecture for Statistical Learning and Data Mining from System Log Streams}},

  Author                   = {Xu, Wei and Bod\'{\i}k, Peter and Patterson, David},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Modern computer systems are instrumented to generate huge amounts of system log data. This data contains valuable information for managing the system, localizing failures, and recovery. However, the complexity of these systems greatly surpasses what can be understood by human operators and thus automated analysis systems are beginning to be used. Due to preprocessing required by the statistical algorithms, the extremely high volume of data cannot be processed using ad-hoc scripts. We present a flexible, modular and scalable architecture for statistical learning from large data streams that can easily process lots of data. We built a prototype that is evaluated using system log data from a commercial on-line service. Moreover, the results of the analysis were genuinely useful for the on-line service operators.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THey present a flexible, modular and scalable architecture for statistical learning from large data streams that can easily process lots of data. We built a prototype that is evaluated using system log data from a commercial on-line service. Moreover, the results of the analysis were genuinely useful for the on-line service operators. 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.7897}
}

@Conference{Xu2010,
  Title                    = {Detecting large-scale system problems by mining console logs},
  Author                   = {Xu, W.a and Huang, L.b and Fox, A.a and Patterson, D.a and Jordan, M.I.c},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Pages                    = {37-44},

  Abstract                 = {Surprisingly, console logs rarely help operators detect problems in large-scale datacen- ter services, for they often consist of the voluminous intermixing of messages from many software components written by independent developers. We propose a general methodology to mine this rich source of information to automatically detect system runtime problems. We use a combination of program analysis and information retrieval techniques to transform free-text console logs into numerical features, which captures sequences of events in the system. We then analyze these features using machine learning to detect operational problems. We also show how to distill the results of our analysis to an operator-friendly one-page decision tree showing the critical messages associated with the detected problems. In addition, we extend our methods to online problem detection where the sequences of events are continuously generated as data streams. Copyright 2010 by the author(s)/owner(s).},
  Affiliation              = {EECS Department, UC Berkeley, United States; Intel Labs, Berkeley, United States; EECS and Statistics Department, UC Berkeley, United States},
  Document_type            = {Conference Paper},
  Journal                  = {ICML 2010 - Proceedings, 27th International Conference on Machine Learning},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {propose a general methodology to mine this rich source of information to automatically detect system runtime problems. We use a combination of program analysis and information retrieval techniques to transform free-text console logs into numerical features, which captures sequences of events in the system. We then analyze these features using machine learning to detect operational problems. Very weak on the ML front, can not see if innovative. 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77956513188&partnerID=40&md5=f933498ff0de2c1f2a0538c2b8c77706}
}

@Misc{Xu,
  Title                    = {{Intel Labs Berkeley}},

  Author                   = {Xu, Wei and Huang, Ling and Fox, Armando and Patterson, David and Jordan, Michael I.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Surprisingly, console logs rarely help operators detect problems in large-scale datacenter services, for they often consist of the voluminous intermixing of messages from many software components written by independent developers. We propose a general methodology to mine this rich source of information to automatically detect system runtime problems. We use a combination of program analysis and information retrieval techniques to transform free-text console logs into numerical features, which captures sequences of events in the system. We then analyze these features using machine learning to detect operational problems. We also show how to distill the results of our analysis to an operatorfriendly one-page decision tree showing the critical messages associated with the detected problems. In addition, we extend our methods to online problem detection where the sequences of events are continuously generated as data streams.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Xu2010},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.170.1958}
}

@Article{Yamanishi2002,
  Title                    = {{A Unifying Framework for Detecting Outliers and Change Points from Non-Stationary Time Series Data}},
  Author                   = {Yamanishi, Kenji and Takeuchi, Jun-ichi},
  Journal                  = {IN PROC. OF THE EIGHTH ACM SIGKDD, ACM},
  Year                     = {2002},
  Pages                    = {676 -- 681},
  Volume                   = {18},

  __markedentry            = {[Alexander:]},
  Abstract                 = {We m'e concerned vith the issues of outlier detection and change point detection from a data stream. In the area of data mining, there have been increased interest in these issues since the former is related to fraud detection, rare event discovery, etc., vhile the latter is related to event/trend change detection, activity monitoring, etc. Specifically, it is important to consider the situation where the data source is non-stationary, since the nature of data source may change over time in real applications. Although in most previous work outlier detection and change point detection have not been related explicitly, this paper presents a unifying frame- vork for dealing vith both of them on the basis of the theory of on-line learning of non-stationary time series. In this framevork a probabilistic model of the data source is inerementally learned using an on-line discounting learning algorithm, which can track the changing data source adaplively by forgetting the effect of past data gradually. Then the score for any given data is calculated to measure its deviation from the learned model, vith a higher score indicating a high possibility of being an outlier. Further change points in a data stream are detected by applying this scoring method into a time series of moving averaged losses for prediction using the learned model. Specifically ve develop an efficient algorithms for on-line discounting learning of auto-regression models from time series data, and demonstrate the validity of our framework through simulation and experimental applications to stock market data analysis.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In this framevork a probabilistic model of the data source is incrementally learned using an on-line discounting learning algorithm, which can track the changing data source adaplively by forgetting the effect of past data gradually. They develop an efficient algorithms for on-line discounting learning of auto-regression models from time series data, and demonstrate the validity of our framework through simulation and experimental applications to stock market data analysis. 1,3,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.3469}
}

@InProceedings{Yan2006,
  Title                    = {{A Novel Scalable Algorithm for Supervised Subspace Learning}},
  Author                   = {Yan, Jun and Liu, Ning and Zhang, Benyu and Yang, Qiang and Yan, Shuicheng and Chen, Zheng},
  Booktitle                = {Sixth International Conference on Data Mining (ICDM'06)},
  Year                     = {2006},
  Month                    = dec,
  Pages                    = {721--730},
  Publisher                = {IEEE},

  Abstract                 = {Subspace learning approaches aim to discover important statistical distribution on lower dimensions for high dimensional data. Methods such as principal component analysis (PCA) do not make use of the class information, and linear discriminant analysis (LDA) could not be performed efficiently in a scalable way. In this paper, we propose a novel highly scalable supervised subspace learning algorithm called as supervised Kampong measure (SKM). It assigns data points as close as possible to their corresponding class mean, simultaneously assigns data points to be as far as possible from the other class means in the transformed lower dimensional subspace. Theoretical derivation shows that our algorithm is not limited by the number of classes or the singularity problem faced by LDA. Furthermore, our algorithm can be executed in an incremental manner in which learning is done in an online fashion as data streams are received. Experimental results on several datasets, including a very large text data set RCV1, show the outstanding performance of our proposed algorithm on classification problems as compared to PCA, LDA and a popular feature selection approach, information gain (IG).},
  Doi                      = {10.1109/ICDM.2006.7},
  ISBN                     = {0-7695-2701-7},
  ISSN                     = {1550-4786},
  Keywords                 = {Asia,Classification algorithms,Clustering algorithms,Computational complexity,Computer science,Linear discriminant analysis,Machine learning,Machine learning algorithms,Principal component analysis,Statistical distributions,learning (artificial intelligence),linear discriminant analysis,principal component analysis,scalable algorithm,singularity problem,statistical distribution,statistical distributions,supervised Kampong measure,supervised subspace learning},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Yan2006a},
  Shorttitle               = {Data Mining, 2006. ICDM '06. Sixth International C},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4053097}
}

@Conference{Yan2006a,
  Title                    = {A novel scalable algorithm for supervised subspace learning},
  Author                   = {Yan, J.a and Liu, N.a and Zhang, B.a and Yang, Q.b and Yan, S.c and Chen, Z.a},
  Year                     = {2006},
  Note                     = {cited By (since 1996)4},
  Pages                    = {721-730},

  Abstract                 = {Subspace learning approaches aim to discover important statistical distribution on lower dimensions for high dimensional data. Methods such as Principal Component Analysis (PCA) do not make use of the class information, and Linear Discriminant Analysis (LDA) could not be performed efficiently in a scalable way. In this paper, we propose a novel highly scalable supervised subspace learning algorithm called as Supervised Kampong Measure (SKM). It assigns data points as close as possible to their corresponding class mean, simultaneously assigns data points to be as far as possible from the other class means in the transformed lower dimensional subspace. Theoretical derivation shows that our algorithm is not limited by the number of classes or the singularity problem faced by LDA. Furthermore, our algorithm can be executed in an incremental manner in which learning is done in an online fashion as data streams are received. Experimental results on several datasets, including a very large text data set RCV1, show the outstanding performance of our proposed algorithm on classification problems as compared to PCA, LDA and a popular feature selection approach, Information Gain (IG). Ã‚Â© 2006 IEEE.},
  Affiliation              = {Microsoft Research Asia, 49 Zhichun Road, Beijing 100080, China; Department of Computer Science, Hong Kong University of Science and Technology, Hong Kong; ECE Department, University of Illinois, Urbana Champaign, United States},
  Art_number               = {4053097},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THey propose a novel highly scalable supervised subspace learning algorithm called as Supervised Kampong Measure (SKM). The algorithm can be executed in an incremental manner in which learning is done in an online fashion as data streams are received. Experiments shows outstanding performance of our proposed algorithm on classification problems as compared to PCA, LDA and a popular feature selection approach, Information Gain (IG) 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-47349092283&partnerID=40&md5=586962a874f69f85edb8ef8dd80b1ce0}
}

@Article{Yan2006b,
  Title                    = {{A novel scalable algorithm for supervised subspace learning}},
  Author                   = {Yan, Jun and Liu, Ning and Zhang, Benyu and Yang, Qiang and Yan, Shuicheng and Chen, Zheng},
  Journal                  = {IN PROCEEDING OF IEEE INTERNATIONAL CONFERENCE ON DATA MINING},
  Year                     = {2006},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Yan2006a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.85.1174}
}

@InProceedings{Yan2012,
  Title                    = {{Online incremental regression for electricity price prediction}},
  Author                   = {Yan, Junchi and Tian, Chunhua and Wang, Yu and Huang, Jin},
  Booktitle                = {Proceedings of 2012 IEEE International Conference on Service Operations and Logistics, and Informatics},
  Year                     = {2012},
  Month                    = jul,
  Pages                    = {31--35},
  Publisher                = {IEEE},

  Abstract                 = {Modeling methods aiming at predicting electricity price accurately, should be capable of handling a continuous stream of data while keeping responsive to the potential structural changes. To this end, traditional machine learning based approaches are widely applied such as Multi-linear Regression, Artificial Neural Network (ANN), Time Series Models like Auto Regressive Moving Average Models (ARMA), Gaussian Process (GP), random forests and Genetic Algorithm (GA), all of which can fall into two categories: the parametric and non parametric model. While practical challenges in forecasting streaming data come along with the structural variation of the testing samples making the training samples not necessarily representative enough towards the new arriving samples. In such an online forecasting context, an incremental supervised learning based algorithm is better suited in contrast to the batch-mode one. Given the fact that it can adapt to the new coming streaming data by accommodating the possible variations of new samples, as well as allows for the removal of old data if necessary. An incremental learning algorithm is presented in this paper, i.e. the online support vector regression model, which enjoys the merits of less memory capacity and less computational overload compared with the batch methods. Promising results are demonstrated by evaluating with other typical regression methods for the electricity price forecasting task on a publicly available benchmark data set.},
  Doi                      = {10.1109/SOLI.2012.6273500},
  ISBN                     = {978-1-4673-2401-4},
  Keywords                 = {ANN,ARMA,Adaptation models,Artificial neural networks,Computational modeling,Gaussian process,Incremental Regression,Incremental Support Vector Regression,MATLAB,Mathematical model,On-line Learning,Predictive models,Price Forecasting,Weather forecasting,artificial neural network,autoregressive moving average model,electricity price forecasting,electricity price prediction,genetic algorithm,incremental supervised learning,learning (artificial intelligence),load forecasting,machine learning,multilinear regression,nonparametric model,online forecasting context,online incremental regression,online support vector regression model,power engineering computing,random forest,regression analysis,support vector machines,time series,time series model},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Yan2012a},
  Shorttitle               = {Service Operations and Logistics, and Informatics },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6273500}
}

@Conference{Yan2012a,
  Title                    = {Online incremental regression for electricity price prediction},
  Author                   = {Yan, J. and Tian, C. and Wang, Y. and Huang, J.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {31-35},

  Abstract                 = {Modeling methods aiming at predicting electricity price accurately, should be capable of handling a continuous stream of data while keeping responsive to the potential structural changes. To this end, traditional machine learning based approaches are widely applied such as Multi-linear Regression, Artificial Neural Network (ANN), Time Series Models like Auto Regressive Moving Average Models (ARMA), Gaussian Process (GP), random forests and Genetic Algorithm (GA), all of which can fall into two categories: the parametric and nonparametric model. While practical challenges in forecasting streaming data come along with the structural variation of the testing samples making the training samples not necessarily representative enough towards the new arriving samples. In such an online forecasting context, an incremental supervised learning based algorithm is better suited in contrast to the batch-mode one. Given the fact that it can adapt to the new coming streaming data by accommodating the possible variations of new samples, as well as allows for the removal of old data if necessary. An incremental learning algorithm is presented in this paper, i.e. the online support vector regression model, which enjoys the merits of less memory capacity and less computational overload compared with the batch methods. Promising results are demonstrated by evaluating with other typical regression methods for the electricity price forecasting task on a publicly available benchmark data set. Ã‚Â© 2012 IEEE.},
  Affiliation              = {IBM Research - China, Beijing, 100193, China},
  Art_number               = {6273500},
  Author_keywords          = {Incremental Regression; Incremental Support Vector Regression; On-line Learning; Price Forecasting},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of 2012 IEEE International Conference on Service Operations and Logistics, and Informatics, SOLI 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. In such an online forecasting context, an incremental supervised learning based algorithm is better suited in contrast to the batch-mode one. An incremental learning algorithm is presented in this paper, i.e. the online support vector regression model, which enjoys the merits of less memory capacity and less computational overload compared with the batch methods. Promising results are demonstrated 1,2,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867206679&partnerID=40&md5=6518a085ec1468712785945353dd97e6}
}

@Misc{YangHang2010,
  Title                    = {{Stream mining over fluctuating network traffic at variable data rates}},

  Author                   = {{Yang Hang} and Fong, S.},
  Year                     = {2010},

  Abstract                 = {Data stream mining algorithm, such as the popular classifier implemented by Hoeffding tree algorithm (HTA) is acclaimed to be able to handle high speed data streams that potentially amounts to infinity. It emerges as a hot research area recently on applying HTA in different applications that require real-time responses and fast decision making. In particular, we discovered the effect of Internet traffic on Hoeffding bound (HB) which is one of the key performance indicators in HTA stream mining is related to fluctuation. The error of HB oscillates with the fluctuation of data rate in real-time data stream which causes frequent HTA tree reconstruction, and in turn that has an adverse effect on the overall prediction accuracy. From the experiment in this paper, we observe that the HB is related to HTA's accuracy. And data streams extracted from Internet traffic exhibit fluctuations of highly variable data rates, they influence significantly on HB value. A simple and effective mechanism without the need of arbitrating or intervening with the traffic data rates is proposed in this paper for smoothing the HB fluctuation. From our simulation, the results show that the HB fluctuation is smoothed, and the accuracy in HTA is stabilized. It is believed that the proposed technique can subside the problem of stream mining in network environment where traffic is fluctuating.},
  Keywords                 = {Accuracy,Data mining,Decision trees,Error analysis,Fluctuations,HB fluctuation,HTA stream mining,HTA tree reconstruction,Hoeffding Tree Algorithm,Hoeffding bound,Hoeffding tree algorithm,Internet,Internet traffic,Real time systems,component,data mining,data rate fluctuation,data stream mining algorithm,data streams extraction,decision making,fast decision making,fluctuating network traffic,high speed data streams,key performance indicators,network environment,overall prediction accuracy,real time application,real time constraint,real-time data stream,real-time responses,real-time systems,stream mining,telecommunication traffic,traffic data rates,trees (mathematics),variable data rates},
  Owner                    = {Alexander},
  Pages                    = {436--441},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They've done research on the use of Hoeffding tree algorithm (HTA) in data stream, and discovered the effect of Internet traffic on Hoeffding bound (HB) which is one of the key performance indicators in HTA stream mining is related to fluctuation. They observe that the HB is related to HTA's accuracy, so they propose a simple mechanism for smoothing the HB fluctuation. Experiments show that it works; the HB fluctuation is smoothed,and the accuracy in HTA is stabilized.They believe that the proposed technique can subside the problem of stream mining in network environment where traffic is fluctuating. 1,2,3,4,6},
  Shorttitle               = {Advanced Information Management and Service (IMS),},
  Timestamp                = {2014.10.15}
}

@Misc{YangHang2010a,
  Title                    = {{An experimental comparison of decision trees in traditional data mining and data stream mining}},

  Author                   = {{Yang Hang} and Fong, S.},
  Year                     = {2010},

  Abstract                 = {Data Stream mining (DSM) is claimed to be the successor of traditional data mining where it is capable of mining continuous incoming data streams in real-time with an acceptable performance. Nowadays many computer applications evolved to online and on-demand basis, fresh data are feeding in at high speeds. Not only a decision response needs to be made rapidly, the trained decision tree models would have to be updated recurrently as frequent as the latest data arrive. By the nature of traditional data mining, training datasets are assumed structured and static, and the decision tree models are either refreshed in batches or never. That is, the full dataset will be completely scanned (sometimes in multiple repetitions), induction of rules by Greedy algorithm that proceeds in manner of divide-and-conquer in the case of constructing a C4.5 decision tree. DSM on the other hand progressively builds and renews the decision tree model at a time when a new pass of data come by. In this paper, we evaluated the performance of a popular decision tree in DSM, which is known as Hoeffding Tree vis-aÃŒâ‚¬-vis that of C4.5. A good mix of types of datasets was used in the experiments for investigating the apparent differences between the decision trees. An open-source DSM simulator was programmed in JAVA for the experiments.},
  Keywords                 = {Accuracy,Computational modeling,Data mining,Data models,Decision trees,Hoeffding tree,Hoeffding tree algorithm,JAVA programming,JAVA simulator,Java,Noise,Portable media players,data mining,data stream mining,decision response,decision tree,decision tree model,decision trees,divide and conquer methods,divide-and-conquer algorithm,greedy algorithm,greedy algorithms,noise data,open source DSM simulator,public domain software},
  Owner                    = {Alexander},
  Pages                    = {442--447},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {They evaluated the performance of a popular decision tree in DSM, which is known as Hoeffding Tree vis-aÃŒâ‚¬-vis that of C4.5. A good mix of types of datasets was used in the experiments for investigating the apparent differences between the decision trees. An open-source DSM simulator was programmed in JAVA for the experiments. Nothign new, only compared two algorithms. Set aside though},
  Shorttitle               = {Advanced Information Management and Service (IMS),},
  Timestamp                = {2014.10.15}
}

@InProceedings{YKLWJJKHR2008,
  Title                    = {{Time-based insertion methods for monitoring sensor data}},
  Author                   = {{Yang Koo Lee} and {Ling Wang} and {Young Jin Jung} and {Hiseok Kim} and {Keun Ho Ryu}},
  Booktitle                = {2008 8th IEEE International Conference on Computer and Information Technology},
  Year                     = {2008},
  Month                    = jul,
  Pages                    = {833--838},
  Publisher                = {IEEE},

  Abstract                 = {In wireless sensor network, the sensors collect data about natural phenomenon and transmit them to a server in real-time. Many researches mainly focus on processing continuous queries as approximate forms. However, these approaches are difficult to apply to such environmental applications which require storing the correct data. In this paper, we introduce two insertion methods, called TSI (time-segment insertion) and TPI (time-point insertion), to save the storage space without loss of raw data useful for queries by using the sensorspsila temporal attributes. In our methods, storing and discarding the incoming data is represented by a time interval that takes two timestamps at which the value of data is changed. The performance of TSI and TPI is finally judged and compared with the naive method. Because naive method does not take the temporal representation and duplicate values problem into account, the tuples obtained from data stream are quite a lot more than those of ours, whereby query execution time is greater as well.},
  Doi                      = {10.1109/CIT.2008.4594782},
  ISBN                     = {978-1-4244-2357-6},
  Keywords                 = {Biosensors,Data analysis,Data engineering,Memory management,Monitoring,Network servers,Query processing,Sensor phenomena and characterization,Spatial databases,Wireless sensor networks,monitoring,monitoring sensor data,query execution time,time-based insertion methods,time-segment insertion,wireless sensor network,wireless sensor networks},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, about database insertion, cant say that any ML has been used.},
  Shorttitle               = {Computer and Information Technology, 2008. CIT 200},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4594782}
}

@InProceedings{Yang2011c,
  Title                    = {{CLUES}},
  Author                   = {Yang, Di and Guo, Zhenyu and Rundensteiner, Elke A. and Ward, Matthew O.},
  Booktitle                = {Proceedings of the 20th ACM international conference on Information and knowledge management - CIKM '11},
  Year                     = {2011},

  Address                  = {New York, New York, USA},
  Month                    = oct,
  Pages                    = {815},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/2063576.2063694},
  ISBN                     = {9781450307178},
  Keywords                 = {density-based cluster,evolution,stream,visualization},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate fo Yang2011b},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2063576.2063694}
}

@Conference{Yang2011b,
  Title                    = {CLUES: A unified framework supporting interactive exploration of density-based clusters in streams},
  Author                   = {Yang, D. and Guo, Z. and Rundensteiner, E.A. and Ward, M.O.},
  Year                     = {2011},
  Note                     = {cited By (since 1996)2},
  Pages                    = {815-824},

  Abstract                 = {Although various mining algorithms have been proposed in the literature to efficiently compute clusters, few strides have been made to date in helping analysts to interactively explore such patterns in the stream context. We present a framework called CLUES to both computationally and visually support the process of real-time mining of density-based clusters. CLUES is composed of three major components. First, as foundation of CLUES, we develop an evolution model of density-based clusters in data streams that captures the complete spectrum of cluster evolution types across streaming windows. Second, to equip CLUES with the capability of efficiently tracking cluster evolution, we design a novel algorithm to piggy-back the evolution tracking process into the underlying cluster detection process. Third, CLUES organizes the detected clusters and their evolution interrelationships into a multidimensional pattern space - presenting clusters at different time horizons and across different abstraction levels. It provides a rich set of visualization and interaction techniques to allow the analyst to explore this multi-dimensional pattern space in real-time. Our experimental evaluation, including performance studies and a user study, using real streams from ground group movement monitoring and from stock transaction domains confirm both the efficiency and effectiveness of our proposed CLUES framework. Ã‚Â© 2011 ACM.},
  Affiliation              = {Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA, United States},
  Author_keywords          = {density-based cluster; evolution; stream; visualization},
  Document_type            = {Conference Paper},
  Journal                  = {International Conference on Information and Knowledge Management, Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THey present a framework called CLUES to both computationally and visually support the process of real-time mining of density-based clusters. Three components: 1 evolution model of density-based clusters in data streams. 2 a novel algorithm to piggy-back the evolution tracking process into the underlying cluster detection process. 3 organizes the detected clusters and their evolution interrelationships. Experiments confirm both the efficiency and effectiveness of our proposed CLUES framework. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-83055191289&partnerID=40&md5=6e670c15402bff07d95abfdd50b02d99}
}

@InProceedings{Yang2010a,
  Title                    = {{Interactive visual exploration of neighbor-based patterns in data streams}},
  Author                   = {Yang, Di and Guo, Zhenyu and Xie, Zaixian and Rundensteiner, Elke A. and Ward, Matthew O.},
  Booktitle                = {Proceedings of the 2010 international conference on Management of data - SIGMOD '10},
  Year                     = {2010},

  Address                  = {New York, New York, USA},
  Month                    = jun,
  Pages                    = {1151},
  Publisher                = {ACM Press},

  Doi                      = {10.1145/1807167.1807305},
  ISBN                     = {9781450300322},
  Keywords                 = {pattern mining,streaming data,visual interaction},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Yang2010},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1807167.1807305}
}

@Conference{Yang2010,
  Title                    = {Interactive visual exploration of neighbor-based patterns in data streams},
  Author                   = {Yang, D. and Guo, Z. and Xie, Z. and Rundensteiner, E.A. and Ward, M.O.},
  Year                     = {2010},
  Note                     = {cited By (since 1996)2},
  Pages                    = {1151-1154},

  Abstract                 = {We will demonstrate our system, called V iStream, supporting interactive visual exploration of neighbor-based patterns [7] in data streams. V iStream does not only apply innovative multi-query strategies to compute a broad range of popular patterns, such as clusters and outliers, in a highly efficient manner, but it also provides a rich set of visual interfaces and interactions to enable real-time pattern exploration. With ViStream, analysts can easily interact with pattern mining processes by navigating along the time horizons, abstraction levels and parameter spaces, and thus better understand the phenomena of interest. Copyright 2010 ACM.},
  Affiliation              = {Worcester Polytechnic Institute, United States},
  Author_keywords          = {pattern mining; streaming data; visual interaction},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They demonstrate their system, called V iStream, supporting interactive visual exploration of neighbor-based patterns [7] in data streams. They find patterns such as clusters and outlier, and visualize them They claim to make innovative multi-query strategies to compute a broad range of popular patterns, so approved. 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954690726&partnerID=40&md5=88102c6f7c15031ca7ac7b875b11aed5}
}

@Article{Yang2013,
  Title                    = {Mining neighbor-based patterns in data streams },
  Author                   = {Di Yang and Elke A. Rundensteiner and Matthew O. Ward},
  Journal                  = {Information Systems },
  Year                     = {2013},
  Number                   = {3},
  Pages                    = {331 - 350},
  Volume                   = {38},

  Abstract                 = {Discovery of complex patterns such as clusters, outliers, and associations from huge volumes of streaming data has been recognized as critical for many application domains. However, little research effort has been made toward detecting patterns within sliding window semantics as required by real-time monitoring tasks, ranging from real time traffic monitoring to stock trend analysis. Applying static pattern detection algorithms from scratch to every window is impractical due to their high algorithmic complexity and the real-time responsiveness required by streaming applications. In this work, we develop methods for the incremental detection of neighbor-based patterns, in particular, density-based clusters and distance-based outliers over sliding stream windows. Incremental computation for pattern detection queries is challenging. This is because purging of to-be-expired data from previously formed patterns may cause birth, shrinkage, splitting or termination of these complex patterns. To overcome this, we exploit the “predictability” property of sliding windows to elegantly discount the effect of expired objects with little maintenance cost. Our solution achieves guaranteed minimal CPU consumption, while keeping the memory utilization linear in the number of objects in the window. To thoroughly analyze the performance of our proposed methods, we develop a cost model characterizing the performance of our proposed neighbor-based pattern mining strategies. We conduct an analysis study to not only identify the key performance factors for each strategy but also show under which conditions each of them are most efficient. Our comprehensive experimental study, using both synthetic and real data from domains of moving object monitoring and stock trades, demonstrates superiority of our proposed strategies over alternate methods in both CPU processing resources and in memory utilization.},
  Doi                      = {http://dx.doi.org/10.1016/j.is.2012.08.001},
  ISSN                     = {0306-4379},
  Keywords                 = {Streaming},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They develop methods for the incremental detection of neighbor-based patterns, on density-based clusters and distance-based outliers over sliding stream windows. They exploit the “predictability” property of sliding windows to elegantly discount the effect of expired objects with little maintenance cost. Our solution achieves guaranteed minimal CPU consumption, while keeping the memory utilization linear in the number of objects in the window. The comprehensive experimental study demonstrates superiority of our proposed strategies over alternate methods in both CPU processing resources and in memory utilization. So this paper is focused on performance metrics in pattern detection in sliding stream windows. Seems interesting. Maybe SotA as they say little research has been done in this area before. 1,2,3,4,(5?),6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306437912001056}
}

@Article{Yang2009a,
  Title                    = {{A shared execution strategy for multiple pattern mining requests over streaming data}},
  Author                   = {Yang, Di and Rundensteiner, Elke A. and Ward, Matthew O.},
  Journal                  = {Proceedings of the VLDB Endowment},
  Year                     = {2009},

  Month                    = aug,
  Number                   = {1},
  Pages                    = {874--885},
  Volume                   = {2},

  Doi                      = {10.14778/1687627.1687726},
  ISSN                     = {21508097},
  Owner                    = {alex},
  Publisher                = {VLDB Endowment},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Yang2009},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=1687627.1687726}
}

@Article{Yang2012a,
  Title                    = {Shared execution strategy for neighbor-based pattern mining requests over streaming windows},
  Author                   = {Yang, D. and Rundensteiner, E.A. and Ward, M.O.},
  Journal                  = {ACM Transactions on Database Systems},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {1},
  Volume                   = {37},

  Abstract                 = {In diverse applications ranging from stock trading to traffic monitoring, data streams are continuously monitored by multiple analysts for extracting patterns of interest in real time. These analysts often submit similar pattern mining requests yet customized with different parameter settings. In this work, we present shared execution strategies for processing a large number of neighbor-based pattern mining requests of the same type yet with arbitrary parameter settings. Such neighbor-based pattern mining requests cover a broad range of popular mining query types, including detection of clusters, outliers, and nearest neighbors. Given the high algorithmic complexity of the mining process, serving multiple such queries in a single system is extremely resource intensive. The naive method of detecting and maintaining patterns for different queries independently is often infeasible in practice, as its demands on system resources increase dramatically with the cardinality of the query workload. In order to maximize the efficiency of the system resource utilization for executing multiple queries simultaneously, we analyze the commonalities of the neighborbased pattern mining queries, and identify several general optimization principles which lead to significant system resource sharing among multiple queries. In particular, as a preliminary sharing effort, we observe that the computation needed for the range query searches (the process of searching the neighbors for each object) can be shared among multiple queries and thus saves the CPU consumption. Then we analyze the interrelations between the patterns identified by queries with different parameters settings, including both pattern-specific and window-specific parameters. For that, we first introduce an incremental pattern representation, which represents the patterns identified by queries with different pattern-specific parameters within a single compact structure. This enables integrated pattern maintenance for multiple queries. Second, by leveraging the potential overlaps among sliding windows, we propose a metaquery strategy which utilizes a single query to answer multiple queries with different window-specific parameters. By combining these three techniques, namely the range query search sharing, integrated pattern maintenance, and metaquery strategy, our framework realizes fully shared execution of multiple queries with arbitrary parameter settings. It achieves significant savings of computational and memory resources due to shared execution. Our comprehensive experimental study, using real data streams from domains of stock trades and moving object monitoring, demonstrates that our solution is significantly faster than the independent execution strategy, while using only a small portion of memory space compared to the independent execution.We also show that our solution scales in handling large numbers of queries in the order of hundreds or even thousands under high input data rates. Ã‚Â© 2012 ACM.},
  Affiliation              = {WPI, Computer Science Department, United States},
  Art_number               = {5},
  Author_keywords          = {Multiple query optimization; Pattern mining; Stream processing},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {They first introduce an incremental pattern representation, which represents the patterns identified by queries with different pattern-specific parameters within a single compact structure. They then propose a metaquery strategy which utilizes a single query to answer multiple queries with different window-specific parameters. Experiments demonstrate that their solution is significantly faster than the independent execution strategy, while using only a small portion of memory space, and scales well I guess the pattern representation is the ML part? Very heavy abstract. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84859093114&partnerID=40&md5=6764206b7bb1ef526c2e29661fac068f}
}

@Conference{Yang2009,
  Title                    = {A shared execution strategy for multiple pattern mining requests over streaming data},
  Author                   = {Yang, D. and Rundensteiner, E.A. and Ward, M.O.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)10},
  Number                   = {1},
  Pages                    = {874-885},
  Volume                   = {2},

  Abstract                 = {In diverse applications ranging from stock trading to traffic monitoring, popular data streams are typically monitored by multiple analysts for patterns of interest. These analysts may submit similar pattern mining requests, such as cluster detection queries, yet customized with different parameter settings. In this work, we present an efficient shared execution strategy for processing a large number of density-based cluster detection queries with arbitrary parameter settings. Given the high algorithmic complexity of the clustering process and the real-time responsiveness required by streaming applications, serving multiple such queries in a single system is extremely resource intensive. The naive method of detecting and maintaining clusters for different queries independently is often infeasible in practice, as its demands on system resources increase dramatically with the cardinality of the query workload. To overcome this, we analyze the interrelations between the cluster sets identified by queries with different parameters settings, including both pattern-specific and window-specific parameters. We introduce the notion of the growth property among the cluster sets identified by different queries, and characterize the conditions under which it holds. By exploiting this growth property we propose a uniform solution, called Chandi, which represents identified cluster sets as one single compact structure and performs integrated maintenance on them - resulting in significant sharing of computational and memory resources. Our comprehensive experimental study, using real data streams from domains of stock trades and moving object monitoring, demonstrates that Chandi is on average four times faster than the best alternative methods, while using 85% less memory space in our test cases. It also shows that Chandi scales in handling large numbers of queries on the order of hundreds or even thousands under high input data rates. Ã‚Â© 2009 VLDB Endowment.},
  Affiliation              = {Worcester Polytechnic Institute, Computer Science Department, United States},
  Document_type            = {Article},
  Journal                  = {Proceedings of the VLDB Endowment},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present an efficient shared execution strategy for processing a large number of density-based cluster detection queries with arbitrary parameter settings. They propose a uniform solution, called Chandi, which represents identified cluster sets as one single compact structure and performs integrated maintenance on them - resulting in significant sharing of computational and memory resources. Experiments demonstrate that Chandi is on average four times faster than the best alternative methods, while using 85% less memory space in our test cases Very theoretically hard abstract, but their solution seems interesting. 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954738342&partnerID=40&md5=f041779af9ef4822257327a091dcb05d}
}

@Conference{Yang2013c,
  Title                    = {Mining and linking patterns across live data streams and stream archives},
  Author                   = {Yang, D. and Zhao, K. and Hasan, M. and Lu, H. and Rundensteiner, E. and Ward, M.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {12},
  Pages                    = {1346-1349},
  Volume                   = {6},

  Abstract                 = {We will demonstrate the visual analytics system V istreamT, that supports interactive mining of complex patterns within and across live data streams and stream pattern archives. Our system is equipped with both computational pattern mining and visualization techniques, which allow it to not only efficiently discover and manage patterns but also effectively convey the mining results to human analysts through visual displays. In our demonstration, we will illustrate that with V istreamT, analysts can easily submit, monitor and interact with a broad range of query types for pattern min-ing. This includes novel strategies for extracting complex patterns from streams in real time, summarizing neighbour-based patterns using multi-resolution compression strate-gies, selectively pushing patterns into the stream archive, validating the popularity or rarity of stream patterns by stream archive matching, and pattern evolution tracking to link patterns across time. Ã‚Â© 2013 VLDB Endowment.},
  Affiliation              = {Worcester Polytechnic Institute, United States},
  Document_type            = {Article},
  Journal                  = {Proceedings of the VLDB Endowment},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Further work on Yang2010, same system V istreamT. Abstract is a little longer.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84891053091&partnerID=40&md5=0d5e7c2baa784f712469a0e6cabddd35}
}

@Article{Yang2013e,
  Title                    = {{Mining and linking patterns across live data streams and stream archives}},
  Author                   = {Yang, Di and Zhao, Kaiyu and Hasan, Maryam and Lu, Hanyuan and Rundensteiner, Elke and Ward, Matthew},
  Journal                  = {Proceedings of the VLDB Endowment},
  Year                     = {2013},

  Month                    = aug,
  Number                   = {12},
  Pages                    = {1346--1349},
  Volume                   = {6},

  Doi                      = {10.14778/2536274.2536312},
  ISSN                     = {21508097},
  Owner                    = {alex},
  Publisher                = {VLDB Endowment},
  Qualityassured           = {qualityAssured},
  Review                   = {Duplicate of Yang2013c},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2536274.2536312}
}

@Article{Yang2012b,
  Title                    = {Incrementally Optimized Decision Tree for Mining Imperfect Data Streams},
  Author                   = {Yang, H. and Fong, S.},
  Journal                  = {Communications in Computer and Information Science},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {281-296},
  Volume                   = {293 PART 1},

  Abstract                 = {The Very Fast Decision Tree (VFDT) is one of the most important classification algorithms for real-time data stream mining. However, imperfections in data streams, such as noise and imbalanced class distribution, do exist in real world applications and they jeopardize the performance of VFDT. Traditional sampling techniques and post-pruning may be impractical for a non-stopping data stream. To deal with the adverse effects of imperfect data streams, we have invented an incremental optimization model that can be integrated into the decision tree model for data stream classification. It is called the Incrementally Optimized Very Fast Decision Tree (I-OVFDT) and it balances performance (in relation to prediction accuracy, tree size and learning time) and diminishes error and tree size dynamically. Furthermore, two new Functional Tree Leaf strategies are extended for I-OVFDT that result in superior performance compared to VFDT and its variant algorithms. Our new model works especially well for imperfect data streams. I-OVFDT is an anytime algorithm that can be integrated into those existing VFDT-extended algorithms based on Hoeffding bound in node splitting. The experimental results show that I-OVFDT has higher accuracy and more compact tree size than other existing data stream classification methods. Ã‚Â© Springer-Verlag Berlin Heidelberg 2012.},
  Affiliation              = {Department of Computer and Information Science, University of Macau, Taipa, Macau SAR, China},
  Author_keywords          = {Data stream mining; decision tree classification; incremental optimization; optimized very fast decision tree},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They have invented an incremental optimization model that can be integrated into the decision tree model for data stream classification. It is called the Incrementally Optimized Very Fast Decision Tree (I-OVFDT) and it balances performance and diminished error. Two new Functional Tree Leaf strategies are extended for I-OVFDT that result in superior performance compared to VFDT and its variant algorithms. The new model works especially well for imperfect data streams, and have higher accuracy and more compact tree size than other existing data stream classification methods Does this imply better than SotA? 1,2,3,4,(5?),6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880497064&partnerID=40&md5=bdf37f27e853fec41fbdf10165baf7e0}
}

@Article{Yang2012c,
  Title                    = {A very fast decision tree algorithm for real-time data mining of imperfect data streams in a distributed wireless sensor network},
  Author                   = {Yang, H.a and Fong, S.a and Sun, G.b and Wong, R.c },
  Journal                  = {International Journal of Distributed Sensor Networks},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Volume                   = {2012},

  Abstract                 = {Wireless sensor networks (WSNs) are a rapidly emerging technology with a great potential in many ubiquitous applications. Although these sensors can be inexpensive, they are often relatively unreliable when deployed in harsh environments characterized by a vast amount of noisy and uncertain data, such as urban traffic control, earthquake zones, and battlefields. The data gathered by distributed sensors - which serve as the eyes and ears of the system - are delivered to a decision center or a gateway sensor node that interprets situational information from the data streams. Although many other machine learning techniques have been extensively studied, real-time data mining of high-speed and nonstationary data streams represents one of the most promising WSN solutions. This paper proposes a novel stream mining algorithm with a programmable mechanism for handling missing data. Experimental results from both synthetic and real-life data show that the new model is superior to standard algorithms. Ã‚Â© 2012 Hang Yang et al.},
  Affiliation              = {Department of Computer and Information Science, University of Macau, Taipa, Macau; Department of Electronic Engineering, Beijing University of Technology, Beijing 100022, China; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia},
  Art_number               = {863545},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. This paper proposes a novel stream mining algorithm with a programmable mechanism for handling missing data in Wireless Sensor Networks (WSN). Experimental results from both synthetic and real-life data show that the new model is superior to standard algorithms 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84872776801&partnerID=40&md5=fc66e7c3a1f1c29e9922f8d423d060a0}
}

@InProceedings{Yang2013d,
  Title                    = {{A novel real-time framework for extracting patterns from trajectory data streams}},
  Author                   = {Yang, Hanqing and Gruenwald, Le and Boulanger, Mathilda},
  Booktitle                = {Proceedings of the 4th ACM SIGSPATIAL International Workshop on GeoStreaming - IWGS '13},
  Year                     = {2013},

  Address                  = {New York, New York, USA},
  Month                    = nov,
  Pages                    = {26--32},
  Publisher                = {ACM Press},

  Abstract                 = {The rapid development and deployment of location-acquisition equipment such as GPS systems and GSM communication networks has made collection of spatio-temporal trajectory datasets possible and led to the demand of managing and mining patterns from trajectory datasets to discover objects' movement behavior. As trajectories are generated continuously without limitation and boundaries, they form stream data. Though there are lots of research work done on mining trajectory datasets, none of them considers trajectory data as streams. They treat trajectory data as static data and run multiple scans on the data. In this paper, we present our efforts in facilitating this demand by developing a novel stream data mining algorithm to discover spatio-temporal sequential patterns from trajectories in real time; our algorithm is the first on-line trajectory mining algorithm and only needs to scan the trajectory dataset one time. We also propose a new data structure, called trajectory stream mining tree (TSM-tree), to store and represent up-to-date trajectory patterns. We conduct experiments using real life trajectory datasets to evaluate the performance of our algorithm.},
  Doi                      = {10.1145/2534303.2534313},
  ISBN                     = {9781450325325},
  Keywords                 = {spatio-temporal data mining,stream data,trajectory pattern},
  Owner                    = {alex},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They developed a novel stream data mining algorithm to discover spatio-temporal sequential patterns from trajectories in real time. The algorithm is the first on-line trajectory mining algorithm and only needs to scan the trajectory dataset one time. They also propose a new data structure, called trajectory stream mining tree (TSM-tree), to store and represent up-to-date trajectory patterns. We conduct experiments using real life trajectory datasets to evaluate the performance of our algorithm. The trajectory predicion can be used in GPS and GSM comm networks, to discover objects movement behaviour. Could be very interesting for Telenor. They say they are the first with this type of algo. 1,2,3,4,(5?),6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2534303.2534313}
}

@Conference{Yang2004,
  Title                    = {Mining short association rules with one database scan},
  Author                   = {Yang, L. and Sanver, M.},
  Year                     = {2004},
  Note                     = {cited By (since 1996)3},
  Pages                    = {392-395},

  Abstract                 = {New data mining applications such as online data mining and data stream mining require real time discovery of frequent itemset patterns and association rules in a single sequential scan of data. This paper presents a method for mining short frequent itemsets and association rules by such a single scan. The method uses array as a simple compact data structure to organize frequency counts of all itemsets no longer than a predefined length. A bijection between itemsets and array elements is set up. Itemsets are arranged in the array so that new items can be added at any time during the mining process. The method is fast and is capable of online and stream mining. Its performance is shown through experiments.},
  Affiliation              = {Department of Computer Science, Western Michigan University, Kalamazoo, MI 49008, United States},
  Author_keywords          = {Association rules; Data mining; Data stream mining; Frequent itemsets; Online mining},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the International Conference on Information and Knowledge Engineering , IKE'04},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper presents a method for mining short frequent itemsets and association rules by such a single scan. The method is fast and is capable of online and stream mining. Its performance is shown through experiments. Very short abstract. Method is "capable", whatever that means 1,3,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-12344280394&partnerID=40&md5=731949dd7b46e67d3ba5dcfe605e427c}
}

@InProceedings{Yang2012,
  Title                    = {{Online Recovery of Missing Values in Vital Signs Data Streams Using Low-Rank Matrix Completion}},
  Author                   = {Yang, Shiming and Kalpakis, Konstantinos and Mackenzie, Colin F. and Stansbury, Lynn G. and Stein, Deborah M. and Scalea, Thomas M. and Hu, Peter F.},
  Booktitle                = {2012 11th International Conference on Machine Learning and Applications},
  Year                     = {2012},
  Month                    = dec,
  Pages                    = {281--287},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Continuous, automated, electronic patient vital signs data are important to physicians in evaluating traumatic brain injury (TBI) patients' physiological status and reaching timely decisions for therapeutic interventions. However, missing values in the medical data streams hinder applying many standard statistical or machine learning algorithms and result in losing some episodes of clinical importance. In this paper, we present a novel approach to filling missing values in streams of vital signs data. We construct sequences of Hankel matrices from vital signs data streams, find that these matrices exhibit low-rank, and utilize low-rank matrix completion methods from compressible sensing to fill in the missing data. We demonstrate that our approach always substantially outperforms other popular fill-in methods, like k-nearest-neighbors and expectation maximization. Further, we show that our approach recovers thousands of simulated missing data for intracranial pressure, a critical stream of measurements for guiding clinical interventions and monitoring traumatic brain injuries.},
  Doi                      = {10.1109/ICMLA.2012.55},
  ISBN                     = {978-1-4673-4651-1},
  Keywords                 = {Biomedical monitoring,Brain injuries,Educational institutions,Hankel matrices,Hankel matrix,Hankel matrix sequences,Heart rate,Iterative closest point algorithm,Silicon,Sparse matrices,TBI patient physiological status,brain,clinical interventions,compressed sensing,compressible sensing,continuous automated electronic patient vital sign,data imputation,injuries,low rank,low-rank matrix completion method,matrix completion,medical data streams,medical information systems,missing values,neurophysiology,online missing value recovery,patient monitoring,therapeutic interventions,traumatic brain injury,traumatic brain injury monitoring,vital signs},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {present a novel approach to filling missing values in streams of vital signs data. They demonstrate that their approach always substantially outperforms other popular fill-in methods, like k-nearest-neighbors and expectation maximization. Further, we show that our approach recovers thousands of simulated missing data for intracranial pressure, a critical stream of measurements for guiding clinical interventions and monitoring traumatic brain injuries. Health care related, but a new problem area; missing values in a stream 1,2,4,6},
  Shorttitle               = {Machine Learning and Applications (ICMLA), 2012 11},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6406676}
}

@Article{Yang2011,
  Title                    = {Incremental mining of across-streams sequential patterns in multiple data streams},
  Author                   = {Yang, S.-Y.a and Chao, C.-M.b and Chen, P.-Z.c and Sun, C.-H.c },
  Journal                  = {Journal of Computers},
  Year                     = {2011},
  Note                     = {cited By (since 1996)9},
  Number                   = {3},
  Pages                    = {449-457},
  Volume                   = {6},

  Abstract                 = {Sequential pattern mining is the mining of data sequences for frequent sequential patterns with time sequence, which has a wide application. Data streams are streams of data that arrive at high speed. Due to the limitation of memory capacity and the need of real-time mining, the results of mining need to be updated in real time. Multiple data streams are the simultaneous arrival of a plurality of data streams, for which a much larger amount of data needs to be processed. Due to the inapplicability of traditional sequential pattern mining techniques, sequential pattern mining in multiple data streams has become an important research issue. Previous research can only handle a single item at a time and hence is incapable of coping with the changing environment of multiple data streams. In this paper, therefore, we propose the IAspam algorithm that not only can handle a set of items at a time but also can incrementally mine across-streams sequential patterns. In the process, stream data are converted into bitmap representation for mining. Experimental results show that the IAspam algorithm is effective in execution time when processing large amounts of stream data. Ã‚Â© 2011 Academy Publisher.},
  Affiliation              = {Department of Media Art, Kang-Ning Junior College of Medical Care and Management, Taipei, Taiwan 114, Taiwan; Department of Computer Science and Information Management, Soochow University, Taipei, Taiwan 100, Taiwan; Department of Computer Science and Information Engineering, Tamkang University, Tamsui, Taiwan 25137, Taiwan},
  Author_keywords          = {Data stream mining; Incremental mining; Multiple data streams; Sequential pattern mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose the IAspam algorithm that not only can handle a set of items at a time but also can incrementally mine across-streams sequential patterns. In the process, stream data are converted into bitmap representation for mining. Experimental results show that the IAspam algorithm is effective in execution time when processing large amounts of stream data 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79953101548&partnerID=40&md5=a0b7c5e39bd36c9d9ff3bbc51ceff27c}
}

@Article{Yang2011a,
  Title                    = {Incremental mining of closed sequential patterns in multiple data streams},
  Author                   = {Yang, S.-Y.a and Chao, C.-M.b and Chen, P.-Z.c and Sun, C.-H.c },
  Journal                  = {Journal of Networks},
  Year                     = {2011},
  Note                     = {cited By (since 1996)6},
  Number                   = {5},
  Pages                    = {728-735},
  Volume                   = {6},

  Abstract                 = {Sequential pattern mining searches for the relative sequence of events, allowing users to make predictions on discovered sequential patterns. Due to drastically advanced information technology over recent years, data have rapidly changed, growth in data amount has exploded and real-time demand is increasing, leading to the data stream environment. Data in this environment cannot be fully stored and ineptitude in traditional mining techniques has led to the emergence of data stream mining technology. Multiple data streams are a branch of the data stream environment. The MILE algorithm cannot preserve previously mined sequential patterns when new data are entered because of the concept of one-time fashion mining. To address this problem, we propose the ICspan algorithm to continue mining sequential patterns through an incremental approach and to acquire a more accurate mining result. In addition, due to the algorithm constraint in closed sequential patterns mining, the generation and records for sequential patterns will be reduced, leading to a decrease of memory usage and to an effective increase of execution efficiency. Ã‚Â© 2011 ACADEMY PUBLISHER.},
  Affiliation              = {Department of Media Art, Kang-Ning Junior College of Medical Care and Management, Taipei 114, Taiwan; Department of Computer Science and Information Management, Soochow University, Taipei 100, Taiwan; Department of Computer Science, Information Engineering Tamkang University, Tamsui 25137, Taiwan},
  Author_keywords          = {Data Stream Mining; Incremental Mining; Multiple Data Streams; Sequential Pattern Mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose the ICspan algorithm to continue mining sequential patterns through an incremental approach and to acquire a more accurate mining result. In addition, due to the algorithm constraint in closed sequential patterns mining, the generation and records for sequential patterns will be reduced, leading to a decrease of memory usage and to an effective increase of execution efficiency Their algorithm is an improvement on the MILE algorithm. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79955939439&partnerID=40&md5=d4644033691c7405aa904fbb639a8830}
}

@Article{Yang2013a,
  Title                    = {Visage: A face interpretation engine for smartphone applications},
  Author                   = {Yang, X.a and You, C.-W.a and Lu, H.b and Lin, M.a and Lane, N.D.c and Campbell, A.T.a },
  Journal                  = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {149-168},
  Volume                   = {110 LNICST},

  Abstract                 = {Smartphones represent powerful mobile computing devices enabling a wide variety of new applications and opportunities for human interaction, sensing and communications. Because smartphones come with front-facing cameras, it is now possible for users to interact and drive applications based on their facial responses to enable participatory and opportunistic face-aware applications. This paper presents the design, implementation and evaluation of a robust, real-time face interpretation engine for smartphones, called Visage, that enables a new class of face-aware applications for smartphones. Visage fuses data streams from the phone's front-facing camera and built-in motion sensors to infer, in an energy-efficient manner, the user's 3D head poses (i.e., the pitch, roll and yaw of user's heads with respect to the phone) and facial expressions (e.g., happy, sad, angry, etc.). Visage supports a set of novel sensing, tracking, and machine learning algorithms on the phone, which are specifically designed to deal with challenges presented by user mobility, varying phone contexts, and resource limitations. Results demonstrate that Visage is effective in different real-world scenarios. Furthermore, we developed two distinct proof-of-concept applications, Streetview+ and Mood Profiler driven by Visage. Ã‚Â© 2013 ICST Institute for Computer Science, Social Informatics and Telecommunications Engineering.},
  Affiliation              = {Dartmouth College, 6211 Sudikoff Lab., Hanover, NH 03755, United States; Intel Lab., 2200 Mission College Blvd, Santa Clara, CA 95054, United States; Microsoft Research Asia, No. 5 Dan Ling St., Haidian District, Beijing, China},
  Author_keywords          = {face interpretation engine; face-aware mobile application},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present a face recognition software called visage for mobile, which uses ML techniques on data streams from a mobile's camera. Included because they relate the software to the problem of tracking head movement and context. Can be interesting since ML on the mobile is a novel concept. 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84874810756&partnerID=40&md5=7e4a921007dd6e9f4bfa71e67c90e8b1}
}

@Misc{Yang,
  Title                    = {{Visage: A Face Interpretation Engine for Smartphone Applications}},

  Author                   = {Yang, Xiaochao and You, Chuang-wen and Lu, Hong and Lin, Mu and Lane, Nicholas D. and Campbell, Andrew T.},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Smartphones represent powerful mobile computing devices enabling a wide variety of new applications and opportunities for human interaction, sensing and communications. Because smartphones come with front-facing cameras, it is now possible for users to interact and drive applications based on their facial responses to enable participatory and opportunistic face-aware applications. This paper presents the design, implementation and evaluation of a robust, real-time face interpretation engine for smartphones, called Visage, thatenablesanewclassof face-aware applications for smartphones. Visage fuses data streams from the phone’s front-facing camera and built-in motion sensors to infer, in an energy-e cient manner, the user’s 3D head poses (i.e., the pitch, roll and yaw of user’s heads with respect to the phone) and facial expressions (e.g., happy, sad, angry, etc.). Visage supports a set of novel sensing, tracking, and machine learning algorithms on the phone, which are specifically designed to deal with challenges presented by user mobility, varying phone contexts, and resource limitations. Results demonstrate that Visage is e↵ective in di↵erent real-world scenarios. Furthermore, we developed two distinct proof-of-concept applications, Streetview+ and Mood Profiler driven by Visage. Key words: face-aware mobile application, face interpretation engine},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Yang2013a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.297.6932}
}

@Article{Yang2006,
  Title                    = {Online correlation analysis for multiple dimensions data streams},
  Author                   = {Yang, X.a b and Dong, Y.a and Xu, H.a and Liu, X.a and Qian, J.a and Wang, Y.a },
  Journal                  = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
  Year                     = {2006},
  Note                     = {cited By (since 1996)3},
  Number                   = {10},
  Pages                    = {1744-1750},
  Volume                   = {43},

  Abstract                 = {Studied in this paper is the problem of identifying correlations between two multiple-dimensions data streams under constrained resources. A novel online canonical correlation analysis (CCA) algorithm based on approximate technique, called QuickCCA, is proposed. To solve bottleneck of CCA's performance, QuickCCA uses a column-sampling with non-equal probability to compress the numbers of tuples and construct synopsis matrix first. And based on the synopsis matrix, the most k principal correlation coefficients between evolving multiple-dimensions data streams are computed rapidly. Theoretic analysis and experiments indicate that QuickCCA can accurately identify correlations between two multiple-dimensions data streams in synchronic sliding windows model. Compared with the existing correlation analysis algorithm for data streams, the QuickCCA algorithm reduces complexity of computation efficiently and trades accuracy with performance. It can be presented as a generic tool for a multitude of applications on data stream mining problems.},
  Affiliation              = {College of Computer Science and Engineering, Southeast University, Nanjing 210096, China; Information Management Institute, Fujian College of Traditional Chinese Medicine, Fuzhou 350003, China},
  Author_keywords          = {Approximation; Canonical correlation analysis; Constrained resources; Data stream; Non-equal probability sampling},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A novel online canonical correlation analysis (CCA) algorithm based on approximate technique, called QuickCCA, is proposed. To solve bottleneck of CCA's performance, QuickCCA uses a column-sampling with non-equal probability to compress the numbers of tuples and construct synopsis matrix first. Experiments indicate that QuickCCA can accurately identify correlations between two multiple-dimensions data streams in synchronic sliding windows model. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33845513416&partnerID=40&md5=fe20e83576c2cebfa8fa064dea74c2e4}
}

@Article{Ye2013,
  Title                    = {Online belief propagation algorithm for probabilistic latent semantic analysis},
  Author                   = {Ye, Y.a b and Gong, S.a and Liu, C.a and Zeng, J.a and Jia, N.b and Zhang, Y.b },
  Journal                  = {Frontiers of Computer Science},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {4},
  Pages                    = {526-535},
  Volume                   = {7},

  Abstract                 = {Probabilistic latent semantic analysis (PLSA) is a topic model for text documents, which has been widely used in text mining, computer vision, computational biology and so on. For batch PLSA inference algorithms, the required memory size grows linearly with the data size, and handling massive data streams is very difficult. To process big data streams, we propose an online belief propagation (OBP) algorithm based on the improved factor graph representation for PLSA. The factor graph of PLSA facilitates the classic belief propagation (BP) algorithm. Furthermore, OBP splits the data stream into a set of small segments, and uses the estimated parameters of previous segments to calculate the gradient descent of the current segment. Because OBP removes each segment from memory after processing, it is memory-efficient for big data streams. We examine the performance of OBP on four document data sets, and demonstrate that OBP is competitive in both speed and accuracy for online expectation maximization (OEM) in PLSA, and can also give a more accurate topic evolution. Experiments on massive data streams from Baidu further confirm the effectiveness of the OBP algorithm. Ã‚Â© 2013 Higher Education Press and Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {School of Computer Science and Technology, Soochow University, Suzhou, 215006, China; Feng Chao Revenue, Baidu Online Network Technology Co., LTD, Beijing, 100000, China},
  Author_keywords          = {belief propagation; expectation maximization; probabilistic latent semantic analysis; topic models},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They e propose an online belief propagation (OBP) algorithm based on the improved factor graph representation for PLSA (Probabilistic latent semantic analysis ). They examine the performance of OBP on four document data sets, and demonstrate that OBP is competitive in both speed and accuracy for online expectation maximization (OEM) in PLSA, and can also give a more accurate topic evolution The goal is finding the topic model in text mining, and this work is improvement on the normal batch processing. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880828710&partnerID=40&md5=62113a3c36c597c4984e51b6123bcf9f}
}

@Article{Yeon2010,
  Title                    = {Model averaging via penalized regression for tracking concept drift},
  Author                   = {Yeon, K.a and Song, M.S.a and Kim, Y.a and Choi, H.b and Park, C.c },
  Journal                  = {Journal of Computational and Graphical Statistics},
  Year                     = {2010},
  Note                     = {cited By (since 1996)2},
  Number                   = {2},
  Pages                    = {457-473},
  Volume                   = {19},

  Abstract                 = {A supervised learning algorithm aims to build a prediction model using training examples. This paradigm typically has the assumptions that the underlying distribution and the true input-output dependency do not change. However, these assumptions often fail to hold, especially in data streams. This phenomenon is known as concept drift. We propose a new model combining algorithm for tracking concept drift in data streams. The final predictive ensemble model has a form of a weighted average and ridge regression combiner. The coefficients of the combiner are determined by ridge regression with the constraints such that the coefficients are nonnegative and sum to 1. The proposed algorithm is devised via a new measure of concept drift, the angle between the estimated weights from data and the optimal weight vector obtained under no concept drift. It is shown that the ridge tuning parameter plays a crucial role of forcing the proposed algorithm to adapt to concept drift. Our main findings include (i) the proposed algorithm can achieve the optimal weights in the case of no concept drift if the tuning parameter is sufficiently large, and (ii) the angle is monotonically increasing as the tuning parameter decreases. These imply that if the tuning parameter is wellcontrolled, the algorithm can produce weights which reflect the degree of concept drift measured by the angle. Using various numerical examples, it is shown that the proposed algorithm can track concept drift better than other existing ensemble methods. Supplemental materials, computer code and R-package, are available online. Ã‚Â© 2010 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
  Affiliation              = {Department of Statistics, Seoul National University, Seoul, 151-742, South Korea; Department of Informational Statistics, Hoseo University, Asan, 330-713, South Korea; Department of Statistics, University of Georgia, Athens, GA 30602-1952, United States},
  Author_keywords          = {Data stream; Drifting concept; Ensemble method; Model combiner},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new model combining algorithm for tracking concept drift in data streams. The final predictive ensemble model has a form of a weighted average and ridge regression combine. They use a new measure of concept drift; the angle between the estimated weights from data and the optimal weight vector obtained under no concept drift. It is shown that the proposed algorithm can track concept drift better than other existing ensemble methods 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77956700814&partnerID=40&md5=6854bfdbd5948f4313fb6afa41731606}
}

@Article{Yin2012,
  Title                    = {Approximate data mining for sliding window based data streams},
  Author                   = {Yin, K.-C. and Hsieh, Y.-L. and Yang, D.-L.},
  Journal                  = {Journal of Computers},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {2},
  Pages                    = {1-13},
  Volume                   = {23},

  Abstract                 = {In the sliding window model of continuous dynamic data streams, the real-time process and update is an important issue for association rule mining. The existing researches deal with the problem by using specific data structures to retain the scanned data. However, if the next window slot contains any new frequent items, all the data must be rescanned to generate itemsets containing the new frequents. It is prohibitive to read the data twice for time-critical mining of continuous data streams. In order to meet the requirement of scanning data only one time, we propose a new approximate data stream mining algorithm (ADSMiner) using an extended FP-tree (EFP-tree) to save the current frequent-patterns. The EFP-tree not only records the frequent itemsets, but also keeps the counts of each itemset in the panes. If any new 1-itemset becomes frequent after the old data is replaced by the new data, there is no need to re-read the data. Instead, it is just added to the EFP-tree. When the order of the frequent 1-itemsets sequence changes, we use the Longest Common Subsequence method to locate the nodes requiring adjustment and maintain the structure of EFP-tree efficiently. The results of experiment show that our approach performs well as we expected on various datasets.},
  Affiliation              = {Department of Information Engineering and Computer Science, Feng Chia University, Taichung 407, Taiwan, Taiwan},
  Author_keywords          = {Approximate mining; Association rule; Data stream; FP-tree; Sliding window},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In order to meet the requirement of scanning data only one time, they propose a new approximate data stream mining algorithm (ADSMiner) using an extended FP-tree (EFP-tree) to save the current frequent-patterns. The results of experiment show that our approach performs well as we expected on various datasets. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864356364&partnerID=40&md5=b7ada9caa958e9d39a3fe6f9f497e56e}
}

@Misc{YKYCA2007,
  Title                    = {{Online power quality disturbances identification based on data stream technologies}},

  Author                   = {{Yinghui Kong} and {Jinsha Yuan} and {Linlin Che} and {Jing An}},
  Year                     = {2007},

  Abstract                 = {Power quality disturbances identification is the important procedure for improving the power quality, and online application has actual value. An efficient method for power quality disturbances identification is presented in this paper. Wavelet decomposition is used for extracting the features of various disturbances, and decision tree in data mining is used for identifying the disturbances. For online application, sliding window model and one-pass scan algorithms for wavelet decompositions are used. This method has low cost in memory and run time, it can identify different disturbances in high accuracy and less time. Simulation experiment using several typical disturbances, swell, sag, interrupt, harmonic, transient impulse, transient oscillation, show the effectiveness of proposed method.},
  Keywords                 = {Classification tree analysis,Decision trees,Entropy,Filter bank,Low pass filters,Multiresolution analysis,Power engineering,Power harmonic filters,Power quality,Sorting,data mining,data processing,data stream technologies,decision tree,decision trees,feature extraction,identification,one-pass scan algorithms,power engineering computing,power quality disturbances identification,power supply quality,power system faults,real time systems,transient impulse,transient oscillation,wavelet decomposition,wavelet transforms},
  Owner                    = {Alexander},
  Pages                    = {585--590},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {An efficient method for power quality disturbances identification is presented in this paper. Wavelet decomposition is used for extracting the features of various disturbances, and decision tree in data mining is used for identifying the disturbances. For online application, sliding window model and one-pass scan algorithms for wavelet decompositions are used. This method has low cost in memory and run time, it can identify different disturbances in high accuracy and less time. 1,3,4,6},
  Shorttitle               = {Power Engineering Conference, 2007. IPEC 2007. Int},
  Timestamp                = {2014.10.15}
}

@Conference{Yogita2013a,
  Title                    = {Clustering techniques for streaming data-a survey},
  Author                   = {Yogita and Toshniwal, D.},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {951-956},

  Abstract                 = {Nowadays many applications are generating streaming data for an example real-time surveillance, internet traffic, sensor data, health monitoring systems, communication networks, online transactions in the financial market and so on. Data Streams are temporally ordered, fast changing, massive, and potentially infinite sequence of data. Data Stream mining is a very challenging problem. This is due to the fact that data streams are of tremendous volume and flows at very high speed which makes it impossible to store and scan streaming data multiple time. Concept evolution in streaming data further magnifies the challenge of working with streaming data. Clustering is a data stream mining task which is very useful to gain insight of data and data characteristics. Clustering is also used as a pre-processing step in over all mining process for an example clustering is used for outlier detection and for building classification model. In this paper we will focus on the challenges and necessary features of data stream clustering techniques, review and compare the literature for data stream clustering by example and variable, describe some real world applications of data stream clustering, and tools for data stream clustering. Ã‚Â© 2013 IEEE.},
  Affiliation              = {Electronics and Computer Engineering Department, Indian Institute of Technology Roorkee, India},
  Art_number               = {6514355},
  Author_keywords          = {Clustering; Data Stream Mining; Streaming Data},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2013 3rd IEEE International Advance Computing Conference, IACC 2013},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {n this paper we will focus on the challenges and necessary features of data stream clustering techniques, review and compare the literature for data stream clustering by example and variable, describe some real world applications of data stream clustering, and tools for data stream clustering Set aside as potential background source.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84879857497&partnerID=40&md5=12d5d1768b9d7359abb2631e0e2194dc}
}

@InProceedings{Yogita2013,
  Title                    = {{Clustering techniques for streaming data-a survey}},
  Author                   = {Yogita, Y. and Toshniwal, D.},
  Booktitle                = {2013 3rd IEEE International Advance Computing Conference (IACC)},
  Year                     = {2013},
  Month                    = feb,
  Pages                    = {951--956},
  Publisher                = {IEEE},

  Abstract                 = {Nowadays many applications are generating streaming data for an example real-time surveillance, internet traffic, sensor data, health monitoring systems, communication networks, online transactions in the financial market and so on. Data Streams are temporally ordered, fast changing, massive, and potentially infinite sequence of data. Data Stream mining is a very challenging problem. This is due to the fact that data streams are of tremendous volume and flows at very high speed which makes it impossible to store and scan streaming data multiple time. Concept evolution in streaming data further magnifies the challenge of working with streaming data. Clustering is a data stream mining task which is very useful to gain insight of data and data characteristics. Clustering is also used as a pre-processing step in over all mining process for an example clustering is used for outlier detection and for building classification model. In this paper we will focus on the challenges and necessary features of data stream clustering techniques, review and compare the literature for data stream clustering by example and variable, describe some real world applications of data stream clustering, and tools for data stream clustering.},
  Doi                      = {10.1109/IAdCC.2013.6514355},
  ISBN                     = {978-1-4673-4529-3},
  Keywords                 = {Clustering,Data Stream Mining,Streaming Data,classification model,clustering task,concept evolution,data mining,data sequence,data stream clustering technique,data stream mining,outlier detection,pattern clustering,streaming data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Yogita2013a},
  Shorttitle               = {Advance Computing Conference (IACC), 2013 IEEE 3rd},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6514355}
}

@Article{Yu2014,
  Title                    = {Semi-supervised time series modeling for real-time flux domain detection on passive dns traffic},
  Author                   = {Yu, B. and Smith, L. and Threefoot, M.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {258-271},
  Volume                   = {8556 LNAI},

  Abstract                 = {Flux domain is one of the most active threat vectors and its behavior keeps changing to evade existing detection measures. In order to differentiate the malicious flux domains from legitimate ones such as content delivery network (CDN) and network time protocol (NTP) services that have similar behavior, a novel time series model is created with a set of features that are not only focused on domain name system (DNS) time-to-live (TTL) but on loyalty and entropy of DNS resource records. An offline system is built with big data technology for training the model in a semi-supervised mode. In addition, an online platform is designed and developed to support large throughput real-time DNS streaming data processing with advanced analytics technologies. The feature extraction, classification, accuracy and performance are discussed based on large amount of real world DNS data in this paper. Ã‚Â© 2014 Springer International Publishing Switzerland.},
  Affiliation              = {Infoblox Inc., Santa Clara, CA, United States},
  Author_keywords          = {Big data analytics; DNS flux; Network security; Semi-supervised machine learning; Time series model},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {An offline system is built with big data technology for training the model in a semi-supervised mode. In addition, an online platform is designed and developed to support large throughput real-time DNS streaming data processing with advanced analytics technologies. The feature extraction, classification, accuracy and performance are discussed based on large amount of real world DNS data in this paper Problem of flux domain detection in intrusion detection networks. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905500185&partnerID=40&md5=4d33d3e8bee2d8632402ad36f47e7657}
}

@Conference{Yu2012,
  Title                    = {A new evolving data streams system with data fusion},
  Author                   = {Yu, H.a and Wang, Z.b and Liu, X.c },
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {1743-1746},

  Abstract                 = {Cluster analysis is an important data mining issue, where objects under investigation are grouped into subsets of the original set of objects. In recent several years, a few clustering algorithms have been developed for the data stream problem. However these algorithms lack of extensibility or efficiency. In this paper we propose a new evolving data streams system with data fusion. We discuss a fundamentally different philosophy for data stream clustering which is guided by application centered requirements. The system is highly suitable for real-time implementation and is demonstrated through a series of experiments. The experiments over a number of real and synthetic data sets illustrate the effectiveness and efficiency. Ã‚Â© 2012 IEEE.},
  Affiliation              = {School of Electronic and Information Engineering, Hunan University of Technology, Zhuzhou Hunan, China; Department of Electric-Optic Engineering, ZhongShan Torch Polytechnic, Zhongshan GuangDong, China; Department of Computer and Information, Zhuzhou Vocational School of Industrial Technology, Zhuzhou Hunan, China},
  Art_number               = {6322751},
  Author_keywords          = {Cluster; Data stream; evolving algorithm; fusion},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2012 International Conference on Industrial Control and Electronics Engineering, ICICEE 2012},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new evolving data streams system with data fusion. they discuss a fundamentally different philosophy for data stream clustering which is guided by application centered requirements. The system is highly suitable for real-time implementation and is demonstrated through a series of experiments. The experiments over a number of real and synthetic data sets illustrate the effectiveness and efficiency 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870034521&partnerID=40&md5=d9731d0d17647fe6cc1920d721a9e967}
}

@InProceedings{Yu2005,
  Title                    = {{Online Mining of Data Streams: Applications, Techniques and Progress}},
  Author                   = {Yu, P.S.},
  Booktitle                = {21st International Conference on Data Engineering (ICDE'05)},
  Year                     = {2005},
  Pages                    = {1146--1146},
  Publisher                = {IEEE},

  Abstract                 = {No abstract},
  Doi                      = {10.1109/ICDE.2005.101},
  ISBN                     = {0-7695-2285-8},
  ISSN                     = {1084-4627},
  Keywords                 = {Aggregates,Data engineering,Data mining,Database systems,Frequency,Internet,Intrusion detection,Roads,Seminars,Stock markets,data mining,data streams,database management system,large data sets,online mining,very large databases},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {No abstract, and seems to be a review/summary of online mining.},
  Shorttitle               = {Data Engineering, 2005. ICDE 2005. Proceedings. 21},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1410243}
}

@Article{Yu2012a,
  Title                    = {Trajectory stream mining framework facing to real time query processing},
  Author                   = {Yu, Y. and Wang, Q. and Wang, X. and Wang, H. and He, J.},
  Journal                  = {Yi Qi Yi Biao Xue Bao/Chinese Journal of Scientific Instrument},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {12},
  Pages                    = {2803-2811},
  Volume                   = {33},

  Abstract                 = {In order to solve the real time query problem in trajectory data stream, a trajectory data stream mining framework (TSMF) facing to real time query processing is proposed, which contains two parts: online trajectory data stream mining and offline real time query processing. For the online part, we first perform online line segment data stream clustering based on density to obtain line segment clusters for received data stream. Then, according to the line segment cluster results, the trajectory clusters and swarm patterns are updated online based on TCT and SHT storage index. For the offline part, in order to respond to users' real time query request, three real time query processing methods facing to moving target are implemented, which are current closed trajectory clusters query (CCTC), current closed swarm query (CCSwarm) and k-nearest neighboring trajectory (k-NNT) query. When a user requests to query from trajectory data stream, the query result is quickly reported from the trajectory clusters and swarm patterns discovered in the online part. Comprehensive experiments on large scale real trajectory data and synthetic data demonstrate the mining effectiveness, efficiency, scalability and fast query processing speed of the proposed TSMF framework.},
  Affiliation              = {School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China},
  Author_keywords          = {Query processing; Real time capacity; Swarm pattern; Trajectory cluster; Trajectory stream mining},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {In order to solve the real time query problem in trajectory data stream, a trajectory data stream mining framework (TSMF) facing to real time query processing is proposed, which contains two parts: online trajectory data stream mining and offline real time query processing. Comprehensive experiments on large scale real trajectory data and synthetic data demonstrate the mining effectiveness, efficiency, scalability and fast query processing speed of the proposed TSMF framework. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84873115526&partnerID=40&md5=c3bcf3d6d0893b09ffc4ecc2051f14a0}
}

@Article{Yun2014a,
  Title                    = {Mining maximal frequent patterns by considering weight conditions over data streams},
  Author                   = {Yun, U.a and Lee, G.a and Ryu, K.H.b },
  Journal                  = {Knowledge-Based Systems},
  Year                     = {2014},
  Note                     = {cited By (since 1996)3},
  Pages                    = {49-65},
  Volume                   = {55},

  Abstract                 = {Frequent pattern mining over data streams is currently one of the most interesting fields in data mining. Current databases have needed more immediate processes since enormous amounts of data are being accumulated and updated in real time. However, existing traditional approaches have not been entirely suitable for a data stream environment since they operate with more than two database scans. Moreover, frequent pattern mining over data streams mostly generates an enormous number of frequent patterns, thereby causing a significant amount of overheads. In addition, as weight conditions are very useful factors in reflecting importance for each object in the real world, it is necessary to apply them to the mining process in order to obtain more practical, meaningful patterns. To consider and solve these problems, we propose a novel method for mining Weighted Maximal Frequent Patterns (WMFPs) over data streams, called MWS (Maximal frequent pattern mining with Weight conditions over data Streams). MWS guarantees efficient mining performance in the data stream environment by scanning stream databases only once, and prevents overheads of pattern extractions with an abbreviated notation: a maximal frequent pattern form instead of the general one. Furthermore, MWS contributes to enhanced reliability of the mining results by applying weight conditions to each element of the data streams. Extensive experiments report that MWS has outstanding performance in comparison to previous algorithms. Ã‚Â© 2013 Elsevier B.V. All rights reserved.},
  Affiliation              = {Department of Computer Engineering, Sejong University, Seoul, South Korea; Department of Computer Science, Chungbuk National University, Cheongju, South Korea},
  Author_keywords          = {Data mining; Data stream; Knowledge discovery; Maximal frequent pattern mining; Weight condition},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a novel method for mining Weighted Maximal Frequent Patterns (WMFPs) over data streams called MWS. MWS guarantees efficient mining performance in the data stream environment by scanning stream databases only once. Extensive experiments report that MWS has outstanding performance in comparison to previous algorithms (Does this mean compared to SotA?) 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84888305971&partnerID=40&md5=2fa06343deaa50da66852e11a9d800b6}
}

@Misc{Zaniolo,
  Title                    = {{Mining Data Bases and Data Streams}},

  Author                   = {Zaniolo, Carlo and Thakkar, Hetal},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Data mining represents an emerging technology area of great importance to homeland security. Data mining enables knowledge discovery on databases by identifying patterns that are novel, useful, and actionable. It has proven successful in many domains, such as banking, e-commerce, genomic, investment, telecom, web analysis, link analysis, and security applications. In this chapter, we will survey the main methods and applications of data mining and the information systems recently developed for supporting the mining process. We then overview the key areas of data mining research, in particular, on-line mining of massive data streams, such as those that flow continuously on the Internet and other communication channels. We show that the traditional store-now & mine-later techniques are no longer effective either because of the size of the data stream or because of the real-time response requirement. Thus new fast & light algorithms and suitable systems must be developed for mining data streams.},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {In this chapter, we will survey the main methods and applications of data mining and the information systems recently developed for supporting the mining process. We then overview the key areas of data mining research, Book review, discarded.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.161.1318}
}

@Conference{Zaslavsky2013a,
  Title                    = {ShareLikesCrowd: Mobile analytics for participatory sensing and crowd-sourcing applications},
  Author                   = {Zaslavsky, A.a and Jayaraman, P.P.a and Krishnaswamy, S.b },
  Year                     = {2013},
  Note                     = {cited By (since 1996)1},
  Pages                    = {128-135},

  Abstract                 = {Data and continuous data streams from mobile users/devices are becoming increasingly important for numerous applications including urban modelling, transportation, and more recently for mobile crowd-sensing to support citizen journalism and participatory sensing where sensor informatics and social networking meet. While significant efforts have focused towards the analysis of mobile user data, a key challenge that needs to be addressed in order to realize the full-potential is to address the scalability issues of real-time data collection and processing at run time. By scalability, we refer to both the challenges of data capture from a large number of users, as well as the issues of energy consumed on individual devices as a result of that capture. In this paper, we present mobile/on-board data stream mining as an effective approach to address the scalability issues of mobile data collection and run-time processing and as a significant component of mobile run-time analytics. We present experimental evaluation using the Nokia mobile data challenge open track dataset to show the significant energy and bandwidth savings that mobile data stream mining can achieve with no significant loss of useful information in this process. Ã‚Â© 2013 IEEE.},
  Affiliation              = {ICT Centre, CSIRO, Canberra, Australia; I2R, Singapore},
  Art_number               = {6547440},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THey present mobile/on-board data stream mining as an effective approach to address the scalability issues of mobile data collection and run-time processing and as a significant component of mobile run-time analytics. We present experimental evaluation using the Nokia mobile data challenge open track dataset to show the significant energy and bandwidth savings that mobile data stream mining can achieve with no significant loss of useful information in this process Not sure what they have come up with on their own, and what is just a presentation of existing practice. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84881448561&partnerID=40&md5=762054d6d68b61d4ab2dec06b3f2b50b}
}

@InProceedings{Zaslavsky2013,
  Title                    = {{ShareLikesCrowd: Mobile analytics for participatory sensing and crowd-sourcing applications}},
  Author                   = {Zaslavsky, Arkady and Jayaraman, Prem Prakash and Krishnaswamy, Shonali},
  Booktitle                = {2013 IEEE 29th International Conference on Data Engineering Workshops (ICDEW)},
  Year                     = {2013},
  Month                    = apr,
  Pages                    = {128--135},
  Publisher                = {IEEE},

  Abstract                 = {Data and continuous data streams from mobile users/devices are becoming increasingly important for numerous applications including urban modelling, transportation, and more recently for mobile crowd-sensing to support citizen journalism and participatory sensing where sensor informatics and social networking meet. While significant efforts have focused towards the analysis of mobile user data, a key challenge that needs to be addressed in order to realize the full-potential is to address the scalability issues of real-time data collection and processing at run time. By scalability, we refer to both the challenges of data capture from a large number of users, as well as the issues of energy consumed on individual devices as a result of that capture. In this paper, we present mobile/on-board data stream mining as an effective approach to address the scalability issues of mobile data collection and run-time processing and as a significant component of mobile run-time analytics. We present experimental evaluation using the Nokia mobile data challenge open track dataset to show the significant energy and bandwidth savings that mobile data stream mining can achieve with no significant loss of useful information in this process.},
  Doi                      = {10.1109/ICDEW.2013.6547440},
  ISBN                     = {978-1-4673-5304-5},
  Keywords                 = {Nokia mobile data challenge open track dataset,ShareLikesCrowd,citizen journalism,continuous data streams,crowd-sourcing applications,data capture,data mining,experimental evaluation,mobile analytics,mobile computing,mobile crowd-sensing,mobile data collection,mobile data stream mining,mobile devices,mobile run-time analytics,mobile user data,mobile users,on-board data stream mining,participatory sensing,real-time data collection,real-time data processing,run-time processing,sensor informatics,social networking,transportation,urban modelling},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zaslavsky2013a},
  Shorttitle               = {Data Engineering Workshops (ICDEW), 2013 IEEE 29th},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6547440}
}

@Article{Zhan2012,
  Title                    = {An algorithm for data stream speed anomaly detection based on RCSW},
  Author                   = {Zhan, Y.a and Wu, C.-M.b and Wang, B.-J.a },
  Journal                  = {Tien Tzu Hsueh Pao/Acta Electronica Sinica},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {4},
  Pages                    = {674-680},
  Volume                   = {40},

  Abstract                 = {In many fields, data stream continues to grow in terms of generation speed, scale and vibration, which makes the data stream mining more difficult. RCSW is used in data stream mining to finish data steam sampling. The three concept such as real-time T, key time point set, data stream processing ratio are proposed. Then an algorithm for data stream speed anomaly detection is proposed, which monitor and predict flow velocity. The system intelligently adjust ring buffer and data stream processing ratio if there is excessive flow velocity, in order to solve the conflicts commendably between data processing power and flow velocity, throughput and limited memory. Experimental results show that it is an algorithm for data stream speed anomaly detection which can ensure normal execution of data stream mining and well meet the need of the system real-time.},
  Affiliation              = {Zhejiang Institute of Communications, Hangzhou, Zhejiang 311112, China; Institute of Computer System Architecture, Zhejiang University, Hangzhou, Zhejiang 310027, China},
  Author_keywords          = {Data stream; Real-time T; Ring circular sliding window (RCSW); Time point},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Three concepts such as real-time T, key time point set, data stream processing ratio are proposed. Then an algorithm for data stream speed anomaly detection is proposed, which monitor and predict flow velocity. Experimental results show that it is an algorithm for data stream speed anomaly detection which can ensure normal execution of data stream mining and well meet the need of the system real-time. Bad english, 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84862656825&partnerID=40&md5=ffa49f5ce5fdf5108fdda356ddffbfa4}
}

@InProceedings{Zhang2010a,
  Title                    = {{Mining frequent closed itemsets over data stream based on Bitvector and digraph}},
  Author                   = {Zhang, Guanglu and Lei, Jingsheng and Wu, Xinghui},
  Booktitle                = {2010 2nd International Conference on Future Computer and Communication},
  Year                     = {2010},
  Pages                    = {V2--241--V2--246},
  Publisher                = {IEEE},
  Volume                   = {2},

  Abstract                 = {A data stream is a continuous, huge, fast changing, rapid, infinite sequence of data elements. The nature of streaming data makes it essential to use online algorithms which require only one scan over the data for knowledge discovery. Mining frequent patterns on streaming data is a new challenging problem. Recent research mainly focuses on mining frequent itemsets over data stream. However, when the threshold of support set is small, the number of frequent itemsets is staggering. moreover frequent closed itemsets is completely contains the information of frequent itemsets and the total number of frequent closed itemsets is still much smaller than that of frequent itemsets. Therefore, mining frequent closed itemsets is a better choice. In this paper, A new algorithm named MFCIDS\_BD (Mining Frequent Closed Itemsets Over Data Stream Based On Bit-vector and Digraph) is proposed to mine frequent all closed itemset in the transaction sliding window over data stream. MFCIDS\_BD uses a Bit-vector table based data structure, an an effective bit-sequence representation of items, to dynamically maintain all information over transactions slding window. A digraph based data structure is developed in the MFCIDS\_BD to depth-first mine all CFs. The maximum number of nodes in digraph does not exceed the total number of items in data stream. in the mining process, MFCIDS\_BD uses simple bit Ã¢â‚¬Å“ANDÃ¢â‚¬ï¿½ Operations to calculate the support of itemset. MFC-DS\_BD Effectively save the save memory and improve speed. Experimental results show that MFCIDS\_BD is effective and efficient.},
  Doi                      = {10.1109/ICFCC.2010.5497389},
  ISBN                     = {978-1-4244-5821-9},
  Keywords                 = {Computer science,Data mining,Data structures,Information science,Itemsets,MFCIDS-BD algorithm,Mathematics,Pattern analysis,Performance analysis,Statistics,Tree data structures,bit AND operations,bit sequence representation,bit vector table,data mining,data stream,data streaming,data structure,data structures,digraph,directed graphs,frequent closed itemset mining,frequent closed itemsets,frequent pattern mining,knowledge discovery,online algorithms,transaction sliding window},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhang2010b},
  Shorttitle               = {Future Computer and Communication (ICFCC), 2010 2n},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5497389}
}

@Conference{Zhang2010b,
  Title                    = {Mining frequent closed itemsets over data stream based on bitvector and digraph},
  Author                   = {Zhang, G.a and Lei, J.b and Wu, X.c },
  Year                     = {2010},
  Note                     = {cited By (since 1996)3},
  Pages                    = {V2241-V2246},
  Volume                   = {2},

  Abstract                 = {A data stream is a continuous,huge,fast changing,rapid,infinite sequence of data elements.The nature of streaming data makes it essential to use online algorithms which require only one scan over the data for knowledge discovery.Mining frequent patterns on streaming data is a new challenging problem . Recent research mainly focuses on mining frequent itemsets over data stream. However, when the threshold of support set is small, the number of frequent itemsets is staggering. moreever frequent closed itemsets is completely contains the information of frequent itemsets and the tatol number of frequent closed itemsets is still much smaller than that of frequent itemsets . Therefore, mining frequent closed itemsets is a better choice .In this paper,A new algotihm named MFCIDS-BD (Mining Frequent Closed Itemsets Over Data Stream Based On Bit-vector and Digraph) is proposed to mine frequent all closed itemset in the transaction sliding window over data stream. MCFIDS-BD uses a Bit-vector table based data structure,an an effective bit-sequence representation of items, to dynamically maintain all information over transactions slding window. A digraph based data structure is developed in the MFCDS-BD to depth-first mine all CFIs. The maximum number of nodes in digraph does not exceed the total number of items in data stream. in the mining process, MFCDS-BD uses simple bit "AND" Operations to calculate the support of itemset. MFC-DS-BD Effectively save the save memory and improve speed. Experimental results show that MFCSD-BD is effective and effi-cient. Ã‚Â©2010 IEEE.},
  Affiliation              = {School of Mathematics and Statistics, Hainan Normal University, Hai Kou, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nan Jing, China; School of Information Science and Technology, Hainan Normal University, Hai Kou, China},
  Art_number               = {5497389},
  Author_keywords          = {Data mining; Data stream; Frequent closed itemsets},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings of the 2010 2nd International Conference on Future Computer and Communication, ICFCC 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A new algotihm named MFCIDS-BD (Mining Frequent Closed Itemsets Over Data Stream Based On Bit-vector and Digraph) is proposed to mine frequent all closed itemset in the transaction sliding window over data stream. . in the mining process, MFCDS-BD uses simple bit "AND" Operations to calculate the support of itemset. MFC-DS-BD Effectively save the save memory and improve speed. Experimental results show that MFCSD-BD is effective and effi-cient. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78049332751&partnerID=40&md5=852bca2f8ae0cdc9d3a073d4c40ca9c3}
}

@Article{Zhang2013,
  Title                    = {Online bursty events detection based on emoticons},
  Author                   = {Zhang, L.-M.a and Jia, Y.a and Zhou, B.a and Zhao, J.-H.a and Hong, F.b },
  Journal                  = {Jisuanji Xuebao/Chinese Journal of Computers},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {8},
  Pages                    = {1659-1667},
  Volume                   = {36},

  Abstract                 = {How to effectively and efficiently detect the online public events in massive data streams has become a hot research area nowadays. In this paper, we propose a novel approach to mine online events based on emoticons. Emoticons in texts streams always burst with hot events, so we could monitor the states of emoticons and quickly mine the bursty periods so as to detect events. Firstly, we build an emoticon model based on frequent patterns mining and mutual information, and detect their periods using Kleinberg's method. Then, we use Heuristic Affinity Propagation (HAP) to cluster and aggregate events. Besides, a recycle module is proposed in the last part of the frame so as to make precise event abstraction. Experimental results show that our algorithm can detect online events in microblog streams effectively, and could meet the needs of real-time process both in speed and accuracy.},
  Affiliation              = {College of Computer, National University of Defense Technology, Changsha 410073, China; Xi'an Satellite Control Center, Xi'an 710043, China},
  Author_keywords          = {Bursty events; Emoticons; Microblog; Online detection},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a novel approach to mine online events based on emoticons. Emoticons in texts streams always burst with hot events, so we could monitor the states of emoticons and quickly mine the bursty periods so as to detect events. Experimental results show that the algorithm can detect online events in microblog streams effectively, and could meet the needs of real-time process both in speed and accuracy. Maybe interesting for Telenor. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84882804821&partnerID=40&md5=2cfe300767199ad219025a830b1f319f}
}

@Conference{Zhang2010c,
  Title                    = {Towards health data stream analytics},
  Author                   = {Zhang, Q.a and Pang, C.a and Mcbride, S.a and Hansen, D.a and Cheung, C.b and Steyn, M.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)2},
  Pages                    = {282-287},

  Abstract                 = {Data streams, or data sets which continuously and rapidly grow over time, are a prominent form of clinical data generated during the monitoring and treatment of patients in the health care industry. We propose the name Health Data Stream Analytics (HDSA) to the application of stream data processing to clinical data. Our work in this area is demonstrating the useful role Health Data Stream Analytics can play in clinical decision support, patient safety improvement and early detection of adverse patient outcomes. Two major challenges in applying stream data processing to heath care are tailoring query support for the clinical context and dealing with the clinical requirement of online query processing. In this paper, we propose the Anaesthetic Data Analyser (ADA) as a Health Data Stream Analytics System for the anaesthetics specialty and describe how it addresses these challenges. ADA differentiates from current approaches by looking at trends in the data stream rather than a single data value against a preset threshold. The trend analysis supported by ADA is a novel application in this area, and enables support for adverse symptoms monitoring in physiological stream data, alerting clinicians when a pre-defined adverse data pattern is detected in the physiological signals. This paper also describes an online query processing algorithm and the results of experiments on "real world" physiological steam data which indicate the algorithms has sub-second response times for trend queries. Ã‚Â© 2010 IEEE.},
  Affiliation              = {Australian e-Health Research Centre, Australia; Anaesthesia Department, Royal Brisbane Women's Hospital, Australia},
  Art_number               = {5558827},
  Document_type            = {Conference Paper},
  Journal                  = {2010 IEEE/ICME International Conference on Complex Medical Engineering, CME2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THey propose the name Health Data Stream Analytics (HDSA) to the application of stream data processing to clinical data. Our work in this area is demonstrating the useful role Health Data Stream Analytics can play in clinical decision support. This paper also describes an online query processing algorithm and the results of experiments on real world physiological steam data which indicate the algorithms has sub-second response times for trend queries. 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77957791675&partnerID=40&md5=169696b61dc13ad40c801b21e56c1368}
}

@InProceedings{Zhang2010,
  Title                    = {{Towards Health Data Stream Analytics}},
  Author                   = {Zhang, Qing and Pang, Chaoyi and Mcbride, Simon and Hansen, David and Steyn, Michael},
  Booktitle                = {IEEE/ICME International Conference on Complex Medical Engineering},
  Year                     = {2010},
  Month                    = jul,
  Pages                    = {282--287},
  Publisher                = {IEEE},

  Abstract                 = {Data streams, or data sets which continuously and rapidly grow over time, are a prominent form of clinical data generated during the monitoring and treatment of patients in the health care industry. We propose the name Health Data Stream Analytics (HDSA) to the application of stream data processing to clinical data. Our work in this area is demonstrating the useful role Health Data Stream Analytics can play in clinical decision support, patient safety improvement and early detection of adverse patient outcomes. Two major challenges in applying stream data processing to heath care are tailoring query support for the clinical context and dealing with the clinical requirement of online query processing. In this paper, we propose the Anaesthetic Data Analyser (ADA) as a Health Data Stream Analytics System for the anaesthetics specialty and describe how it addresses these challenges. ADA differentiates from current approaches by looking at trends in the data stream rather than a single data value against a preset threshold. The trend analysis supported by ADA is a novel application in this area, and enables support for adverse symptoms monitoring in physiological stream data, alerting clinicians when a pre-defined adverse data pattern is detected in the physiological signals. This paper also describes an online query processing algorithm and the results of experiments on Ã¢â‚¬Å“real worldÃ¢â‚¬ï¿½ physiological steam data which indicate the algorithms has sub-second response times for trend queries.},
  Doi                      = {10.1109/ICCME.2010.5558827},
  ISBN                     = {978-1-4244-6841-6},
  Keywords                 = {adverse symptoms monitoring,anaesthetic data analyser,health care,health data stream analytics system,heath care,medical computing,medical information systems,online query processing algorithm,patient safety improvement,physiological signals,physiological stream data,pre-defined adverse data pattern,stream data processing,tailoring query support},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhang2010c},
  Shorttitle               = {Complex Medical Engineering (CME), 2010 IEEE/ICME },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5558827}
}

@Article{Zhang2009,
  Title                    = {Adaptive correlation analysis in stream time series with sliding windows },
  Author                   = {Tiancheng Zhang and Dejun Yue and Yu Gu and Yi Wang and Ge Yu},
  Journal                  = {Computers \& Mathematics with Applications },
  Year                     = {2009},
  Note                     = {Advances in Fuzzy Sets and Knowledge Discovery },
  Number                   = {6},
  Pages                    = {937 - 948},
  Volume                   = {57},

  Abstract                 = {Correlation analysis is a very useful technique for similarity search in the field of data stream mining. The traditional method is not suitable for real time processing especially when the amount of stream sequences is very large. In this paper, we propose \{HBR\} (Hierarchical Boolean Representation), a novel technique for correlation analysis in stream time series. The original stream sequences are transformed into the Macro-Boolean series and the Micro-Boolean series successively, and the candidate correlation set can be easily obtained by simple bit operations. With huge amount of stream series, this method can quickly get the correlation pairs of series efficiently by reducing complicated calculation in a little space. Meanwhile, this approach can update the Boolean series incrementally with very low cost and adjust some important coefficients adaptively by the stream feature. The experimental evaluations show that \{HBR\} has excellent computation complexity with high accuracy.},
  Doi                      = {http://dx.doi.org/10.1016/j.camwa.2008.10.083},
  ISSN                     = {0898-1221},
  Keywords                 = {Correlation analysis},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {they propose \{HBR\} (Hierarchical Boolean Representation), a novel technique for correlation analysis in stream time series. With huge amount of stream series, this method can quickly get the correlation pairs of series efficiently by reducing complicated calculation in a little space. The experimental evaluations show that \{HBR\} has excellent computation complexity with high accuracy. 1,3,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0898122108005671}
}

@InProceedings{Zhang2007,
  Title                    = {{Correlation Analysis Based on Hierarchical Boolean Representation over Time Series Data Streams}},
  Author                   = {Zhang, Tiancheng and Yue, Dejun and Yu, Ge and Gu, Yu},
  Booktitle                = {Fourth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2007)},
  Year                     = {2007},
  Pages                    = {740--744},
  Publisher                = {IEEE},
  Volume                   = {2},

  Abstract                 = {Correlation analysis is a basic problem in the field of data stream mining. Traditional method is not suitable for real time processing with huge amount of stream data. We propose a hierarchical Boolean representation method for correlation analysis among time series data streams. The original streaming series are transformed into the Macro- Boolean series and then the Micro-Boolean series successively, and the candidate can be easily gained by simple bit operations. With huge amount of streaming series, this method can quickly get the correlation pairs of series in an efficient way by reducing huge calculation in a little space The experimental evaluations show that our method has better computation complexity with high accuracy.},
  Doi                      = {10.1109/FSKD.2007.230},
  ISBN                     = {0-7695-2874-0},
  Keywords                 = {Boolean functions,Computational efficiency,Data analysis,Data engineering,Data mining,Information analysis,Information science,Interpolation,Monitoring,Sampling methods,Time series analysis,correlation analysis,data mining,data stream mining,hierarchical Boolean representation,time series,time series data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhang2007},
  Shorttitle               = {Fuzzy Systems and Knowledge Discovery, 2007. FSKD },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4406174}
}

@Conference{Zhang2007a,
  Title                    = {Correlation analysis based on hierarchical Boolean representation over time series data streams},
  Author                   = {Zhang, T. and Yue, D. and Yu, G. and Gu, Y.},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {740-744},
  Volume                   = {2},

  Abstract                 = {Correlation analysis is a basic problem in the field of data stream mining. Traditional method is not suitable for real time processing with huge amount of stream data. We propose a hierarchical Boolean representation method for correlation analysis among time series data streams. The original streaming series are transformed into the Macro-Boolean series and then the Micro-Boolean series successively, and the candidate can be easily gained by simple bit operations. With huge amount of streaming series, this method can quickly get the correlation pairs of series in an efficient way by reducing huge calculation in a little space The experimental evaluations show that our method has better computation complexity with high accuracy. Ã‚Â© 2007 IEEE.},
  Affiliation              = {School of Information Science and Engineering, Northeastern University, ShenYang, China},
  Art_number               = {4406174},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - Fourth International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2007},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Correlation analysis is a basic problem. They propose a hierarchical Boolean representation method for correlation analysis among time series data streams. experimental evaluations show that our method has better computation complexity with high accuracy 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-44049094776&partnerID=40&md5=082fc9a323a92296939af00296f84656}
}

@Misc{Zhang2009c,
  Title                    = {Toward Autonomic Grids: Analyzing the Job Flow with Affinity Streaming},

  Author                   = {Zhang, Xiangliang and Germain-renaud, Cecile and Furtlehner, Cyril and Sebag, Mich\`{e}le and Perez, Julien},
  HowPublished             = {15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  Year                     = {2009},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The Affinity Propagation (AP) clustering algorithm proposed by Frey and Dueck (2007) provides an understandable, nearly optimal summary of a dataset, albeit with quadratic computational complexity. This paper, motivated by Autonomic Computing, extends AP to the data streaming framework. Firstly a hierarchical strategy is used to reduce the complexity to O(N 1+ε); the distortion loss incurred is analyzed in relation with the dimension of the data items. Secondly, a coupling with a change detection test is used to cope with non-stationary data distribution, and rebuild the model as needed. The presented approach Strap is applied to the stream of jobs submitted to the EGEE Grid, providing an understandable description of the job flow and enabling the system administrator to spot online some sources of failures.},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper, motivated by Autonomic Computing, extends AP ( Affinity Propagation (AP) clustering algorithm from 2007) to the data streaming framework. The presented approach Strap is applied to the stream of jobs submitted to the EGEE Grid, providing an understandable description of the job flow and enabling the system administrator to spot online some sources of failures. 1,2,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.215.7009}
}

@Article{Zhang,
  Title                    = {{Multi-scale real-time grid monitoring with job stream mining}},
  Author                   = {Zhang, Xiangliang and Sebag, Mich\`{e}le and Germain-renaud, C\'{e}cile},
  Journal                  = {IN 9TH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID (CCGRID), 2009},
  Pages                    = {420 -- 427},

  __markedentry            = {[Alexander:]},
  Abstract                 = {The ever increasing scale and complexity of large computational systems ask for sophisticated management tools, paving the way toward Autonomic Computing. A first step toward Autonomic Grids is presented in this paper; the interactions between the grid middleware and the stream of computational queries are modeled using statistical learning. The approach is implemented and validated in the context of the EGEE grid. The GSTRAP system, embedding the STRAP Data Streaming algorithm, provides manageable and understandable views of the computational workload based on gLite reporting services. An online monitoring module shows the instant distribution of the jobs in real-time and its dynamics, enabling anomaly detection. An offline monitoring module provides the administrator with a consolidated view of the workload, enabling the visual inspection of its long-term trends},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A first step toward Autonomic Grids is presented in this paper; the interactions between the grid middleware and the stream of computational queries are modeled using statistical learning. The GSTRAP system, embedding the STRAP Data Streaming algorithm, provides manageable and understandable views of the computational workload based on gLite reporting services. A middleware/software solution to solve autonomic computing, with online and offline monitoring 1,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.217.9987}
}

@Article{Zhang2012,
  Title                    = {Real-time clinical decision support system with data stream mining},
  Author                   = {Zhang, Y.a and Fong, S.a and Fiaidhi, J.b and Mohammed, S.b },
  Journal                  = {Journal of Biomedicine and Biotechnology},
  Year                     = {2012},
  Note                     = {cited By (since 1996)4},
  Volume                   = {2012},

  Abstract                 = {This research aims to describe a new design of data stream mining system that can analyze medical data stream and make real-time prediction. The motivation of the research is due to a growing concern of combining software technology and medical functions for the development of software application that can be used in medical field of chronic disease prognosis and diagnosis, children healthcare, diabetes diagnosis, and so forth. Most of the existing software technologies are case-based data mining systems. They only can analyze finite and structured data set and can only work well in their early years and can hardly meet today's medical requirement. In this paper, we describe a clinical-support-system based data stream mining technology; the design has taken into account all the shortcomings of the existing clinical support systems. Ã‚Â© Copyright 2012 Yang Zhang et al.},
  Affiliation              = {Department of Computer and Information Science, University of Macau, Macau; Department of Computer Science, Lakehead University, Thunder Bay, Canada},
  Art_number               = {580186},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They describe a clinical-support-system based data stream mining technology; the design has taken into account all the shortcomings of the existing clinical support systems. approved under uncertainty. nothing about results 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864928991&partnerID=40&md5=a152b2a0ff27b1413c92a8a4086a61ad}
}

@Article{Zhang2014a,
  Title                    = {{A fast online learning algorithm for distributed mining of BigData}},
  Author                   = {Zhang, Yu and Sow, Daby and Turaga, Deepak and van der Schaar, Mihaela},
  Journal                  = {ACM SIGMETRICS Performance Evaluation Review},
  Year                     = {2014},

  Month                    = apr,
  Number                   = {4},
  Pages                    = {90--93},
  Volume                   = {41},

  Abstract                 = {BigData analytics require that distributed mining of numerous data streams is performed in real-time. Unique challenges associated with designing such distributed mining systems are: online adaptation to incoming data characteristics, online processing of large amounts of heterogeneous data, limited data access and communication capabilities between distributed learners, etc. We propose a general framework for distributed data mining and develop an efficient online learning algorithm based on this. Our framework consists of an ensemble learner and multiple local learners, which can only access different parts of the incoming data. By exploiting the correlations of the learning models among local learners, our proposed learning algorithms can optimize the prediction accuracy while requiring significantly less information exchange and computational complexity than existing state-of-the-art learning solutions.},
  Doi                      = {10.1145/2627534.2627562},
  ISSN                     = {01635999},
  Owner                    = {alex},
  Publisher                = {ACM},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THey propose a general framework for distributed data mining and develop an efficient online learning algorithm based on this. The framework consists of an ensemble learner and multiple local learners. By exploiting the correlations of the learning models among local learners, our proposed learning algorithms can optimize the prediction accuracy while requiring significantly less information exchange and computational complexity than existing state-of-the-art learning solutions. 1,3,4,5,6},
  Timestamp                = {2014.10.17},
  Url                      = {http://dl.acm.org/citation.cfm?id=2627534.2627562}
}

@Conference{Zhang2014,
  Title                    = {A fast online learning algorithm for distributed mining of bigdata},
  Author                   = {Zhang, Y.a and Sow, D.b and Turaga, D.b and Van Der Schaar, M.a},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Number                   = {4},
  Pages                    = {90-93},
  Volume                   = {41},

  Abstract                 = {BigData analytics require that distributed mining of numerous data streams is performed in real-time. Unique challenges associated with designing such distributed mining systems are: online adaptation to incoming data characteristics, online processing of large amounts of heterogeneous data, limited data access and communication capabilities between distributed learners, etc. We propose a general frameworkfor distributed data mining and develop an efficientonline learning algorithm based on this. Our frameworkconsists of an ensemble learner and multiple local learners, which can only access different parts of the incoming data. By exploiting the correlations of the learning models among local learners, our proposed learning algorithms can optimize the prediction accuracy while requiring significantly less information exchange and computational complexity than existing state-of-the-art learning solutions.},
  Affiliation              = {University of California, LOS Angeles, CA, United States; IBM T.J. Watson Research Center, United States},
  Document_type            = {Article},
  Journal                  = {Performance Evaluation Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhang2014a},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84902485162&partnerID=40&md5=a364c5f44b785972e4da5284dd2572c6}
}

@Misc{Zhanga,
  Title                    = {{A Fast Online Learning Algorithm for Distributed Mining of}},

  Author                   = {Zhang, Yu and Sow, Daby and {Van Der Schaar}, Mihaela and Turaga, Deepak},

  __markedentry            = {[Alexander:]},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Zhang2014a},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.389.4158}
}

@Conference{Zhang2009b,
  Title                    = {A fast subspace partition clustering algorithm for high dimensional data streams},
  Author                   = {Zhang, Z. and Wang, H.},
  Year                     = {2009},
  Note                     = {cited By (since 1996)1},
  Pages                    = {491-495},
  Volume                   = {1},

  Abstract                 = {Data stream clustering is an important research problem in data stream mining. However, clustering arbitrary shapes over high dimensional data streams has not been well addressed. In this paper, we propose a fast subspace partition data streams clustering algorithm, which adopts two-phased clustering framework. In the online component, the extension of adjacent unit (E-unit), which has common edge or vertex with dense units, is presented. Moreover, the improved CDTree lattice structure is introduced to store the information of non-empty units, maintain the position relationships among units, and keep the affiliation between dense units (D-units) and E-units. Outdated units which need to be faded are performed by decayed function, so that the corresponding micro-clusters are maintained dynamically. In the offline component, the final clusters are generated according to all the micro-clusters by searching D-units in radius range. Experimental results show that SPDStream has higher clustering quality than CluStream which can not generate clusters of arbitrary shapes. Furthermore, our approach has better scalability with different dimensionality and different partition granularity. Ã‚Â©2009 IEEE.},
  Affiliation              = {College of Information Science and Engineering, Yanshan University, Qinhuangdao City, China},
  Art_number               = {5357796},
  Author_keywords          = {CD-tree lattice structure; Clustering; Data mining; Data streams; Subspace partition},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 2009 IEEE International Conference on Intelligent Computing and Intelligent Systems, ICIS 2009},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {propose a fast subspace partition data streams clustering algorithm, which adopts two-phased clustering framework. improved CDTree lattice structure is introduced to store the information of non-empty units. It used decay function on outdated units. Offline component generates final clusters. Experimental results show that SPDStream has higher clustering quality than CluStream which can not generate clusters of arbitrary shapes Pretty sure I've read this one before somewhere 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77949572517&partnerID=40&md5=6a63faacddcfdf0ed9115ea528b77a0f}
}

@InProceedings{Zhao2013,
  Title                    = {{A Concept Drifting Based Clustering Framework for Data Streams}},
  Author                   = {Zhao, Gansen and Li, Ziliu and Liu, Fujiao and Tang, Yong},
  Booktitle                = {2013 Fourth International Conference on Emerging Intelligent Data and Web Technologies},
  Year                     = {2013},
  Month                    = sep,
  Pages                    = {122--129},
  Publisher                = {IEEE},

  Abstract                 = {It has attracted extensive interests to discover knowledge from data streams generated in real-time. At present, there are some data streams mining frameworks, providing mining solutions for data streams. This paper proposes an on-demand framework (SRAStream) based on the concept drifting detection. SRAStream allows quick clustering with certain accuracy using only limited resource, enabling the real-time mining of very large data stream with acceptable cost. A concept drifting detecting algorithm is proposed, which employs a quick clustering solution to achieve an accurate detection and then perform the related detecting calculation. Experiments have been conducted based on the UCI datasets. The result suggests that the proposed framework does work well and improve the processing speed greatly in data streams clustering.},
  Doi                      = {10.1109/EIDWT.2013.26},
  ISBN                     = {978-1-4799-2141-6},
  Keywords                 = {Accuracy,Algorithm design and analysis,Big Data,Clustering algorithms,Concept Drifting,Context,Data Streams,Data mining,Framework,Monitoring,On-Demand Clustering,Real-time systems,SRAStream,UCI datasets,concept drifting based clustering framework,concept drifting detecting algorithm,data mining,data stream clustering,knowledge discovery,on-demand framework,pattern clustering,real-time very large data stream mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an on-demand framework (SRAStream) based on the concept drifting detection. SRAStream allows quick clustering with certain accuracy using only limited resource, enabling the real-time mining of very large data stream with acceptable cost. A concept drifting detecting algorithm is proposed, which employs a quick clustering solution to achieve an accurate detection. Experiments suggests that the proposed framework does work well and improve the processing speed greatly in data streams clustering. 1,3,4,6},
  Shorttitle               = {Emerging Intelligent Data and Web Technologies (EI},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6631604}
}

@Conference{Zhao2013b,
  Title                    = {A concept drifting based clustering framework for data streams},
  Author                   = {Zhao, G.a and Li, Z.c and Liu, F.a b and Tang, Y.a b},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Pages                    = {122-129},

  Abstract                 = {It has attracted extensive interests to discover knowledge from data streams generated in real-time. At present, there are some data streams mining frameworks, providing mining solutions for data streams. This paper proposes an on-demand framework (SRAStream) based on the concept drifting detection. SRAStream allows quick clustering with certain accuracy using only limited resource, enabling the real-time mining of very large data stream with acceptable cost. A concept drifting detecting algorithm is proposed, which employs a quick clustering solution to achieve an accurate detection and then perform the related detecting calculation. Experiments have been conducted based on the UCI datasets. The result suggests that the proposed framework does work well and improve the processing speed greatly in data streams clustering. Ã‚Â© 2013 IEEE.},
  Affiliation              = {School of Computer Science, South China Normal University, Guangzhou, China; Guangzhou Key Lab on Cloud Security and Assessment, Guangzhou, China; School of Software, Sun Yat-Sen University, Guangzhou, China},
  Art_number               = {6631604},
  Author_keywords          = {Big Data; Concept Drifting; Data Streams; Framework; On-Demand Clustering},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 4th International Conference on Emerging Intelligent Data and Web Technologies, EIDWT 2013},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhao2013},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84889570882&partnerID=40&md5=3c02a4fff3f882085a38f8e1829f8ed9}
}

@Article{Zhao2014a,
  Title                    = {Online transfer learning},
  Author                   = {Zhao, P.a and Hoi, S.C.H.b and Wang, J.c and Li, B.d },
  Journal                  = {Artificial Intelligence},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Pages                    = {76-102},
  Volume                   = {216},

  Abstract                 = {In this paper, we propose a novel machine learning framework called "Online Transfer Learning" (OTL), which aims to attack an online learning task on a target domain by transferring knowledge from some source domain. We do not assume data in the target domain follows the same distribution as that in the source domain, and the motivation of our work is to enhance a supervised online learning task on a target domain by exploiting the existing knowledge that had been learnt from training data in source domains. OTL is in general very challenging since data in both source and target domains not only can be different in their class distributions, but also can be diverse in their feature representations. As a first attempt to this new research problem, we investigate two different settings of OTL: (i) OTL on homogeneous domains of common feature space, and (ii) OTL across heterogeneous domains of different feature spaces. For each setting, we propose effective OTL algorithms to solve online classification tasks, and show some theoretical bounds of the algorithms. In addition, we also apply the OTL technique to attack the challenging online learning tasks with concept-drifting data streams. Finally, we conduct extensive empirical studies on a comprehensive testbed, in which encouraging results validate the efficacy of our techniques. Ã‚Â© 2014 Elsevier B.V.},
  Affiliation              = {Data Analytics Department, Institute for Infocomm Research, ASTAR, Singapore, Singapore; School of Information Systems, Singapore Management University, Singapore, Singapore; Department of Computer Science, University of Chicago, United States; Department of Finance, Economics and Management School, Wuhan University, 430072, China},
  Author_keywords          = {Knowledge transfer; Online learning; Transfer learning},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Propose a new framework called OTL, a supervised online learner. They use it on homogeneous and heterogeneous data, as well as trying to capture concept drift. They report good results},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84904998040&partnerID=40&md5=122a60258182023c6e6c31610407ccb7}
}

@Article{Zhao2013a,
  Title                    = {Outlier detection in cold-chain logistics temperature monitoring},
  Author                   = {Zhao, W.a and Dai, W.b and Zhou, S.a },
  Journal                  = {Elektronika ir Elektrotechnika},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {3},
  Pages                    = {65-68},
  Volume                   = {19},

  Abstract                 = {In the field of cold chain logistics, the key point is the real time control of temperature. Thus the failure of synchronous temperature monitoring is the bottleneck of coldchain temperature monitoring. Targeting at the real-time features of synchronous temperature monitoring, this paper discusses some issues about RFID technology applied to outlier detection. Through comparing differing feasible RFID data mining methods, along with the requirements of the cold chain temperature monitoring, we put forward the improved QOD (quick outlier detection) algorithm by clustering based on data stream. After that, we prove that QOD algorithm's performance can be improved after optimization and compared it with several other related methods in accuracy, memory consumption.},
  Affiliation              = {School of Software, Fudan University, 220, Handan Road, Shanghai, 200433, China; School of Management, Fudan University, 220, Handan Road, Shanghai, 200433, China},
  Author_keywords          = {Radiofrequency identification; Remote monitoring; Temperature sensors},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {Through comparing differing feasible RFID data mining methods, along with the requirements of the cold chain temperature monitoring, they put forward the improved QOD (quick outlier detection) algorithm by clustering based on data stream. After that, we prove that QOD algorithm's performance can be improved after optimization and compared it with several other related methods in accuracy, memory consumption. 1,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84875130514&partnerID=40&md5=092c72c7e445706dcd0ad7fdcc7ebcd4}
}

@Article{Zhi2007,
  Title                    = {A unifying method for outlier and change detection from data streams based on local polynomial fitting},
  Author                   = {Zhi, L.a and Hong, M.a and Yongbing, M.b},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {150-161},
  Volume                   = {4426 LNAI},

  Abstract                 = {Online detection of outliers and change points from a data stream are two very exciting topics in the area of data mining. This paper explores the relationship between these two issues, and presents a unifying method for dealing with both of them. Previous approaches often use parametric techniques and try to give exact results. In contrast, we present a nonparametric method based on local polynomial fitting, and give approximate results by fuzzy partition and decision. In order to measure the possibility of being an outlier and a change point, two novel score functions are defined based on the forward and backward prediction errors. The proposed method can detect outliers and changes simultaneously, and can distinguish between them. Comparing to the conventional parametric approaches, our method is more convenient for implementation, and more appropriate for online and interactive data mining. Simulation results confirm the effectiveness of the proposed method. Ã‚Â© Springer-Verlag Berlin Heidelberg 2007.},
  Affiliation              = {Department of Mathematics, Sichuan University, Chengdu, 610064, China; Southwest China Institute of Electronic Technology, Chendu, 610036, China},
  Author_keywords          = {Change point; Data mining; Data stream; Fuzzy partition; Local polynomial fitting; Outlier},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present a nonparametric method based on local polynomial fitting, and give approximate results by fuzzy partition and decision. The proposed method can detect outliers and changes simultaneously, and can distinguish between them. Experiments show effectiveness, and that their method is more appropriate than the conventional parametric approaches. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38049136673&partnerID=40&md5=11a0ee0e77f36337a5965d02a0f6581c}
}

@Conference{Zhi2007a,
  Title                    = {A unifying method for outlier and change detection from data streams},
  Author                   = {Zhi, L. and Hong, M. and Yongdao, Z.},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Pages                    = {580-585},
  Volume                   = {1},

  Abstract                 = {Detection of outliers and identification of change points in a data stream are two very exciting topics in the area of data mining. This paper explores the relationship between these two issues, and presents a unifying method for dealing with both of them. This approach is based on a probabilistic model of time series whose parameters are updated adaptively. The forward and backward prediction errors over a sliding window are used to represent the deviation extent of an outlier and the change degree of a change point. Unlike former approaches, the present one uses fuzzy partition method and fuzzy decision principle to alarm possible outliers and changes, which is more appropriate for online and interactive data mining from data streams. Simulation results confirm the effectiveness of the proposed method. Ã‚Â© 2006 IEEE.},
  Affiliation              = {Department of Mathematics, Sichuan University, Chengdu, China},
  Art_number               = {4072155},
  Document_type            = {Conference Paper},
  Journal                  = {2006 International Conference on Computational Intelligence and Security, ICCIAS 2006},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhi2007},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38549095494&partnerID=40&md5=9506d6fe4568229ca40616df48aeab7f}
}

@Article{Zhishui2011,
  Title                    = {A kind of data stream clustering algorithm based on grid-density},
  Author                   = {Zhishui, Z.},
  Journal                  = {Communications in Computer and Information Science},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 2},
  Pages                    = {418-423},
  Volume                   = {215 CCIS},

  Abstract                 = {One target on this thesis is to study and realize a kind of data stream clustering algorithm with quick running rate and high clustering accuracy. In order to reach this, we have done some work as follows. Background and relevant work on data stream mining is discussed. Popular traditional clustering algorithms are summarized and the data stream clustering algorithms are researched. On the basis of these, we propose GD-Stream (Grid-Density based Evolving Stream) algorithm, which is a framework based on grid-density. By modifying the synopsis data structure, This algorithm has the following characteristics. Borrowing the framework from CluStream algorithm, GD-Stream is divided into online layer and offline layer, using density-decaying skill Online layer reads data stream rapidly, and stores relative information by synopsis data structure. With this, offline layer provide accurate clustering. The two layers work together to achieve the balance of accuracy and speed.. Ã‚Â© 2011 Springer-Verlag Berlin Heidelberg.},
  Affiliation              = {Department of Mathematics and Computer Science, Tongling University, Tongling, China},
  Author_keywords          = {Clustering; Data Stream; Grid-Density},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {. Popular traditional clustering algorithms are summarized and the data stream clustering algorithms are researched. On the basis of these, we propose GD-Stream (Grid-Density based Evolving Stream) algorithm, which is a framework based on grid-density. Based on CluStream, so it has a online and offline component. 1,2,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052369207&partnerID=40&md5=f7d27b1216a97797b15d42e3269873fa}
}

@Article{Zhong2005a,
  Title                    = {Efficient streaming text clustering},
  Author                   = {Zhong, S.},
  Journal                  = {Neural Networks},
  Year                     = {2005},
  Note                     = {cited By (since 1996)33},
  Number                   = {5-6},
  Pages                    = {790-798},
  Volume                   = {18},

  Abstract                 = {Clustering data streams has been a new research topic, recently emerged from many real data mining applications, and has attracted a lot of research attention. However, there is little work on clustering high-dimensional streaming text data. This paper combines an efficient online spherical k-means (OSKM) algorithm with an existing scalable clustering strategy to achieve fast and adaptive clustering of text streams. The OSKM algorithm modifies the spherical k-means (SPKM) algorithm, using online update (for cluster centroids) based on the well-known Winner-Take-All competitive learning. It has been shown to be as efficient as SPKM, but much superior in clustering quality. The scalable clustering strategy was previously developed to deal with very large databases that cannot fit into a limited memory and that are too expensive to read/scan multiple times. Using the strategy, one keeps only sufficient statistics for history data to retain (part of) the contribution of history data and to accommodate the limited memory. To make the proposed clustering algorithm adaptive to data streams, we introduce a forgetting factor that applies exponential decay to the importance of history data. The older a set of text documents, the less weight they carry. Our experimental results demonstrate the efficiency of the proposed algorithm and reveal an intuitive and an interesting fact for clustering text streams - one needs to forget to be adaptive. Ã‚Â© 2005 Elsevier Ltd. All rights reserved.},
  Affiliation              = {Department of Computer Science and Engineering, Florida Atlantic University, Boca Raton, FL 33431, United States},
  Author_keywords          = {Competitive learning; Spherical k-means; Streaming clustering; Text clustering},
  Document_type            = {Conference Paper},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This paper combines an efficient online spherical k-means (OSKM) algorithm with an existing scalable clustering strategy to achieve fast and adaptive clustering of text streams. The OSKM algorithm modifies the spherical k-means (SPKM) algorithm, using online update (for cluster centroids) based on the well-known Winner-Take-All competitive learning. To adapt to online learning, a decaying factor is introduced. Experimental results show effectiveness. 1,2,3,4,5,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-27744489908&partnerID=40&md5=225c391cea7e909dc9333dc037ce7708}
}

@InProceedings{ZZW2009,
  Title                    = {{A fast subspace partition clustering algorithm for high dimensional data streams}},
  Author                   = {{Zhongping Zhang} and {Hao Wang}},
  Booktitle                = {2009 IEEE International Conference on Intelligent Computing and Intelligent Systems},
  Year                     = {2009},
  Month                    = nov,
  Pages                    = {491--495},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Data stream clustering is an important research problem in data stream mining. However, clustering arbitrary shapes over high dimensional data streams has not been well addressed. In this paper, we propose a fast subspace partition data streams clustering algorithm, which adopts two-phased clustering framework. In the online component, the extension of adjacent unit (E-unit), which has common edge or vertex with dense units, is presented. Moreover, the improved CD-tree lattice structure is introduced to store the information of non-empty units, maintain the position relationships among units, and keep the affiliation between dense units (D-units) and E-units. Outdated units which need to be faded are performed by decayed function, so that the corresponding microclusters are maintained dynamically. In the offline component, the final clusters are generated according to all the micro-clusters by searching D-units in radius range. Experimental results show that SPDStream has higher clustering quality than CluStream which can not generate clusters of arbitrary shapes. Furthermore, our approach has better scalability with different dimensionality and different partition granularity.},
  Doi                      = {10.1109/ICICISYS.2009.5357796},
  ISBN                     = {978-1-4244-4754-1},
  Keywords                 = {CD-Tree lattice structure,CD-tree lattice structure,Cities and towns,Clustering algorithms,Communications technology,D-units,Data engineering,Data mining,E-units,Educational institutions,Information science,Lattices,Partitioning algorithms,Shape,clustering,data mining,data stream clustering,data stream mining,data streams,decayed function,dense units,extension of adjacent unit,fast subspace partition clustering algorithm,high dimensional data streams,microclusters,partition granularity,pattern clustering,subspace partition,tree data structures,two-phased clustering framework},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhang2009b, just with new lead author},
  Shorttitle               = {Intelligent Computing and Intelligent Systems, 200},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5357796}
}

@Article{Zhou2008a,
  Title                    = {Tracking clusters in evolving data streams over sliding windows},
  Author                   = {Zhou, A.a and Cao, F.a b and Qian, W.a and Jin, C.a c },
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2008},
  Note                     = {cited By (since 1996)51},
  Number                   = {2},
  Pages                    = {181-214},
  Volume                   = {15},

  Abstract                 = {Mining data streams poses great challenges due to the limited memory availability and real-time query response requirement. Clustering an evolving data stream is especially interesting because it captures not only the changing distribution of clusters but also the evolving behaviors of individual clusters. In this paper, we present a novel method for tracking the evolution of clusters over sliding windows. In our SWClustering algorithm, we combine the exponential histogram with the temporal cluster features, propose a novel data structure, the Exponential Histogram of Cluster Features (EHCF). The exponential histogram is used to handle the in-cluster evolution, and the temporal cluster features represent the change of the cluster distribution. Our approach has several advantages over existing methods: (1) the quality of the clusters is improved because the EHCF captures the distribution of recent records precisely; (2) compared with previous methods, the mechanism employed to adaptively maintain the in-cluster synopsis can track the cluster evolution better, while consuming much less memory; (3) the EHCF provides a flexible framework for analyzing the cluster evolution and tracking a specific cluster efficiently without interfering with other clusters, thus reducing the consumption of computing resources for data stream clustering. Both the theoretical analysis and extensive experiments show the effectiveness and efficiency of the proposed method. Ã‚Â© Springer-Verlag London Limited 2007.},
  Affiliation              = {Department of Computer Science and Engineering, Fudan University, Shanghai 200433, China; IBM China Research Lab, Beijing 100094, China; Department of Computer Science, East China University of Science and Technology, Shanghai 200237, China},
  Author_keywords          = {Cluster tracking; Data streams; Evolving; Sliding windows},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They present a novel method for tracking the evolution of clusters over sliding windows. In our SWClustering algorithm, we combine the exponential histogram with the temporal cluster features, propose a novel data structure, the Exponential Histogram of Cluster Features (EHCF) . Both the theoretical analysis and extensive experiments show the effectiveness and efficiency of the proposed method. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-43249088014&partnerID=40&md5=80f980dba562a98dfa7a48f233743331}
}

@Misc{Zhou,
  Title                    = {{Online Incremental Feature Learning with Denoising Autoencoders}},

  Author                   = {Zhou, Guanyu and Sohn, Kihyuk and Lee, Honglak},

  __markedentry            = {[Alexander:]},
  Abstract                 = {While determining model complexity is an important problem in machine learning, many feature learning algorithms rely on cross-validation to choose an optimal number of features, which is usually challenging for online learning from a massive stream of data. In this paper, we propose an incremental feature learning algorithm to determine the optimal model complexity for large-scale, online datasets based on the denoising autoencoder. This algorithm is composed of two processes: adding features and merging features. Specifically, it adds new features to minimize the objective function’s residual and merges similar features to obtain a compact feature representation and prevent over-fitting. Our experiments show that the proposed model quickly converges to the optimal number of features in a large-scale online setting. In classification tasks, our model outperforms the (non-incremental) denoising autoencoder, and deep networks constructed from our algorithm perform favorably compared to deep belief networks and stacked denoising autoencoders. Further, the algorithm is effective in recognizing new patterns when the data distribution changes over time in the massive online data stream},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose an incremental feature learning algorithm to determine the optimal model complexity for large-scale, online datasets based on the denoising autoencoder. This algorithm is composed of two processes: adding features and merging features. The algorithm is effective in recognizing new patterns when the data distribution changes over time in the massive online data stream They implemented this algo in deep belief networks as well. 1,2,3,4,6},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.309.8246}
}

@InProceedings{Zhou2010,
  Title                    = {{A More Accurate Space Saving Algorithm for Finding the Frequent Items}},
  Author                   = {Zhou, Jun and Chen, Ming and Xiong, Huan},
  Booktitle                = {2010 2nd International Workshop on Database Technology and Applications},
  Year                     = {2010},
  Month                    = nov,
  Pages                    = {1--5},
  Publisher                = {IEEE},

  Abstract                 = {The frequent items problem is to process a stream as a stream of items and find all items occurring more than a given fraction of the time. It is one of the most heavily studied problems in data stream mining, dating back to the 1980s. Aiming at higher false positive rate of the Space-Saving algorithm, an LRU-based (Least Recently Used, LRU) improved algorithm with low frequency item pre-eliminated is proposed. Accuracy, stability and adaptability of the improved algorithm have been apparently enhanced. Experimental results indicate that the algorithm can not only be used to find the frequent items, and can be used to estimate the frequency of them precisely. The improved algorithm can be used for online processing both high-speed network packet stream and backbone NetFlow stream.},
  Doi                      = {10.1109/DBTA.2010.5659027},
  ISBN                     = {978-1-4244-6975-8},
  Keywords                 = {Accuracy,Algorithm design and analysis,Classification algorithms,Complexity theory,Heuristic algorithms,LRU-based improved algorithm,Monitoring,NetFlow stream,Radiation detectors,computer networks,data mining,data stream mining,frequent items,high-speed network packet stream,space-saving algorithm,stability},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {An LRU-based (Least Recently Used, LRU) improved algorithm with low frequency item pre-eliminated is proposed. Accuracy, stability and adaptability of the improved algorithm have been apparently enhanced. Experimental results indicate that the algorithm can not only be used to find the frequent items, and can be used to estimate the frequency of them precisely. The improved algorithm can be used for online processing both high-speed network packet stream and backbone NetFlow stream. 1,2,3,4,6},
  Shorttitle               = {Database Technology and Applications (DBTA), 2010 },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5659027}
}

@Conference{Zhou2010b,
  Title                    = {A more accurate space saving algorithm for finding the frequent items},
  Author                   = {Zhou, J.a and Chen, M.a and Xiong, H.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The frequent items problem is to process a stream as a stream of items and find all items occurring more than a given fraction of the time. It is one of the most heavily studied problems in data stream mining, dating back to the 1980s. Aiming at higher false positive rate of the Space-Saving algorithm, an LRU-based (Least Recently Used, LRU) improved algorithm with low frequency item pre-eliminated is proposed. Accuracy, stability and adaptability of the improved algorithm have been apparently enhanced. Experimental results indicate that the algorithm can not only be used to find the frequent items, and can be used to estimate the frequency of them precisely. The improved algorithm can be used for online processing both high-speed network packet stream and backbone NetFlow stream. Ã‚Â©2010 IEEE.},
  Affiliation              = {Department of Computer Science, Institute of Command Automation, PLAUST, Nanjing, China; Department of Computer Network, China Electrical System Engineering Research Institute, Beijing, China},
  Art_number               = {5659027},
  Author_keywords          = {Anomaly detection; Component; Data stream; Frequent items; LRU; NetFlow},
  Document_type            = {Conference Paper},
  Journal                  = {2010 2nd International Workshop on Database Technology and Applications, DBTA2010 - Proceedings},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhou2010},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78651309473&partnerID=40&md5=564ee0a7e47ea764d110c12aa6ffb6b2}
}

@Conference{Zhou2008b,
  Title                    = {Efficient online subsequence searching in data streams under dynamic time warping distance},
  Author                   = {Zhou, M.a and Wong, M.H.b },
  Year                     = {2008},
  Note                     = {cited By (since 1996)13},
  Pages                    = {686-695},

  Abstract                 = {Data streams of real numbers are generated naturally in many applications. The technology of online subsequence searching in data streams becomes more and more important for monitoring and mining stream data. Due to its capability of handling temporal distortions in sequences, Dynamic Time Warping (DTW) distance is a widely used similarity measure for time-series pattern matching. Unfortunately, because of the high computational complexity of DTW, no one has proposed efficient methods for online subsequence searching under DTW distance, especially over high speed data streams. In this paper, we observe that some important properties of DTW can be used to eliminate a lot of redundant computations. Based on these properties, an efficient batch filtering method for online subsequence searching in data streams is proposed. The experimental results show that when no global path constraint is used, the proposed method outperforms the best known method up to 25 times in terms of throughput. When global path constraint is considered, the proposed method can still outperform the rival method under most of the settings of the global path constraint, although our method does not exploit any information about the constraint. Ã‚Â© 2008 IEEE.},
  Affiliation              = {Department of Computer Science and Technology, Zhuhai College, Jinan University, Zhuhai, Guangdong, China; Department of Computer Science and Engineering, Chinese University of Hong Kong, Shatin, N.T., Hong Kong},
  Art_number               = {4497477},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They observe that some important properties of DTW ( dynamic time warping) can be used to eliminate a lot of redundant computations. Based on these properties, an efficient batch filtering method for online subsequence searching in data streams is proposed. The experimental results show that when no global path constraint is used, the proposed method outperforms the best known method up to 25 times in terms of throughput. When global path constraint is considered, the proposed method can still outperform the rival method under most of the settings 1,3,4,(5?),6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-52649095871&partnerID=40&md5=6d75daa8beed9dc5f2b6bd9fc708428f}
}

@InProceedings{Zhou2008,
  Title                    = {{Efficient Online Subsequence Searching in Data Streams under Dynamic Time Warping Distance}},
  Author                   = {Zhou, Mi and Wong, Man Hon},
  Booktitle                = {2008 IEEE 24th International Conference on Data Engineering},
  Year                     = {2008},
  Month                    = apr,
  Pages                    = {686--695},
  Publisher                = {IEEE},

  Abstract                 = {Data streams of real numbers are generated naturally in many applications. The technology of online subsequence searching in data streams becomes more and more important for monitoring and mining stream data. Due to its capability of handling temporal distortions in sequences, dynamic time warping (DTW) distance is a widely used similarity measure for time-series pattern matching. Unfortunately, because of the high computational complexity of DTW, no one has proposed efficient methods for online subsequence searching under DTW distance, especially over high speed data streams. In this paper, we observe that some important properties of DTW can be used to eliminate a lot of redundant computations. Based on these properties, an efficient batch filtering method for online subsequence searching in data streams is proposed. The experimental results show that when no global path constraint is used, the proposed method outperforms the best known method up to 25 times in terms of throughput. When global path constraint is considered, the proposed method can still outperform the rival method under most of the settings of the global path constraint, although our method does not exploit any information about the constraint.},
  Doi                      = {10.1109/ICDE.2008.4497477},
  ISBN                     = {978-1-4244-1836-7},
  Keywords                 = {Computer science,Condition monitoring,Data mining,Distortion measurement,Euclidean distance,Filtering,Manufacturing processes,Pattern matching,Plasma measurements,Time measurement,batch filtering method,data mining,data stream mining,data stream monitoring,dynamic time warping distance,filtering theory,online subsequence searching,pattern matching,pattern similarity measure,sequences,temporal distortion handling,time series,time-series pattern matching},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhou2008b},
  Shorttitle               = {Data Engineering, 2008. ICDE 2008. IEEE 24th Inter},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4497477}
}

@InProceedings{Zhou2010a,
  Title                    = {{Parallel Computing Model of Multiple Dimensions Data Streams Canonical Correlation Analysis with GPU}},
  Author                   = {Zhou, Yong and Lu, Xiaowei and Cheng, Chuntian},
  Booktitle                = {2010 2nd International Conference on Information Engineering and Computer Science},
  Year                     = {2010},
  Month                    = dec,
  Pages                    = {1--4},
  Publisher                = {IEEE},

  Abstract                 = {Notice of RetractionAfter careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.With view to satisfying the requirement of real-time under the circumstance of resource-constraints, specific and practical architecture for high-dimensional data streams are proposed, meanwhile, based on CUDA (Compute Unified Device Architecture), canonical correlation analysis between two multiple dimensions data streams using data cube pattern and dimensionality-reduction technique is carried out in this framework. The theoretical analysis and experimental results show that the parallel processing method can online detect correlations between multiple dimension data streams accurately in the synchronous sliding window mode. According to the pure CPU method, this method has significant speed advantage, well meeting the real-time requirements of high-dimensional data streaming and can be applied to the field of data stream mining widely.},
  Doi                      = {10.1109/ICIECS.2010.5677895},
  ISBN                     = {978-1-4244-7939-9},
  ISSN                     = {2156-7379},
  Keywords                 = {Algorithm design and analysis,Analytical models,Computer architecture,Correlation,Covariance matrix,Data models,GPU,Graphics processing unit,canonical correlation analysis,compute unified device architecture,computer graphic equipment,coprocessors,data cube pattern,data mining,data stream mining,dimensionality reduction technique,high dimensional data streaming,multiple dimensions data streams,parallel architectures,parallel computing model,parallel processing method},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {retracted},
  Shorttitle               = {Information Engineering and Computer Science (ICIE},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5677895}
}

@Conference{Zhou2010c,
  Title                    = {RETRACTED ARTICLE: Parallel computing model of multiple dimensions data streams canonical correlation analysis with GPU},
  Author                   = {Zhou, Y.a and Lu, X.a and Cheng, C.b },
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {With view to satisfying the requirement of real-time under the circumstance of resource-constraints, specific and practical architecture for high-dimensional data streams are proposed, meanwhile, based on CUDA(Compute Unified Device Architecture), canonical correlation analysis between two multiple dimensions data streams using data cube pattern and dimensionality-reduction technique is carried out in this framework. The theoretical analysis and experimental results show that the parallel processing method can online detect correlations between multiple dimension data streams accurately in the synchronous sliding window mode. According to the pure CPU method, this method has significant speed advantage, well meeting the real-time requirements of high-dimensional data streaming and can be applied to the field of data stream mining widely. Ã‚Â©2010 IEEE.},
  Affiliation              = {School of Software, University of Technology, Dalian 116620, China; Faculty of Infrastructure Engineering, University of Technology, Dalian 116620, China},
  Art_number               = {5677895},
  Author_keywords          = {Canonical correlation; Compute Unified Device Architecture; Dimensionreduction technique; GPU; High-dimensional data streams},
  Document_type            = {Conference Paper},
  Journal                  = {2nd International Conference on Information Engineering and Computer Science - Proceedings, ICIECS 2010},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79951622529&partnerID=40&md5=fddedb16d37d90ccafc05e49030b92d8}
}

@Article{Zhou2012,
  Title                    = {Parallel computing method of canonical correlation analysis for high-dimensional data streams in irregular streams},
  Author                   = {Zhou, Y.a and Lu, X.-W.a and Cheng, C.-T.b },
  Journal                  = {Ruan Jian Xue Bao/Journal of Software},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Number                   = {5},
  Pages                    = {1053-1072},
  Volume                   = {23},

  Abstract                 = {This paper addresses an approach that uses GPU (graphic processing unit)-based processing architecture model and its parallel algorithm for high-dimensional data streams over the irregular streams in order to satisfy the real-time requirement under the resource-constraints. This six layers model combines the GPU high wide-band property of data processing with analysis data stream in a sliding window. Next, canonical correlation analysis is carried out between two high-dimensional data streams, by a data cube pattern, and a dimensionality-reduction method in this framework based on compute unified device architecture (CUDA). The theoretical analysis and experimental results show that the parallel processing method can detect correlations on high dimension data streams, online, accurately in the synchronous sliding window mode. According to the pure CPU method, this technique has significant speed advantage and conducts the real-time requirement of highdimensional data stream very well. It provides a common strategy for the applied field of data stream mining. Ã‚Â© 2012 ISCAS.},
  Affiliation              = {School of Software, Dalian University of Technology, Dalian 116620, China; School of Hydraulic Engineering, Dalian University of Technology, Dalian 116024, China},
  Author_keywords          = {Canonical correlation; Compute unified device architecture; Dimensionality-reduction technique; Graphic processing unit (GPU); High-dimensional data stream},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {This six layers model combines the GPU high wide-band property of data processing with analysis data stream in a sliding window. Experimental results show that the parallel processing method can detect correlations on high dimension data streams, online, accurately in the synchronous sliding window mode. According (Compared?) to the pure CPU method, this technique has significant speed advantage and conducts the real-time requirement of highdimensional data stream very well A way of implementing GPU parallellity in correlation analysis on data streams. 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84862648061&partnerID=40&md5=53a76614ed4e36375c7156b1ffdb4015}
}

@Article{Zhou2012a,
  Title                    = {An algorithm based on horizontal bit vectors for mining frequent patterns in data streams},
  Author                   = {Zhou, Y.a and Wen, D.b and Li, Y.a and Li, H.c },
  Journal                  = {International Journal of Advancements in Computing Technology},
  Year                     = {2012},
  Note                     = {cited By (since 1996)2},
  Number                   = {5},
  Pages                    = {68-74},
  Volume                   = {4},

  Abstract                 = {Most algorithms for mining frequent patterns in data streams are based on structures like FP-tree, complex mining method makes time and storage space large compared to the bit vector expression. In this paper, an algorithm based on Horizontal Bit vectors for mining Frequent Patterns in data Streams HB-FPS is proposed. HB-FPS is divided into two phases, in online phase, it uses bit vectors to horizontally express all the transactions according to whether an item occurs in them, bit value 1 means occurrence, and bit value 0 means the opposite. In offline phase, HB-FPS starts from the biggest item, first mines all the frequent 2-itemsets that contain the item, and then generates candidate k-itemsets by frequent (k-1)-itemsets to growth mine all the frequent patterns by the item unit group. Experiments show that, HB-FPS has high efficiency and good scalability. Theory analysis also indicates that is has a good space overhead.},
  Affiliation              = {College of Mathematics and Information Technology, Hebei Normal University of Science and Technology, Qinhuangdao, Hebei 066004, China; College of Information Science and Engineering, Yanshan University, Qinhuangdao, Hebei 066004, China; College of LiRen, Yanshan University, Qinhuangdao, Hebei 066004, China},
  Author_keywords          = {Data stream; Frequent pattern; Horizontal bit vector},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {an algorithm based on Horizontal Bit vectors for mining Frequent Patterns in data Streams HB-FPS is proposed. Online and offline phase. Experiments show that, HB-FPS has high efficiency and good scalability. I have a feeling I have read this before 1,2,3,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84859386734&partnerID=40&md5=0006ab3774362c8199c3b01dc431ff0d}
}

@InProceedings{Zhu2011,
  Title                    = {{A Study on the Application of Data Stream Clustering Mining through a Sliding and Damped Window to Intrusion Detection}},
  Author                   = {Zhu, Can-Shi and Dun, Xiao and Zhu, Lin},
  Booktitle                = {2011 Fourth International Conference on Information and Computing},
  Year                     = {2011},
  Month                    = apr,
  Pages                    = {22--26},
  Publisher                = {IEEE},

  Abstract                 = {With an ever-greater increase in network bandwidth, network speed and network traffic, network attack techniques are constantly changing and improving, making it formidable for the traditional network security defense measures to keep pace with this challenge. In this paper, a theoretical analysis is made first of both the traditional intrusion detection and the data stream mining, and then, a research is conducted into a network security defense technique based on the integration of data stream mining and intrusion detection, thereby coming up with an algorithm in the light of data stream clustering mining through a sliding and damped window. And this algorithm is applied to the intrusion detection systems so as to approach the traditional problem of inadequate real-time intrusion detection. Through analysis and simulation, it turns out that the algorithm has a lower requirement for operating environment but a higher clustering quality, thus facilitating good reference to improvement in the performance of intrusion detection.},
  Doi                      = {10.1109/ICIC.2011.30},
  ISBN                     = {978-1-61284-688-0},
  Keywords                 = {Accuracy,Algorithm design and analysis,Approximation algorithms,Clustering algorithms,Data mining,Intrusion detection,Real time systems,clustering mining,damped window,data mining,data stream clustering mining,data streams,intrusion detection,network attack techniques,network bandwidth,network security,network speed,network traffic,security of data,sliding window},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhu2011a},
  Shorttitle               = {Information and Computing (ICIC), 2011 Fourth Inte},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5954494}
}

@Conference{Zhu2011a,
  Title                    = {A study on the application of data stream clustering mining through a sliding and damped window to intrusion detection},
  Author                   = {Zhu, C.-S. and Dun, X. and Zhu, L.},
  Booktitle                = {2011 Fourth International Conference on Information and Computing},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Pages                    = {22-26},

  Abstract                 = {With an ever-greater increase in network bandwidth, network speed and network traffic, network attack techniques are constantly changing and improving, making it formidable for the traditional network security defense measures to keep pace with this challenge. In this paper, a theoretical analysis is made first of both the traditional intrusion detection and the data stream mining, and then, a research is conducted into a network security defense technique based on the integration of data stream mining and intrusion detection, thereby coming up with an algorithm in the light of data stream clustering mining through a sliding and damped window. And this algorithm is applied to the intrusion detection systems so as to approach the traditional problem of inadequate real-time intrusion detection. Through analysis and simulation, it turns out that the algorithm has a lower requirement for operating environment but a higher clustering quality, thus facilitating good reference to improvement in the performance of intrusion detection. Ã‚Â© 2011 IEEE.},
  Affiliation              = {Engineering College, Air Force Engineering University, Xi'an, China},
  Art_number               = {5954494},
  Author_keywords          = {Clustering mining; Data streams; Intrusion detection; Sliding window},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 4th International Conference on Information and Computing, ICIC 2011},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They have studied traditional intrusion detection and the data stream mining, and come up with an algorithm in the light of data stream clustering mining through a sliding and damped window. Through analysis and simulation, it turns out that the algorithm has a lower requirement for operating environment and higher clustering quality (compared to what?). Weak abstract, no comparisons or results described 1,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80051628888&partnerID=40&md5=c72381a8f7579427ef73bb9d87924c3b}
}

@Article{Zhu2014,
  Title                    = {Evolving soft subspace clustering },
  Author                   = {Lin Zhu and Longbing Cao and Jie Yang and Jingsheng Lei},
  Journal                  = {Applied Soft Computing },
  Year                     = {2014},
  Note                     = {Evolving Soft Computing Techniques and Applications },
  Number                   = {0},
  Pages                    = {210 - 228},
  Volume                   = {14, Part B},

  Abstract                 = {Abstract A key challenge to most conventional clustering algorithms in handling many real world problems is that, data points in different clusters are often correlated with different subsets of features. To address this problem, subspace clustering has attracted increasing attention in recent years. In practical data mining applications, data points may arrive in continuous streams with chunks of samples being collected at different time points. In addition, huge amounts of data often cannot be kept in the main memory due to memory restriction. Accordingly, a range of evolving clustering algorithms has been proposed, however, traditional evolving clustering methods cannot be effectively applied to large-scale high dimensional data and data streams. In this study, we extend the online learning strategy and scalable clustering technique to soft subspace clustering to form evolving soft subspace clustering. We propose two online soft subspace clustering algorithms, \{OFWSC\} and OEWSC, and two streaming soft subspace clustering algorithms, SSSC_F and SSSC_E. The proposed evolving soft subspace clustering leverages on the effectiveness of online learning scheme and scalable clustering methods for streaming data by revealing the important local subspace characteristics of high dimensional data. Substantial experimental results on both artificial and real-world datasets demonstrate that our proposed methods are generally effective in evolving clustering and achieve superior performance over existing soft subspace clustering techniques.},
  Doi                      = {http://dx.doi.org/10.1016/j.asoc.2013.03.002},
  ISSN                     = {1568-4946},
  Keywords                 = {Subspace clustering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They extend the online learning strategy and scalable clustering technique to soft subspace clustering to form evolving soft subspace clustering. We propose two online soft subspace clustering algorithms, OFWSC and OEWSC, and two streaming soft subspace clustering algorithms, SSSC_F and SSSC_E. experimental results on both artificial and real-world datasets demonstrate that our proposed methods are generally effective in evolving clustering and achieve superior performance over existing soft subspace clustering techniques. 1,2,3,4,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1568494613000756}
}

@Conference{Zhu2012,
  Title                    = {Research into the network security model blended of data stream mining and intrusion detection system},
  Author                   = {Zhu, L. and Zhu, C.-S.},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},
  Pages                    = {496-499},

  Abstract                 = {In response of the fact that traditional intrusion detection systems are not able to fulfill the requirements for specific network security, such as fast processing speed, stronger defense capability, and higher real-time performance, a model of network security defense is built on the integration of data stream mining and intrusion detection; and, a data stream clustering algorithm is designed for mining in the model. Through analysis and simulation, the model turns out to be higher in detection rate and lower in false-alarming or false negative rate, thus achieving a better result. Ã‚Â© 2012 IEEE.},
  Affiliation              = {Engineering College, Air Force University of Engineering, Xi'an, China},
  Art_number               = {6295122},
  Author_keywords          = {Data Stream Mining; Intrusion Detection; Network Security},
  Document_type            = {Conference Paper},
  Journal                  = {ICCSE 2012 - Proceedings of 2012 7th International Conference on Computer Science and Education},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {a model of network security defense is built on the integration of data stream mining and intrusion detection; and, a data stream clustering algorithm is designed for mining in the model. Through analysis and simulation, the model turns out to be higher in detection rate and lower in false-alarming or false negative rate, thus achieving a better result Short abstract. 4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84868150123&partnerID=40&md5=0a0cc5d12c5a62111a974b9b4a0cd901}
}

@InProceedings{Zhu2007,
  Title                    = {{Granular Computing based Intrusion Detection Model upon Network Monitor Data Streams}},
  Author                   = {Zhu, Xiaodong and Huang, Zhiqiu and Zhang, Junhua and Yang, Shuqun},
  Booktitle                = {2007 2nd International Conference on Pervasive Computing and Applications},
  Year                     = {2007},
  Month                    = jul,
  Pages                    = {414--418},
  Publisher                = {IEEE},

  Abstract                 = {The network intrusion detection system is a reasonable supplement on firewall, it can monitor data stream in network in real-time. Considering the problem of the urgent requirement of intrusion detection techniques upon large unbounded network monitor data streams, we presented a novel granular computing based intrusion detection model, and successfully applied it into the project MAUDS (Multi-agent based Intelligent Intrusion Detection System). lots of experiments indicated that this model can work well for intrusion detection. Based on this model, many algorithms and techniques could be developed. On the other hand, it is also useful to understand the nature of decision rules and association rules mining in network monitor data streams.},
  Doi                      = {10.1109/ICPCA.2007.4365479},
  ISBN                     = {978-1-4244-0970-9},
  Keywords                 = {Association rules,Computer networks,Computerized monitoring,Condition monitoring,Data analysis,Data mining,Educational institutions,Intelligent sensors,Intrusion detection,Transaction databases,association rules mining,data mining,data streams,decision rules,firewall,granular computing,intrusion detection,intrusion detection techniques,multi-agent systems,multiagent based intelligent intrusion detection s,network intrusion detection system,network monitor data streams,security of data,unbounded network monitor data streams},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zhu2007a},
  Shorttitle               = {Pervasive Computing and Applications, 2007. ICPCA },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4365479}
}

@Conference{Zhu2007a,
  Title                    = {Granular computing based intrusion detection model upon network monitor data streams},
  Author                   = {Zhu, X. and Huang, Z. and Zhang, J. and Yang, S.},
  Booktitle                = {2007 2nd International Conference on Pervasive Computing and Applications},
  Year                     = {2007},
  Note                     = {cited By (since 1996)3},
  Pages                    = {414-418},

  Abstract                 = {The network intrusion detection system is a reasonable supplement on firewall, it can monitor data stream in network in real-time. Considering the problem of the urgent requirement of intrusion detection techniques upon large unbounded network monitor data streams, we presented a novel granular computing based intrusion detection model, and successfully applied it into the project MAUDS (Multiagent based Intelligent Intrusion Detection System). Lots of experiments indicated that this model can work well for intrusion detection. Based on this model many algorithms and techniques could be developed On the other hand it is also useful to understand the nature of decision rules and association rules mining in network monitor data streams. Ã‚Â© 2007 IEEE.},
  Affiliation              = {College of Information Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China},
  Art_number               = {4365479},
  Author_keywords          = {Data mining; Data streams; Granular computing; Intrusion detection},
  Document_type            = {Conference Paper},
  Journal                  = {2007 2nd International Conference on Pervasive Computing and Applications, ICPCA'07},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {THey presented a novel granular computing based intrusion detection model, and successfully applied it into the project MAUDS (Multiagent based Intelligent Intrusion Detection System). Lots of experiments indicated that this model can work well for intrusion detection Bad abstract, very weak on details 1,4,6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38649102205&partnerID=40&md5=3dd7b060452b8aef14d035207dc52441}
}

@Article{Zhu2004,
  Title                    = {{Dynamic plan migration for continuous queries over data streams}},
  Author                   = {Zhu, Yali and Rundensteiner, Elke A. and Heineman, George T.},
  Journal                  = {IN ACM SIGMOD},
  Year                     = {2004},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Dynamic plan migration is concerned with the on-the-fly transition from one continuous query plan to a semantically equivalent yet more efficient plan. Migration is important for stream monitoring systems where long-running queries may have to withstand fluctuations in stream workloads and data characteristics. Existing migration methods generally adopt a pause-drain-resume strategy that pauses the processing of new data, purges all old data in the existing plan, until finally the new plan can be plugged into the system. However, these existing strategies do not address the problem of migrating query plans that contain stateful operators, such as joins. We now develop solutions for online plan migration for continuous stateful plans. In particular, in this paper, we propose two alternative strategies, called the moving state strategy and the parallel track strategy, one exploiting reusability and the second employs parallelism to seamlessly migrate between continuous join plans without affecting the results of the query. We develop cost models for both migration strategies to analytically compare them. We embed these migration strategies into the CAPE [7], a prototype system of a stream query engine, and conduct a comparative experimental study to evaluate these two strategies for window-based join plans. Our experimental results illustrate that the two strategies can vary significantly in terms of output rates and intermediate storage spaces given distinct system configurations and stream workloads},
  Owner                    = {Alexander},
  Priority                 = {prio2},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. It's about query-plan migration, which seems database related not ML, though it has implications for stream processing.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.408.566}
}

@Article{Zihayat2014,
  Title                    = {Mining top-k high utility patterns over data streams },
  Author                   = {Morteza Zihayat and Aijun An},
  Journal                  = {Information Sciences },
  Year                     = {2014},
  Note                     = {Processing and Mining Complex Data Streams },
  Number                   = {0},
  Pages                    = {138 - 161},
  Volume                   = {285},

  Abstract                 = {Abstract Online high utility itemset mining over data streams has been studied recently. However, the existing methods are not designed for producing top-k patterns. Since there could be a large number of high utility patterns, finding only top-k patterns is more attractive than producing all the patterns whose utility is above a threshold. A challenge with finding top-k high utility itemsets over data streams is that it is not easy for users to determine a proper minimum utility threshold in order for the method to work efficiently. In this paper, we propose a new method (named T-HUDS) for finding top-k high utility patterns over sliding windows of a data stream. The method is based on a compressed tree structure, called HUDS-tree, that can be used to efficiently find potential top-k high utility itemsets over sliding windows. T-HUDS uses a new utility estimation model to more effectively prune the search space. We also propose several strategies for initializing and dynamically adjusting the minimum utility threshold. We prove that no top-k high utility itemset is missed by the proposed method. Our experimental results on real and synthetic datasets show that our strategies and new utility estimation model work very effectively and that T-HUDS outperforms two state-of-the-art high utility itemset algorithms substantially in terms of execution time and memory storage.},
  Doi                      = {http://dx.doi.org/10.1016/j.ins.2014.01.045},
  ISSN                     = {0020-0255},
  Keywords                 = {High utility pattern mining},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {They propose a new method (named T-HUDS) for finding top-k high utility patterns over sliding windows of a data stream. Results on both real and syntethic data show outperforms two other SotA algorithms in time and memory. Possible primary study. 1,2,3,4,5,6},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0020025514000814}
}

@Misc{Zliobaite,
  Title                    = {{Next challenges for adaptive learning systems}},

  Author                   = {Zliobaite, Indre and Bifet, Albert and Gabrys, Bogdan and Gama, Joao and Musial, Katarzyna and Gaber, Mohamed and Minku, Leandro},

  __markedentry            = {[Alexander:]},
  Abstract                 = {Learning from evolving streaming data has become a ‘hot’ research topic in the last decade and many adaptive learning algorithms have been developed. This research was stimulated by rapidly growing amounts of industrial, transactional, sensor and other business data that arrives in real time and needs to be mined in real time. Under such circumstances, constant manual adjustment of models is inefficient and with increasing amounts of data is becoming infeasible. Nevertheless, adaptive learning models are still rarely employed in business applications in practice. In the light of rapidly growing structurally rich ‘big data’, new generation of parallel computing solutions and cloud computing services as well as recent advances in portable computing devices, this article aims to identify the current key research directions to be taken to bring the adaptive learning closer to application needs. We identify six forthcoming challenges in designing and building adaptive learning (prediction) systems: making adaptive systems scalable, dealing with realistic data, improving usability and trust, integrating expert knowledge, taking into account various application needs, and moving from adaptive algorithms towards adaptive tools. Those challenges are critical for the evolving stream settings, as the process of model building needs to be fully automated and continuous.},
  Owner                    = {Alexander},
  Priority                 = {prio3},
  Qualityassured           = {qualityAssured},
  Review                   = {, this article aims to identify the current key research directions to be taken to bring the adaptive learning closer to application needs. We identify six forthcoming challenges in designing and building adaptive learning (prediction) systems set aside as background source.},
  Timestamp                = {2014.10.22},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.402.4755}
}

@Article{Zliobaite2014,
  Title                    = {{Adaptive Preprocessing for Streaming Data}},
  Author                   = {Zliobaite, Indre and Gabrys, Bogdan},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2014},

  Month                    = feb,
  Number                   = {2},
  Pages                    = {309--321},
  Volume                   = {26},

  Abstract                 = {Many supervised learning approaches that adapt to changes in data distribution over time (e.g., concept drift) have been developed. The majority of them assume that the data comes already preprocessed or that preprocessing is an integral part of a learning algorithm. In real-application tasks, data that comes from, e.g., sensor readings, is typically noisy, contain missing values, redundant features, and a very large part of model development efforts is devoted to data preprocessing. As data is evolving over time, learning models need to be able to adapt to changes automatically. From a practical perspective, automating a predictor makes little sense if preprocessing requires manual adjustment over time. Nevertheless, adaptation of preprocessing has been largely overlooked in research. In this paper, we introduce and address the problem of adaptive preprocessing. We analyze when and under what circumstances it is beneficial to handle adaptivity of preprocessing and adaptivity of the learning model separately. We present three scenarios where handling adaptive preprocessing separately benefits the final prediction accuracy and illustrate them using computational examples. As a result of our analysis, we construct a prototype approach for combining adaptive preprocessing with adaptive predictor online. Our case study with real sensory data from a production process demonstrates that decoupling the adaptivity of preprocessing and the predictor contributes to improving the prediction accuracy. The developed reference framework and our experimental findings are intended to serve as a starting point in systematic research of adaptive preprocessing mechanisms for adaptive learning with evolving data.},
  Doi                      = {10.1109/TKDE.2012.147},
  ISSN                     = {1041-4347},
  Keywords                 = {Adaptation models,Adaptive systems,Concept drift,Data models,Feature extraction,Predictive models,Principal component analysis,Supervised learning,adaptive predictor,adaptive preprocessing,data distribution,data handling,final prediction accuracy,learning (artificial intelligence),learning algorithm,learning model adaptivity,real-application tasks,sensor readings,sensory data,streaming data,supervised learning approaches},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {introduce and address the problem of adaptive preprocessing. We analyze when and under what circumstances it is beneficial to handle adaptivity of preprocessing and adaptivity of the learning model separately. They construct a prototype approach for combining adaptive preprocessing with adaptive predictor online. This looks at the problem that current research assume that the data comes already preprocessed or that preprocessing is an integral part of a learning algorithm. They analyse preprocessing that would be needed in the real world. They say their research should be a starting point for adaptive learning with evolving data. 1,2,5,6},
  Shorttitle               = {Knowledge and Data Engineering, IEEE Transactions },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247432}
}

@InProceedings{ZPLYWHSQ2008,
  Title                    = {{Fast similarity matching on data stream with noise}},
  Author                   = {{Zou Peng} and {Su Liang} and {Jia Yan} and {Han Wei Hong} and {Yang Shu Qiang}},
  Booktitle                = {2008 IEEE 24th International Conference on Data Engineering Workshop},
  Year                     = {2008},
  Month                    = apr,
  Pages                    = {194--199},
  Publisher                = {IEEE},

  Abstract                 = {Data stream has attracted many researchers from various communities (network, database and data mining). There are a variety of techniques for solving the similarity matching in time series datasets. However, subsequence matching over data stream, finding those subsequences which are similar to a query sequence in a progressive and real-time fashion, is a challenging and novel problem due to the high speed, large quantity, potentially unbounded and evolving stream data. In this paper, firstly, we design a bound technique to prune the unnecessary computation as much as possible. Then, a novel algorithm is proposed which can identify all matched subsequences from data stream under the DTW (Dynamic Time Warping) distance in a "single pass". Furthermore, our experiments on synthetic and real data show that the proposed method is at least 3 times faster than the existing algorithm: SPRING, only increasing several extra bytes.},
  Doi                      = {10.1109/ICDEW.2008.4498316},
  ISBN                     = {978-1-4244-2161-9},
  Keywords                 = {Communications technology,Computer science,Data mining,Databases,Hardware,Intrusion detection,Military communication,Monitoring,Sampling methods,Springs,data mining,data stream,database management systems,database system,dynamic time warping,noise,pattern discovery,pattern matching,query processing,query sequence,subsequence similarity matching,time series dataset},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zou2008},
  Shorttitle               = {Data Engineering Workshop, 2008. ICDEW 2008. IEEE },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4498316}
}

@InProceedings{Zou2013,
  Title                    = {{FlexQuery: An online query system for interactive remote visual data exploration at large scale}},
  Author                   = {Zou, Hongbo and Schwan, Karsten and Slawinska, Magdalena and Wolf, Matt and Eisenhauer, Greg and Zheng, Fang and Dayal, Jai and Logan, Jeremy and Liu, Qing and Klasky, Scott and Bode, Tanja and Clark, Michael and Kinsey, Matt},
  Booktitle                = {2013 IEEE International Conference on Cluster Computing (CLUSTER)},
  Year                     = {2013},
  Month                    = sep,
  Pages                    = {1--8},
  Publisher                = {IEEE},

  Abstract                 = {The remote visual exploration of live data generated by scientific simulations is useful for scientific discovery, performance monitoring, and online validation for the simulation results. Online visualization methods are challenged, however, by the continued growth in the volume of simulation output data that has to be transferred from its source - the simulation running on the high end machine - to where it is analyzed, visualized, and displayed. A specific challenge in this context is limits in the communication bandwidth between data source(s) and sinks. Previous work places queries `near' data sources, exploiting their data reduction capabilities, but such work does not address the common scenario in which scientists make multiple different queries on the data being produced. This paper considers the general case in which science users are interested in different (sub)sets of the data produced by a high end simulation. We offer the FlexQuery online data query system that can deploy and execute data queries `along' the I/O and analytics pipelines. FlexQuery carefully extends such analytics pipelines, using online performance monitoring and data location tracking, to realize data queries in ways that minimize additional data movement and offer low latency in data query execution. Using a real-world scientific application - the Maya astrophysics code and its analytics workflow - we demonstrate FlexQuery's ability to dynamically deploy queries for low-latency remote data visualization.},
  Doi                      = {10.1109/CLUSTER.2013.6702635},
  ISBN                     = {978-1-4799-0898-1},
  Keywords                 = {Bandwidth,Contracts,Data models,Data visualization,Engines,FlexQuery system,Maya astrophysics code,Monitoring,Pipelines,analytics workflow,communication bandwidth,data location tracking,data movement,data reduction,data reduction capabilities,data sink,data source,data visualisation,interactive remote visual data exploration,low-latency remote data visualization,online data query system,online performance monitoring,online query,online visualization methods,query processing,remote visualization,scientific discovery,scientific simulations,simulation output data},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {duplicate of Zou2013a},
  Shorttitle               = {Cluster Computing (CLUSTER), 2013 IEEE Internation},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6702635}
}

@Conference{Zou2013a,
  Title                    = {FlexQuery: An online query system for interactive remote visual data exploration at large scale},
  Author                   = {Zou, H.a and Schwan, K.a and Slawinska, M.a and Wolf, M.a b and Eisenhauer, G.a and Zheng, F.a and Dayal, J.a and Logan, J.b and Liu, Q.b and Klasky, S.b and Bode, T.c and Clark, M.c and Kinsey, M.c },
  Booktitle                = {2013 IEEE International Conference on Cluster Computing (CLUSTER)},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The remote visual exploration of live data generated by scientific simulations is useful for scientific discovery, performance monitoring, and online validation for the simulation results. Online visualization methods are challenged, however, by the continued growth in the volume of simulation output data that has to be transferred from its source - the simulation running on the high end machine - to where it is analyzed, visualized, and displayed. A specific challenge in this context is limits in the communication bandwidth between data source(s) and sinks. Previous work places queries 'near' data sources, exploiting their data reduction capabilities, but such work does not address the common scenario in which scientists make multiple different queries on the data being produced. This paper considers the general case in which science users are interested in different (sub)sets of the data produced by a high end simulation. We offer the FlexQuery online data query system that can deploy and execute data queries 'along' the I/O and analytics pipelines. FlexQuery carefully extends such analytics pipelines, using online performance monitoring and data location tracking, to realize data queries in ways that minimize additional data movement and offer low latency in data query execution. Using a real-world scientific application - the Maya astrophysics code and its analytics workflow - we demonstrate FlexQuery's ability to dynamically deploy queries for low-latency remote data visualization. Ã‚Â© 2013 IEEE.},
  Affiliation              = {College of Computing, Georgia Institute of Technology, Atlanta, GA, United States; Scientific Data Group, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Center for Relativistic Astrophysics, Georgia Institute of Technology, Atlanta, GA, United States},
  Art_number               = {6702635},
  Author_keywords          = {data reduction; online query; remote visualization},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - IEEE International Conference on Cluster Computing, ICCC},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {They offer the FlexQuery online data query system that can deploy and execute data queries 'along' the I/O and analytics pipelines. FlexQuery carefully extends such analytics pipelines, using online performance monitoring and data location tracking, to realize data queries in ways that minimize additional data movement and offer low latency in data query execution. For use in scientific research. Approved under uncertainty 1,2},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893540205&partnerID=40&md5=25699f010921162a8f1c301eb1b9d204}
}

@Conference{Zou2008,
  Title                    = {Fast similarity matching on data stream with noise},
  Author                   = {Zou, P. and Su, L. and Jia, Y. and Han, W. and Yang, S.},
  Year                     = {2008},
  Note                     = {cited By (since 1996)3},
  Pages                    = {194-199},

  Abstract                 = {Data stream has attracted many researchers from various communities (network, database and data mining). There are a variety of techniques for solving the similarity matching in time series datasets. However, subsequence matching over data stream, finding those subsequences which are similar to a query sequence in a progressive and real-time fashion, is a challenging and novel problem due to the high speed, large quantity, potentially unbounded and evolving stream data. In this paper, firstly, we design a bound technique to prune the unnecessary computation as much as possible. Then, a novel algorithm is proposed which can identify all matched subsequences from data stream under the DTW (Dynamic Time Warping) distance in a "single pass". Furthermore, our experiments on synthetic and real data show that the proposed method is at least 3 times faster than the existing algorithm: SPRING, only increasing several extra bytes. Ã‚Â© 2008 IEEE.},
  Affiliation              = {School of Computer Science, National University of Defense Technology, Changsha 410073, China},
  Art_number               = {4498316},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Relevance                = {relevant},
  Review                   = {A novel algorithm is proposed which can identify all matched subsequences from data stream under the DTW (Dynamic Time Warping) distance in a "single pass". Furthermore, our experiments on synthetic and real data show that the proposed method is at least 3 times faster than the existing algorithm: SPRING, only increasing several extra bytes. 1,2,3,4,(5?),6},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-50249155454&partnerID=40&md5=ebc38e7c09d84ac9b39fc7a3013cd182}
}

@Conference{2014,
  Title                    = {Proceedings of SPIE-IS and T Electronic Imaging - Visualization and Data Analysis 2014},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Volume                   = {9017},

  Abstract                 = {The proceedings contain 32 papers. The topics discussed include: a framework for analysis of the upper airway from real-time MRI sequences; configurable IP-space maps for large-scale, multi-source network data visual analysis and correlation; linked visual analysis of structured datasets and document collections; a reference web architecture and patterns for real-time visual analytics on large streaming data; visualizing confusion matrices for multidimensional signal detection correlational methods; collaborative data analysis with smart tangible devices; visualization of off-screen data on tablets using context-providing bar graphs and scatter plots; HyFinBall: a two-handed, hybrid 2D/3D desktop VR interface for multi-dimensional visualization; relating interesting quantitative time series patterns with text events and text features; visual abstraction of complex motion patterns; abstract rendering: out-of-core rendering for information visualization; and simulation and visualization of velocity fields in simple electrokinetic devices.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings of SPIE - The International Society for Optical Engineering},
  Owner                    = {Alexander},
  Page_count               = {366},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84894600849&partnerID=40&md5=894dd9f562e7fe3a5061589a5e2bac4c}
}

@Conference{2014a,
  Title                    = {2013 International Conference on Future Computer and Information Technology, ICFCIT 2013},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},
  Volume                   = {86},

  Abstract                 = {The proceedings contain 130 papers. The special focus in this conference is on Computer and Information Technology. The topics include: Research on partition optimization of fuzzy analytical control with a modifying factor; the present situation and development trend of Chinese modern communication systems; the application of genetic algorithms to solve network routing problems; design of wireless communication module in information appliance; study on promoting harmonious relationships between teachers and students; error detection by software signatures based on control flow graph; an empirical study on influencing factors of e-learning behavior in an enterprise knowledge community; path planning for a ground robot with aerial vision; on computational efficiency of the push-and-pull algorithm by arsham et al.; research of the domain-oriented software reuse method in an aerial armament test system; analytical method for the modeling of optical fiber sensors for intensity modulation based on curved reflection; automatic license plate recognition based on complex backgrounds; deformation tracking by multi-resolution gradient descent method; constructions of resolvable incomplete group divisible designs; research on wireless transmission technology of remote image; algorithm research of measure distance on airborne radar; stability analysis of the interaction between malicious and benign worms; virtual learning in health education; research on data clustering algorithms of data mining; a novel ultra wideband low noise amplifier; analysis of an internet worm propagation model with graded infection rates; the real-time computing of the Stirling formula based on hardware acceleration; clustering over uncertain data stream; rural household differentiation and urbanization; satellite orbit prediction based on the deep neural network error model; prediction of total energy consumption in china by the fuzzy grey Markov chain based on quadratic fitting; design of ZnO film sensor; rateless codes erasure correcting with two feedback for cooperative relay; social network relationships mining algorithm based on microblog; spectrum allocation for improving the fairness of cognitive LTE networks; a reusable object-oriented skeleton framework based on TBB; a survey of routing protocol in underwater sensor networks; the analysis of interference from radar to TD-LTE; cloud service recommendation model based on personality preference and trust; visual language ICON and its application in the geographic information system; echo cancellation technology scheme based on an LMS adaptive filter; deep thought in generic programming; application research on the GIS-based telecom net resources management system; visualization method of LOD based on hierarchical voronoi diagrams; an improved analytical method of inverse kinematics of a humanoid robot; design of dynamic role assignment based on Robocop 3D simulation; Interactive image resizing using seam carving and object detection; tacit knowledge and engineering education; an improved multi-ary search based anti-collision algorithm; visibility threshold model based stereo image watermarking with self-recovery; metadata-intensive I/O optimizations in parallel file systems; performance analysis of a QOSTBC scheme with low complexity; a framework for cloud database security; enhancing night time videos using the non-subsampled contourlet transform; the application of renormalized research in a complex network; a hunting search based trust QoS routing algorithm of the future network; center surround feature detection of volumetric data; characterizing the performance of impala over massive data set; spectral segmentation based on the weighted histogram; evaluation of the OTDOA positioning method in the LTE-a system; research on downstep of high-low sequences in Chinese; review on RF positioning technology based on CSS; advanced distributed unscented particle filter for simultaneous localization and mapping; a study on the cooperation motives of mobile operators and financial institutions in the near field communication payment industry; mobile object retrieval using client server architecture; copy-move forgery detection using SURF and a local heuristic search scheme; a new scheme for cooperative spectrum sensing with multiple antennae in cognitive radio networks; a study on factors affecting computer-assisted language learning; motivating students in the introductory programming course; correction of illumination non-uniformity in an optical imaging system; a new method of training neural networks for data driven; a model of virtual instrument software; probability elicitation in extended influence diagram by a bottom-up approach and discussion on computer and network based foreign language teaching.},
  Document_type            = {Conference Review},
  Journal                  = {WIT Transactions on Engineering Sciences},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84897750675&partnerID=40&md5=1195084da6ad127f956e78b4c6d8a518}
}

@Conference{2014b,
  Title                    = {SIGMOD 2014 - Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
  Year                     = {2014},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 164 papers. The topics discussed include: lazy evaluation of transactions in database systems; scalable atomic visibility with ramp transactions; in search of influential event organizers in online social networks; influence maximization: near-optimal time complexity meets practical efficiency; efficient location-aware influence maximization; density-based place clustering in geo-social networks; hypersphere dominance: an optimal approach; efficient algorithms for optimal location queries in road networks; robust set reconciliation; how to stop under-utilization and love multicores; resource-oriented approximation for frequent itemset mining from bursty data streams; on complexity and optimization of expensive queries in complex event processing; and complex event analytics: online aggregation of stream sequence patterns.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  Owner                    = {Alexander},
  Page_count               = {1630},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84904293625&partnerID=40&md5=3eaa4fdabdffb00081270f263eec9b46}
}

@InProceedings{2013,
  Title                    = {{Table of contents}},
  Booktitle                = {2013 8th ChinaGrid Annual Conference},
  Year                     = {2013},
  Month                    = aug,
  Pages                    = {v--vi},
  Publisher                = {IEEE},

  Abstract                 = {The following topics are dealt with: extensible data transmission service; Internet; latency-balanced MPI collective communication optimization; heterogeneous server energy consumption characterization; bidding based cloud resource dynamic allocation method; multiple attribute decision based cloud resource dynamic allocation method; biometric encryption; mobile cloud computing; cloud resource allocation scheme; wind driven optimization; SOA reliability prediction model; hidden Markov model; energy-efficient delay-constrained sensor network routing; public batch auditing protocol; multicloud storage data security; online redundancy mining; enterprise WLAN traffic; multidimensional spatial RkNN query processing; MapReduce multiway joins; large-scale data stream processing system; Hadoop; delay scheduling algorithm; high performance flash card matching; NAND flash latency; PCI-E interface; incremental Web video crawler; digital media cloud data recommendation scientific workflow},
  Doi                      = {10.1109/ChinaGrid.2013.7},
  ISBN                     = {978-0-7695-5058-9},
  Keywords                 = {Hadoop,Internet,MapReduce multiway joins,NAND flash latency,PCI-E interface,SOA reliability prediction model,application program interfaces,bidding based cloud resource dynamic allocation me,biometric encryption,cloud computing,cloud resource allocation scheme,cryptographic protocols,data communication,data mining,data recommendation,delay scheduling algorithm,digital media cloud,energy consumption,energy-efficient delay-constrained sensor network ,enterprise WLAN traffic,extensible data transmission service,flash memories,heterogeneous server energy consumption characteri,hidden Markov model,hidden Markov models,high performance flash card matching,incremental Web video crawler,large-scale data stream processing system,latency-balanced MPI collective communication opti,message passing,mobile cloud computing,mobile computing,multicloud storage data security,multidimensional spatial RkNN query processing,multiple attribute decision based cloud resource d,online redundancy mining,parallel processing,peripheral interfaces,power aware computing,processor scheduling,public batch auditing protocol,query processing,recommender systems,resource allocation,scientific workflow,search engines,service-oriented architecture,storage management,telecommunication traffic,video retrieval,wind driven optimization,wireless LAN},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Table of contents for a book of sorts.},
  Shorttitle               = {ChinaGrid Annual Conference (ChinaGrid), 2013 8th},
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6623854}
}

@Conference{2013a,
  Title                    = {Proceedings of 2nd International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications, BigMine 2013 - Held in Conjunction with SIGKDD 2013 Conference},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 14 papers. The topics discussed include: soft-CsGDT: soft cost-sensitive Gaussian decision tree for cost-sensitive classification of data streams; searching time series with Hadoop in an electric power company; long-memory time series ensembles for concept shift detection; estimating building simulation parameters via Bayesian structure learning; solving combinatorial optimization problems using relaxed linear programming: a high performance computing perspective; CAPRI: a tool for mining complex line patterns in large log data; direct out-of-memory distributed parallel frequent pattern mining; TV predictor: personalized program recommendations to be displayed on SmartTVs; data-driven study of urban infrastructure to enable city-wide ubiquitous computing; pushing constraints into data streams; forecasting building occupancy using sensor network data; maintaining connected components for infinite graph streams; and an architecture for detecting events in real-time using massive heterogeneous data sources.},
  Document_type            = {Conference Review},
  Journal                  = {Proc. of 2nd Int. Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications, BigMine 2013 - Held in Conj. with SIGKDD 2013 Conf.},
  Owner                    = {Alexander},
  Page_count               = {117},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Only a collection of papers},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84897368579&partnerID=40&md5=e99778db56fca3e62e97ed04364f818b}
}

@Conference{2013b,
  Title                    = {Proceedings - 17th IEEE International Enterprise Distributed Object Computing Conference, EDOC 2013},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 28 papers. The topics discussed include: a framework for the systematic comparison and evaluation of compliance monitoring approaches; ensuring consistency among business goals and business process models; extracting data objects and their states from process models; an ontology-based well-founded proposal for modeling resources and capabilities in ArchiMate; formalising natural language specifications using a cognitive linguistics/configuration based approach; checking conformance with reference architectures: a case study; assessing risks and opportunities in enterprise architecture using an extended ADT approach; real-time analytics for legacy data streams in health: monitoring health data quality; modeling and prediction of monetary and non-monetary business values; a metamodeling approach for reasoning on multiple requirements models; and sizing the underlying factorization structure of a class model.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
  Owner                    = {Alexander},
  Page_count               = {290},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84897369414&partnerID=40&md5=d4ca36a0e56eafa0473ea072a0e0e530}
}

@Article{2013c,
  Title                    = {2012 International Conference on Information Technology and Management Innovation, ICITMI 2012},
  Journal                  = {Applied Mechanics and Materials},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Number                   = {PART 1},
  Volume                   = {263-266},

  Abstract                 = {The proceedings contain 679 papers. The special focus in this conference is on Information Technology and Management Innovation. The topics include: Flash sliver prevents laser penetrating organic materials; the design of controller in AVS video decoder chip based on openrisc; a design of charger with intelligent charging and capacity detection; an examination of the traits and genesis of chaohu stone, East China; effect of hardness and position on wear behavior of steel pairs; reconstruction of noisy electromagnetic fields by means of compressive sensing theory; a data pretreatment method about power system load modeling; design of small step frequency conversion module in s band; priors for time series forecasting; properties of the estimators for additive-accelerated hazard ratio model; sampled data representation of nonlinear state delay system; convolutive blind source separation applied to the communication signals; a data capture technique at the application layer; a video quality assessment model based on edge information; fast mining of closed frequent itemsets in data streams; researching skyway design based digital aerial photogrammetric camera; the research of blast furnace blower shaft fault diagnosis beased on wavelet analysis; a radar intelligence simulation method based on data mining techniques; research on signal processing circuits of ring oscillator accelerometer; non negative solutions conditions of nonlinear urban river model; recent research progress on extension data mining methods; research of data tree model in coal mine heterogeneous database integration; the data concurrent operation of multi medial xtension technique; complexity constrained detection of continuous phase modulation based on breadth-first method; estimation of leaf thickness with remote sensing; simulation and analysis of linear multiple user detection based on simulink; defect reconstruction in laminated composites by ultrasonic imaging; design of capacity loss tester of power transformer; directional smoothness constraint based error concealment; experimental platform for feature selection of signal of ball mill; fusing remote sensing images using a statistical model; intelligent aquaculture monitoring system based on fieldbus; study on AC stray current corrosion law of buried steel pipelines; the establishment of a flexible PdM system for industry detection; virtual manipulation of multi-wall carbon nanotubes with atomic force microscope; vehicle attitude control simulation based on soft and hard damping; hamiltonian robust controller design of permanent magnet wind generators; regulator strategies for switched reluctance generators based on direct energy control; study on the acceleration process of water-jet propulsion ship; synchronous control technology research of hydraulic lifting system; attitude coordination control of spacecraft formation; development of non-contact switch controller of roller drive motor; nonlinear robust adaptive control using direct adaptive method; constructing a hierarchy and simulation model to assess digital recorder sensor system; photography measurement sensor application present situation and development trend; the application of wireless sensor network in agriculture information collection; networking based on zigbee technology for wireless physiological signals acquisition; spectrum and spatial invariant based remote sensing image classification; attack wireless sensor network using compromised key redistribution; a novel low-voltage CMOS mixer with differential floating-gate input; research of mobile terminal QOS analysis model based on time and location; momentum factor constant modulus algorithm and theory; research of AODV protocol based on interconnecting MANET and internet; a micro-cluster-based data stream clustering method for P2P traffic classification; an OFDM channel estimation method with radial basis function neural network; on performance of combining methods for three-node relay network; dynamic generalized suffix arrays; modeling and analysis of multilingual information parallel downloads in data grid; requirement analysis of storage management system; research on database design of corn decision support system; research on task-oriented application design; study on metric of generic intertexuality based on user behavior; the framework study of city SEE information inquiry system; schedule optimization of time petri nets based on ant colony systems; semantic service registration and retrieval for smart home; study and optimization of database on android platform; developing an online payment system for campus level examination; exploring the resource nature of online sourcing marketplace; research on bayesian network retrieval model in electronic commerce; research on the mechanism of trust in the open online sourcing marketplace; a new opinion information acquisition system of mop forum; leakage protection system based on zigbee design; a survey on malware containment models in smartphones; research on access control policy for confidential information system; influence of path attacks on security of six-state scheme; research on micro-certificate based security system for internet of things; the security protection and technology analysis of information system; research of smart gird functional safety certification and based on the collaborative industrial design of product development research.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84872483894&partnerID=40&md5=21f22bf6df5b997cbec34618b6740fbd}
}

@Article{2013d,
  Title                    = {Web-Age Information Management - 14th International Conference, WAIM 2013, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Volume                   = {7923 LNCS},

  Abstract                 = {The proceedings contain 85 papers. The topics discussed include: frequent subgraph summarization with error control; improving semi-supervised text classification by using Wikipedia knowledge; time series representation: a random shifting perspective; mining frequent itemsets from sparse data streams in limited memory environments; human dynamics revealed through log analytics in a cloud computing environment; data fusion: resolving conflicts from multiple sources; imputation for categorical attributes with probabilistic reasoning; a new approach to identify influential spreaders in complex networks; presenting XML schema mapping with conjunctive-disjunctive views; an ETL framework for online analytical processing of linked open data; and a framework for analyzing monetary cost of database systems in the cloud.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {829},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880019986&partnerID=40&md5=39970efc29a6d1b2a4d97e0538f4b7b0}
}

@Article{2013e,
  Title                    = {8th International Conference on Dependability and Complex Systems, DepCoS-RELCOMEX 2013},
  Journal                  = {Advances in Intelligent Systems and Computing},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Volume                   = {224},

  Abstract                 = {The proceedings contain 50 papers. The special focus in this conference is on Dependability and Complex Systems. The topics include: Application level execution model for transparent distributed computing; risk assessment aspects in mastering the value function of security measures; reduction of computational cost in mutation testing by sampling mutants; reliability analysis of discrete transportation systems using critical states; a reference model for the selection of open source tools for requirements management; a probabilistic approach to the count-to-infinity problem in distance-vector routing algorithms; a quality estimation of mutation clustering in C# programs; using virtualization technology for fault-tolerant replication in LAN; quantification of simultaneous-AND gates in temporal fault trees; improving of non-interactive zero-knowledge arguments using oblivious transfer; virtual environment for implementation and testing private wide area network solutions; optimization of privacy preserving mechanisms in mining continuous patterns; technical and program aspects on monitoring of highway flows; integral functionals of semi-Markov processes in reliability problems; generating repair rules for database integrity maintenance; optimization algorithm for the preservation of sensor coverage; towards evolution methodology for service-oriented systems; The LVA-index in clustering; the end-to-end rate adaptation application for real-time video monitoring; discrete transportation systems quality performance analysis by critical states detection; freshness constraints in the RT framework; transformational modeling of BPMN business process in SOA context; reliability assessment of supporting satellite system EGNOS; an approach to automated verification of multi-level security system models; a web service-based platform for distributed web applications integration; universal platform for composite data stream processing services management; proposal of cost-effective tenant-based resource allocation model for a SaaS system; automatic load testing of web application in SaaS model; on testing wireless sensor networks; towards precise architectural decision models; K-induction based verification of real-time safety critical systems; dependability aspects of autonomic cooperative computing systems; life cycle cost through reliability and verification of info communication system components for modeling and control of saturated traffic in megalopolis.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84882933162&partnerID=40&md5=92c5c7d1e9b56bbf0abf1571fcdea0bb}
}

@Article{2013g,
  Title                    = {4th International Conference on Information Computing and Applications, ICICA 2013},
  Journal                  = {Communications in Computer and Information Science},
  Year                     = {2013},
  Note                     = {cited By (since 1996)0},
  Volume                   = {391 PART I},

  Abstract                 = {The proceedings contain 63 papers. The special focus in this conference is on Information Computing and Applications. The topics include: Web service resources aggregation based on the customer behavior; adaptive consensus of multi-agents in jointly connected networks; web context analysis based on generic ontology; redundant nodes elimination in wireless sensor networks; determinant of the generalized Lucas RSFMLR circulant matrices in communication; wireless broadband networks in complex mine environment; ultra wideband OFDM channel estimation algorithm based on instantaneous power filtering; smooth-threshold GEE variable selection based on quadratic inference functions with longitudinal data; distributed computing platform for task stream processing; chaos in traffic flow based on LA model; adaptive replica management model for data-intensive application; study of EMC problems with vehicles; automatic scoring of English writing based on joint of lexical and phrasal features; scalable multipoint videoconferencing scheme without MCU; control pass check technology of switches based on expert system; evaluation strategy and translation of environment calculus; topic-centric candidate priors for expert finding models; design and implementation of the food shelf-life monitoring system; theoretical framework of technical kinematics evaluation software; real-time monitoring system for transformer based on GSM; bus-mounted intelligent control system based on GE controller; track algorithm for high speed target based on buffer-diffluence model; an enhancing K-means algorithm based on sorting and partition; B2C trading platform security strategy based on the optimal stopping theory; research on fast loading large scale point cloud data file; cloud computing security in multi-processor virtualization environment; study of cloud computing in cellphone terminal; evolution analysis of online knowledge transfer network; a high-efficient distance spectrum algorithm for turbo codes; granular sketch based uncertain data streams pattern mining; study on economic development based on factor and cluster analysis; gray correlation model of enterprise commercial credit risk assessment; video key frame extraction for semantic retrieval; granular sketch based uncertain time series streams clustering; efficient inference about the partially linear varying coefficient model with random effect for longitudinal data; particular solutions of a class of nonlinear reaction-diffusion equations; Hopf bifurcation of Rayleigh model with delay; route standardization based on polygon triangulation cutting algorithm; strong convergence for finding fixed point of multi-valued mapping and a hand model updating algorithm based on mean shift.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84901797959&partnerID=40&md5=117975154815e3ebe16efd255ca8e953}
}

@Conference{2012,
  Title                    = {Proceedings of 1st Int. Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications, BigMine-12 - Held in Conjunction with SIGKDD Conference},
  Year                     = {2012},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 16 papers. The topics discussed include: CluChunk: clustering large scale user-generated content incorporating chunklet information; parallel rough set based knowledge acquisition using mapreduce from big data; delta-SimRank computing on MapReduce; incrementally optimized decision tree for noisy big data; a density-based clustering structure mining algorithm for data streams; subscriber classification within telecom networks utilizing big data technologies and machine learning; accelerating minor allele frequency computation with graphics processors; online feature selection for mining big data; accelerating bayesian network parameter learning using hadoop and MapReduce; stream-dashboard: a framework for mining, tracking and validating clusters in a data stream; and a kernel fused perceptron for the online classification of large-scale data.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Owner                    = {Alexander},
  Page_count               = {132},
  Qualityassured           = {qualityAssured},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84866602153&partnerID=40&md5=eefb80c79a6c4577a379e361d5693c6e}
}

@InProceedings{2011,
  Title                    = {{[Front and back cover]}},
  Booktitle                = {The Fourth International Workshop on Advanced Computational Intelligence},
  Year                     = {2011},
  Month                    = oct,
  Pages                    = {c1--c4},
  Publisher                = {IEEE},

  Abstract                 = {The following topics are dealt with: advanced computational intelligence; rough set; genetic algorithm; distributed computing; flexible job-shop scheduling; system-of-systems vulnerability analysis; V-BLAST sphere decoding; spanning tree problem; object representation model; real time path planning; ant colony optimization; multi-objective evolutionary algorithm; RBF neural network; particle swarm optimization; multi-color extraction method; adaptive NN tracking control; gravitational chaotic search algorithm; approximate optimal control tracking; multi-target tracking approach; generalize disjunctive paraconsistent data model; discriminative item mining; weighted passive nearest neighbor algorithm; structure-encoding differential evolution algorithm; real-time data stream clustering; event-driven control program automatic verification; threshold signature scheme; data model driven architecture; improved post-nonlinear independent component analysis; pruning algorithm; remote sensing image classification; fuzzy matrices; grey-box neural network; training ANFIS system; delay BAM neural network stability; tuning method; ensemble learning balancing; Kalman filtering; hybrid learning model; multi-focus image fusion; object-based image retrieval; language grounding model; decision fusion; functional network analysis; image interpolation; image deblurring method; discrete-time dynamic system stability; feature selection methods; Lasso logistic regression; vehicle scheduling; cooperative air-defense system; bifurcation analysis; close-loop time-delayed filter system; Newton iteration formula; 3D object recognition; parameter identification; intelligent displacement back-analysis method; single machine total weighted tardiness scheduling problem; dimensionality reduction method; temporal Bayesian network; online leasing problem; network supported intelligent cooperative diagnosis; Hopf bifurcation analysis; multi-mode human-machine interface; GA-fuzzy automatic generation - ontroller; tele-operation robot system; hybrid clonal selection algorithm; modified LEACH protocol; fuzzy Lyapunov synthesis; and underwater vehicle.},
  Doi                      = {10.1109/IWACI.2011.6159663},
  ISBN                     = {978-1-61284-375-9},
  Keywords                 = {3D object recognition,GA-fuzzy automatic generation controller,Hopf bifurcation analysis,Kalman filtering,Kalman filters,Lasso logistic regression,Lyapunov methods,Newton iteration formula,Newton method,RBF neural network,V-BLAST sphere decoding,adaptive NN tracking control,adaptive control,advanced computational intelligence,ant colony optimisation,ant colony optimization,approximate optimal control tracking,bifurcation,bifurcation analysis,close-loop time-delayed filter system,data mining,data model driven architecture,data models,decision fusion,delay BAM neural network stability,digital signatures,dimensionality reduction method,discrete-time dynamic system stability,discriminative item mining,distributed computing,ensemble learning balancing,event-driven control program automatic verificatio,feature selection methods,flexible job-shop scheduling,functional network analysis,fuzzy Lyapunov synthesis,fuzzy matrices,fuzzy reasoning,fuzzy set theory,generalize disjunctive paraconsistent data model,genetic algorithm,genetic algorithms,gravitational chaotic search algorithm,grey-box neural network,hybrid clonal selection algorithm,hybrid learning model,image classification,image colour analysis,image deblurring method,image fusion,image interpolation,image restoration,image retrieval,improved post-nonlinear independent component anal,independent component analysis,intelligent displacement back-analysis method,interpolation,job shop scheduling,landslide monitoring system,language grounding model,modified LEACH protocol,multicolor extraction method,multifocus image fusion,multimode human-machine interface,multiobjective evolutionary algorithm,multitarget tracking approach,network supported intelligent cooperative diagnosi,neurocontrollers,nonlinear control systems,object representation model,object-based image retrieval,online leasing problem,optimal control,parameter identification,particle swarm optimisation,particle swarm optimization,pattern clustering,program verification,protocols,pruning algorithm,radial basis function networks,real time path planning,real-time data stream clustering,regression analysis,remote sensing,remote sensing image classification,rough set,rough set theory,search problems,single machine scheduling,single machine total weighted tardiness scheduling,software architecture,spanning tree problem,stability,structure-encoding differential evolution algorith,system-of-systems vulnerability analysis,teleoperation robot system,temporal Bayesian network,threshold signature scheme,training ANFIS system,tuning method,underwater vehicle,vehicle scheduling,weighted passive nearest neighbor algorithm},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Cover for book that contains many topics.},
  Shorttitle               = {Advanced Computational Intelligence (IWACI), 2011 },
  Timestamp                = {2014.10.15},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6159663}
}

@Conference{2011a,
  Title                    = {Proceedings - 2011 12th IEEE International Conference on Mobile Data Management Workshops and Seminars, MDM 2011},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Volume                   = {2},

  Abstract                 = {The proceedings contain 74 papers. The topics discussed include: MD-HBase: a scalable multi-dimensional data infrastructure for location aware services; DiSCO: a distributed semantic cache overlay for location-based services; efficient online algorithms for the polygonal approximation of trajectory data; disclosure-free GPS trace search in smartphone networks; optimizing sensor data acquisition for energy-efficient smartphone-based continuous event processing; optimizing the energy consumption of continuous query processing with mobile clients; context-aware user's interests for personalizing mobile search; data types and operations for spatio-temporal data streams; enhancement of semantic business processes with information profiles: application of mobile context information; mobility prediction based on machine learning; towards a safe realization of privacy-preserving data publishing mechanisms; and using continua health alliance standards - implementation and experiences of IEEE 11073.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings - IEEE International Conference on Mobile Data Management},
  Owner                    = {Alexander},
  Page_count               = {464},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-82055176148&partnerID=40&md5=0c3690ac70b8eef0054a128f26b54515}
}

@Article{2011b,
  Title                    = {Data and Applications Security and Privacy XXV - 25th Annual IFIP WG 11.3 Conference, DBSec 2011, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Volume                   = {6818 LNCS},

  Abstract                 = {The proceedings contain 26 papers. The topics discussed include: information flow containment: a practical basis for malware defense; re-designing the web's access control system; integrated management of security policies; cooperative data access in multi-cloud environments; multiparty authorization framework for data sharing in online social networks; public-key encrypted bloom filters with applications to supply chain integrity; an optimization model for the extended role mining problem; dynamics in delegation and revocation schemes: a logical approach; history-dependent inference control of queries by dynamic policy adoption; multilevel secure data stream processing; query processing in private data outsourcing using anonymization; private database search with sublinear query time; efficient distributed linear programming with limited disclosure; and privacy-preserving data mining: a game-theoretic approach.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {309},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79960210009&partnerID=40&md5=7d846c910bf46c6a56cb54cec590599c}
}

@Conference{2011c,
  Title                    = {Proceedings - 2010 Brazilian Symposium on Games and Digital Entertainment, SBGames 2010},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 26 papers. The topics discussed include: A decision-making process for digital storytelling; a method for generating emergent behaviors using machine learning to strategy games; a model for real time ocean breaking waves animation; a robotic system for rehabilitation of distal radius fracture using games; a simple architecture for digital games on demand using low performance resources under a cloud computing paradigm; a soft real-time concurrent graphics platform; a software process simulator machine for software engineering simulation games; an architecture with automatic load balancing and distribution for digital games; an artificial intelligence system to help the player of real-time strategy games; an educational robotic game for transit education based on the Lego mindstorms NXT platform; and data stream mining algorithms for building decision models in a computer role-playing game simulation.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings - 2010 Brazilian Symposium on Games and Digital Entertainment, SBGames 2010},
  Owner                    = {Alexander},
  Page_count               = {251},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79960265194&partnerID=40&md5=d4b39a457f27de7e08067ada10a05591}
}

@Article{2011d,
  Title                    = {Modeling Decisions for Artificial Intelligence - 8th International Conference, MDAI 2011, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Volume                   = {6820 LNAI},

  Abstract                 = {The proceedings contain 22 papers. The topics discussed include: online social honeynets: trapping web crawlers in OSN; cost-sensitive learning; evolving graph structures for drug discovery; fuzzy measures and comonotonicity on multisets; a parallel fusion method for heterogeneous multi-sensor transportation data; a dynamic value-at-risk portfolio model; modeling heterogeneity among experts in multi-criteria group decision making problems; fast mining of non-derivable episode rules in complex sequences; hybridizing data stream mining and technical indicators in automated trading systems; semi-supervised dimensionality reduction via harmonic functions; semi-supervised agglomerative hierarchical clustering with ward method using clusterwise tolerance; agglomerative clustering using asymmetric similarities; on hard c-means using quadratic penalty-vector regularization for uncertain data; and fuzzy-possibilistic product partition: a novel robust approach to c-means clustering.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {268},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79961156814&partnerID=40&md5=390ccc11451f9ee95cfcea8cb010860b}
}

@Article{2011e,
  Title                    = {Analysis of Social Media and Ubiquitous Data - International Workshops, MUSE 2010, Revised Selected Papers},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Volume                   = {6904 LNAI},

  Abstract                 = {The proceedings contain 8 papers. The topics discussed include: logging user activities and sensor data on mobile devices; intentional modeling of social media design knowledge for government-citizen communication; grooming analysis modeling the social interactions of online discussion groups; exploring gender differences in member profiles of an online dating site across 35 countries; community assessment using evidence networks; towards adjusting mobile devices to user's behaviour; bayesian networks to predict data mining algorithm behavior in ubiquitous computing environments; and online and offline trend cluster discovery in spatially distributed data streams.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {164},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, just proceedings.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052812880&partnerID=40&md5=e577cdcd6a043f5e33ed6078bddfc0ad}
}

@Article{2011f,
  Title                    = {Adaptive and Intelligent Systems - Second International Conference, ICAIS 2011, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Volume                   = {6943 LNAI},

  Abstract                 = {The proceedings contain 37 papers. The topics discussed include: the game-theoretic approach to machine learning and adaptation; exploration and exploitation in online learning; towards online adaptive ambient intelligent environments for multiple occupants; the evolution of evolutionary computation; incremental semi-automatic correction of misclassified spatial objects; on-line human recognition from video surveillance using incremental SVM on texture and color features; an improved adaptive PID controller based on online LSSVR with multi RBF kernel tuning; an extended sliding mode learning algorithm for type-2 fuzzy neural networks; time stamping in the presence of latency and drift; artificial recurrence for classification of streaming data with concept shift; new drift detection method for data streams; and learning curve in concept drift while using active learning paradigm.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {426},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Set of conference proceedings.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053311612&partnerID=40&md5=705508c63e75b1d3e950e24e28834ee9}
}

@Article{2011g,
  Title                    = {Discovery Science - 14th International Conference, DS 2011, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Volume                   = {6926 LNAI},

  Abstract                 = {The proceedings contain 27 papers. The topics discussed include: on the expressive power of deep architectures; learning from label preferences; information distance and its extensions; models for autonomously motivated exploration in reinforcement learning; optimal estimation; monotone instance ranking with MIRA; MOA-TweetReader : real-time analysis in twitter streaming data; application of semantic kernels to literature-based gene function annotation; MEI: mutual enhanced infinite generative model for simultaneous community and topic detection; a methodology for mining document-enriched heterogeneous information networks; multiple hypothesis testing in pattern discovery; a parameter-free method for discovering generalized clusters in a network; detecting anti-majority opinionists using value-weighted mixture voter model; and using ontologies in semantic data mining with SEGS and g-SEGS.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {379},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053942129&partnerID=40&md5=ac0eb9dbb03317b0dbcc81335bd22ce3}
}

@Article{2011h,
  Title                    = {Advances in Intelligent Data Analysis X - 10th International Symposium, IDA 2011, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Volume                   = {7014 LNCS},

  Abstract                 = {The proceedings contain 36 papers. The topics discussed include: comparative analysis of power consumption in university buildings using envSOM; context-aware collaborative data stream mining in ubiquitous devices; intra-firm information flow: a content-structure perspective; mining fault-tolerant item sets using subset size occurrence distributions; towards automatic pathway generation from biological full-text publications; online writing data representation: a graph theory approach; the dynamic stage Bayesian network: identifying and modelling key stages in a temporal process; robustness of change detection algorithms; prototype-based classification of dissimilarity data; identification of nuclear magnetic resonance signals via Gaussian mixture decomposition; graphical feature selection for multilabel classification tasks; data quality through model checking techniques; and binding statistical and machine learning models for short-term forecasting of global solar radiation.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {423},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded due to being proceedings},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80455129891&partnerID=40&md5=b97dd00d07b6a7f813db6c5a149d72c3}
}

@Conference{2011i,
  Title                    = {2011 7th International Conference on Emerging Technologies, ICET 2011},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 51 papers. The topics discussed include: a blind adaptive channel shortening algorithm using any lag auto correlation minimization (ALAM); a burst resolution technique for data streams management in the real-time data warehouse; a framework based on OWL-S for healthcare information provision; a virtual telehealth framework: applications and technical considerations; activity-based correlation of personal documents and their visualization using association rule mining; an algorithmic transformation for FPGA implementation of high throughput filters; scattering parameter measurements of infinite tunable reflectarrays; signal analysis, design methodology, and modular development of a TR module for phased array radars; switched mode transmitter architecture using low pass delta sigma modulator; and threat modeling using formal methods: a new approach to develop secure web applications.},
  Document_type            = {Conference Review},
  Journal                  = {2011 7th International Conference on Emerging Technologies, ICET 2011},
  Owner                    = {Alexander},
  Page_count               = {275},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80755159460&partnerID=40&md5=5bb001a7b673b51cb5e2b0d0d3a0512a}
}

@Conference{2011j,
  Title                    = {Proceedings - 2011 12th IEEE International Conference on Mobile Data Management, MDM 2011},
  Year                     = {2011},
  Note                     = {cited By (since 1996)0},
  Volume                   = {1},

  Abstract                 = {The proceedings contain 74 papers. The topics discussed include: MD-HBase: a scalable multi-dimensional data infrastructure for location aware services; DiSCO: a distributed semantic cache overlay for location-based services; efficient online algorithms for the polygonal approximation of trajectory data; disclosure-free GPS trace search in smartphone networks; optimizing sensor data acquisition for energy-efficient smartphone-based continuous event processing; optimizing the energy consumption of continuous query processing with mobile clients; context-aware user's interests for personalizing mobile search; data types and operations for spatio-temporal data streams; enhancement of semantic business processes with information profiles: application of mobile context information; mobility prediction based on machine learning; towards a safe realization of privacy-preserving data publishing mechanisms; and using continua health alliance standards - implementation and experiences of IEEE 11073.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings - IEEE International Conference on Mobile Data Management},
  Owner                    = {Alexander},
  Page_count               = {464},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-82055172276&partnerID=40&md5=360c4562f472612ea9929328ccb49130}
}

@Conference{2010,
  Title                    = {MobiDE 2010 - Proceedings of the 9th ACM International Workshop on Data Engineering for Wireless and Mobile Access, in Conjunction with ACM SIGMOD / PODS 2010},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 11 papers. The topics discussed include: composition challenges in large-scale cyber-physical systems; an online framework for publishing privacy-sensitive location traces; using data mining to handle missing data in multi-hop sensor network applications; an algebric window model for data stream management; random hyperplane projection using derived dimensions; minimum-hot-spot query trees for wireless sensor networks; SMS based group communication system for mobile devices; an efficient structured P2P overlay over MANET; a cooperative spatial-aware cache for mobile environments; direction-based spatial skylines; and transactional support of ad-hoc collaborations in mobile environments.},
  Document_type            = {Conference Review},
  Journal                  = {MobiDE 2010 - Proceedings of the 9th ACM International Workshop on Data Engineering for Wireless and Mobile Access, in Conjunction with ACM SIGMOD / PODS 2010},
  Owner                    = {Alexander},
  Page_count               = {96},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77958049111&partnerID=40&md5=349902322d4a5c83998317c86dfd6e88}
}

@Article{2010a,
  Title                    = {International Conference on Information and Communication Technologies, ICT 2010},
  Journal                  = {Communications in Computer and Information Science},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},
  Volume                   = {101},

  Abstract                 = {The proceedings contain 123 papers. The special focus in this conference is on Information and Communication Technologies. The topics include: Design and modeling of power efficient, high performance 32-bit ALU through advanced HDL synthesis; a new multi-language encryption technique for MANET; protecting digital images using DTCWT-DCT; VLSI design of four quadrant analog voltage-mode multiplier and its application; an optimizing technique for MDGT using DRSA algorithm association with IP traceback strategies; learning classifier systems approach for automated discovery of hierarchical censored production rules; feature based watermarking algorithm by adopting Arnold transform; inference of gene networks from microarray data through a phenomic approach; design and analysis of specification based Ids for wireless networks using soft computing; enhanced substitution-diffusion based image cipher using improved chaotic map; network forensic analysis by correlation of attacks with network attributes; robust and real time data delivery in wireless sensor networks; multiple QoS guided heuristic for independent task scheduling in grid; a framework for network forensic analysis; a new trust model based on time series prediction and Markov model; nearest neighbour classification for trajectory data; security-aware efficient route discovery for DSR in MANET; congestion games in wireless channels with multipacket reception capability; high speed cache design using multi-diameter CNFET at 32nm technology; instance-based classification of streaming data using emerging patterns; three layered adaptation model for context aware E-learning; problem area identification with secure data aggregation in wireless sensor networks; graceful degradation in performance of wavescalar architecture; dual tree complex wavelet transform based video object tracking; identifying the attack source by IP traceback; an approach towards secure and multihop time synchronization in wireless sensor network; application of kohonan SOM in prediction; a reinforcement learning approach for price offer in supplier selection process; wavelet and hadamard transforms for image retrieval using color models; a hybridized graph mining approach; virtual nodes for self stabilization in wireless sensor networks; small square microstrip antenna; extraction of optimal biclusters from gene expression data; analysis of data warehouse quality metrics using LR; cluster-base directional rumor routing in wireless sensor network; pre-confirmation neural network for reducing the region of interest in an image for face detection; performance of clustering in mobile domain; morphological analyzer for Telugu using support vector machine; visualization of state transition systems in a parallel environment; a QOS framework for mobile ad-hoc in large scale networks; performance modeling of MANET routing protocols with multiple mode wormhole attacks; microcontroller based monitoring and control of greenhouse enivironment; an approximate algorithm for solving dynamic facility layout problem; tied mixture modeling in Hindi speech recognition system; extraction of pose invariant facial features; context representation and management in a pervasive environment; color image restoration method for Gaussian noise removal; realisation of various EBG structures; combined off-line signature verification using neural networks; digital image steganography based on combination of DCT and DWT; neural networks based detection of purpose data in text; a low cost GPS based vehicle collision avoidance system; human skin region identification using fusion technique; secret sharing scheme for image encryption using new transformation matrix; measuring the reusability level of software packages using reusability testing scripts; recent trends in superscalar architecture to exploit more instruction level parallelism; a neural network based solution to color image restoration problem; spline biorthogonal wavelet design; securing password file using Bezier CurvesL; moving object tracking using object segmentation and mobile health care system for patient monitoring.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880711296&partnerID=40&md5=19c3ae182d500e9718691d9129452d8f}
}

@Conference{2010b,
  Title                    = {APPLIED COMPUTING 2010 - The 25th Annual ACM Symposium on Applied Computing},
  Year                     = {2010},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 449 papers. The topics discussed include: text versus non-text distinction in online handwritten documents; enhancing document structure analysis using visual analytics; an automatic linking service of document images reducing the effects of OCR errors with latent semantics; standardized interoperable image retrieval; RecoMap: an interactive and adaptive map-based recommender; convex onion peeling genetic algorithm: an efficient solution to map labeling of point-feature; modeling cardinal directions in the 3D space with the objects interaction cube matrix; a wavelet-based sampling algorithm for wireless sensor networks applications; data stream anomaly detection through principal subspace tracking; a fast approximation strategy for summarizing a set of streaming time series; and online mining of temporal maximal utility itemsets from data streams.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings of the ACM Symposium on Applied Computing},
  Owner                    = {Alexander},
  Page_count               = {2253},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77954795721&partnerID=40&md5=be4e4b587ab62dcdb7f06bfa75273ad4}
}

@Conference{2009,
  Title                    = {Proceedings of the 3rd International Workshop on Knowledge Discovery from Sensor Data, SensorKDD'09 in Conjunction with the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD-09},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 16 papers. The topics discussed include: a data modeling approach to climate change attribution; space missions and sensor networking: challenging scenarios; how optimized environmental sensing helps address information overload on the web; handling outliers and concept drift in online mass flow prediction in CFB boilers; an exploration of climate data using complex networks; a comparison of SNOTEL and AMSR-E snow water equivalent datasets in western U.S. watersheds; EDISKCO: energy efficient distributed in-sensor-network k-center clustering with outliers; phenological event detection from multitemporal image data; mining in a mobile environment; on the identification of intra-seasonal changes in the Indian summer monsoon; reduction of ground-based sensor sites for spatio-temporal analysis of aerosols; OcVFDT: one-class very fast decision tree for one-class classification of data streams; and a frequent pattern based framework for event detection in sensor network stream data.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings of the 3rd International Workshop on Knowledge Discovery from Sensor Data, SensorKDD'09 in Conjunction with the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD-09},
  Owner                    = {Alexander},
  Page_count               = {150},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70450165277&partnerID=40&md5=1ad3c8c053e3e015e1989ff133a49077}
}

@Conference{2009a,
  Title                    = {Pattern Recognition in Information Systems - Proceedings of the 9th International Workshop on Pattern Recognition in Information Systems - PRIS 2009 In Conjunction with ICEIS 2009},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 9 papers. The topics discussed include: machine learning in online advertising; from cliques to equilibria - the dominant-set framework for pairwise data clustering; estimating the number of segments of a turn in dialogue systems; on the automatic classification of reading disorders; RefLink: an interface that enables people with motion impairments to analyze web content and dynamically link to references; clustering and density estimation for streaming data using volume prototypes; combining data clusterings with instance level constraints; PCA supervised and unsupervised classifiers in signal processing; semi-supervised least-squares support vector classifier based on virtual leave one out residuals; recognition-based segmentation of Arabic handwriting; and automatic analysis of historical manuscripts.},
  Document_type            = {Conference Review},
  Journal                  = {Pattern Recognition in Information Systems - Proceedings of the 9th International Workshop on Pattern Recognition in Information Systems - PRIS 2009 In Conjunction with ICEIS 2009},
  Owner                    = {Alexander},
  Page_count               = {116},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-74749086266&partnerID=40&md5=7bd1d331631f4b667055162ce4d1d840}
}

@Article{2009b,
  Title                    = {Knowledge acquisition: Approaches, algorithms and applications - Pacific rim knowledge acquisition workshop, PKAW 2008, revised selected papers},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Volume                   = {5465 LNAI},

  Abstract                 = {The proceedings contain 20 papers. The topics discussed include: experiments with adaptive transfer rate in reinforcement learning; clustering over evolving data streams based on online recent-biased approximation; automatic database creation and object's model learning; finding the most interesting association rules by aggregating objective interestingness measures; pruning strategies based on the upper bound of information gain for discriminative subgraph mining; a novel classification algorithm based on association rules mining; multiple classification ripple round rules: a preliminary study; generalising symbolic knowledge in online classification and prediction; using formal concept analysis towards cooperative e-learning; navigation and annotation with formal concept analysis; web mining for Malaysia's political social networks using artificial immune system; and accessing touristic knowledge bases through a natural language interface.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {251},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-67650257629&partnerID=40&md5=1185a75e5aba5407bf02ae5c909065c7}
}

@Article{2009c,
  Title                    = {Advances in Machine Learning - First Asian Conference on Machine Learning, ACML 2009, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Volume                   = {5828 LNAI},

  Abstract                 = {The proceedings contain 29 papers. The topics discussed include: machine learning and ecosystem informatics: challenges and opportunities; density ratio estimation: a new versatile tool for machine learning; transfer learning beyond text classification; improving adaptive bagging methods for evolving data streams; a hierarchical face recognition algorithm; conditional density estimation with class probability estimators; linear time model selection for mixture of heterogeneous components; max-margin multiple-instance learning via semidefinite programming; a reformulation of support vector machines for general confidence functions; robust discriminant analysis based on nonparametric maximum entropy; context-aware online commercial intention detection; feature selection via maximizing neighborhood soft margin; accurate probabilistic error bound for eigenvalues of kernel matrix; and community detection on weighted networks: a variational Bayesian method.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {424},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70649112224&partnerID=40&md5=ae5c042e6a9337d2b7e9b1b0836a6b31}
}

@Article{2009d,
  Title                    = {Data Warehousing and Knowledge Discovery - 11th International Conference, DaWaK 2009, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2009},
  Note                     = {cited By (since 1996)0},
  Volume                   = {5691 LNCS},

  Abstract                 = {The proceedings contain 37 papers. The topics discussed include: towards a modernization process for secure data warehouses; visual modelling of data warehousing flows with UML profiles; data stream prediction using incremental hidden Markov models; history guided low-cost change detection in streams; a joint design approach of partitioning and allocation in parallel data warehouses; non-derivable item set and non-derivable literal set representations of patterns admitting negation; a fast feature-based method to detect unusual patterns in multidimensional datasets; efficient online aggregates in dense-region-based data cube representations; exact and approximate sizes of convex datacubes; finding clothing that fit through cluster analysis and objective interestingness measures; ontology-based exchange and immediate application of business calculation definitions for online analytical processing; and mining high-correlation association rules for inferring gene regulation networks.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {490},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70349472972&partnerID=40&md5=e456a9bac2a91b4256b524d03bd64c80}
}

@Conference{2008,
  Title                    = {Proceedings - IEEE International Conference on Data Mining Workshops, ICDM Workshops 2008},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 119 papers. The topics discussed include: comparing accuracies of rule evaluation models to determine human criteria on evaluated rule sets; comparing reliability of association rules and OLAP statistical tests; wavelet-based data perturbation for simultaneous privacy-preserving and statistics-preserving; online reliability estimates for individual predictions in data streams; a study on the reliability of case-based reasoning systems; domain driven data mining (D3M); parameter tuning for differential mining of string patterns; behavior informatics and analytics: let behavior talk; one-class classification of text streams with concept drift; post-processing of discovered association rules using ontologies; discovering implicit redundancies in network communications for detecting inconsistent values; and actionable knowledge discovery for threats intelligence support using a multi-dimensional data mining methodology.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining Workshops, ICDM Workshops 2008},
  Owner                    = {Alexander},
  Page_count               = {1035},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-62449200466&partnerID=40&md5=4fbf9e5503c8e55acee9beb6793a7900}
}

@Conference{2008b,
  Title                    = {Proceedings - 5th International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2008},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Volume                   = {1},

  Abstract                 = {The proceedings contain 637 papers. The topics discussed include: a collaborative filtering algorithm based on rough set and fuzzy clustering; a new clustering analysis used for generating fuzzy control rules; a hybrid statistical language model applied to the domain specific information retrieval; a new approach to blog post summarization using fast features; an approach to handle overload in real-time data stream management system; fuzzy database languages integration using expressive power; a new approach for facial expression recognition based on Burial Markov model; a new image quality approach based on decision fusion; a ranking algorithm via changing Markov probability matrix based on distribution factor; dominance-based variable precision rough fuzzy approach in fuzzy information system; grey correlation analysis of corrosion on oil atmospheric distillation equipment; and mining positive and negative fuzzy sequential patterns in large transaction databases.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings - 5th International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2008},
  Owner                    = {Alexander},
  Page_count               = {678},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-58149116689&partnerID=40&md5=2f02c3eec211938294660f811bbe741f}
}

@Article{2008f,
  Title                    = {Foundations of Intelligent Systems: 17th International Symposium, ISMIS 2008, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2008},
  Note                     = {cited By (since 1996)0},
  Volume                   = {4994 LNAI},

  Abstract                 = {The proceedings contain 71 papers. The topics discussed include: from goals to high-variability software design; intelligent software engineering tools for NASA's crew exploration vehicle; boosting support vector machines for imbalanced data sets; class-oriented reduction of decision tree complexity; evaluating decision tress grown with asymmetric entropies; stepwise induction of logistic model trees; stochastic propositionalization for efficient multi-relational learning; analyzing behavior of objective rule evaluation indices based on Pearson product-moment correlation coefficient; obtaining low-arity discretizations from online data streams; maps ensemble for semi-supervised learning of large high dimensional datasets; and mining induced and embedded subtrees in ordered, unordered, and partially-ordered trees.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {659},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-44649139842&partnerID=40&md5=7683f291d4d3001c254a0c5ab95d5c43}
}

@Article{2007,
  Title                    = {Business Intelligence for the Real-Time Enterprises: First International Workshop, BIRTE 2006 Revised Selected Papers},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Volume                   = {4365 LNCS},

  Abstract                 = {The proceedings contain 12 papers. The topics discussed include: practical considerations for real-time business intelligence; what can hierarchies do for data streams?; leveraging distributed publish/subscribe systems for scalable stream query processing; transaction reordering and grouping for continuous data loading; a scalable heterogeneous solution for massive data collection and database loading; two-phase data warehouse optimized for data mining; document-centric OLAP in the schema-chaos world; business process learning for real time enterprises; an integrated approach to process-driven business performance monitoring and analysis for real-time enterprises; and quality contracts for real-time enterprises.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {165},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, collection of papers.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38149047522&partnerID=40&md5=bf3e551b866b5b4482c9056f9b721b9c}
}

@Article{2007a,
  Title                    = {Knowledge Discovery in Databases: PKDD 2007 - 11th European Conference on Principles and Practice of Knowledge Discovery in Databases, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Volume                   = {4702 LNAI},

  Abstract                 = {The proceedings contain 67 papers. The topics discussed include: learning, information extraction and the web; putting things in order: on the fundamental role of ranking in classification and probability estimation; mining queries; adventures in personalized information access; using the web to reduce data sparseness in pattern-based information extraction; a graphical model for content based image suggestion and feature selection; efficient AUC optimization for classification; classification of web document using a graph-based model and structural patterns; context-specific independence mixture modelling for protein families; an algorithm to find overlapping community structure in networks; privacy preserving market based data analysis; and feature extraction from sensor data streams for real-time human behaviour recognition.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {655},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38049105573&partnerID=40&md5=81a7a25b62c37d4b48b477b1528ebcfd}
}

@Conference{2007b,
  Title                    = {Genetic Programming: 10th European Conference, EuroGP 2007},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Volume                   = {4445 LNCS},

  Abstract                 = {The proceedings contain 35 papers. The topics discussed include: a grammatical genetic programming approach to modularity in genetic algorithms; confidence intervals for computational effort comparisons; crossover bias in genetic programming; density estimation with genetic programming for inverse problem solving; fast genetic programming on GPUs; genetic programming with fitness based on model checking; geometric particle swarm optimisation; mining distributed evolving data streams using fractal GP ensembles; on the limiting distribution of program sizes in tree-based genetic programming; predicting prime numbers using Cartesian genetic programming; real-time, non-intrusive evaluation of VoIP; analysing the regularity of genomes using compression and expression simplification; code regulation in open ended evolution; data mining of genetic programming run logs; evolving modular recursive sorting algorithms; and the induction of finite transducers using genetic programming.},
  Document_type            = {Conference Review},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Owner                    = {Alexander},
  Page_count               = {389},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34548107655&partnerID=40&md5=e833cbd54984a44f184ab9dd365c59fa}
}

@Article{2007c,
  Title                    = {Longwall innovations to debut},
  Journal                  = {Australian Mining},
  Year                     = {2007},
  Note                     = {cited By (since 1996)0},
  Number                   = {7},
  Pages                    = {116-117},
  Volume                   = {99},

  Abstract                 = {DBT will highlight its innovative new Compact Loader, which is making its world debut at AIMEX 2007. Other exhibits include the revolutionary Longwall Top Coal Caving (LTCC) roof support, the EL62, said to be the most powerful medium-seam ranging arm on the market, and automation products including PMC-R shield control and PMC-D drive control. The DBT booth will also feature live data transfer from an Australian mine. The DBT Compact Loader comes standard with a universal Rapid Attachment System RAS & QDS for rapid pickup and release of accessories. The LTCC shield on display allows mining to the total seam height of up to 8 m by using a longwall shearer to cut the bottom 2.8-3 m and then caving the top coal. The DBT booth will also feature a live data feed from several mines allowing visitors to visualise real time longwall extraction processes.},
  Document_type            = {Article},
  Owner                    = {Alexander},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded. Exhibition advertisement for a weapon.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34548361853&partnerID=40&md5=da81e84829ef45d9d11ab80c54a517d6}
}

@Article{2006,
  Title                    = {Knowledge Discovery in Databases: PKDD 2006 - 10th European Conference on Principles and Practice of Knowledge Discovery in Databases, Proceedings},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2006},
  Note                     = {cited By (since 1996)0},
  Volume                   = {4213 LNAI},

  Abstract                 = {The proceedings contain 67 papers. The topics discussed include: on temporal evolution in data streams; learning to have fun; winning the DARPA grand challenge; challenges of urban sensing; clustering scientific literature using sparse citation graph analysis; an adaptive prequential learning framework for Bayesian network classifiers; adaptive active classification of cell assay images; learning parameters in entity relationship graphs from ranking preferences; detecting fraudulent personalities in networks of online auctioneers; discovery of interesting regions in spatial data sets using supervised clustering; optimal string mining under frequency constraints; closed sets for labeled data; Web communities identification from random walks; information marginalization on subgraph; transductive learning for text classification using explicit knowledge models; and exploring multiple communities with kernel-based link analysis.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {676},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33750334170&partnerID=40&md5=502af540a111c45ae7afc0d44a581774}
}

@Conference{2006a,
  Title                    = {Proceedings of the 15th ACM Conference on Information and Knowledge Management, CIKM 2006},
  Year                     = {2006},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings 124 contain papers. The topics discussed include: the real-time nature and value of homeland security information; efficient processing of complex similarity queries in RDBMS through query rewriting; distributed spatio-temporal similarity search; structure-based querying of proteins using wavelets; an approximate multi-word matching algorithm for robust document retrieval; movie review mining and summarization; utility scoring of product reviews; mining blog stories using community-based and temporal clustering; investigating the exhaustivity dimension in content-oriented XML element retrieval evaluation; evaluation by comparing result sets in context; estimating average precision with incomplete and imperfect judgments; classification spanning correlated data streams; validating associations in biological databases; and mining compressed commodity workflows from massive RFID data sets.},
  Document_type            = {Conference Review},
  Journal                  = {International Conference on Information and Knowledge Management, Proceedings},
  Owner                    = {Alexander},
  Page_count               = {887},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, Proceedings.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-36649031470&partnerID=40&md5=9c5d5f2c70b355a70e17ff7a58a648e8}
}

@Conference{2005,
  Title                    = {Proceedings - 15th International Workshop on Research Issues in Data Engineering: Stream Data Mining and Applications, RIDE-SDMA 2005},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 10 papers from the 15th International Workshop on Research Issues in Data Engineering: Stream Data Mining and Applications, RIDE-SDMA 2005. The topics discussed include: an efficient algorithm for incremental mining of association rules; online mining (recently) maximal frequent itemsets over data streams; a clustering method using an irregular size cell graph; using probabilistic latent semantic analysis for web page grouping; maintaining knowledge-bases of navigational patterns from streams of navigational sequences; data mining approaches to software fault diagnosis; handling nominal features in anomaly intrusion detection problems; and time-decaying bloom filters for data streams with skewed distributions.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings of the IEEE International Workshop on Research Issues in Data Engineering},
  Owner                    = {Alexander},
  Page_count               = {94},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-27144487369&partnerID=40&md5=0d436d6b8a7c6c2a719ad78a34dce7c0}
}

@Conference{2005a,
  Title                    = {Intelligent Computing: Theory and Applications III},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Volume                   = {5803},

  Abstract                 = {The proceedings contain 19 papers from the conference on Intelligent Computing: Theory and Applications III. The topics discussed include: difference-similitude set theory; improved object optimal synthetic description, modeling, learning, and discrimination by GEOGINE computational kernel; evolutionary learning through replicator dynamics in continuous space games; genetic-program-based data mining for hybrid decision-theoretic algorithms and theories; rule mining and classification in the presence of feature level and class label ambiguities; intelligent instance selection of data streams for smart sensor applications; and highly efficient incremental estimation of Gaussian mixture models for online data stream clustering.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings of SPIE - The International Society for Optical Engineering},
  Owner                    = {Alexander},
  Page_count               = {187},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-27544495686&partnerID=40&md5=0fb17dfe8716730e2053f4ece365e496}
}

@Conference{2005b,
  Title                    = {Proceedings of the 2005 International Conference on Information and Knowledge Engineering, IKE'05},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 50 papers. The topics discussed include: the application of fuzzy logic in a hybrid fuzzy knowledge-based system for multiobjective optimization of power distribution system operations; mapping problem solving methods on domain knowledge: a case study on synthetic tasks; a novel short-term stock price predicting system; the execution of strategic information system planning in industrial potash plant; development of a benchmark system for analyzing collaborative group performance as part of an educational online knowledge management system; a systems-oriented approach to knowledge management as a tool for decision making; agent-based knowledge sharing mechanism for cooperative software process modeling; the design of an interactive approach to statistical data mining; software agents in bridge management; knowledge processing and modern communication systems; and adaptive clusters and histograms over data streams.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings of the 2005 International Conference on Information and Knowledge Engineering, IKE'05},
  Owner                    = {Alexander},
  Page_count               = {371},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864952777&partnerID=40&md5=5a32b8ce67841e41cf93ca29b51358a1}
}

@Article{2005c,
  Title                    = {Grid and Cooperative Computing - GCC 2005 - 4th International Conference, Proceeding},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},
  Volume                   = {3795 LNCS},

  Abstract                 = {The proceedings contain 143 papers. The topics discussed include: towards global collaborative computing: opportunities and challenges of peer to peer networks and applications; management of real-time streaming data grid services; A QoS-satisfied interdomain overlay multicast algorithm for live media service grid; automated immunization against denial-of-service attacks featuring stochastic packet inspection; mobile-agent-based Web service composition; SVM approach with CTNT to detect DDoS attacks in grid computing; model transformation based verification of Web services composition; a worn behavioral approach to susceptible host detection; a dynamic Web service selection strategy with QoS global optimization based on multi-objective genetic algorithm; and a formal model for grid service deployment in grid service mining based on installation strategies.},
  Document_type            = {Conference Review},
  Owner                    = {Alexander},
  Page_count               = {1211},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33646845668&partnerID=40&md5=53040fe0b51b4600ca0432c7767ee337}
}

@Conference{2005d,
  Title                    = {Proceedings of the 2005 SIAM International Conference on Data Mining, SDM 2005},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 79 papers. The topics discussed include: mining frequent itemsets from data streams with a time-sensitive sliding window; surveying data for patchy structure; 2-dimensional singular value decomposition for 2D maps and images; a random walks perspective on maximizing satisfaction and profit; summarizing and mining skewed data streams; online analysis of community evolution in data streams; privacy-aware market basket data set generation: a feasible approach for inverse frequent set mining; clustering with model-level constraints; on abnormality detection in spuriously populated data streams; on variable constraints in privacy preserving data mining; clustering with constraints: feasibility issues and the k-means algorithm; finding young stellar populations in elliptical galaxies from independent components of optical spectra; a cutting algorithm for the minimum sum-of-squared error clustering; and dynamic classification of defect structures in molecular dynamics simulation data.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings of the 2005 SIAM International Conference on Data Mining, SDM 2005},
  Owner                    = {Alexander},
  Page_count               = {647},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880113790&partnerID=40&md5=ad280460c35c5cd58984e74ceba75a85}
}

@Conference{2005e,
  Title                    = {Proceedings - 21st International Conference on Data Engineering, ICDE 2005},
  Year                     = {2005},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 119 papers from the 21st International Conference on Data Engineering, ICDE 2005. The topics discussed include: effective computation of biased quantiles over data streams; a unified framework for monitoring data streams in real time; adaptive caching for continuous queries; exploiting correlated attributes in acquisitional query processing; reverse nearest neighbors in large graphs; a framework for high-accuracy privacy-preserving mining; mining closed relational graphs with connectivity constraints; efficient algorithms for pattern matching on directed acyclic graphs; and on the optimal ordering of maps and selections under factorization.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings - International Conference on Data Engineering},
  Owner                    = {Alexander},
  Page_count               = {1173},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-28444487403&partnerID=40&md5=4707b08c8586c7a0edbd47e321fb1473}
}

@Conference{2002,
  Title                    = {Proceedings - 2002 IEEE International Conference on Data Mining, ICDM 2002},
  Year                     = {2002},
  Note                     = {cited By (since 1996)0},

  Abstract                 = {The proceedings contain 121 papers. The topics discussed include: empirical comparison of various reinforcement learning strategies for sequential targeted marketing; investigative profiling with computer forensic log data and association rules; text document categorization by term association; online algorithms for mining semi-structured data stream; a lazy approach to pruning classification rules; high performance data mining using the nearest neighbor join; mining molecular fragments: finding relevant substructures of molecules; mining general temporal association rules for items with different exhibition periods; learning with progressive transductive support vector machine; evolutionary time series segmentation for stock data mining; using functional PCA for cardiac motion exploration; speed-up iterative frequent itemset mining with constraint changes; a theory of inductive query answering; and cluster merging and splitting in hierarchical clustering algorithms.},
  Document_type            = {Conference Review},
  Journal                  = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  Owner                    = {Alexander},
  Page_count               = {779},
  Qualityassured           = {qualityAssured},
  Review                   = {Discarded, proceedings collection only.},
  Source                   = {Scopus},
  Timestamp                = {2014.10.15},
  Url                      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78149316133&partnerID=40&md5=27d890b29a9d8f2bd6341d418d57023e}
}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:ieeexplore\;0\;2011\;2013\;Abdulsalam2007\;Aggarwal200
8\;Agrawal2006\;AnakJoseph2014\;Angelov2011\;Anuradha2014\;Ari2012\;As
ai2002\;Ashani2009\;BRDWHYYSC2004\;Banerjee2013\;Barouni-Ebarhimi2007\
;Berndt2012\;Berry2013\;Bian2013\;Biem2013\;Bigelow2012\;Bilenko2005\;
Blount2010\;Bouchachia2014\;Brzezinski2014\;Budhaditya2009\;Bulut2005\
;CZPJJBCKZ2012\;Cabanes2013\;Campagna2011\;Campanile2007\;Canzian2014\
;Cao2010\;Chandrika2011\;Chang-peng2009\;Chao2011\;Chao2012\;Chauhan20
12\;Chen2008\;Chen2010\;Chen2011\;Chu2004\;Cohen2006\;Cook2013\;Coucei
ro2012\;DLL2005\;Daneshmand2011\;Dass2010\;Dilectin2012\;Dingping2013\
;Ditzler2011\;Dongre2014\;Ducasse2010\;Ediger2011\;Ediger2014\;Elfeky2
006\;Ericson2012\;Ezeife2007\;FLL2008\;Farid2012\;Feng2009\;Folino2007
\;Fong2013\;Foo2010\;Fortino2012\;Frias-Blanco2014\;GLTC2007\;Gaber201
0\;Gao2010\;Gao2010a\;Gaoshan2010\;Gedik2014\;Gillick2010\;Greensmith2
006\;Gu2008\;Gu2009\;Guo2009\;Gupta2009\;HFLHHSC2008\;HFLYL2004\;HFLYL
KS2004\;HFLYLKS2005\;HFLYLKS2005a\;HJWSL2009\;Haghighi2009\;Halkidi201
1\;Han2011\;Hang2010\;Hang2010a\;Harris2005\;Hart2007\;Hayes2013\;Heie
rman2003\;Horovitz2007\;Huijun2012\;Ikonomovska2011\;JDRL2008\;Jawad20
06\;Jea2011\;Kan2010\;Kanoun2014\;Karim2014\;Kasiviswanathan2013\;Kavi
tha2010\;Kavitha2012\;Kavitha2012a\;Keogh2003\;Khan2009\;Kholghi2010\;
Kranjc2013\;Kriminger2012\;Krishnaswamy2012\;Kumar2013\;Lahiri2009\;Le
ite2014\;Leite2014a\;Li-li2009\;Li2006\;Li2006a\;Li2006b\;Li2007\;Liao
2010\;Lin2006\;Lin2012\;Looks2007\;Lunteren2012\;Ma2011\;Mao2009\;Mao2
011\;Mardani2014\;Mauer2011\;Mingliang2009\;Mishin2012\;Mohamed2009\;M
ozafari2008\;Murakami2012\;Naeimi2013\;Namadchian2012\;Nassar2013\;Neo
phytou2011\;Ng2008\;Nguyen2011\;Niennattrakul2009\;Olmezogullari2013\;
Olmezogullari2013a\;Ouyang2008\;Ozkan2013\;Paliyawan2014\;Parker2013\;
Patil2012\;Phua2008\;Phung2007\;QHLZZ2005\;Qadeer2009\;Ratner2008\;Ren
2009\;Ren2010\;Rojas2009\;SQQZ2006\;Saravanan2013\;Satzger2011\;Shaeib
2010\;Shcherbakov2013\;Sherchan2012\;Shetty2011\;Simeone2012\;Simmonds
2014\;Slavakis2014\;Sow2010\;Tabatabaei2013\;Tan2009\;Tang2009\;Tang20
13\;Tekin2013\;Thakkar2008\;Thakkar2011\;Theeten2014\;Thommandram2013\
;Thommandram2014\;Tian2008\;Tian2009\;Tiwari2013\;Ueno2012\;Vachkov200
7\;Vallim2010\;Wan2008\;Wang2009\;Wang2011\;Wang2011a\;Wankhade2012\;W
ickramaarachchi2013\;Wu2009\;Wu2012\;XSWC2013\;Xiaojun2012\;YKLWJJKHR2
008\;YKYCA2007\;Yan2006\;Yan2012\;Yang2012\;YangHang2010\;YangHang2010
a\;Yogita2013\;Yu2005\;ZPLYWHSQ2008\;ZZW2009\;Zaslavsky2013\;Zhang2007
\;Zhang2010\;Zhang2010a\;Zhao2013\;Zhou2008\;Zhou2010\;Zhou2010a\;Zhu2
007\;Zhu2011\;Zliobaite2014\;Zou2013\;;
1 ExplicitGroup:sciencedirect\;0\;Agarwal2008\;Alzghoul2011\;Beringer2
006\;Budk2014\;Chang2006\;Chang2009\;Chen2012\;Cohen2008a\;Farzanyar20
13\;Gaber2013\;Gan2014\;Geisler2012\;Guo2011\;Hemalatha2013\;Hemalatha
2014\;Hill2013\;Hofleitner2012\;Kasabov2013\;Kavanaugh2012\;Khrouf2014
\;Kong2010\;Kranjc2014\;Krishna2010\;Lee2009\;Leite2013\;Li2006c\;Li20
09\;Li2009a\;Liu2009\;Montana2009\;PhridviRaj2014\;PhridviRaj2014a\;Re
eve2013\;Sancho-Asensio2014\;Shie2012\;Tasoulis2013\;Teng2003\;Tsai200
9\;Vallim2013\;Vallim2014\;Xiong2009\;Yang2013\;Zhang2009\;Zhu2014\;Zi
hayat2014\;;
1 ExplicitGroup:scopus\;0\;2002\;2005\;2005a\;2005b\;2005c\;2005d\;200
5e\;2006\;2006a\;2007\;2007a\;2007b\;2007c\;2008\;2008b\;2008f\;2009\;
2009a\;2009b\;2009c\;2009d\;2010\;2010a\;2010b\;2011a\;2011b\;2011c\;2
011d\;2011e\;2011f\;2011g\;2011h\;2011i\;2011j\;2012\;2013a\;2013b\;20
13c\;2013d\;2013e\;2013g\;2014\;2014a\;2014b\;Aboalsamh2009\;Agarwal20
07\;Agarwal2008a\;Aggarwal2009\;Aggarwal2012\;Aggarwal2014\;Aghabozorg
i2014\;Agrawal2009\;Agrawal2011\;Ahmadi2012\;Ahmed2008\;Ahmed2011a\;Ah
n2013\;Akhouri2013\;Almeida2013\;Amatriain2013\;Anagnostopoulos2013\;A
ngelov2010\;Angelov2011a\;Anuradha2014a\;Ao2009\;Ao2009a\;Asai2002a\;A
sai2007\;Attar2012\;Aƒa€“lmezoA‡A§ullari2013\;BAƒA¶se2010\;Banerjee201
3a\;Barouni-Ebarhimi2007a\;Barouni-Ebrahimi2008\;Beringer2007\;Beringe
r2007a\;Berndt2012a\;Berry2013a\;Bhargavi2012\;Bhatnagar2005\;Bifet200
9\;Bifet2011\;Bifet2011a\;Bifet2011b\;Bifet2013\;Bilenko2005a\;Blount2
010a\;BranisavljeviA„a€¡2010\;Brink2013\;Bulut2005a\;Cabanes2013a\;Cal
ders2012\;Campagna2011a\;Cao2012\;Carley2005\;Carmona-Cejudo2011\;Carm
ona2012\;Cesario2014\;Chandrika2011a\;Chang2003\;Chang2003a\;Chang2004
\;Chang2005\;Chang2005a\;Chang2005b\;Chang2006c\;Chang2013\;Chang2013a
\;Chao2011a\;Chao2012a\;Chauhan2012a\;Chen2006\;Chen2007\;Chen2009\;Ch
en2009a\;Chen2009b\;Chen2010a\;Chen2011a\;Chen2011b\;Chen2011c\;Chen20
14a\;Cheng2008\;Cheng2010\;Cheng2013a\;Chok2009\;Choudhury2011\;Choudh
ury2013\;Chu2004a\;Cohen2008b\;Cook2013a\;Costa2010\;Costa2011\;Coucei
ro2012a\;Cunha2013\;Czarnowski2014\;Dai2004\;Dam2007\;Dang2006\;Dang20
07\;Dang2008\;Dass2010a\;DeFrancisciMorales2013\;Dilectin2012a\;Ding20
13\;Ditzler2011a\;Du2007\;Ediger2011a\;Ediger2014a\;Elfeky2004\;Elfeky
2006a\;Elgamal2005\;Engel2009\;Erhan2010\;Ezeife2007a\;Farid2012a\;Far
id2013a\;Feng2005\;Feng2009a\;Ferrer-Troyano2005\;Ferrer-Troyano2005a\
;Finlay2014a\;Fischer2012\;Fong2011\;Fong2013a\;Fong2013b\;Fortino2012
a\;Gaber2006\;Gaber2007\;Gaber2010a\;Gaber2010b\;Gaber2012\;GagneII200
9\;Gama2003\;Gama2006\;Gama2007\;Gan2012\;Gao2010b\;Gao2010c\;Garg2010
\;Gedik2014a\;Geisler2010\;Georgiadis2013\;Gillick2006\;Gillick2010a\;
Golab2011\;Gondal2013\;Greensmith2006a\;Gu2008a\;Gu2009a\;Guo2011a\;Gu
pta2010\;Gupta2012\;Gupta2012a\;Haghighat2013\;Haghighi2009a\;Haghighi
2010\;Haghighi2013\;Han2011a\;Hang2010b\;Hang2010c\;Hang2010d\;Hang201
0e\;Hao2014\;Hassani2012\;Hassani2013\;Hawwash2010\;He2005\;HeiermanII
I2003\;Ho2008\;Hofgesang2009\;Horovitz2005\;Horovitz2007\;Huang2005\;H
uang2009\;Huang2011\;Huang2014\;Hunter2007\;Ikonomovska2011a\;Ikonomov
ska2011b\;Ishida2008\;Jawad2006a\;Jea2011a\;Jiang2006\;Jiang2011\;Jona
s2006\;Kan2010a\;Kandogan2014\;Karacal2006\;Karacal2009\;Kargupta2004\
;Karim2014a\;Kavitha2010a\;Kavitha2012b\;Kavitha2012c\;Keogh2003a\;Kha
lilian2013\;Khan2009a\;Kholghi2010a\;Khrouf2014a\;Kim2012\;Kim2012a\;K
im2012b\;Kiselev2009\;Kloeckl2012\;Kong2009\;KoprowskiJr.2002\;Korn200
6\;Kosina2012\;Kranen2012\;Kranjc2013a\;Kranjc2014a\;Kriminger2012a\;K
rishnaswamy2012a\;Kumar2013a\;Lahiri2009a\;Laleh2010\;Last2007\;Latif2
014\;Lee2005\;Lee2007\;Leite2012\;Li2004\;Li2004a\;Li2005\;Li2005a\;Li
2005b\;Li2005c\;Li2006e\;Li2006f\;Li2007a\;Li2007b\;Li2008\;Li2008a\;L
i2008b\;Li2008c\;Li2009b\;Li2010\;Li2011\;Li2011a\;Li2012\;Li2012a\;Li
2012b\;Li2012c\;Li2013\;Li2014\;Li2014a\;Liang2007\;Liao2010a\;Lin2003
\;Lin2003a\;Lin2006a\;Liu2003\;Liu2004\;Liu2005\;Liu2005a\;Liu2007\;Li
u2008\;Liu2008a\;Liu2008b\;Liu2009b\;Liu2010\;Liu2011\;Liu2013\;Liu201
4\;Looks2007a\;Loperfido2007\;Lunteren2012a\;Ma2011a\;Madia2014\;Magdy
2010\;Manohar2013\;Mao2007\;Mao2009a\;Mao2011a\;Mao2011b\;Mao2013\;Mar
dani2014a\;Marrs2011\;Marrs2012\;Mauer2011a\;Mavani2013\;Meng2006\;Mia
o2010\;Michael2009\;MillAƒA¡n-Giraldo2008\;Mimran2014\;Mingliang2009a\
;Miotto2011\;Mohamed2009a\;Mora2011\;Morinaga2004\;Mousavi2013\;Mozafa
ri2008a\;Mueller2006\;Murakami2012a\;Nakasumi2005\;Namadchian2012a\;Na
ssar2013a\;Nelson2013\;Neophytou2011a\;Ng2008a\;Ng2008b\;Ng2011\;Nguye
n-Tuong2011\;Nguyen2011a\;Ni2010\;Nishida2005\;Oberwinkler2004\;Oberwi
nkler2005\;Ogras2006\;Olmezogullari2013b\;Orriols-Puig2011\;Ouyang2008
a\;Ozkan2013a\;Paliyawan2014a\;Park2013\;Parker2013a\;Patil2012a\;Pati
l2012b\;Peng2012\;Percival2014\;Pham2013\;PhridviRaj2013\;PhridviRaj20
14b\;Phua2008a\;Plimpton2014a\;Pramod2012\;Presti2014\;Qadeer2009a\;Qi
n2006\;Rakthanmanon2012\;Rakthanmanon2013\;Ramachandran2006\;RasheedaS
hameem2013\;Rashid2013\;Rassi2008\;Ratner2008a\;Rautio2009\;Rehman2012
\;Ren2008\;Ren2008a\;Ren2009a\;Ren2011\;Ren2011a\;Ren2011b\;Roach2006\
;Rojas2009a\;Rusitschka2013\;Saravanan2013a\;Satzger2011a\;Sayed2014\;
Schwaighofer2009\;Seemann2013\;Shahparast2014\;Shcherbakov2013a\;Sherc
han2012a\;Shie2010\;Shin2014a\;Silva2013\;Simeone2012a\;Song2004\;Song
2009\;Sow2010a\;Sow2010b\;Sow2010c\;Stacey2007a\;Stahl2012\;Su2008\;Su
snjak2012\;Tabatabaei2013a\;Tan2009a\;Tan2013\;Tanbeer2010\;Tang2006\;
Tang2012\;Tao2009\;Tao2010\;Tapson2013a\;Tasoulis2011a\;Tasoulis2011b\
;Tekin2013a\;Thakkar2008a\;Thakkar2008b\;Thakkar2009\;Thakkar2011a\;Th
am2007\;Thommandram2013a\;Tian2008a\;Tian2009a\;Tiwari2013a\;Ueno2012a
\;Vachkov2007a\;Vallim2011\;Vallim2013a\;Vaziri2014\;Vestrand2002\;Ves
trand2004\;Vijayakumar2006\;Vijayakumar2010\;Vivekanandan2011\;Vosecky
2013\;Vyas2011\;Walton2005\;Wan2008a\;Wang2005\;Wang2005a\;Wang2006\;W
ang2006a\;Wang2006b\;Wang2009a\;Wang2010\;Wang2010a\;Wang2011b\;Wang20
11c\;Wang2011d\;Wang2012\;Wang2012a\;Wang2012b\;Wang2013\;Wang2013a\;W
ang2014\;Wankhade2012a\;Wojnarski2008\;Woo2009\;Wozniak2002\;Wu2009a\;
Wu2012a\;Wu2013\;Xie2008\;Xie2013\;Xu2010\;Xu2013\;Yan2006a\;Yan2012a\
;Yang2004\;Yang2006\;Yang2009\;Yang2010\;Yang2011\;Yang2011a\;Yang2011
b\;Yang2012a\;Yang2012b\;Yang2012c\;Yang2013a\;Yang2013c\;Ye2013\;Yeon
2010\;Yin2012\;Yogita2013a\;Yu2012\;Yu2012a\;Yu2014\;Yun2014a\;Zaslavs
ky2013a\;Zhan2012\;Zhang2007a\;Zhang2009b\;Zhang2010b\;Zhang2010c\;Zha
ng2012\;Zhang2013\;Zhang2014\;Zhao2013a\;Zhao2013b\;Zhao2014a\;Zhi2007
\;Zhi2007a\;Zhishui2011\;Zhong2005a\;Zhou2008a\;Zhou2008b\;Zhou2010b\;
Zhou2010c\;Zhou2012\;Zhou2012a\;Zhu2007a\;Zhu2011a\;Zhu2012\;Zou2008\;
Zou2013a\;;
1 ExplicitGroup:acmdl\;0\;Aggarwal2014a\;Agrawal2011a\;Ahn2013a\;Almei
da2013a\;Amatriain2013a\;Bifet2009a\;Bifet2011c\;Bjering2010\;Blount20
10b\;Boese2010\;Chang2003b\;Chang2003c\;Chen2002\;Chen2011d\;Cheng2013
b\;Chok2009a\;Chok2009b\;Choudhury2013a\;Chrupala2012\;ConferenceChair
-Chandola2011\;ConferenceChair-Das2012\;Dang2007a\;DeFrancisciMorales2
013a\;Demers2005\;Ferrer-Troyano2005b\;Ferrer-Troyano2006\;Fischer2012
a\;Franklin2010\;Gaber2004\;Gaber2010c\;Gama2003a\;Garg2010a\;Geisler2
010a\;GeneralChair-Song2007\;Georgiadis2013a\;Guo2011b\;Hawkins2013\;H
o2008a\;Jiang2006a\;Jonas2006a\;Kim2012c\;Kim2012d\;Korn2006a\;Kosina2
012a\;Kranen2011\;Krempl2014\;Kumar2013b\;Lee2008\;Li2005d\;Li2006g\;L
i2012d\;Li2012e\;Li2014b\;Liu2003a\;Liu2009c\;Luan2014\;Melville2013\;
Morinaga2004a\;Mousavi2013a\;Nath2008\;Nath2009\;Ogras2005\;Pandey2004
\;PhridviRaj2013a\;Pramod2012a\;ProgramChair-Fan2012\;ProgramChair-Fan
2013\;Rakthanmanon2012a\;Rashid2013a\;Robinson2012\;Rusitschka2013a\;S
chwaighofer2009a\;Shie2010a\;Silva2013a\;Tao2009a\;Teng2003a\;Thakkar2
008c\;Vatsavai2008\;Vijayakumar2006a\;Wang2006c\;Xie2013a\;Yang2009a\;
Yang2010a\;Yang2011c\;Yang2013d\;Yang2013e\;Zhang2014a\;;
1 ExplicitGroup:citeseerx\;0\;2003\;A\;Aarthi\;Abakumov\;Abbass2004\;A
garwal\;Aggarwal\;Aggarwal2008a\;Aggarwala\;Aggarwalb\;Aggarwalc\;Alsu
mait2008\;An\;Asai2002b\;Authors\;Authors2009\;Authorsa\;Authorsb\;Aut
horsc\;Authorsd\;Authorse\;Authorsf\;Authorsg\;Authorsh\;Authorsi\;Bab
cock2003\;Barlet-Ros2007\;Becker2007\;Beringer\;Beringer2005\;Bifet\;B
ifet2012\;Bifeta\;Bifetb\;Bifetc\;Bigelow\;Bilenko2005b\;Boese\;Bronni
mann2004\;Brzezinski\;Bulut\;Bulut2003\;Bulut2004\;Buluta\;Cai\;Calder
s2013\;Campagna\;Cao\;Cardei2000\;Carmona\;Carmona-cejudo\;Castillo\;C
eci\;Chandrasekaran2004\;Chauhan\;Chen\;Chen2001\;Chen2002a\;Chen2002b
\;Chen2006a\;Chena\;Cheng\;Ciampi\;Clifton\;Cohen2004\;Conjunction2009
\;Cook\;Da\;Dam\;Dang\;David\;De\;Deng\;DiYang\;DiYangWpi\;DiYanga\;Di
Yangb\;DiYangc\;Ding\;Ditzler2011b\;Ediger\;Elfeky2004a\;Erhan2010a\;F
errera€“troyano\;Gaber\;Gaber2004a\;Galagate\;Gama2003b\;Gama2005\;Gar
nett\;Georgiadis\;Golab\;Gu2009b\;Guha2005\;Haghighi\;Han\;Han2005\;Ha
ng\;Hazan\;He\;Heierman2004\;Hicks\;Hill2007\;Hinneburg\;Ho\;Hossain\;
Hyuk\;Ikonomovska\;In\;Islam2005\;Islam2005a\;Jain\;Jiang\;Jiang2007\;
Jose\;Karacal\;Kautz\;Keogh2003b\;Kharazmi2000\;Kleinberg2006\;Kong\;K
otov\;Kumar\;Lambert2001\;Last\;Leontyev\;Li\;Li2004b\;Li2004c\;Li2006
h\;Lia\;Lian2008\;Liao\;Lin\;Lin2003b\;Lin2006b\;Ling\;Liu\;Loo2005\;M
ahabal\;Mahmood\;Mala\;Malini\;Mao\;Maoa\;Mazur\;Mckelvey\;Melville201
1\;Meng\;Morinaga\;Mousavi\;Mozafari2007\;Mukherjee\;Nabil\;Nath\;Nath
a\;Neophytou\;Neumeyer2010\;Nguyen2004\;Noack\;Nunez2007\;Ordonez2003\
;Panigrahi\;Parita\;Park\;Perrochon1999\;Pfleger2004\;Qin\;Qin2005\;Qu
an2011\;Rakthanmanon2012b\;Rangaswami\;Reddy\;Repoff\;S\;Satzger\;Schw
eller\;Schweller2004\;Schwellera\;Schwellerb\;Shaik\;Silveira\;Singh\;
Soundararaj\;Sridevi\;Sukhov2004\;Sun\;Tao\;Taoa\;Teng2003b\;Thakkar\;
Thakkar2008d\;Thakkara\;Thombre\;Thuraisingham\;Tiwari\;Veloso2003\;Vi
jayakumar2006b\;Vinceslas\;Wakchaure\;Wang\;Wojnarski\;Wojnarskia\;Xi\
;Xie2010\;Xu\;Xua\;Yamanishi2002\;Yan2006b\;Yang\;Zaniolo\;Zhang\;Zhan
g2009c\;Zhanga\;Zhou\;Zhu2004\;Zliobaite\;;
}

